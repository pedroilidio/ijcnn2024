active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            0MzMzMzMBECYmZmZmZkRwGBmZmZmZva/aGZmZmZmEkBgZmZmZmb2vw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJv8CZmZmZmek/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcDMzMzMzMwcwNDMzMzMzPw/aGZmZmZmDkBoZmZmZmYOQA==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/QzMzMzMz8P9DMzMzMzPw/0MzMzMzM/D/MzMzMzMwcwA==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJP4CZmZmZmem/AJqZmZmZyT8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z8wMzMzMzMDwICZmZmZmdm/oJmZmZmZ+T9AMzMzMzPjPw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzG0DMzMzMzMwYwGhmZmZmZg5AmJmZmZmZAcCYmZmZmZkBwA==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcAwMzMzMzPzvzAzMzMzM/O/0MzMzMzM/D9oZmZmZmYGQA==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0BkZmZmZmYawDgzMzMzMwNAcGZmZmZm9j8gMzMzMzPjvw==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzA0AgMzMzMzPjvyAzMzMzM+O/ZGZmZmZmEsA4MzMzMzMLQA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGEAAAAAAAAAUwAAAAAAAAABAAAAAAAAAEEAAAAAAAAAcwA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8L8AAAAAAADwPw==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8BAMzMzMzPjPzAzMzMzMwPAYGZmZmZm9r9oZmZmZmYWQA==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0BkZmZmZmYawJCZmZmZmfm/kJmZmZmZ+b+cmZmZmZkZQA==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0DAmZmZmZnZP2RmZmZmZhrAnJmZmZmZGUDIzMzMzMwMwA==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAAwAAAAAAAABBAAAAAAAAAEMAAAAAAAAAUQA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAcwAAAAAAAAABAAAAAAAAAHEAAAAAAAAAAAA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzE0CAmZmZmZnJv9DMzMzMzPw/aGZmZmZmDkBmZmZmZmYkwA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmIECYmZmZmZkrwKCZmZmZmQFAQDMzMzMz8z+gmZmZmZkBQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz478gMzMzMzPjvzgzMzMzMwtAyMzMzMzMBMDAmZmZmZnZPw==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC0BoZmZmZmYWwICZmZmZmdk/MDMzMzMzC0CgmZmZmZn5vw==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzM/L9kZmZmZmYOwJyZmZmZmQlAnJmZmZmZAUDAmZmZmZnJPw==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAswAAAAAAAACJAAAAAAAAACEAAAAAAAADwPw==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcDgzMzMzMz8P8CZmZmZmek/IDMzMzMz87/AmZmZmZnpPw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0BmZmZmZmYSwGhmZmZmZvY/MDMzMzMz47+gmZmZmZnZPw==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAAABAAAAAAAAACMAAAAAAAADwPw==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMDECYmZmZmZkVwGhmZmZmZhpAgJmZmZmZ2b+YmZmZmZkRwA==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAHEAAAAAAAAAYwAAAAAAAABTAAAAAAAAAFEAAAAAAAADwvw==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAIwAAAAAAAAPA/AAAAAAAA8D8AAAAAAADwvw==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8BAMzMzMzPjP9DMzMzMzARAoJmZmZmZ+T8wMzMzMzMDwA==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBsDAzMzMzMz8vwCamZmZmck/YGZmZmZmDsBoZmZmZmYgQA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkCYmZmZmZkBwKCZmZmZmek/0MzMzMzM/D+YmZmZmZkJwA==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMEEAwMzMzMzMXwKCZmZmZmQlAYGZmZmZmBsBAMzMzMzPzPw==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAUwAAAAAAAAABAAAAAAAAACEAAAAAAAADwvw==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz879kZmZmZmYkwDgzMzMzMxtAODMzMzMzF0AgMzMzMzPzvw==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGEAAAAAAAAAcwAAAAAAAAADAAAAAAAAA8L8AAAAAAAAQQA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAADwPwAAAAAAAPA/AAAAAAAACEAAAAAAAADwvw==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j8zMzMzMzMhwDQzMzMzMwtAmpmZmZmZGUDMzMzMzMwEwA==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T+AmZmZmZnZv2BmZmZmZva/gJmZmZmZ2b9AMzMzMzPjPw==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZm9r+cmZmZmZn5P5yZmZmZmfk/ODMzMzMz4z8yMzMzMzMDwA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zszMzMzMEEAyMzMzMzMXwJyZmZmZmQFAkJmZmZmZ6b/AmZmZmZnJPw==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAAAAAAAAAAAPA/AAAAAAAAAAAAAAAAAAAIwA==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz479mZmZmZmYSwKCZmZmZmdk/NDMzMzMzA0A0MzMzMzMDQA==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMCYmZmZmZn5v5qZmZmZmRlAoJmZmZmZ2T+YmZmZmZn5vw==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMz8z9mZmZmZmYGwJqZmZmZmQFAmJmZmZmZ6b+gmZmZmZnJPw==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUCgmZmZmZkJQGBmZmZmZgbAMDMzMzMzE8BAMzMzMzPzPw==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmEkAwMzMzMzMLwNDMzMzMzARAoJmZmZmZ+T+YmZmZmZkVwA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZEUCgmZmZmZnZPzAzMzMzM+O/MDMzMzMz47/MzMzMzMwMwA==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9AMzMzMzPjP0AzMzMzM+M/gJmZmZmZ2b9AMzMzMzPjPw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb/gzMzMzMz8P+DMzMzMzPw/AJmZmZmZyb+QmZmZmZkJwA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+YmZmZmZkJwGhmZmZmZgZAoJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+YmZmZmZkBwGhmZmZmZg5AmJmZmZmZCcDQzMzMzMz8Pw==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGMAAAAAAAADwvwAAAAAAAAhAAAAAAAAAEEAAAAAAAAAAAA==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAYwAAAAAAAAPA/AAAAAAAA8D8AAAAAAAAIQA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ6T+AmZmZmZnpP4CZmZmZmek/wMzMzMzM/D/QzMzMzMwQwA==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkA0MzMzMzMTQMzMzMzMzBjAzMzMzMzMHMA0MzMzMzMTQA==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0BmZmZmZmYWwJiZmZmZmfm/aGZmZmZm9j80MzMzMzMDQA==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/MzMzMzMwUwGhmZmZmZg5AoJmZmZmZ6T8wMzMzMzPzvw==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T8wMzMzMzPzv6CZmZmZmek/0MzMzMzM/D+YmZmZmZkBwA==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAIwAAAAAAAAPC/AAAAAAAA8D8AAAAAAAAUQA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyT80MzMzMzMbwKCZmZmZmem/zMzMzMzMEECYmZmZmZkJQA==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZyT+gmZmZmZnJP5qZmZmZmQlAZmZmZmZmDsCgmZmZmZnJPw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAADwPwAAAAAAABxAAAAAAAAA8L8AAAAAAAAQwA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAUwAAAAAAAABTAAAAAAAAAAAAAAAAAAAAYQA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAUwAAAAAAAAAAAAAAAAAAAFEAAAAAAAAAQwA==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAQwAAAAAAAAABAAAAAAAAA8L8AAAAAAADwvw==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZm9j+QmZmZmZn5vzgzMzMzMwtAnJmZmZmZEUBkZmZmZmYewA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMFEAwMzMzMzMbwICZmZmZmem/AJqZmZmZyT+gmZmZmZkBQA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z8wMzMzMzMDwKCZmZmZmfk/0MzMzMzMDEAwMzMzMzMLwA==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMEMAgMzMzMzPzv3BmZmZmZgZA4MzMzMzM/D/AmZmZmZnpPw==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAADwvwAAAAAAAABAAAAAAAAAAAAAAAAAAADwvw==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMDMBoZmZmZmYSwDAzMzMzMwtAYGZmZmZm9j8wMzMzMzMLQA==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+YmZmZmZkVwGhmZmZmZhZA0MzMzMzMBEAwMzMzMzMDwA==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmGsDAzMzMzMwEwEAzMzMzMwNAoJmZmZmZGUAAmpmZmZnZPw==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz878wMzMzMzPzv4CZmZmZmcm/gJmZmZmZyb9oZmZmZmYGQA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkDMzMzMzMwQwNDMzMzMzPw/aGZmZmZmDkDMzMzMzMwQwA==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJiZmZmZyb9gZmZmZmYmwKCZmZmZmSVAgGZmZmZmBkCAmZmZmZkBwA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBEBgZmZmZmb2v4CZmZmZmdm/mJmZmZmZFcBoZmZmZmYSQA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT+YmZmZmZkhwGhmZmZmZiBAMDMzMzMzF8DQzMzMzMwYQA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAAwAAAAAAAAPA/AAAAAAAAAMAAAAAAAAAAwA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMBMA4MzMzMzMDQJyZmZmZmR1AZGZmZmZmFsCQmZmZmZn5vw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcAwMzMzMzPzv6CZmZmZmek/0MzMzMzM/D/QzMzMzMz8Pw==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r8wMzMzMzMDwKCZmZmZmfk/QDMzMzMz4z+gmZmZmZn5Pw==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMEEDAzMzMzMz8vzAzMzMzMxPA0MzMzMzMGEBgZmZmZmYOwA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz479mZmZmZmYawDAzMzMzM+O/aGZmZmZm9j+amZmZmZkZQA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2b+gmZmZmZnZv2hmZmZmZva/zMzMzMzMBECgmZmZmZnZvw==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ6b/QzMzMzMwUQGBmZmZmZg7AgJmZmZmZ6b8AmpmZmZnJPw==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zszMzMzMGEBkZmZmZmYOwJyZmZmZmQlAODMzMzMz8z8yMzMzMzMbwA==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+YmZmZmZkJwKCZmZmZmek/oJmZmZmZ6T+gmZmZmZnpPw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zszMzMzMBEA4MzMzMzPjPzgzMzMzM+M/kJmZmZmZ2b8yMzMzMzMLwA==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwEwDAzMzMzM+O/mpmZmZmZEUCYmZmZmZn5vw==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAUwAAAAAAAAAAAAAAAAAAAFEAAAAAAAAAIQA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAIwAAAAAAAAAjAAAAAAAAAHEAAAAAAAAAIQA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAIwAAAAAAAAAAAAAAAAAAAAMAAAAAAAAAIQA==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+YmZmZmZn5v2ZmZmZmZhLAmpmZmZmZFUA0MzMzMzMDQA==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+gmZmZmZnZP5qZmZmZmRlAzMzMzMzMDMDMzMzMzMwEwA==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0BoZmZmZmb2P2ZmZmZmZhbAaGZmZmZm9j+gmZmZmZnZPw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsA0MzMzMzMDQKCZmZmZmdk/NDMzMzMzA0AwMzMzMzPjvw==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAQwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwEwGhmZmZmZvY/oJmZmZmZ2T+gmZmZmZnZPw==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzM/L+gmZmZmZnJP5qZmZmZmQFAoJmZmZmZyT+YmZmZmZnpvw==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAQAAAAAAAAPC/AAAAAAAAAEAAAAAAAAAQwA==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          QDMzMzMzC0AwMzMzMzMnwEAzMzMzMwtAQDMzMzMzA0BAMzMzMzMDQA==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-30 21:21:23.752403
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder
  final_params:
    final_estimator:
      call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
      params:
        estimator:
          call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
          params:
            estimators:
            - - rf
              - call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: sqrt
                  max_leaf_nodes: null
                  max_samples: 0.5
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 5
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  monotonic_cst: null
                  n_estimators: 150
                  n_jobs: 14
                  oob_score: true
                  random_state: 0
                  verbose: true
                  warm_start: false
            - - xt
              - call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: sqrt
                  max_leaf_nodes: null
                  max_samples: 0.5
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 5
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  monotonic_cst: null
                  n_estimators: 150
                  n_jobs: 14
                  oob_score: true
                  random_state: 0
                  verbose: true
                  warm_start: false
    keep_original_features: true
    level:
      call: deep_forest.cascade.SequentialLevel
      params:
        last_level: null
        memory: null
        steps:
        - - alternating_forests
          - call: deep_forest.cascade.AlternatingLevel
            params:
              last_level: null
              n_jobs: null
              sparse_threshold: 0.3
              transformer_weights: null
              transformers:
              - - xt_embedder
                - call: sklearn.pipeline.Pipeline
                  params:
                    memory: null
                    steps:
                    - - xt
                      - call: deep_forest.tree_embedder.ForestEmbedder
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                          max_node_size: 0.8
                          max_pvalue: 1.0
                          method: path
                          node_weights: log_node_size
                    - - densifier
                      - call: nakano_datasets_v2.estimators.Densifier
                        params: {}
                    - - pca
                      - call: sklearn.decomposition._pca.PCA
                        params:
                          copy: true
                          iterated_power: auto
                          n_components: 0.8
                          n_oversamples: 10
                          power_iteration_normalizer: auto
                          random_state: 0
                          svd_solver: auto
                          tol: 0.0
                          whiten: false
                    verbose: false
              - - rf_embedder
                - call: sklearn.pipeline.Pipeline
                  params:
                    memory: null
                    steps:
                    - - rf
                      - call: deep_forest.tree_embedder.ForestEmbedder
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                          max_node_size: 0.95
                          max_pvalue: 1.0
                          method: path
                          node_weights: log_node_size
                    - - densifier
                      - call: nakano_datasets_v2.estimators.Densifier
                        params: {}
                    - - pca
                      - call: sklearn.decomposition._pca.PCA
                        params:
                          copy: true
                          iterated_power: auto
                          n_components: 0.8
                          n_oversamples: 10
                          power_iteration_normalizer: auto
                          random_state: 0
                          svd_solver: auto
                          tol: 0.0
                          whiten: false
                    verbose: false
              verbose: false
              verbose_feature_names_out: true
        - - label_imputer
          - call: deep_forest.weak_labels.LabelComplementImputer
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
              label_freq_percentile: 0.5
              last_level: null
              threshold: 0.5
              verbose: true
              weight_proba: true
        verbose: false
    max_levels: 10
    memory: null
    verbose: 10
    warm_start: false
  name: cascade_lc_tree_embedder
  params: {}
hash: b63f6d4ec52d8523e70e615d5e4cc9c0b4ae483517e662c39db0c2f477d0ab5f
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/b63f6d4_20231230T211653819680_cascade_lc_tree_embedder_CAL500.yml
results:
  fit_time:
  - 259.7513852119446
  - 251.34772968292236
  - 255.25897192955017
  - 261.36137223243713
  - 256.5514850616455
  fitted_params:
    level1.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 201
    - 194
    - 204
    - 203
    - 202
    level1.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 200
    - 192
    - 201
    - 201
    - 199
    level1.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level10.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 211
    - 208
    - 213
    - 216
    - 212
    level10.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 229
    - 221
    - 231
    - 231
    - 230
    level10.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level2.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 210
    - 208
    - 212
    - 214
    - 209
    level2.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 228
    - 220
    - 230
    - 228
    - 228
    level2.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level3.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 212
    - 210
    - 215
    - 216
    - 211
    level3.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 230
    - 222
    - 231
    - 231
    - 228
    level3.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level4.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 211
    - 210
    - 215
    - 217
    - 211
    level4.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 231
    - 223
    - 232
    - 230
    - 230
    level4.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level5.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 211
    - 208
    - 215
    - 216
    - 212
    level5.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 230
    - 223
    - 232
    - 232
    - 229
    level5.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level6.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 208
    - 209
    - 215
    - 217
    - 212
    level6.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 228
    - 223
    - 232
    - 230
    - 229
    level6.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level7.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 210
    - 206
    - 213
    - 217
    - 212
    level7.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 228
    - 223
    - 231
    - 230
    - 230
    level7.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level8.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 210
    - 207
    - 213
    - 216
    - 212
    level8.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 228
    - 222
    - 231
    - 231
    - 229
    level8.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
    level9.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 208
    - 207
    - 213
    - 216
    - 212
    level9.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 229
    - 223
    - 231
    - 231
    - 228
    level9.label_imputer.label_frequency_estimates_:
    - - 0.1142074081729254
      - 0.6329265264214243
      - 0.31149949587449577
      - 0.2203271290113395
      - 0.5824584465713498
      - 0.3108309884559884
      - 0.3393152854090354
      - 0.21168392451599283
      - 0.310743058111479
      - 0.22092075581800447
      - 0.373193356351251
      - 0.31293688179296597
      - 0.14038996775188634
      - 0.2505836062086062
      - 0.31034234997216736
      - 0.2612669944294791
      - 0.2628021097237624
      - 0.2387147556646778
      - 0.36023924361690307
      - 0.17615728498081434
      - 0.3819103698929066
      - 0.14726097609760969
      - 0.46605995393495403
      - 0.3723289630266374
      - 0.1494907028997938
      - 0.23416729012080054
      - 0.2502587233429986
      - 0.3342588653176888
      - 0.13684518606627064
      - 0.10938614154860013
      - 0.4290227057330552
      - 0.22871772825462192
      - 0.43398446582657113
      - 0.16087832849881045
      - 0.4448547507223096
      - 0.21160869418843894
      - 0.16685172782486118
      - 0.06671975246975247
      - 0.10372934482797391
      - 0.0648926998926999
      - 0.12575693246945618
      - 0.07034631309176648
      - 0.06228980185098101
      - 0.13114790964963888
      - 0.06881961245270887
      - 0.27755838657193577
      - 0.12446787745083202
      - 0.07145765913055707
      - 0.29905876068376064
      - 0.320947270814292
      - 0.08849118936618934
      - 0.547513294953689
      - 0.2450043525944854
      - 0.11562535600364549
      - 0.1802913721319793
      - 0.6715182228973808
      - 0.17665853716990082
      - 0.07603224553224554
      - 0.08449156703729874
      - 0.2034821588029107
      - 0.32753618835549875
      - 0.15998305615952674
      - 0.0653081994837314
      - 0.39246614589064777
      - 0.2867126190759611
      - 0.2959640878956884
      - 0.2762474076437962
      - 0.22665738544221514
      - 0.48024548271944106
      - 0.19666941585546227
      - 0.31500392144331535
      - 0.11255964056480057
      - 0.3331526619033057
      - 0.15388391772286725
      - 0.550498938891796
      - 0.1636416009285327
      - 0.20479057178216675
      - 0.8772066643034381
      - 0.5623479209915381
      - 0.6498079140062833
      - 0.3379619130869129
      - 0.17297971539042967
      - 0.07804059280801608
      - 0.13704691772873587
      - 0.49691637066637057
      - 0.1247266776433443
      - 0.0797988162144159
      - 0.27532454329883393
      - 0.12977421480328455
      - 0.06710902291971013
      - 0.06840819674153008
      - 0.08158313877755205
      - 0.061885508374272424
      - 0.1757750693120011
      - 0.07270688241431415
      - 0.1353647498020109
      - 0.10901327908903667
      - 0.08732600909165066
      - 0.08434421481296481
      - 0.09200068858325287
      - 0.07261801739030421
      - 0.06332434172108084
      - 0.0801915356370802
    - - 0.10037947148692762
      - 0.6565682683329741
      - 0.30656041536820083
      - 0.22525547928773731
      - 0.6091852935293529
      - 0.32495018407998766
      - 0.3147321317944988
      - 0.22287542591404383
      - 0.29465781471275976
      - 0.22002795184613366
      - 0.3667896541443052
      - 0.3286008419273222
      - 0.1492775122929762
      - 0.22919318335985
      - 0.3231791130928294
      - 0.2770645164632473
      - 0.26478940846918375
      - 0.2413025749760443
      - 0.3110915535829031
      - 0.18798557053507547
      - 0.3773125803964142
      - 0.14875120198153902
      - 0.4382401097162668
      - 0.3906050421514339
      - 0.13224225836585385
      - 0.24814672727043857
      - 0.23573817625541763
      - 0.3186984405984796
      - 0.12862139964412692
      - 0.12012386736070946
      - 0.4442029734612152
      - 0.2213243106100249
      - 0.425057149640483
      - 0.15134103006652022
      - 0.4331013010141287
      - 0.18829158495825157
      - 0.19353222260830957
      - 0.0471199992267408
      - 0.09709826430332047
      - 0.06972044667446692
      - 0.09799498589821169
      - 0.058840960104943434
      - 0.05622720302952862
      - 0.1391356656382166
      - 0.06716167636648923
      - 0.28868343131735985
      - 0.11097005085407144
      - 0.06193699340251064
      - 0.31505922343834425
      - 0.3410662878787878
      - 0.08306037949166752
      - 0.5717879714531501
      - 0.2534212913523258
      - 0.13057801478131142
      - 0.16893014163485626
      - 0.7023988522500426
      - 0.19446952594088007
      - 0.05223855064418943
      - 0.06423735211816606
      - 0.20207246546079743
      - 0.3326067334470695
      - 0.1572127571348917
      - 0.07839513522653056
      - 0.4220500529212649
      - 0.2719484219484219
      - 0.2834708330078699
      - 0.2586747730311601
      - 0.23765275957223525
      - 0.46196805800740165
      - 0.20294673648993683
      - 0.3286338238380987
      - 0.10757066530262406
      - 0.3416899685282039
      - 0.14672107783520827
      - 0.5767338707044589
      - 0.16701866578343483
      - 0.19357118190451522
      - 0.87775336929839
      - 0.5750663992440308
      - 0.6562166795228388
      - 0.3244125267528249
      - 0.1883490296512118
      - 0.08071343744639198
      - 0.14048870528574134
      - 0.5108868186465183
      - 0.10825079115895442
      - 0.08879292620246024
      - 0.3040091784800811
      - 0.10398106382954866
      - 0.06099873818793964
      - 0.06860848248210885
      - 0.07094854379337137
      - 0.05408662219007046
      - 0.18478693820799083
      - 0.06182517691951654
      - 0.14353488284224664
      - 0.11604678220131515
      - 0.0921546965145581
      - 0.10154671606971825
      - 0.06786765407175444
      - 0.07296926044268355
      - 0.0722037329595469
      - 0.08464536150820999
    - - 0.09753865925740925
      - 0.6412199582283239
      - 0.3097863680627019
      - 0.2213321335373222
      - 0.5800403091775375
      - 0.30861944598300134
      - 0.3330651491365778
      - 0.2201301129461533
      - 0.30453751322905037
      - 0.21535878762441257
      - 0.36250048765963117
      - 0.31515648143845815
      - 0.13919258938408904
      - 0.2343208462169017
      - 0.2904830036907389
      - 0.27671493112918255
      - 0.2735633766617033
      - 0.22629667785917779
      - 0.33519810009373574
      - 0.1951329347567211
      - 0.36877090562317094
      - 0.1560242182028869
      - 0.485248677474287
      - 0.3762396302432923
      - 0.14095393312426277
      - 0.24209355850568262
      - 0.25354845046021507
      - 0.3054382422663354
      - 0.13911459828179773
      - 0.1178954795204795
      - 0.44457633248394113
      - 0.22588035409375573
      - 0.43839365448144774
      - 0.16825854374457713
      - 0.46070301543221137
      - 0.1916171514389015
      - 0.18320635408547498
      - 0.07754860879860881
      - 0.09272317341624273
      - 0.06916526162215816
      - 0.11395204385261204
      - 0.061030520405520414
      - 0.06096697048416556
      - 0.15632993768336556
      - 0.06983656932636523
      - 0.258951667274523
      - 0.11950672586861844
      - 0.0591639079874374
      - 0.2986245761813944
      - 0.3291022304415161
      - 0.08907852306140064
      - 0.5452970019368695
      - 0.256729101897169
      - 0.13905405997511255
      - 0.17932657230410037
      - 0.6756376533709068
      - 0.15139614310809962
      - 0.05914265806887881
      - 0.08752429603493433
      - 0.20438348401005368
      - 0.3182711553679295
      - 0.15403849943268247
      - 0.07782147622917454
      - 0.4182977566239299
      - 0.25530915038342994
      - 0.2967484129256759
      - 0.272179909306422
      - 0.23695306697884014
      - 0.4628030204183786
      - 0.20975376060871342
      - 0.3332524484123191
      - 0.11665115674238344
      - 0.34816299292105735
      - 0.17459594643537726
      - 0.5724381882006387
      - 0.15828540920103587
      - 0.197577306952307
      - 0.9007962959300935
      - 0.5518778838961977
      - 0.6693047936468988
      - 0.3153191704236596
      - 0.201214740381977
      - 0.0846829793998629
      - 0.13830056859226164
      - 0.4732185340590722
      - 0.12103353635611694
      - 0.08097606201538785
      - 0.2657603233152683
      - 0.12005937085003349
      - 0.06037357635471931
      - 0.06857911326557276
      - 0.07339857854563736
      - 0.06911990854703809
      - 0.1810289918414918
      - 0.0684947670855153
      - 0.12986230672400884
      - 0.1229719102971708
      - 0.0665281130036769
      - 0.09120060961134493
      - 0.07541090963570354
      - 0.07599403240513616
      - 0.07245480617573641
      - 0.07207661752498709
    - - 0.11725809684143015
      - 0.6333339380465048
      - 0.32363805549289415
      - 0.2149943963864418
      - 0.5895730673820562
      - 0.30844742773009814
      - 0.3085190642690642
      - 0.2218846916136072
      - 0.31345647077789934
      - 0.20534160124677367
      - 0.3738991503350965
      - 0.31677176251644334
      - 0.14217640824783678
      - 0.2386326508378051
      - 0.3182060728107826
      - 0.2602813560722642
      - 0.28704240743075704
      - 0.23393836718836714
      - 0.3325603466010696
      - 0.174279521443387
      - 0.39144896179470634
      - 0.16201545204204781
      - 0.4724353193103193
      - 0.36730592547032687
      - 0.14556634337884333
      - 0.23014550461358968
      - 0.23759090551513418
      - 0.3354472417616747
      - 0.13080208060261253
      - 0.12095855082293758
      - 0.4281723904750222
      - 0.2285155856276546
      - 0.41294265801728036
      - 0.17638493663909266
      - 0.45992457414871213
      - 0.19650838325760922
      - 0.18580239205239202
      - 0.08600394744144746
      - 0.09405443296126816
      - 0.07136624178290843
      - 0.11367125383979315
      - 0.05905329849172973
      - 0.0683665971193464
      - 0.14388006550845406
      - 0.07327380564547492
      - 0.2618566598665566
      - 0.11761838461701096
      - 0.06282721110307318
      - 0.3048172193406467
      - 0.32469278137882784
      - 0.09408468798774922
      - 0.5437081176801731
      - 0.23357381881757155
      - 0.1492825124710008
      - 0.18285431044051725
      - 0.6768019307081806
      - 0.14655435187553756
      - 0.07705549558997835
      - 0.07939595226797995
      - 0.20680647854560896
      - 0.33481396689730014
      - 0.17545587679516247
      - 0.061103439982750335
      - 0.39261063936063934
      - 0.26919159595338976
      - 0.299902752924731
      - 0.2597462618530034
      - 0.2329053758741258
      - 0.4638136520158992
      - 0.2123706723711128
      - 0.33155538281942776
      - 0.10684062737543748
      - 0.3418888981388981
      - 0.16550431594549242
      - 0.5895182018732743
      - 0.16130524780570732
      - 0.20269017123855826
      - 0.8881035190060722
      - 0.5409225658186654
      - 0.6370771843332818
      - 0.3204539751634511
      - 0.16729396572166944
      - 0.09045750777000776
      - 0.13791789807414803
      - 0.5109699744699745
      - 0.12961025086025085
      - 0.08631602602190835
      - 0.27135364152585195
      - 0.11655510781198312
      - 0.06876907548039879
      - 0.059323220970948234
      - 0.08843338199398804
      - 0.08083274168179826
      - 0.20901022286891854
      - 0.06833115235458985
      - 0.16223332826593692
      - 0.1053981208144749
      - 0.09004288394532298
      - 0.09529830538609049
      - 0.08217827384155846
      - 0.07097053197399547
      - 0.07568065714617439
      - 0.07786099668122139
    - - 0.10254507874989803
      - 0.6335667164550658
      - 0.32544915832959304
      - 0.18570232054828412
      - 0.5823664943046964
      - 0.30515487117049617
      - 0.31059006043183257
      - 0.22537392661087963
      - 0.29980472770787175
      - 0.22496163966752192
      - 0.34284034364679516
      - 0.325230855287035
      - 0.15475775712287768
      - 0.25076776719308735
      - 0.2977273075931911
      - 0.28202280919065903
      - 0.27016594889578754
      - 0.19164137032558087
      - 0.32965012041098996
      - 0.18612335581085582
      - 0.364594434276894
      - 0.1597538977154121
      - 0.4570413227451042
      - 0.3734726985807394
      - 0.13587587477707733
      - 0.23781704406704401
      - 0.22192262547230024
      - 0.3136910530989478
      - 0.12576132512930266
      - 0.1183370581733959
      - 0.464580362118241
      - 0.21182104360332382
      - 0.4216376128694519
      - 0.15673995388669298
      - 0.4303050904132812
      - 0.21390827949814073
      - 0.1754698315868528
      - 0.061561586561586557
      - 0.0979567817803112
      - 0.05834555147741961
      - 0.10869348043261086
      - 0.04498677248677248
      - 0.06980176745594517
      - 0.13921318165750823
      - 0.07178520658634296
      - 0.2786421647666627
      - 0.09787533417051489
      - 0.052801298271509256
      - 0.30989100405767067
      - 0.31699675680444905
      - 0.09319905683542046
      - 0.5507060881406244
      - 0.25353003706964095
      - 0.1368206158613135
      - 0.18357240798417268
      - 0.6679669219669219
      - 0.18288135621891022
      - 0.0696262011197076
      - 0.07403499952589021
      - 0.19698446106213097
      - 0.344209118110217
      - 0.17030266034911162
      - 0.07293096590292211
      - 0.38272781632479896
      - 0.29087072053928115
      - 0.26362480713900127
      - 0.26079282281727934
      - 0.20084182961930214
      - 0.4727180647635193
      - 0.18972903711275801
      - 0.32547948043655095
      - 0.10647901567845389
      - 0.3512914280652303
      - 0.1453246957881139
      - 0.5708063654454605
      - 0.16732666363618742
      - 0.18336399867298736
      - 0.8743191833709073
      - 0.557755595099345
      - 0.6717588121169713
      - 0.31954799446324045
      - 0.17691032571453486
      - 0.08910500274136637
      - 0.14270321973441868
      - 0.47536572622779516
      - 0.14096921100999915
      - 0.08060002348130338
      - 0.2813325150378721
      - 0.09342088541163468
      - 0.0648730453559265
      - 0.05290526466997054
      - 0.07697642105490335
      - 0.07391184084732473
      - 0.1985533758611801
      - 0.07848544511044511
      - 0.15076472799687085
      - 0.1047369792905507
      - 0.08164490614825662
      - 0.08981113075940661
      - 0.07438552324739847
      - 0.08109074951853042
      - 0.07014898045298108
      - 0.06542122295761213
  score_time:
  - 8.028081893920898
  - 8.038632869720459
  - 8.151082754135132
  - 8.112593412399292
  - 9.31243348121643
  test_level0__average_precision_macro:
  - 0.3439965215829258
  - 0.3171479133031416
  - 0.3130744771326732
  - 0.32056990282657843
  - 0.34265784301579777
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.5248569189250814
  - 0.4883536558759061
  - 0.494639108797553
  - 0.5159508449371054
  - 0.5244174483301629
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.5606134642918175
  - 0.5165720149132944
  - 0.5269275752097451
  - 0.5476988217866178
  - 0.5481823188405945
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.46086230102751147
  - 0.42222913540517554
  - 0.42873502515859924
  - 0.44470986833531345
  - 0.46640465638359974
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360422
  - 0.7916584109371906
  - 0.7853180106994255
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360424
  - 0.7916584109371904
  - 0.7853180106994254
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7932138925032529
  - 0.7827669902912621
  - 0.7888099289360424
  - 0.7916584109371902
  - 0.7853180106994254
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.7242367211293926
  - 0.7148853697323084
  - 0.7100375574665051
  - 0.7158929666287116
  - 0.7210003606868147
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.17765989390451406
  - -0.17969833564493756
  - -0.17605845260734657
  - -0.17505448781454333
  - -0.18456508817119083
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.17765989390451406
  - -0.1796983356449376
  - -0.17605845260734662
  - -0.1750544878145433
  - -0.1845650881711908
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.17765989390451403
  - -0.17969833564493753
  - -0.17605845260734657
  - -0.17505448781454325
  - -0.18456508817119077
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.2017383409069873
  - -0.19886694937715346
  - -0.2035578872917888
  - -0.20164666725059122
  - -0.20604024593807932
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.029126213592233014
  - -0.037534674063800275
  - -0.035131618456610954
  - -0.033287101248266296
  - -0.03011690112938379
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.02912621359223301
  - -0.037534674063800275
  - -0.03513161845661095
  - -0.033287101248266296
  - -0.030116901129383793
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.029126213592233007
  - -0.037534674063800275
  - -0.03513161845661095
  - -0.03328710124826629
  - -0.030116901129383786
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.07402493796362002
  - -0.08624768089053804
  - -0.08640455524170625
  - -0.08246036612069721
  - -0.0729593933751059
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6729897391609817
  - 0.6590890717449049
  - 0.6687224941714094
  - 0.672946026676338
  - 0.66190288863309
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.6572945177075558
  - 0.6430707876370887
  - 0.6512684902074208
  - 0.6551611051898008
  - 0.6465214909061251
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6607138078086191
  - 0.6455900724286516
  - 0.6535785351119248
  - 0.6578502085498543
  - 0.6487840537209111
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5809071051393258
  - 0.57175333094994
  - 0.5640909149872317
  - 0.5716940118988083
  - 0.5773036135744803
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5606134642918176
  - 0.5165720149132944
  - 0.5269275752097449
  - 0.5476988217866177
  - 0.5481823188405947
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.01351685977157105
  - 0.007636638181988101
  - 0.004754370006266316
  - 0.006207169815291706
  - 0.010264227994829296
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.3074327708180554
  - 0.266899352058382
  - 0.2810245442432738
  - 0.2934313414595434
  - 0.2959573410144599
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.3163100545876165
  - 0.26999713175753326
  - 0.28207565345979524
  - 0.2976215248900649
  - 0.29926486648104683
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.026823287541657945
  - 0.013944465205974825
  - 0.007658211683002996
  - 0.014961435891939285
  - 0.019152219287340757
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.843528382003901
  - 0.8193994271690546
  - 0.8202658662545346
  - 0.8327129826747082
  - 0.8400910071344834
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -86.71134020618557
  - -90.99107142857143
  - -88.83505154639175
  - -87.60204081632654
  - -89.6938775510204
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.20678610749674706
  - -0.21723300970873785
  - -0.21119007106395754
  - -0.20834158906280964
  - -0.21468198930057458
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.20678610749674708
  - -0.21723300970873785
  - -0.21119007106395757
  - -0.20834158906280958
  - -0.2146819893005746
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.20678610749674706
  - -0.21723300970873782
  - -0.2111900710639575
  - -0.2083415890628095
  - -0.21468198930057458
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.27576327887060725
  - -0.28511463026769146
  - -0.289962442533495
  - -0.2841070333712885
  - -0.27899963931318517
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.23512896809943779
  - -0.2641785553751883
  - -0.24752558993488952
  - -0.23581907030742486
  - -0.24718345356239307
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360422
  - 0.7916584109371906
  - 0.7853180106994255
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360424
  - 0.7916584109371904
  - 0.7853180106994254
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7932138925032529
  - 0.7827669902912621
  - 0.7888099289360424
  - 0.7916584109371902
  - 0.7853180106994254
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.7242367211293926
  - 0.7148853697323084
  - 0.7100375574665051
  - 0.7158929666287116
  - 0.7210003606868147
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360422
  - 0.7916584109371906
  - 0.7853180106994255
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7932138925032529
  - 0.7827669902912622
  - 0.7888099289360424
  - 0.7916584109371904
  - 0.7853180106994254
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7932138925032529
  - 0.7827669902912621
  - 0.7888099289360424
  - 0.7916584109371902
  - 0.7853180106994254
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.7242367211293926
  - 0.7148853697323084
  - 0.7100375574665051
  - 0.7158929666287116
  - 0.7210003606868147
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.6098375151682847
  - 0.5924654641124871
  - 0.589776662969527
  - 0.5892208944789067
  - 0.5996672622244226
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7598559461411056
  - 0.7354051445670041
  - 0.750190336723172
  - 0.7601286226957035
  - 0.7506502554587472
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7648710319005622
  - 0.7358214446248118
  - 0.7524744100651107
  - 0.7641809296925752
  - 0.752816546437607
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5997378760237623
  - 0.5969674984415185
  - 0.5835530182332404
  - 0.5884506366871056
  - 0.6041495776644535
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7367630867781002
  - 0.7288488210818308
  - 0.7343609248323489
  - 0.7358827025956015
  - 0.7288488210818309
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7367630867781003
  - 0.7288488210818308
  - 0.7343609248323492
  - 0.7358827025956014
  - 0.7288488210818308
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7367630867781002
  - 0.7288488210818306
  - 0.7343609248323492
  - 0.7358827025956013
  - 0.7288488210818307
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.5672042418338967
  - 0.5771534587861118
  - 0.56551964940396
  - 0.5610624507313655
  - 0.570099063053088
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.05645080572515263
  - 0.05391816920943135
  - 0.05444900410369332
  - 0.055775708341589056
  - 0.05646918961759461
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.05645080572515264
  - 0.05391816920943134
  - 0.05444900410369333
  - 0.05577570834158906
  - 0.05646918961759461
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.05645080572515262
  - 0.053918169209431335
  - 0.05444900410369332
  - 0.05577570834158904
  - 0.056469189617594596
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.1570324792954959
  - 0.13773191094619666
  - 0.14451790806254505
  - 0.15483051589734603
  - 0.15090129763372673
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.2727428357955157
  - 0.28407406997435547
  - 0.2627351762348728
  - 0.27348180267240874
  - 0.29736928503398635
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.24142233781551461
  - 0.2171020412240811
  - 0.2175445128623763
  - 0.23880859199896676
  - 0.24126214103024943
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.2521831105124294
  - 0.22624034905238824
  - 0.22491303804878077
  - 0.25309553342933516
  - 0.24972567123907993
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.39840322337866446
  - 0.38873955446559855
  - 0.3840096211208905
  - 0.40029778916622194
  - 0.4151714395609961
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.25218311051242953
  - 0.22624034905238824
  - 0.2249130380487808
  - 0.2530955334293352
  - 0.24972567123907993
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6252453398814904
  - 0.6004838108182504
  - 0.6062885736606298
  - 0.6139872380221674
  - 0.6268785486550924
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -92.08247422680412
  - -94.98214285714286
  - -94.54639175257732
  - -91.63265306122449
  - -93.18367346938776
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.49403031559447774
  - -0.5552419647355192
  - -0.5956170175674068
  - -0.4699541244121633
  - -0.5318907765279683
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5425041043122021
  - 0.551839324901576
  - 0.5263001600070425
  - 0.5383834640001411
  - 0.5503496874621624
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.5424521349502862
  - 0.49135632412572644
  - 0.4865700780278902
  - 0.5563569506448824
  - 0.5244310207732483
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.5485909228673642
  - 0.49021835698761024
  - 0.48522185414016206
  - 0.5609828593813497
  - 0.5260921382074009
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5391437768224557
  - 0.5535224126180838
  - 0.5287026249471861
  - 0.5426563349985241
  - 0.5589355551806683
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.27825896442830067
  - 0.28666319508253174
  - 0.2595051734144743
  - 0.28235899972792694
  - 0.3002159166177641
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.24303120532042943
  - 0.2178789507078259
  - 0.21789711843090426
  - 0.24211426454901747
  - 0.2433915663322205
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.253271118943874
  - 0.2270522061523103
  - 0.22515254277644045
  - 0.25666042059550775
  - 0.2512818020182263
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.4055315698156449
  - 0.3947877012975314
  - 0.3786620454112291
  - 0.4096635703501307
  - 0.416907867592444
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.253271118943874
  - 0.22705220615231034
  - 0.22515254277644056
  - 0.25666042059550775
  - 0.25128180201822625
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.6256909403065635
  - 0.6012399079152192
  - 0.6066958955024044
  - 0.6186975957183904
  - 0.6293739696838343
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -91.82474226804123
  - -94.27678571428571
  - -94.63917525773196
  - -91.43877551020408
  - -92.9795918367347
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.4929207688216583
  - -0.5545818643135504
  - -0.5944234795289831
  - -0.46571006623452393
  - -0.5309061721791799
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5491228356630533
  - 0.5509526689784716
  - 0.5237082451194065
  - 0.5562843234099485
  - 0.5503689238744892
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.5458432627326318
  - 0.4928663657831334
  - 0.4869885646600394
  - 0.5606572814331802
  - 0.5265623875857849
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.5497119814161601
  - 0.49095778210939656
  - 0.48530201035269543
  - 0.5643750412191559
  - 0.5267973858680524
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5506990273017971
  - 0.5545962165957734
  - 0.5260110147009803
  - 0.5582616677508508
  - 0.5530044705228542
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.28781334322338675
  - 0.2830803548794836
  - 0.26615466709757307
  - 0.2766399981060318
  - 0.3012770496665979
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.24236253241318786
  - 0.21751244683711635
  - 0.21700455166225643
  - 0.23962389099985087
  - 0.24260700143202096
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.2527025181608618
  - 0.2267520250553223
  - 0.22432394598428132
  - 0.25412364067793675
  - 0.2508767246454751
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.41500967488052637
  - 0.38929786799138405
  - 0.38316382962658185
  - 0.40540751025806226
  - 0.4222764533123138
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.25270251816086187
  - 0.2267520250553222
  - 0.22432394598428118
  - 0.2541236406779367
  - 0.25087672464547517
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6248347125619012
  - 0.6009046283497026
  - 0.606214080097128
  - 0.6155669567243457
  - 0.6282466736821322
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -91.56701030927834
  - -94.625
  - -94.61855670103093
  - -91.14285714285714
  - -93.1938775510204
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.4917649203578926
  - -0.5536821913654406
  - -0.5930572132656378
  - -0.47016844198794555
  - -0.532600048368002
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5559391793407027
  - 0.5523953982139258
  - 0.5325176903106903
  - 0.5473006839969193
  - 0.5483382013420006
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.5453068349205845
  - 0.4925838861318041
  - 0.48635929563890556
  - 0.5572626936692515
  - 0.5260484978630804
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.5499142966554446
  - 0.4914557840302294
  - 0.48585466658495957
  - 0.5614467161877951
  - 0.526358483597122
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5572435575327369
  - 0.5550211195079711
  - 0.5292284513140375
  - 0.5521198603488972
  - 0.5581039476231637
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.28576435969539155
  - 0.2871177298086119
  - 0.26187769645959785
  - 0.2710244491325091
  - 0.2922719901366528
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.2421224010365845
  - 0.21785663448017403
  - 0.21759355243020154
  - 0.23994389720777207
  - 0.24138462803685068
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.2523646073955006
  - 0.22677623250302248
  - 0.2243851403735983
  - 0.254054790716234
  - 0.2498472911590697
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.40692821594167367
  - 0.3977169914925359
  - 0.38242948071149807
  - 0.4017320115363997
  - 0.4092744146009425
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.2523646073955007
  - 0.22677623250302248
  - 0.22438514037359839
  - 0.2540547907162339
  - 0.24984729115906973
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.6245517542078665
  - 0.6014186606927058
  - 0.6061959059120869
  - 0.6164476759297512
  - 0.627274686021653
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -92.09278350515464
  - -95.0
  - -94.6701030927835
  - -90.98979591836735
  - -92.88775510204081
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.4934770171000095
  - -0.5552463547556041
  - -0.5966926932172627
  - -0.4696840307063386
  - -0.5329509641076949
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5545312697693511
  - 0.5476791330639366
  - 0.5267637394339546
  - 0.5454752640505627
  - 0.5457268219935618
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.54514905217491
  - 0.4924632641099751
  - 0.48690147290124675
  - 0.5569093792633769
  - 0.5239482214190052
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.548951195535522
  - 0.49067052002726713
  - 0.48491753480907157
  - 0.5618413228693353
  - 0.5254929871007075
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.543114740232451
  - 0.5558562032987447
  - 0.5301301701308901
  - 0.5500499009262138
  - 0.5479599442538136
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.2872216386106783
  - 0.2784275965136805
  - 0.25682321426045884
  - 0.27620767064077145
  - 0.2966769009333591
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.24033115033069402
  - 0.21796149485420002
  - 0.21744508750763372
  - 0.2412697243726722
  - 0.2412477501979467
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.2512925334164599
  - 0.22689691872381612
  - 0.22465260197025266
  - 0.25561330860476156
  - 0.24953299124032624
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.4041858682630372
  - 0.3871495103642454
  - 0.3753367812185283
  - 0.41099360968138643
  - 0.4128672028593804
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.25129253341645985
  - 0.22689691872381615
  - 0.22465260197025264
  - 0.25561330860476145
  - 0.24953299124032619
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6230548864594495
  - 0.6015584054106976
  - 0.6067473309224856
  - 0.6173286099765913
  - 0.6272956580178487
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -92.25773195876289
  - -94.72321428571429
  - -94.98969072164948
  - -91.35714285714286
  - -92.93877551020408
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.49417625032206414
  - -0.5544761240527242
  - -0.5960511518281787
  - -0.4670785075210525
  - -0.5332521840463851
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5472891510293518
  - 0.5477365601426708
  - 0.5221110396890724
  - 0.545948683234782
  - 0.5499512000300646
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.5415745242995484
  - 0.49287620776786517
  - 0.48597946938865877
  - 0.5594015130911237
  - 0.5233239729595879
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.5469405538557024
  - 0.4914633432088082
  - 0.4847013162444129
  - 0.5651518648621318
  - 0.5247202541661846
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5383764738817275
  - 0.5533015978023746
  - 0.520090258783223
  - 0.5550498541356975
  - 0.5535411480451873
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.28095835822369164
  - 0.29052958273384544
  - 0.26957436906453247
  - 0.27398989103652094
  - 0.28791651596198686
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.24033995276329037
  - 0.2176325322122931
  - 0.21778067495002557
  - 0.23992677665270526
  - 0.24099818177791893
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.2513421927738974
  - 0.22657132410332265
  - 0.22478801507529797
  - 0.25456634817378987
  - 0.24947448729741875
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.4023941270632958
  - 0.3945101756860474
  - 0.3934206245550388
  - 0.40284756305187935
  - 0.40159413989077986
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.2513421927738974
  - 0.22657132410332262
  - 0.22478801507529797
  - 0.25456634817378987
  - 0.2494744872974187
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.623576598188453
  - 0.6013035627547928
  - 0.6066871617038552
  - 0.6162246785917402
  - 0.6273620207094772
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -92.05154639175258
  - -94.84821428571429
  - -94.63917525773196
  - -91.42857142857143
  - -93.1938775510204
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.4951535341271681
  - -0.5552925301808533
  - -0.5954315630331268
  - -0.4704713130331875
  - -0.5342782379834834
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5498228635751492
  - 0.5528745411813838
  - 0.5324153168103034
  - 0.5412970738107922
  - 0.5348516145867626
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.5409297605300427
  - 0.4921070010507211
  - 0.48730530304091446
  - 0.5565076959135705
  - 0.5222099237773612
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.5464694820348864
  - 0.49071320222414067
  - 0.4858376897256453
  - 0.5618029735026502
  - 0.5234991714453937
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5421256324424658
  - 0.5550027215900776
  - 0.536098182710933
  - 0.5458860603918216
  - 0.5371716931854082
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.28236266144090444
  - 0.2856934488103233
  - 0.26734001766218224
  - 0.2728154168314323
  - 0.2838612382528961
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.2412432448236113
  - 0.2172713063167821
  - 0.21885346274469838
  - 0.24007277502957142
  - 0.24073930491961754
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.25248457112614203
  - 0.22577003689796493
  - 0.22528080285961655
  - 0.25493398084645574
  - 0.24973197015695342
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.40635395088235543
  - 0.3937932027531443
  - 0.3920662436610789
  - 0.40590666125613245
  - 0.40185303151784746
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.252484571126142
  - 0.225770036897965
  - 0.22528080285961652
  - 0.2549339808464557
  - 0.24973197015695345
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6244499891289373
  - 0.6000072808227668
  - 0.607518944722307
  - 0.6173634343765704
  - 0.6272215258868853
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -92.62886597938144
  - -94.95535714285714
  - -94.8659793814433
  - -91.07142857142857
  - -93.64285714285714
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.49265290732050204
  - -0.5555684698174577
  - -0.5982837153306821
  - -0.4698488443361465
  - -0.5328993206003841
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5463424614238722
  - 0.5479473252114679
  - 0.5253482825831746
  - 0.5415619373081325
  - 0.5359127234481424
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.5423812612205099
  - 0.49210395821962066
  - 0.4880280460314398
  - 0.5563708809007348
  - 0.5224493383921306
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.5480260797543859
  - 0.4893633596995541
  - 0.4853335955784553
  - 0.5624494422627458
  - 0.5253387130678003
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5403089034066993
  - 0.5527156940108479
  - 0.5299324257678613
  - 0.5513673979810693
  - 0.5404308068395376
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.28330138581308795
  - 0.2888324949531596
  - 0.25614178786158853
  - 0.27296826416371045
  - 0.2938591079889138
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.24102102015192745
  - 0.21860481263879455
  - 0.21690313457243934
  - 0.23948836169436588
  - 0.24186635653291658
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.2518098244991556
  - 0.22746364880156028
  - 0.22439978696331878
  - 0.2543453761133665
  - 0.2504194311181181
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.4104632785948553
  - 0.39766716752324116
  - 0.37493915526711274
  - 0.39896110110086125
  - 0.4112574613248622
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.2518098244991557
  - 0.2274636488015604
  - 0.22439978696331897
  - 0.25434537611336655
  - 0.2504194311181181
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.6241042834749789
  - 0.6021377750244039
  - 0.605745899286303
  - 0.6168219745742203
  - 0.6278833793020722
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -92.34020618556701
  - -94.65178571428571
  - -95.03092783505154
  - -91.43877551020408
  - -93.1938775510204
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.49453009266791553
  - -0.5547812078953387
  - -0.5956757762654169
  - -0.4710757483758757
  - -0.5320502243613566
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5491996892374846
  - 0.5503335663510638
  - 0.5245561465591753
  - 0.5450049682139149
  - 0.5464623466765245
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.542662381576339
  - 0.49386957670442083
  - 0.485328653346786
  - 0.5549774130851537
  - 0.5247774678040322
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.5483818963761578
  - 0.491814517906961
  - 0.4841161645830421
  - 0.5612763801220452
  - 0.5263588662445027
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5471466889740347
  - 0.5548827361615714
  - 0.5249745149538331
  - 0.5473379633614597
  - 0.5478880447065204
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.2768847004072075
  - 0.28727872076368455
  - 0.2641943742321347
  - 0.2751054948993065
  - 0.29694654753261235
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.23957649001137626
  - 0.21798599635174998
  - 0.21800762297347342
  - 0.23979177843100224
  - 0.24124855177455276
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.25002593507298526
  - 0.226518181804601
  - 0.22493622985042755
  - 0.25415057335331603
  - 0.24981921887440706
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.3988683891182573
  - 0.3935724933087673
  - 0.38842018765619896
  - 0.40825666225436974
  - 0.41204695554577675
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.25002593507298526
  - 0.226518181804601
  - 0.22493622985042755
  - 0.254150573353316
  - 0.24981921887440703
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6227229143648432
  - 0.6007901327295796
  - 0.6068802380840264
  - 0.615656464066701
  - 0.6273880951323108
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -91.9381443298969
  - -94.66071428571429
  - -94.90721649484536
  - -91.62244897959184
  - -93.42857142857143
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.4972283550597122
  - -0.5547061882416933
  - -0.5949174682293454
  - -0.4693370132686288
  - -0.5336438603554883
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.546778823813957
  - 0.5508138045768103
  - 0.5303311341613848
  - 0.5451139768956236
  - 0.5405829986300442
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.5398788626322408
  - 0.49350512947875885
  - 0.48802386653069363
  - 0.5566952844978363
  - 0.5229250290771397
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.5446252127491348
  - 0.49064295172687983
  - 0.48671825663916385
  - 0.5623679330468274
  - 0.5241258712126875
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5412708754497048
  - 0.5556484465774686
  - 0.5314080851957506
  - 0.5525590257185654
  - 0.5445878373006515
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.2697914364624593
  - 0.2940785386515718
  - 0.26605048180695395
  - 0.27208259103597876
  - 0.29641990348800207
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.24014542756496302
  - 0.21876226346290517
  - 0.21787303709864642
  - 0.23888359840094767
  - 0.24147569019206905
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.25103581848626977
  - 0.2274039383624815
  - 0.22490154077517743
  - 0.25394745850205486
  - 0.25001753761390016
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.3929053166753306
  - 0.4045506736151819
  - 0.3887701325259209
  - 0.4037816371564543
  - 0.4113359628030019
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.14533411691075712
  - 0.14256536567144681
  - 0.14157389915914484
  - 0.14290137631554084
  - 0.14934417613391412
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.13257382531315537
  - 0.13225695637238064
  - 0.1302675490695175
  - 0.13047373726061148
  - 0.13703182202196565
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.1334969251908599
  - 0.1332669926129635
  - 0.13113599344766833
  - 0.13150432827619876
  - 0.13786532580951946
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.2415845763620132
  - 0.22050765000802253
  - 0.22836719626488575
  - 0.23815149573310676
  - 0.23919450381893068
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.25103581848626977
  - 0.2274039383624815
  - 0.2249015407751775
  - 0.2539474585020549
  - 0.2500175376139003
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.62358603727096
  - 0.6020977410652494
  - 0.6063924900416789
  - 0.616055891691628
  - 0.6272885289191592
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -92.0
  - -94.80357142857143
  - -94.78350515463917
  - -92.04081632653062
  - -92.93877551020408
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.7658893003703332
  - -0.766383495145631
  - -0.7694925432889598
  - -0.7691698038438678
  - -0.7589657222112147
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.7658893003703333
  - -0.7663834951456311
  - -0.7694925432889601
  - -0.7691698038438677
  - -0.7589657222112146
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.7658893003703332
  - -0.7663834951456311
  - -0.76949254328896
  - -0.7691698038438677
  - -0.7589657222112144
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.6412291797975168
  - -0.6634011396766499
  - -0.6519242046456664
  - -0.6435228168520628
  - -0.6430584564281938
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.4961710260546722
  - -0.5543305424318555
  - -0.594442445679753
  - -0.47263765641467914
  - -0.5320548363459191
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5389360034676479
  - 0.5554052743340129
  - 0.5308041888340839
  - 0.5366792541975376
  - 0.553428067218701
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.5399603799927009
  - 0.4946135174309104
  - 0.487974926836145
  - 0.553542652011153
  - 0.5245611228328149
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.5456819481147589
  - 0.49210342728590667
  - 0.4856099483308638
  - 0.55986443709061
  - 0.5263226457976949
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.53462954458698
  - 0.5614421173205689
  - 0.5323308736282159
  - 0.5453409030671608
  - 0.555105154737748
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.23411069962966666
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.2308301961561324
  - 0.24103427778878542
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.2341106996296667
  - 0.23361650485436894
  - 0.23050745671103995
  - 0.23083019615613234
  - 0.24103427778878542
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.23411069962966666
  - 0.23361650485436888
  - 0.23050745671103987
  - 0.2308301961561323
  - 0.2410342777887854
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.3587708202024832
  - 0.33659886032335007
  - 0.34807579535433375
  - 0.3564771831479373
  - 0.356941543571806
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.8598801779615952
  - 0.8644847782373143
  - 0.8565193944150785
  - 0.8534543290719568
  - 0.8590870531726932
  train_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro_oob:
  - 0.27536285759755286
  - 0.27693763151854744
  - 0.2827489928729107
  - 0.2845482480261935
  - 0.27740813771734785
  train_level0__average_precision_micro:
  - 0.6561388913867644
  - 0.6602509788036304
  - 0.6590205754702729
  - 0.6568141472090118
  - 0.6537457706513984
  train_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_micro_oob:
  - 0.5017092121419666
  - 0.5105048815961309
  - 0.5082700762242075
  - 0.5046517946007057
  - 0.5025586292193154
  train_level0__average_precision_samples:
  - 0.6663976295222692
  - 0.6712256761194896
  - 0.670764177562371
  - 0.6675929512487868
  - 0.6662635682024188
  train_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_samples_oob:
  - 0.5342835875090489
  - 0.543978206424342
  - 0.5403119602583405
  - 0.5369608440461079
  - 0.5368084560544413
  train_level0__average_precision_weighted:
  - 0.8680559155155074
  - 0.8701524544156013
  - 0.864253978718946
  - 0.8615396996243654
  - 0.8676961879019559
  train_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_weighted_oob:
  - 0.39406419406965826
  - 0.39930983214453436
  - 0.4010852534125039
  - 0.4010951133265145
  - 0.3938126696372656
  train_level0__f1_macro:
  - 0.812201845858804
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061425
  train_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_macro_oob:
  - 0.7869591274122019
  - 0.7894697535474233
  - 0.7870789883734866
  - 0.7873209651062195
  - 0.7881861001634144
  train_level0__f1_micro:
  - 0.8122018458588038
  - 0.8112521782424695
  - 0.8125134843581445
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_micro_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734868
  - 0.7873209651062194
  - 0.7881861001634144
  train_level0__f1_samples:
  - 0.8122018458588037
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_samples_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734867
  - 0.7873209651062193
  - 0.7881861001634144
  train_level0__f1_weighted:
  - 0.7695366164921881
  - 0.7635556646082962
  - 0.771056143415029
  - 0.7648499650374455
  - 0.7668929818398204
  train_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_weighted_oob:
  - 0.7184436425634391
  - 0.7204855573276626
  - 0.7199959171174851
  - 0.7205980116947213
  - 0.7179869352405397
  train_level0__fn_macro:
  - -0.16579168164928684
  - -0.16402788150360967
  - -0.16497662711254946
  - -0.1667067192156109
  - -0.16444775545515722
  train_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_macro_oob:
  - -0.17969555315833632
  - -0.17647498132935027
  - -0.17890447081385594
  - -0.17992406036720174
  - -0.17776122272421419
  train_level0__fn_micro:
  - -0.16579168164928682
  - -0.16402788150360967
  - -0.16497662711254943
  - -0.1667067192156109
  - -0.16444775545515716
  train_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_micro_oob:
  - -0.17969555315833632
  - -0.17647498132935027
  - -0.17890447081385594
  - -0.17992406036720177
  - -0.17776122272421416
  train_level0__fn_samples:
  - -0.1657916816492868
  - -0.1640278815036096
  - -0.16497662711254943
  - -0.16670671921561084
  - -0.1644477554551571
  train_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_samples_oob:
  - -0.17969555315833632
  - -0.17647498132935022
  - -0.17890447081385588
  - -0.17992406036720174
  - -0.17776122272421416
  train_level0__fn_weighted:
  - -0.17386019697941293
  - -0.17168690958164645
  - -0.1712980920085136
  - -0.1744471862744105
  - -0.17260466607331051
  train_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_weighted_oob:
  - -0.20024461165054683
  - -0.19468258836679891
  - -0.19777104858252148
  - -0.19915684506014572
  - -0.19780855969118166
  train_level0__fp_macro:
  - -0.022006472491909384
  - -0.024719940253920835
  - -0.022509888529306004
  - -0.02369508795539748
  - -0.023190425838700377
  train_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_macro_oob:
  - -0.033345319429461825
  - -0.034055265123226285
  - -0.034016540812657314
  - -0.03275497452657887
  - -0.034052677112371435
  train_level0__fp_micro:
  - -0.022006472491909384
  - -0.024719940253920835
  - -0.022509888529306004
  - -0.02369508795539748
  - -0.023190425838700374
  train_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_micro_oob:
  - -0.033345319429461825
  - -0.03405526512322629
  - -0.034016540812657314
  - -0.03275497452657887
  - -0.03405267711237143
  train_level0__fp_samples:
  - -0.02200647249190938
  - -0.024719940253920828
  - -0.022509888529306
  - -0.023695087955397477
  - -0.023190425838700374
  train_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_samples_oob:
  - -0.03334531942946182
  - -0.034055265123226285
  - -0.03401654081265731
  - -0.03275497452657886
  - -0.03405267711237142
  train_level0__fp_weighted:
  - -0.056603186528399116
  - -0.06475742581005739
  - -0.05764576457645765
  - -0.06070284868814414
  - -0.06050235208686897
  train_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_weighted_oob:
  - -0.08131174578601413
  - -0.08483185430553852
  - -0.08223303429999358
  - -0.0802451432451331
  - -0.08420450506827863
  train_level0__jaccard_macro:
  - 0.6929581966812639
  - 0.6925628729905269
  - 0.693353121695947
  - 0.6895270925471889
  - 0.6937115914349526
  train_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_macro_oob:
  - 0.6643298602798962
  - 0.6678310926389093
  - 0.6644846191221643
  - 0.6643312936656174
  - 0.6664914151347234
  train_level0__jaccard_micro:
  - 0.6837877656461281
  - 0.6824426202043894
  - 0.6842296511627907
  - 0.6801049762793984
  - 0.6840145690004047
  train_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_micro_oob:
  - 0.6487490613019248
  - 0.6521685483373435
  - 0.6489119908294958
  - 0.6492410130395149
  - 0.6504184349343592
  train_level0__jaccard_samples:
  - 0.6862517243656888
  - 0.6850847390476872
  - 0.6868732142253698
  - 0.6825404311943055
  - 0.6866565843621106
  train_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_samples_oob:
  - 0.6512588339535542
  - 0.654872570229094
  - 0.6515440241500993
  - 0.6517309501667464
  - 0.6531214536477569
  train_level0__jaccard_weighted:
  - 0.6321290900280296
  - 0.6250990852099446
  - 0.6344617377601367
  - 0.6265155038936451
  - 0.6290506669144815
  train_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_weighted_oob:
  - 0.5743295305167906
  - 0.5763858192128017
  - 0.5767340424640808
  - 0.5766449449233269
  - 0.5741302418670569
  train_level0__label_ranking_average_precision_score:
  - 0.6663976295222694
  - 0.6712256761194895
  - 0.6707641775623713
  - 0.6675929512487863
  - 0.6662635682024192
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5342835875090489
  - 0.5439782064243421
  - 0.5403119602583404
  - 0.5369608440461079
  - 0.536808456054441
  train_level0__matthews_corrcoef_macro:
  - 0.08621262753544051
  - 0.07839904838176602
  - 0.08970369509879858
  - 0.08859000520456754
  - 0.08302658347786168
  train_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_macro_oob:
  - 0.005652873252641683
  - 0.0049129787804883356
  - 0.007577547810955218
  - 0.008107288971074808
  - 0.0027640598033355727
  train_level0__matthews_corrcoef_micro:
  - 0.38828173674666566
  - 0.3861184619699044
  - 0.39250320345402734
  - 0.38025352185485234
  - 0.3844812453975128
  train_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_micro_oob:
  - 0.28224282805383166
  - 0.2960572454649974
  - 0.2870821589606167
  - 0.2861396465284543
  - 0.28304551745005474
  train_level0__matthews_corrcoef_samples:
  - 0.38855465440830156
  - 0.38796103759894707
  - 0.39402030134439525
  - 0.37978551775438313
  - 0.38542988288033697
  train_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_samples_oob:
  - 0.2861335371338116
  - 0.2994189179295994
  - 0.29111500631931236
  - 0.28985924902273846
  - 0.28787121053969905
  train_level0__matthews_corrcoef_weighted:
  - 0.16737075950867128
  - 0.14944936546793838
  - 0.17185645708901587
  - 0.1660790941494958
  - 0.16240226816899245
  train_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.012346902632385462
  - 0.008456191972822992
  - 0.013822852427203897
  - 0.01561352068122334
  - 0.006992000959531447
  train_level0__ndcg:
  - 0.885708617859482
  - 0.8879273503790914
  - 0.8887415245374356
  - 0.8866603179154751
  - 0.8849949746057962
  train_level0__ndcg_oob:
  - 0.8276717637912686
  - 0.8329071361803091
  - 0.8321750087676854
  - 0.8298521909488832
  - 0.8281306753804547
  train_level0__neg_coverage_error:
  - -66.6641975308642
  - -65.51538461538462
  - -66.41975308641975
  - -66.92079207920793
  - -65.92821782178218
  train_level0__neg_coverage_error_oob:
  - -89.92592592592592
  - -88.01282051282051
  - -88.8716049382716
  - -89.51485148514851
  - -88.12128712871286
  train_level0__neg_hamming_loss_macro:
  - -0.18779815414119622
  - -0.18874782175753052
  - -0.18748651564185548
  - -0.19040180717100835
  - -0.18763818129385756
  train_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_macro_oob:
  - -0.21304087258779814
  - -0.2105302464525766
  - -0.21292101162651325
  - -0.21267903489378062
  - -0.21181389983658563
  train_level0__neg_hamming_loss_micro:
  - -0.18779815414119622
  - -0.1887478217575305
  - -0.18748651564185545
  - -0.19040180717100835
  - -0.18763818129385754
  train_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_micro_oob:
  - -0.21304087258779816
  - -0.21053024645257654
  - -0.21292101162651325
  - -0.21267903489378065
  - -0.2118138998365856
  train_level0__neg_hamming_loss_samples:
  - -0.18779815414119616
  - -0.18874782175753044
  - -0.18748651564185542
  - -0.1904018071710083
  - -0.18763818129385748
  train_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_samples_oob:
  - -0.21304087258779808
  - -0.21053024645257648
  - -0.2129210116265132
  - -0.21267903489378057
  - -0.21181389983658555
  train_level0__neg_hamming_loss_weighted:
  - -0.230463383507812
  - -0.23644433539170384
  - -0.22894385658497132
  - -0.23515003496255454
  - -0.2331070181601795
  train_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.28155635743656093
  - -0.27951444267233744
  - -0.28000408288251516
  - -0.2794019883052788
  - -0.2820130647594603
  train_level0__neg_label_ranking_loss:
  - -0.14350714201442105
  - -0.1409448791446942
  - -0.14322708838574283
  - -0.1440837052283296
  - -0.14289037511298916
  train_level0__neg_label_ranking_loss_oob:
  - -0.2509666607116252
  - -0.24257403031342048
  - -0.24843234992646393
  - -0.24965089998939177
  - -0.2464485965749711
  train_level0__precision_macro:
  - 0.812201845858804
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061425
  train_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_macro_oob:
  - 0.7869591274122019
  - 0.7894697535474233
  - 0.7870789883734866
  - 0.7873209651062195
  - 0.7881861001634144
  train_level0__precision_micro:
  - 0.8122018458588038
  - 0.8112521782424695
  - 0.8125134843581445
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_micro_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734868
  - 0.7873209651062194
  - 0.7881861001634144
  train_level0__precision_samples:
  - 0.8122018458588037
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_samples_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734867
  - 0.7873209651062193
  - 0.7881861001634144
  train_level0__precision_weighted:
  - 0.7695366164921881
  - 0.7635556646082962
  - 0.771056143415029
  - 0.7648499650374455
  - 0.7668929818398204
  train_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_weighted_oob:
  - 0.7184436425634391
  - 0.7204855573276626
  - 0.7199959171174851
  - 0.7205980116947213
  - 0.7179869352405397
  train_level0__recall_macro:
  - 0.812201845858804
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061425
  train_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_macro_oob:
  - 0.7869591274122019
  - 0.7894697535474233
  - 0.7870789883734866
  - 0.7873209651062195
  - 0.7881861001634144
  train_level0__recall_micro:
  - 0.8122018458588038
  - 0.8112521782424695
  - 0.8125134843581445
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_micro_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734868
  - 0.7873209651062194
  - 0.7881861001634144
  train_level0__recall_samples:
  - 0.8122018458588037
  - 0.8112521782424694
  - 0.8125134843581444
  - 0.8095981928289916
  - 0.8123618187061424
  train_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_samples_oob:
  - 0.7869591274122019
  - 0.7894697535474234
  - 0.7870789883734867
  - 0.7873209651062193
  - 0.7881861001634144
  train_level0__recall_weighted:
  - 0.7695366164921881
  - 0.7635556646082962
  - 0.771056143415029
  - 0.7648499650374455
  - 0.7668929818398204
  train_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_weighted_oob:
  - 0.7184436425634391
  - 0.7204855573276626
  - 0.7199959171174851
  - 0.7205980116947213
  - 0.7179869352405397
  train_level0__roc_auc_macro:
  - 0.94220646580516
  - 0.942791740354963
  - 0.9388741193494395
  - 0.9389145244104243
  - 0.941133459589542
  train_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_macro_oob:
  - 0.5539966013019748
  - 0.5600405007289344
  - 0.5602630368402068
  - 0.5676606370699777
  - 0.5651116251747788
  train_level0__roc_auc_micro:
  - 0.8574524840886907
  - 0.8597247557477483
  - 0.857622072197446
  - 0.8574325657447465
  - 0.8583112496663224
  train_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_micro_oob:
  - 0.7465882613489757
  - 0.7535587062944706
  - 0.7482077443485677
  - 0.7479583044917855
  - 0.7503288073210421
  train_level0__roc_auc_samples:
  - 0.856492857985579
  - 0.8590551208553058
  - 0.856772911614257
  - 0.8559162947716704
  - 0.8571096248870109
  train_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_samples_oob:
  - 0.7490333392883747
  - 0.7574259696865796
  - 0.751567650073536
  - 0.7503491000106083
  - 0.753551403425029
  train_level0__roc_auc_weighted:
  - 0.923691934227409
  - 0.9244742422036323
  - 0.9191773205554739
  - 0.9204328973632602
  - 0.9209082807941285
  train_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_weighted_oob:
  - 0.5625549683476105
  - 0.5637348498699304
  - 0.56575878692395
  - 0.5706732520830523
  - 0.5680374460192841
  train_level0__tn_macro:
  - 0.7440009588876905
  - 0.7411501120238984
  - 0.7426345439290422
  - 0.7415168701336154
  - 0.7444967797750649
  train_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_macro_oob:
  - 0.7326621119501379
  - 0.731814787154593
  - 0.7311278916456909
  - 0.7324569835624339
  - 0.7336345285013939
  train_level0__tn_micro:
  - 0.7440009588876902
  - 0.7411501120238985
  - 0.7426345439290423
  - 0.7415168701336153
  - 0.7444967797750649
  train_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_micro_oob:
  - 0.7326621119501379
  - 0.731814787154593
  - 0.731127891645691
  - 0.7324569835624339
  - 0.7336345285013939
  train_level0__tn_samples:
  - 0.7440009588876902
  - 0.7411501120238984
  - 0.7426345439290423
  - 0.7415168701336152
  - 0.7444967797750648
  train_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_samples_oob:
  - 0.7326621119501378
  - 0.7318147871545929
  - 0.7311278916456909
  - 0.7324569835624339
  - 0.7336345285013938
  train_level0__tn_weighted:
  - 0.5984956509971024
  - 0.584144822039559
  - 0.5948729580861868
  - 0.5938301225209524
  - 0.5940002580996695
  train_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_weighted_oob:
  - 0.5737870917394873
  - 0.5640703935440777
  - 0.5702856883626508
  - 0.5742878279639633
  - 0.5702981051182597
  train_level0__tp_macro:
  - 0.06820088697111351
  - 0.07010206621857107
  - 0.06987894042910223
  - 0.06808132269537633
  - 0.06786503893107756
  train_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_macro_oob:
  - 0.054297015462064
  - 0.05765496639283047
  - 0.05595109672779575
  - 0.054863981543785446
  - 0.05455157166202057
  train_level0__tp_micro:
  - 0.06820088697111351
  - 0.07010206621857107
  - 0.06987894042910224
  - 0.06808132269537634
  - 0.06786503893107758
  train_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_micro_oob:
  - 0.05429701546206401
  - 0.05765496639283047
  - 0.05595109672779576
  - 0.054863981543785446
  - 0.05455157166202057
  train_level0__tp_samples:
  - 0.0682008869711135
  - 0.07010206621857105
  - 0.06987894042910223
  - 0.06808132269537633
  - 0.06786503893107755
  train_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_samples_oob:
  - 0.054297015462063995
  - 0.05765496639283046
  - 0.05595109672779575
  - 0.05486398154378544
  - 0.054551571662020557
  train_level0__tp_weighted:
  - 0.17104096549508563
  - 0.1794108425687373
  - 0.17618318532884217
  - 0.1710198425164932
  - 0.172892723740151
  train_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_weighted_oob:
  - 0.1446565508239517
  - 0.1564151637835848
  - 0.14971022875483425
  - 0.14631018373075794
  - 0.14768883012227982
  train_level10__average_precision_macro:
  - 0.2851462921618469
  - 0.2796692468205061
  - 0.2742000364847169
  - 0.28283261881490973
  - 0.2713054007158437
  train_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_macro_oob:
  - 0.2798036500154144
  - 0.2732205547913068
  - 0.2730007657842677
  - 0.27817420293388395
  - 0.2664812395124982
  train_level10__average_precision_micro:
  - 0.23572129876009396
  - 0.22054795527323406
  - 0.22057468714751322
  - 0.23756143248218747
  - 0.22881536867849958
  train_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_micro_oob:
  - 0.2351136256845135
  - 0.21957961304069973
  - 0.22025133022980842
  - 0.23692846097623
  - 0.2282792884003056
  train_level10__average_precision_samples:
  - 0.24688259797179457
  - 0.22948570521883294
  - 0.22807505157540567
  - 0.250467277800375
  - 0.23739184957031306
  train_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_samples_oob:
  - 0.24622936446287025
  - 0.22838150281321856
  - 0.22749831628488157
  - 0.24951261201594485
  - 0.23691726565037113
  train_level10__average_precision_weighted:
  - 0.4004241923233464
  - 0.40544896949836096
  - 0.39220575058328766
  - 0.39912770687251414
  - 0.38870988335269363
  train_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_weighted_oob:
  - 0.3940901920377263
  - 0.39735133613810164
  - 0.3905203011329527
  - 0.39293411920272864
  - 0.3832271025187707
  train_level10__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level10__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level10__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level10__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level10__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level10__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level10__label_ranking_average_precision_score:
  - 0.24688259797179443
  - 0.22948570521883305
  - 0.22807505157540556
  - 0.25046727780037525
  - 0.23739184957031287
  train_level10__label_ranking_average_precision_score_oob:
  - 0.2462293644628705
  - 0.22838150281321856
  - 0.2274983162848815
  - 0.2495126120159452
  - 0.2369172656503712
  train_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__ndcg:
  - 0.6163211993757273
  - 0.6018019773627389
  - 0.6082668879413095
  - 0.6132161820414138
  - 0.6132036318467354
  train_level10__ndcg_oob:
  - 0.6168736175678419
  - 0.6019117688138835
  - 0.6083949686017788
  - 0.614115395500714
  - 0.6134697432126932
  train_level10__neg_coverage_error:
  - -91.53827160493827
  - -92.38205128205128
  - -93.95802469135802
  - -90.60148514851485
  - -91.91089108910892
  train_level10__neg_coverage_error_oob:
  - -92.55802469135803
  - -93.63846153846154
  - -94.81728395061728
  - -91.74752475247524
  - -92.73514851485149
  train_level10__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level10__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level10__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level10__neg_label_ranking_loss:
  - -0.5032563503568649
  - -0.5419522151808347
  - -0.5864019972716152
  - -0.47833345063541
  - -0.5335825888386264
  train_level10__neg_label_ranking_loss_oob:
  - -0.5092017529438685
  - -0.5485335744721588
  - -0.591646005596779
  - -0.48478239772725057
  - -0.5379981777870915
  train_level10__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__roc_auc_macro:
  - 0.5726834127868007
  - 0.56939538691063
  - 0.5580576151588453
  - 0.5732965699661369
  - 0.5561538643079024
  train_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_macro_oob:
  - 0.5635320947831288
  - 0.5570389291979599
  - 0.5532250978495177
  - 0.5635867498556271
  - 0.5482724253608754
  train_level10__roc_auc_micro:
  - 0.5354774872728538
  - 0.5031129103484052
  - 0.4887920442607592
  - 0.5469257497532758
  - 0.5206410647839611
  train_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_micro_oob:
  - 0.5315260423566182
  - 0.4982832231404173
  - 0.48668691429566147
  - 0.5426063048507739
  - 0.517503770858361
  train_level10__roc_auc_samples:
  - 0.534557847742154
  - 0.5013929968255665
  - 0.48813308901609725
  - 0.5502952607007228
  - 0.5213887007387498
  train_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_samples_oob:
  - 0.530744942383594
  - 0.49630597401153737
  - 0.4858424370707567
  - 0.5457385218356144
  - 0.5185199101495014
  train_level10__roc_auc_weighted:
  - 0.5715400365797555
  - 0.5746492693640992
  - 0.5619307452365264
  - 0.575269801761598
  - 0.557043927941398
  train_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_weighted_oob:
  - 0.5606339359679227
  - 0.5615759518923263
  - 0.5570756600426976
  - 0.5646035825815275
  - 0.549046523413822
  train_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level10__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level10__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level10__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__average_precision_macro:
  - 0.29106369895330686
  - 0.2857283845453624
  - 0.28367757220867396
  - 0.2896980683364982
  - 0.27654555338960946
  train_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_macro_oob:
  - 0.28581263277994917
  - 0.28163586361816945
  - 0.2794498821948799
  - 0.28677831961203304
  - 0.27338005262962545
  train_level1__average_precision_micro:
  - 0.2370792239008645
  - 0.22169792122280363
  - 0.2215760899418785
  - 0.2395473111813125
  - 0.2306247763710541
  train_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_micro_oob:
  - 0.23688014810368035
  - 0.22115660445918117
  - 0.2214667605589936
  - 0.2391559142835247
  - 0.23075859282001915
  train_level1__average_precision_samples:
  - 0.2482906814279842
  - 0.23051870060837643
  - 0.22908826235943203
  - 0.25255683168607185
  - 0.2390730465212271
  train_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_samples_oob:
  - 0.24791408729394543
  - 0.22994612047160184
  - 0.22880341194339174
  - 0.2519314002910938
  - 0.2390539182652939
  train_level1__average_precision_weighted:
  - 0.4059072845361569
  - 0.41383237413305013
  - 0.40446822120510395
  - 0.4056661243593993
  - 0.3928192584607407
  train_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_weighted_oob:
  - 0.39970789101497367
  - 0.40930578947433094
  - 0.4005598971201581
  - 0.40217413280637265
  - 0.39067266309348936
  train_level1__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level1__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level1__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level1__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level1__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level1__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level1__label_ranking_average_precision_score:
  - 0.24829068142798433
  - 0.23051870060837631
  - 0.22908826235943217
  - 0.25255683168607174
  - 0.23907304652122716
  train_level1__label_ranking_average_precision_score_oob:
  - 0.24791408729394537
  - 0.22994612047160198
  - 0.22880341194339163
  - 0.2519314002910937
  - 0.23905391826529412
  train_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__ndcg:
  - 0.6171588489354738
  - 0.6023686373896774
  - 0.6087847530965643
  - 0.6147197002408322
  - 0.6149311672874727
  train_level1__ndcg_oob:
  - 0.618440799117588
  - 0.6027550096379426
  - 0.6092032226455398
  - 0.6159694337042908
  - 0.615727266061835
  train_level1__neg_coverage_error:
  - -91.14320987654321
  - -91.98717948717949
  - -93.86666666666666
  - -90.30445544554455
  - -91.5569306930693
  train_level1__neg_coverage_error_oob:
  - -92.02222222222223
  - -93.26666666666667
  - -94.64197530864197
  - -91.41831683168317
  - -92.3490099009901
  train_level1__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level1__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level1__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level1__neg_label_ranking_loss:
  - -0.5006883956676228
  - -0.5392621516195147
  - -0.5838025116608634
  - -0.4718418936529811
  - -0.5283523725950423
  train_level1__neg_label_ranking_loss_oob:
  - -0.5067970868581978
  - -0.5442850931731976
  - -0.5889261650491635
  - -0.47801316678531275
  - -0.5324562647572518
  train_level1__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__roc_auc_macro:
  - 0.5801898775723812
  - 0.5776033085067177
  - 0.5686043307976016
  - 0.5829501825887614
  - 0.5653744923637414
  train_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_macro_oob:
  - 0.5697896550597504
  - 0.567649089764158
  - 0.5608585808867212
  - 0.5736489867065806
  - 0.559191091672271
  train_level1__roc_auc_micro:
  - 0.5388118573174068
  - 0.5067790516039123
  - 0.49208383311110915
  - 0.5516656769411046
  - 0.5244851375179128
  train_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_micro_oob:
  - 0.5352463737491407
  - 0.5032816415500088
  - 0.4900262885929567
  - 0.5477367011132307
  - 0.5228164459697794
  train_level1__roc_auc_samples:
  - 0.5371554586905853
  - 0.5043229613628795
  - 0.49131349301282856
  - 0.5548051536741355
  - 0.5248129460024828
  train_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_samples_oob:
  - 0.533755576802405
  - 0.5007370985334691
  - 0.4891290501251047
  - 0.550675653965512
  - 0.5230103189035951
  train_level1__roc_auc_weighted:
  - 0.5798473003816426
  - 0.5852084937721334
  - 0.5740891496570184
  - 0.5838201866250318
  - 0.566636452920812
  train_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_weighted_oob:
  - 0.5689558755224966
  - 0.5754957056267134
  - 0.5669035174515352
  - 0.5731923653572517
  - 0.5613341661387519
  train_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level1__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level1__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level1__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__average_precision_macro:
  - 0.2828434216347194
  - 0.27925927842991477
  - 0.2776653960025046
  - 0.28213535717498345
  - 0.2706920385738795
  train_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_macro_oob:
  - 0.2780895987600234
  - 0.27516314721147533
  - 0.27463698772556905
  - 0.2755420865626757
  - 0.2673860632411242
  train_level2__average_precision_micro:
  - 0.23559202772555937
  - 0.22062574243598634
  - 0.2208271690353
  - 0.23742395184068277
  - 0.229181676101817
  train_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_micro_oob:
  - 0.23497938629400247
  - 0.22007510680278863
  - 0.22055270240220126
  - 0.2364308734915226
  - 0.22913661981255795
  train_level2__average_precision_samples:
  - 0.24686072414800983
  - 0.22973708395775785
  - 0.2283338873913871
  - 0.2503470720882722
  - 0.23799795774252167
  train_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_samples_oob:
  - 0.2462455135532474
  - 0.22911677232027308
  - 0.22782845307606983
  - 0.24901483983005976
  - 0.23773696555849985
  train_level2__average_precision_weighted:
  - 0.39621939653791916
  - 0.4029237103622365
  - 0.39473406269414535
  - 0.3978357343802563
  - 0.38897135646533976
  train_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_weighted_oob:
  - 0.3921509823952432
  - 0.39761035236159353
  - 0.3918652770150403
  - 0.39073136834164346
  - 0.384223628942626
  train_level2__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level2__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level2__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level2__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level2__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level2__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level2__label_ranking_average_precision_score:
  - 0.24686072414800986
  - 0.22973708395775766
  - 0.22833388739138707
  - 0.2503470720882722
  - 0.23799795774252172
  train_level2__label_ranking_average_precision_score_oob:
  - 0.24624551355324742
  - 0.22911677232027305
  - 0.22782845307606986
  - 0.24901483983006006
  - 0.23773696555849974
  train_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__ndcg:
  - 0.6164648774362979
  - 0.6018057778915177
  - 0.6083986034561707
  - 0.6127493339704245
  - 0.6135306942243097
  train_level2__ndcg_oob:
  - 0.6167786577481846
  - 0.6022951541108671
  - 0.6085718360395035
  - 0.6132604553260723
  - 0.6141309297686869
  train_level2__neg_coverage_error:
  - -91.65185185185184
  - -92.22307692307692
  - -93.91851851851852
  - -90.29950495049505
  - -91.7871287128713
  train_level2__neg_coverage_error_oob:
  - -92.7358024691358
  - -93.57692307692308
  - -94.64444444444445
  - -91.51980198019803
  - -92.63366336633663
  train_level2__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level2__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level2__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level2__neg_label_ranking_loss:
  - -0.5043612947012319
  - -0.5409404297336368
  - -0.5852098927028294
  - -0.4779322579121963
  - -0.5321488009414667
  train_level2__neg_label_ranking_loss_oob:
  - -0.5098199695145549
  - -0.5465048536071225
  - -0.5905342834220764
  - -0.4848130953408185
  - -0.5368185683904446
  train_level2__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__roc_auc_macro:
  - 0.569693324273084
  - 0.571879897364954
  - 0.5614590189908546
  - 0.5741918584111839
  - 0.5602936966857631
  train_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_macro_oob:
  - 0.5611579156386697
  - 0.5605253406107131
  - 0.5554574744941628
  - 0.5619322790329145
  - 0.5530847378242056
  train_level2__roc_auc_micro:
  - 0.534462631673231
  - 0.5036665732659984
  - 0.4896591147432423
  - 0.5471536019999463
  - 0.5216100157793254
  train_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_micro_oob:
  - 0.5306649621324251
  - 0.4997343118198157
  - 0.4874732286290192
  - 0.5422745780294298
  - 0.5194530729773519
  train_level2__roc_auc_samples:
  - 0.5336969356228708
  - 0.5023429675603336
  - 0.48927745719244425
  - 0.5507647002241391
  - 0.5228755519511153
  train_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_samples_oob:
  - 0.5300302966783579
  - 0.4981334413212565
  - 0.4867244061515304
  - 0.5456400022150459
  - 0.520097978589937
  train_level2__roc_auc_weighted:
  - 0.5659749301632775
  - 0.5752865784270602
  - 0.5651776058590724
  - 0.5763830880683349
  - 0.5616686236732894
  train_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_weighted_oob:
  - 0.5581713082282187
  - 0.5634193458488947
  - 0.5590788689428724
  - 0.5636769948188305
  - 0.5535731850178603
  train_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level2__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level2__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level2__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__average_precision_macro:
  - 0.2857123659861971
  - 0.2810322505957169
  - 0.2793776380402149
  - 0.2848385517128876
  - 0.2736546501442489
  train_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_macro_oob:
  - 0.2796582422448889
  - 0.2755136263170569
  - 0.2757632495389526
  - 0.2812815766297077
  - 0.26894362427070856
  train_level3__average_precision_micro:
  - 0.2358616169877254
  - 0.22069220366374148
  - 0.22093409534999797
  - 0.23805262941969965
  - 0.22938853992508274
  train_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_micro_oob:
  - 0.23503776107446142
  - 0.2198996747585117
  - 0.22105421859287258
  - 0.23785281478499531
  - 0.22889067405924
  train_level3__average_precision_samples:
  - 0.24701358083477867
  - 0.22945786647775962
  - 0.22845626342772776
  - 0.25079946039625284
  - 0.23808794408890718
  train_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_samples_oob:
  - 0.24625802406664168
  - 0.2285563911335436
  - 0.22827346012677577
  - 0.2503214097883016
  - 0.2373386727178553
  train_level3__average_precision_weighted:
  - 0.4003041032912678
  - 0.40618830109263643
  - 0.397697897358228
  - 0.4002245727105205
  - 0.39276937652557276
  train_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_weighted_oob:
  - 0.3943859533628065
  - 0.4003755185145538
  - 0.3940069634760653
  - 0.3959570136619782
  - 0.38762558063610225
  train_level3__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level3__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level3__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level3__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level3__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level3__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level3__label_ranking_average_precision_score:
  - 0.2470135808347787
  - 0.22945786647775968
  - 0.2284562634277278
  - 0.25079946039625317
  - 0.23808794408890716
  train_level3__label_ranking_average_precision_score_oob:
  - 0.24625802406664146
  - 0.2285563911335437
  - 0.22827346012677577
  - 0.25032140978830153
  - 0.23733867271785547
  train_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__ndcg:
  - 0.6165823782032449
  - 0.6014663244985882
  - 0.608535507076194
  - 0.6135613142796175
  - 0.6138046815946169
  train_level3__ndcg_oob:
  - 0.6168368941442639
  - 0.6017310244905689
  - 0.6091823507562438
  - 0.6152810738382225
  - 0.6139741505805191
  train_level3__neg_coverage_error:
  - -91.49876543209876
  - -92.44615384615385
  - -93.89135802469136
  - -90.70792079207921
  - -91.97524752475248
  train_level3__neg_coverage_error_oob:
  - -92.5111111111111
  - -93.81025641025641
  - -94.77283950617284
  - -91.7549504950495
  - -92.83168316831683
  train_level3__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level3__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level3__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level3__neg_label_ranking_loss:
  - -0.5033917255839012
  - -0.541321636593788
  - -0.5856250623664879
  - -0.4768366056606058
  - -0.5318374562571081
  train_level3__neg_label_ranking_loss_oob:
  - -0.5090333710261474
  - -0.5474652024946007
  - -0.5911658195199162
  - -0.48275356673280545
  - -0.5370515563677065
  train_level3__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__roc_auc_macro:
  - 0.5712924615904531
  - 0.5720371722941703
  - 0.5640602600996479
  - 0.5779827812206906
  - 0.559875289150534
  train_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_macro_oob:
  - 0.559059521396466
  - 0.5619809026165045
  - 0.5565629284463557
  - 0.568717811911361
  - 0.5514977660201473
  train_level3__roc_auc_micro:
  - 0.5354759691726461
  - 0.5041200235739485
  - 0.48972658022586885
  - 0.5482388301321706
  - 0.5221059043581212
  train_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_micro_oob:
  - 0.531169338502727
  - 0.499732410973654
  - 0.4879335874477215
  - 0.5445836215880906
  - 0.5191627995794144
  train_level3__roc_auc_samples:
  - 0.5344831109390586
  - 0.5017563985655439
  - 0.4891485085722888
  - 0.5519332386613681
  - 0.5235705284642634
  train_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_samples_oob:
  - 0.530666303998205
  - 0.49697926418228
  - 0.4868487890029365
  - 0.5482448391787709
  - 0.5201856247912815
  train_level3__roc_auc_weighted:
  - 0.5686653113522412
  - 0.5773855495188775
  - 0.5682477953705694
  - 0.5782227369949992
  - 0.5643551585337313
  train_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_weighted_oob:
  - 0.5572211013853051
  - 0.5661719176624516
  - 0.5605821194396088
  - 0.5680253728072975
  - 0.5562587128225165
  train_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level3__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level3__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level3__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__average_precision_macro:
  - 0.28440096772022583
  - 0.28380570170064556
  - 0.27931776929294483
  - 0.2829590583310762
  - 0.26932236798726766
  train_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_macro_oob:
  - 0.2796480346703419
  - 0.2757065983307641
  - 0.2769121612127284
  - 0.2776940033958038
  - 0.26562983754005226
  train_level4__average_precision_micro:
  - 0.23557053116797555
  - 0.2209478885875698
  - 0.2205125293304394
  - 0.23759470310189304
  - 0.22853058293992004
  train_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_micro_oob:
  - 0.23501458681568937
  - 0.22014916032641135
  - 0.22026086560402747
  - 0.2370991134638519
  - 0.228118678321875
  train_level4__average_precision_samples:
  - 0.2469824567340835
  - 0.2297711122860581
  - 0.2279867687114245
  - 0.25044987801517316
  - 0.23714602983597538
  train_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_samples_oob:
  - 0.2461724942566072
  - 0.2288846675560946
  - 0.2274186952502544
  - 0.24965824869427253
  - 0.23653862652697688
  train_level4__average_precision_weighted:
  - 0.39982081226136684
  - 0.4107670444626741
  - 0.3970838081420301
  - 0.3976391109873001
  - 0.3835962771777386
  train_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_weighted_oob:
  - 0.3946313415534093
  - 0.401181174419875
  - 0.3941213264136206
  - 0.3931208064685122
  - 0.3793621560595486
  train_level4__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level4__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level4__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level4__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level4__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level4__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level4__label_ranking_average_precision_score:
  - 0.24698245673408328
  - 0.229771112286058
  - 0.22798676871142454
  - 0.25044987801517304
  - 0.23714602983597527
  train_level4__label_ranking_average_precision_score_oob:
  - 0.24617249425660737
  - 0.22888466755609468
  - 0.22741869525025424
  - 0.24965824869427253
  - 0.23653862652697685
  train_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__ndcg:
  - 0.6162039234882561
  - 0.6016458625066369
  - 0.6080154359547324
  - 0.613578017782247
  - 0.6128925384498765
  train_level4__ndcg_oob:
  - 0.6165883329306568
  - 0.6018961199041032
  - 0.608183533859678
  - 0.6146966847199036
  - 0.6132516869209886
  train_level4__neg_coverage_error:
  - -91.41975308641975
  - -92.36666666666666
  - -94.17283950617283
  - -90.72277227722772
  - -92.00742574257426
  train_level4__neg_coverage_error_oob:
  - -92.49135802469135
  - -93.48461538461538
  - -94.89382716049383
  - -91.89356435643565
  - -92.85148514851485
  train_level4__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level4__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level4__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level4__neg_label_ranking_loss:
  - -0.5026993107746585
  - -0.5407497865104209
  - -0.5863760194045489
  - -0.47850121851011407
  - -0.5337866335154919
  train_level4__neg_label_ranking_loss_oob:
  - -0.5083131382259778
  - -0.5467815753592267
  - -0.592137448166085
  - -0.4848930839473863
  - -0.5387789841391676
  train_level4__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__roc_auc_macro:
  - 0.5722288954437899
  - 0.5745225227624435
  - 0.5627159959590369
  - 0.5730025204954701
  - 0.5582999116152942
  train_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_macro_oob:
  - 0.5632791402167694
  - 0.5642671051814111
  - 0.5562523224159232
  - 0.561807941984627
  - 0.5493772649981347
  train_level4__roc_auc_micro:
  - 0.5351313091274782
  - 0.5047084978969297
  - 0.4890456734137991
  - 0.546798406564346
  - 0.5202380092905298
  train_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_micro_oob:
  - 0.5316722095973212
  - 0.5004694260559178
  - 0.48692355275786664
  - 0.5427527273384187
  - 0.5171777281615211
  train_level4__roc_auc_samples:
  - 0.5344963865246452
  - 0.5024691746380799
  - 0.48844169359896256
  - 0.55053230222943
  - 0.5212603782351298
  train_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_samples_oob:
  - 0.5309007019731826
  - 0.49801229646714856
  - 0.48574321557621974
  - 0.5460757592578419
  - 0.5179020028833423
  train_level4__roc_auc_weighted:
  - 0.5725452802364113
  - 0.5801496188854873
  - 0.5679895468300662
  - 0.5741494845717319
  - 0.5573491808852409
  train_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_weighted_oob:
  - 0.5633789924208633
  - 0.5684999079971997
  - 0.5612292083142847
  - 0.563470087451458
  - 0.5489683791115586
  train_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level4__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level4__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level4__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__average_precision_macro:
  - 0.28635717202606675
  - 0.27881529725917964
  - 0.28174646576036205
  - 0.2863955199165549
  - 0.270688586806268
  train_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_macro_oob:
  - 0.2794370550164269
  - 0.27245337934607816
  - 0.2781629252002483
  - 0.28243608548152144
  - 0.26426541096545103
  train_level5__average_precision_micro:
  - 0.2354966359359157
  - 0.2204536014751891
  - 0.22105946993782832
  - 0.2381055784028738
  - 0.22895602179377533
  train_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_micro_oob:
  - 0.23446647024978373
  - 0.21956792934611957
  - 0.22094596840297678
  - 0.23754543848633683
  - 0.2283228465134881
  train_level5__average_precision_samples:
  - 0.2466137510549468
  - 0.22909047050697717
  - 0.22858060428879967
  - 0.25095609606586516
  - 0.23765152694974506
  train_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_samples_oob:
  - 0.24565052990285932
  - 0.2280190488274786
  - 0.22817709002072414
  - 0.2501238501120781
  - 0.23696172604061078
  train_level5__average_precision_weighted:
  - 0.39880069262028883
  - 0.40300782803710794
  - 0.4009329477691383
  - 0.40245296374671663
  - 0.3870305926345398
  train_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_weighted_oob:
  - 0.39135873571323526
  - 0.39522090891593636
  - 0.39601000512856444
  - 0.3991352065346273
  - 0.37966281623905507
  train_level5__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level5__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level5__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level5__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level5__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level5__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level5__label_ranking_average_precision_score:
  - 0.24661375105494715
  - 0.22909047050697706
  - 0.22858060428879973
  - 0.2509560960658651
  - 0.23765152694974526
  train_level5__label_ranking_average_precision_score_oob:
  - 0.24565052990285918
  - 0.22801904882747845
  - 0.22817709002072428
  - 0.2501238501120783
  - 0.23696172604061083
  train_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__ndcg:
  - 0.6159648855682209
  - 0.601481528856568
  - 0.6086550920348429
  - 0.6140370944719311
  - 0.6135663803639301
  train_level5__ndcg_oob:
  - 0.6159609926903439
  - 0.6016782088915976
  - 0.609013299112487
  - 0.6151688744531724
  - 0.6138227641607664
  train_level5__neg_coverage_error:
  - -91.46913580246914
  - -92.7
  - -93.92592592592592
  - -90.82425742574257
  - -91.91584158415841
  train_level5__neg_coverage_error_oob:
  - -92.47407407407407
  - -93.8974358974359
  - -94.61975308641975
  - -91.77227722772277
  - -92.58910891089108
  train_level5__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level5__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level5__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level5__neg_label_ranking_loss:
  - -0.5036461460753829
  - -0.54268176717422
  - -0.5854634715773228
  - -0.4781622194062761
  - -0.5333789766956442
  train_level5__neg_label_ranking_loss_oob:
  - -0.5093647360051424
  - -0.549115184092053
  - -0.5905113148179849
  - -0.4844953262057204
  - -0.5384806665992131
  train_level5__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__roc_auc_macro:
  - 0.5720811669377323
  - 0.5689139567455072
  - 0.5632812399799995
  - 0.5745677277249904
  - 0.5580323188102555
  train_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_macro_oob:
  - 0.5613257396783321
  - 0.5572364898820821
  - 0.5578193218338198
  - 0.5626899220602313
  - 0.5486255207536319
  train_level5__roc_auc_micro:
  - 0.535089379424168
  - 0.5029368246001981
  - 0.4901804600045502
  - 0.5473409250009177
  - 0.5206612307543499
  train_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_micro_oob:
  - 0.5305909262929359
  - 0.49839003859840936
  - 0.488210422501014
  - 0.5429914395649913
  - 0.5170862696975022
  train_level5__roc_auc_samples:
  - 0.5337678361156883
  - 0.500608146745047
  - 0.48957408492288157
  - 0.5510716460192807
  - 0.5217276472395922
  train_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_samples_oob:
  - 0.5296078786067334
  - 0.4956626434256737
  - 0.4870943826516673
  - 0.546801806214107
  - 0.5183881477133337
  train_level5__roc_auc_weighted:
  - 0.5694149089716188
  - 0.5737151765078266
  - 0.5685808223277694
  - 0.576995834901017
  - 0.5570965899476394
  train_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_weighted_oob:
  - 0.5592082512771502
  - 0.56052844858785
  - 0.5620959248788729
  - 0.5666467992494284
  - 0.5465934767939686
  train_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level5__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level5__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level5__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__average_precision_macro:
  - 0.2792291296896108
  - 0.2813959512971157
  - 0.2800494274588552
  - 0.2844071421068403
  - 0.27216183080703177
  train_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_macro_oob:
  - 0.27443041016936726
  - 0.2728651215049277
  - 0.27654560428831976
  - 0.27849748398691115
  - 0.2679359294354246
  train_level6__average_precision_micro:
  - 0.23484713140749186
  - 0.22077683617265423
  - 0.2213406943040594
  - 0.23802621959835366
  - 0.22865842485567628
  train_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_micro_oob:
  - 0.2340428075258597
  - 0.2199485739806606
  - 0.2212607240660796
  - 0.23705473935873753
  - 0.22827459849860077
  train_level6__average_precision_samples:
  - 0.2462626256915663
  - 0.22958471738877223
  - 0.2288850671007646
  - 0.2507260791977285
  - 0.23740078221420227
  train_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_samples_oob:
  - 0.2453245264656009
  - 0.22873925789223173
  - 0.22855833701667655
  - 0.24955161549057028
  - 0.23689353482153597
  train_level6__average_precision_weighted:
  - 0.3938147010203852
  - 0.4076056310005974
  - 0.39941979159849816
  - 0.399623864067633
  - 0.38813100028795083
  train_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_weighted_oob:
  - 0.38864792807872656
  - 0.3980690534231624
  - 0.39539470625718426
  - 0.39400456672979034
  - 0.3834221873237274
  train_level6__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level6__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level6__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level6__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level6__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level6__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level6__label_ranking_average_precision_score:
  - 0.24626262569156643
  - 0.22958471738877229
  - 0.22888506710076464
  - 0.2507260791977287
  - 0.23740078221420216
  train_level6__label_ranking_average_precision_score_oob:
  - 0.24532452646560118
  - 0.2287392578922318
  - 0.22855833701667674
  - 0.24955161549057028
  - 0.23689353482153588
  train_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__ndcg:
  - 0.6159539683390568
  - 0.601633123185318
  - 0.6088764679268627
  - 0.6138690155337797
  - 0.613100046323135
  train_level6__ndcg_oob:
  - 0.6162202010819107
  - 0.6020018004217312
  - 0.6094011143893019
  - 0.6144952113198661
  - 0.6133741236270492
  train_level6__neg_coverage_error:
  - -91.72345679012345
  - -92.53076923076924
  - -93.9679012345679
  - -90.59653465346534
  - -92.11138613861387
  train_level6__neg_coverage_error_oob:
  - -92.8641975308642
  - -93.83333333333333
  - -94.71358024691358
  - -91.77475247524752
  - -92.88118811881188
  train_level6__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level6__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level6__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level6__neg_label_ranking_loss:
  - -0.5044729037529054
  - -0.5410594173865747
  - -0.5848750555097689
  - -0.4781314100009853
  - -0.5329382029617883
  train_level6__neg_label_ranking_loss_oob:
  - -0.5103109350651877
  - -0.5471185259503296
  - -0.5906200620548102
  - -0.48469242211044555
  - -0.5374828595113411
  train_level6__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__roc_auc_macro:
  - 0.5684339223537502
  - 0.5714430703227271
  - 0.5666771576542863
  - 0.5740920272520439
  - 0.5587002532732804
  train_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_macro_oob:
  - 0.5579078844709969
  - 0.55855414789849
  - 0.5598459115086797
  - 0.561539293732304
  - 0.5506307703597163
  train_level6__roc_auc_micro:
  - 0.5330647803913033
  - 0.5041091109889385
  - 0.49106558769309355
  - 0.5475365717899477
  - 0.5204606299460564
  train_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_micro_oob:
  - 0.5288160699733456
  - 0.49956337390862265
  - 0.48900926638955516
  - 0.542694046159463
  - 0.5176878260182078
  train_level6__roc_auc_samples:
  - 0.5328143529757816
  - 0.5020927982235752
  - 0.49064774374307296
  - 0.5510774741530665
  - 0.521877785468245
  train_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_samples_oob:
  - 0.5286056028912879
  - 0.49753929945848613
  - 0.4884588901354031
  - 0.5462394290229919
  - 0.5190865084417542
  train_level6__roc_auc_weighted:
  - 0.566290122577029
  - 0.577216858781666
  - 0.5704706987350366
  - 0.5753858034261353
  - 0.5595258699989872
  train_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_weighted_oob:
  - 0.5563021996867075
  - 0.563616388854852
  - 0.5633324668628915
  - 0.5638624052895427
  - 0.5509210560206536
  train_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level6__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level6__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level6__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__average_precision_macro:
  - 0.28446010460877347
  - 0.27944995895664226
  - 0.27972190440225436
  - 0.28546672998670086
  - 0.2688764835211217
  train_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_macro_oob:
  - 0.2817345890233523
  - 0.27175694952492574
  - 0.2746735228458454
  - 0.2837998079127759
  - 0.26607871063975574
  train_level7__average_precision_micro:
  - 0.23585854829139247
  - 0.2205094718877027
  - 0.2206664840177375
  - 0.23812321462783276
  - 0.22878763619670228
  train_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_micro_oob:
  - 0.2356012753922288
  - 0.21941025080677357
  - 0.22022326176119378
  - 0.2376223256142886
  - 0.2287592625958147
  train_level7__average_precision_samples:
  - 0.24730965764802446
  - 0.22937700588722035
  - 0.2283195356272592
  - 0.25107156721199825
  - 0.2374757500612274
  train_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_samples_oob:
  - 0.24670314676606134
  - 0.2281750988704926
  - 0.22764610190421086
  - 0.25026319126419205
  - 0.23729460737185398
  train_level7__average_precision_weighted:
  - 0.3988890326862061
  - 0.40326426402743704
  - 0.39808594393463137
  - 0.4010351492960415
  - 0.38463493944975014
  train_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_weighted_oob:
  - 0.3964467248947382
  - 0.39486589430782326
  - 0.39222256270209155
  - 0.3983820791090636
  - 0.3830458693209191
  train_level7__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level7__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level7__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level7__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level7__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level7__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level7__label_ranking_average_precision_score:
  - 0.24730965764802437
  - 0.22937700588722024
  - 0.2283195356272591
  - 0.25107156721199814
  - 0.23747575006122718
  train_level7__label_ranking_average_precision_score_oob:
  - 0.24670314676606125
  - 0.2281750988704925
  - 0.22764610190421083
  - 0.250263191264192
  - 0.23729460737185407
  train_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__ndcg:
  - 0.6166306987313871
  - 0.6013426683496327
  - 0.6083785825274508
  - 0.6135865758493139
  - 0.613492096933148
  train_level7__ndcg_oob:
  - 0.6172415432875159
  - 0.6012557286774797
  - 0.6084518166685359
  - 0.614496709959437
  - 0.6142511050951722
  train_level7__neg_coverage_error:
  - -91.50617283950618
  - -92.4948717948718
  - -93.95802469135802
  - -90.5519801980198
  - -92.01237623762377
  train_level7__neg_coverage_error_oob:
  - -92.54320987654322
  - -93.7
  - -94.75061728395062
  - -91.78465346534654
  - -92.66584158415841
  train_level7__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level7__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level7__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level7__neg_label_ranking_loss:
  - -0.5028348026638253
  - -0.541612112309957
  - -0.5858743261362455
  - -0.47719388835182014
  - -0.5335773206283766
  train_level7__neg_label_ranking_loss_oob:
  - -0.5082760648470399
  - -0.548287336848952
  - -0.5916093492269542
  - -0.4830897457510862
  - -0.5377915743523741
  train_level7__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__roc_auc_macro:
  - 0.5714285088824097
  - 0.571945683111199
  - 0.5605019982587932
  - 0.5771335694744487
  - 0.5554632381660848
  train_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_macro_oob:
  - 0.5635274495142482
  - 0.5597672289071972
  - 0.5522198627557352
  - 0.5686175479775115
  - 0.5490995335397183
  train_level7__roc_auc_micro:
  - 0.5355393254096176
  - 0.503571427275397
  - 0.4891541093906152
  - 0.5482270781456318
  - 0.5201658360030105
  train_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_micro_oob:
  - 0.5324971215249059
  - 0.4985970096406597
  - 0.4864897320998819
  - 0.5443598114976216
  - 0.518077910850155
  train_level7__roc_auc_samples:
  - 0.5349248425162705
  - 0.5014638539490285
  - 0.4888096480187476
  - 0.5516596011825282
  - 0.5215390581601461
  train_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_samples_oob:
  - 0.5315933076370563
  - 0.49616004150198273
  - 0.4860914653099481
  - 0.5476306145655628
  - 0.5193848970812781
  train_level7__roc_auc_weighted:
  - 0.5704346512764599
  - 0.5766802106097133
  - 0.5645627962308868
  - 0.5795464956963239
  - 0.5560154750034061
  train_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_weighted_oob:
  - 0.5648127210096463
  - 0.5640087488537303
  - 0.5557469474016221
  - 0.5702289608016836
  - 0.5500412017919535
  train_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level7__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level7__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level7__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__average_precision_macro:
  - 0.28038531721861054
  - 0.27848143444574514
  - 0.2722710331700245
  - 0.2832124832386453
  - 0.2721491656751862
  train_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_macro_oob:
  - 0.2753494876997947
  - 0.271682125081417
  - 0.2707945208787866
  - 0.2775799920091632
  - 0.26956182273752344
  train_level8__average_precision_micro:
  - 0.23527393233019112
  - 0.22071019571805356
  - 0.22043994596336733
  - 0.2374450906770939
  - 0.2292953969435454
  train_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_micro_oob:
  - 0.23448621401503153
  - 0.2197764946986007
  - 0.2199653693767148
  - 0.23662033608355298
  - 0.2289393240561694
  train_level8__average_precision_samples:
  - 0.24656402264210694
  - 0.2296902644210118
  - 0.22800792565344255
  - 0.2502485827194711
  - 0.2378823135029231
  train_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_samples_oob:
  - 0.2457667333495149
  - 0.22855400215590652
  - 0.22731928040711438
  - 0.24913696017318196
  - 0.23740699958985434
  train_level8__average_precision_weighted:
  - 0.3943255152692109
  - 0.40504968387047574
  - 0.390461738342919
  - 0.3978504529736271
  - 0.38948391144888583
  train_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_weighted_oob:
  - 0.38952034677757325
  - 0.3971080543808385
  - 0.38838938800269734
  - 0.39080762153441134
  - 0.38637097707971
  train_level8__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level8__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level8__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level8__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level8__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level8__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level8__label_ranking_average_precision_score:
  - 0.24656402264210683
  - 0.22969026442101195
  - 0.22800792565344255
  - 0.25024858271947115
  - 0.23788231350292313
  train_level8__label_ranking_average_precision_score_oob:
  - 0.2457667333495148
  - 0.2285540021559063
  - 0.2273192804071145
  - 0.24913696017318196
  - 0.23740699958985423
  train_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__ndcg:
  - 0.6161582773251708
  - 0.6017945060290896
  - 0.6082582725427962
  - 0.6130523277339415
  - 0.6138241447481558
  train_level8__ndcg_oob:
  - 0.6164506761255412
  - 0.6018243580913044
  - 0.6082042828592811
  - 0.6137240217729473
  - 0.6141078019592173
  train_level8__neg_coverage_error:
  - -91.74074074074075
  - -92.1974358974359
  - -94.06172839506173
  - -90.68564356435644
  - -91.96534653465346
  train_level8__neg_coverage_error_oob:
  - -92.80740740740741
  - -93.44358974358974
  - -94.82962962962964
  - -91.86138613861387
  - -92.65841584158416
  train_level8__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level8__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level8__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level8__neg_label_ranking_loss:
  - -0.504125117796892
  - -0.5412269206312216
  - -0.5871921551585281
  - -0.4783004335603709
  - -0.5329197264602531
  train_level8__neg_label_ranking_loss_oob:
  - -0.5099887408906238
  - -0.5478136948691685
  - -0.5925736374029064
  - -0.4849380260662402
  - -0.5373176430498715
  train_level8__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__roc_auc_macro:
  - 0.5686867064526164
  - 0.5695788886203957
  - 0.5565829311283607
  - 0.5729073494762998
  - 0.5575634355771277
  train_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_macro_oob:
  - 0.559799728161109
  - 0.5589602754426206
  - 0.550623666871561
  - 0.5621823688769413
  - 0.5510847990569974
  train_level8__roc_auc_micro:
  - 0.5341225724174998
  - 0.5038634767357598
  - 0.488008355441645
  - 0.5465905111580547
  - 0.521347778828056
  train_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_micro_oob:
  - 0.5299375308337053
  - 0.49919611660585256
  - 0.48549516587823105
  - 0.5420536609334587
  - 0.5187870810786804
  train_level8__roc_auc_samples:
  - 0.5335073366084769
  - 0.5021575586766917
  - 0.4878163066587363
  - 0.5503900587159364
  - 0.5225441605026311
  train_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_samples_oob:
  - 0.529542475552243
  - 0.49701874487804165
  - 0.4851429884233883
  - 0.5455795569226655
  - 0.5200000546122768
  train_level8__roc_auc_weighted:
  - 0.5669584639913631
  - 0.577607750429211
  - 0.5602132552910982
  - 0.5747123122072909
  - 0.5611784084006648
  train_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_weighted_oob:
  - 0.55974632883675
  - 0.5653550699698996
  - 0.554243192240212
  - 0.562245210866408
  - 0.5532446382056172
  train_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level8__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level8__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level8__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__average_precision_macro:
  - 0.28319158714668313
  - 0.28138473134269837
  - 0.2810222054414094
  - 0.28535830919453203
  - 0.27100072342994824
  train_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_macro_oob:
  - 0.2800697460941765
  - 0.27675960442993863
  - 0.2769694402782301
  - 0.27943552085935197
  - 0.2660777860860821
  train_level9__average_precision_micro:
  - 0.23551487373120883
  - 0.22064919947122458
  - 0.2206553260292836
  - 0.23788861331739497
  - 0.22872509136856536
  train_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_micro_oob:
  - 0.2349813389081713
  - 0.22001104400439148
  - 0.22052722453598012
  - 0.23694442306585678
  - 0.2283838853085158
  train_level9__average_precision_samples:
  - 0.2467819349307133
  - 0.22954605274707834
  - 0.22819730700622526
  - 0.2506466499867355
  - 0.23713549318538849
  train_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_samples_oob:
  - 0.2460601656801824
  - 0.22878334735167816
  - 0.22774718606172703
  - 0.24950226165315068
  - 0.2368170274190759
  train_level9__average_precision_weighted:
  - 0.40039742505038567
  - 0.4073079746258434
  - 0.3979348547920742
  - 0.40211449424996987
  - 0.3880492550987467
  train_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_weighted_oob:
  - 0.3948945710170849
  - 0.4015652111890838
  - 0.39363686931941105
  - 0.39555054039901266
  - 0.3831103956232828
  train_level9__f1_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__f1_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__f1_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__f1_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fp_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level9__fp_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__fp_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__fp_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level9__jaccard_macro:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_macro_oob:
  - 0.14361646898204108
  - 0.1443938466944068
  - 0.14453331459251523
  - 0.14420313038850435
  - 0.14266569642284935
  train_level9__jaccard_micro:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_micro_oob:
  - 0.13249806567212805
  - 0.13258617043772467
  - 0.1330517566851819
  - 0.1330084134288126
  - 0.1314218905066819
  train_level9__jaccard_samples:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_samples_oob:
  - 0.1334427670061139
  - 0.1335067159188144
  - 0.134008224732261
  - 0.13392598566812391
  - 0.13238297141499167
  train_level9__jaccard_weighted:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_weighted_oob:
  - 0.22753017182375637
  - 0.23345046713754844
  - 0.230827236547264
  - 0.2283686103841237
  - 0.22822074263941383
  train_level9__label_ranking_average_precision_score:
  - 0.2467819349307133
  - 0.2295460527470784
  - 0.2281973070062252
  - 0.2506466499867356
  - 0.2371354931853887
  train_level9__label_ranking_average_precision_score_oob:
  - 0.24606016568018235
  - 0.22878334735167796
  - 0.22774718606172709
  - 0.24950226165315068
  - 0.2368170274190758
  train_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__ndcg:
  - 0.6162269569948875
  - 0.6017476067165688
  - 0.6083414755420175
  - 0.6134111569797203
  - 0.6132443682666066
  train_level9__ndcg_oob:
  - 0.6165994107110582
  - 0.6021229194382373
  - 0.6086729850227658
  - 0.6138099082831688
  - 0.61364733833054
  train_level9__neg_coverage_error:
  - -91.70370370370371
  - -92.47179487179487
  - -93.75802469135803
  - -90.57673267326733
  - -91.96039603960396
  train_level9__neg_coverage_error_oob:
  - -92.71111111111111
  - -93.75641025641026
  - -94.66913580246914
  - -91.81188118811882
  - -92.88861386138613
  train_level9__neg_hamming_loss_macro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_macro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.765144432458348
  - -0.7652119580890128
  - -0.7676872056137654
  train_level9__neg_hamming_loss_micro:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_micro_oob:
  - -0.7660074313795997
  - -0.7658700522778192
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__neg_hamming_loss_samples:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_samples_oob:
  - -0.7660074313795996
  - -0.7658700522778191
  - -0.7651444324583483
  - -0.7652119580890128
  - -0.7676872056137652
  train_level9__neg_hamming_loss_weighted:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.6550988375255015
  - -0.6489022478496163
  - -0.6525187226626444
  - -0.6545329712090964
  - -0.6545026101865384
  train_level9__neg_label_ranking_loss:
  - -0.5031159485026169
  - -0.5418195831837359
  - -0.58580997737511
  - -0.477707170107737
  - -0.5347711618652725
  train_level9__neg_label_ranking_loss_oob:
  - -0.5088251534583705
  - -0.5474490017676537
  - -0.5914497800465812
  - -0.4841505335461381
  - -0.538789575728439
  train_level9__precision_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__precision_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__precision_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__precision_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__recall_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__recall_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__recall_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__recall_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__roc_auc_macro:
  - 0.5734981343333361
  - 0.568716564270013
  - 0.5616419440750211
  - 0.5748791230654603
  - 0.554884739414043
  train_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_macro_oob:
  - 0.5631751553999964
  - 0.5595046122501177
  - 0.5549792098552305
  - 0.5640774324118114
  - 0.5483970313012343
  train_level9__roc_auc_micro:
  - 0.5349774343621723
  - 0.5034049546246421
  - 0.4891337832413688
  - 0.547574801105021
  - 0.5199622333714249
  train_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_micro_oob:
  - 0.5312749194065126
  - 0.49953679143907276
  - 0.4870336820474621
  - 0.5430313436024352
  - 0.5173338084007433
  train_level9__roc_auc_samples:
  - 0.5341490579564021
  - 0.5014475431414933
  - 0.4887900367857987
  - 0.5511265596412069
  - 0.5204677592305388
  train_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_samples_oob:
  - 0.5301955404690618
  - 0.49730123736484855
  - 0.48620733949674316
  - 0.5463023071489482
  - 0.5181850898040741
  train_level9__roc_auc_weighted:
  - 0.5742310619666429
  - 0.5754337965088031
  - 0.5650059394255822
  - 0.579947013349481
  - 0.5571889784810478
  train_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_weighted_oob:
  - 0.5630968789647456
  - 0.5647024806827421
  - 0.5574629378452757
  - 0.5684450292056251
  - 0.5507853173831888
  train_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tp_macro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_macro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.2348555675416517
  - 0.2347880419109872
  - 0.23231279438623476
  train_level9__tp_micro:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_micro_oob:
  - 0.23399256862040033
  - 0.23412994772218074
  - 0.23485556754165168
  - 0.2347880419109872
  - 0.23231279438623473
  train_level9__tp_samples:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_samples_oob:
  - 0.2339925686204003
  - 0.23412994772218068
  - 0.23485556754165163
  - 0.23478804191098715
  - 0.23231279438623467
  train_level9__tp_weighted:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
  train_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_weighted_oob:
  - 0.34490116247449853
  - 0.3510977521503838
  - 0.34748127733735584
  - 0.3454670287909036
  - 0.3454973898134615
start: 2023-12-30 21:16:53.819680
wrapper: null
