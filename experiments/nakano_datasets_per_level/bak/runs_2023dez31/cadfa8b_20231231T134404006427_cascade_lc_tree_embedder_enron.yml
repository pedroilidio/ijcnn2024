active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            0MzMzMzM/D/MzMzMzMwYwICZmZmZmcm/NDMzMzMzE0CAmZmZmZnJvw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8BoZmZmZmYWQGBmZmZmZva/mJmZmZmZFcBoZmZmZmYSQA==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8CgmZmZmZn5P6CZmZmZmfk/gJmZmZmZ2b9AMzMzMzPjPw==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ADQzMzMz4z8AmJmZmZnZvwCYmZmZmdm/AJiZmZmZ2b8ANDMzMzPjPw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T9oZmZmZmb2P6CZmZmZmdk/aGZmZmZm9j/MzMzMzMwMwA==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gDMzMzMz4z8AmZmZmZnZv4AzMzMzM+M/AJmZmZmZ2b8AmZmZmZnZvw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAHEAAAAAAAAAIwAAAAAAAAAAAAAAAAAAACEAAAAAAAAAcwA==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ2b84MzMzMzPjP5CZmZmZmdm/Z2ZmZmZmEkCZmZmZmZkRwA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz47/AmZmZmZnZP3BmZmZmZvY/yMzMzMzMBMBwZmZmZmb2Pw==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT9AMzMzMzPzP2BmZmZmZgbAAJqZmZmZyT9AMzMzMzPzPw==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAgwAAAAAAAAPC/AAAAAAAA8L8AAAAAAAAYQA==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/AJqZmZmZyT+AmZmZmZnpvw==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsDMzMzMzMwEwJqZmZmZmRVAaGZmZmZm9j+gmZmZmZnZPw==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEMBoZmZmZmYOQGhmZmZmZgZAzMzMzMzMHMA0MzMzMzMTQA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZGcDQzMzMzMwEQICZmZmZmdm/oJmZmZmZ+T/QzMzMzMwEQA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ2b+cmZmZmZn5PzgzMzMzM+M/kJmZmZmZ2b9kZmZmZmb2vw==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcA4MzMzMzMTQACZmZmZmcm/wJmZmZmZ6T+QmZmZmZkJwA==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+gmZmZmZnpPzAzMzMzM/O/gJmZmZmZyb+gmZmZmZnpPw==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b9kZmZmZmYGwMjMzMzMzPy/yMzMzMzM/L/OzMzMzMwcQA==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8L8AAAAAAAAAwA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/AJqZmZmZyT+AmZmZmZnpvw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZFcBoZmZmZmYaQGhmZmZmZhpAmJmZmZmZFcAwMzMzMzMDwA==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          ADIzMzMz47/AmZmZmZkdQMCZmZmZmRVAIDMzMzMzJ8AAMjMzMzPjvw==
      n_labels: 25
      n_samples: 1702
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: enron
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/enron.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 13:59:56.284528
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - xt_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - xt
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.ExtraTreesRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.8
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    - - rf_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - rf
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.RandomForestRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.95
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_tree_embedder
  params: {}
hash: cadfa8bdd7795850806d205ca4c02bf89bd7026042f147d4752a9c21883cdaf9
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/cadfa8b_20231231T134404006427_cascade_lc_tree_embedder_enron.yml
results:
  fit_time:
  - 901.7919554710388
  - 889.6384568214417
  - 935.0029592514038
  - 915.675952911377
  - 936.2614591121674
  fitted_params:
    estimator.level1.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 348
    - 349
    - 339
    - 345
    - 342
    estimator.level1.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 347
    - 353
    - 342
    - 345
    - 347
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level10.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 589
    - 595
    - 569
    - 560
    - 572
    estimator.level10.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 553
    - 576
    - 540
    - 523
    - 543
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level2.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 600
    - 613
    - 601
    - 602
    - 600
    estimator.level2.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 549
    - 558
    - 546
    - 543
    - 546
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level3.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 606
    - 607
    - 594
    - 590
    - 596
    estimator.level3.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 571
    - 579
    - 553
    - 555
    - 562
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level4.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 610
    - 596
    - 585
    - 580
    - 585
    estimator.level4.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 569
    - 576
    - 550
    - 548
    - 555
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level5.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 596
    - 597
    - 577
    - 578
    - 581
    estimator.level5.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 567
    - 576
    - 544
    - 544
    - 551
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level6.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 591
    - 590
    - 579
    - 567
    - 578
    estimator.level6.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 560
    - 576
    - 541
    - 535
    - 547
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level7.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 586
    - 592
    - 575
    - 563
    - 575
    estimator.level7.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 559
    - 571
    - 540
    - 532
    - 554
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level8.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 587
    - 592
    - 568
    - 561
    - 576
    estimator.level8.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 555
    - 571
    - 541
    - 528
    - 548
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
    estimator.level9.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 577
    - 597
    - 573
    - 557
    - 572
    estimator.level9.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 558
    - 571
    - 538
    - 525
    - 547
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.012770824473294935
      - 0.02329315564609682
      - 0.013436787227109805
      - 0.19354561212017352
      - 0.007061100131752306
      - 0.11312093990665417
      - 0.02675885842552509
      - 0.03639825342114221
      - 0.17105685770458492
      - 0.005541802519824497
      - 0.022401535184540803
      - 0.04225406236275801
      - 0.010494829244829244
      - 0.018749414300049325
      - 0.014393810157184776
      - 0.1470944551141437
      - 0.06019939450645972
      - 0.013757636283172066
      - 0.006775490711907066
      - 0.061319091300266
      - 0.01164824571219247
      - 0.023758106516727204
      - 0.030015188226472738
      - 0.06578848992642095
      - 0.042513929555382995
    - - 0.011405239235383228
      - 0.02351171976171976
      - 0.022900936273029294
      - 0.19117050147848702
      - 0.008986950922434792
      - 0.10771934862843953
      - 0.021109889224250923
      - 0.033117987120326695
      - 0.17345814265677084
      - 0.005660909420100597
      - 0.023005793254694734
      - 0.038361004937091894
      - 0.06279575544281427
      - 0.017379205008661715
      - 0.013996705455038786
      - 0.14338061068468166
      - 0.09785648501824973
      - 0.01302540449398056
      - 0.009484126984126984
      - 0.05402334103856371
      - 0.009397724941424128
      - 0.017971641884685363
      - 0.031397028914377005
      - 0.06941267066267065
      - 0.05714037645855828
    - - 0.01238558688335474
      - 0.01972038118355948
      - 0.016304512670791742
      - 0.19663248312145376
      - 0.00971237912414383
      - 0.10741050768523297
      - 0.025881649765578336
      - 0.03223917152591921
      - 0.17924091573923118
      - 0.006347287464308741
      - 0.01915463962167259
      - 0.03435425021196298
      - 0.011346647538508002
      - 0.01810985533484514
      - 0.021865146453058537
      - 0.14603101586023787
      - 0.09316425270033515
      - 0.013811266760704962
      - 0.015167424116287753
      - 0.06765825019768656
      - 0.008265730082349178
      - 0.016864949286824287
      - 0.027137061530164607
      - 0.060771655880351536
      - 0.05014303255043996
    - - 0.012846904253154254
      - 0.02370206625525774
      - 0.017101733064961558
      - 0.19739159391898156
      - 0.011036414565826328
      - 0.10381488950281856
      - 0.022950937950937948
      - 0.03404179985401183
      - 0.16233295994537192
      - 0.007815675960837251
      - 0.019579870074919577
      - 0.03648970077541506
      - 0.010606060606060605
      - 0.019957551113968228
      - 0.013280986153326579
      - 0.15332604541037553
      - 0.056300313489569105
      - 0.01567381527202956
      - 0.0062355939578461125
      - 0.08263652043771287
      - 0.009704761709798518
      - 0.01811551650261328
      - 0.03669960214077861
      - 0.06332137032686483
      - 0.04250366029956921
    - - 0.012512597406381828
      - 0.02606821953832387
      - 0.018751044277360067
      - 0.19514616941700275
      - 0.007679043839758125
      - 0.10962564410873775
      - 0.022688150175895275
      - 0.030425226475262343
      - 0.17730598551381682
      - 0.005195348989152526
      - 0.02077052032934386
      - 0.03478172529896668
      - 0.017765329055651636
      - 0.01793282605138275
      - 0.012981731986834026
      - 0.14285079918954158
      - 0.07715581687070089
      - 0.0150871589119302
      - 0.00784040034040034
      - 0.05913940997274332
      - 0.009921600086073769
      - 0.013718706010937703
      - 0.024281377605845693
      - 0.06418801388313583
      - 0.05547255908481545
  score_time:
  - 15.215914011001587
  - 16.54975914955139
  - 15.926873207092285
  - 16.42430305480957
  - 15.218851566314697
  test_level0__average_precision_macro:
  - 0.3837607610481222
  - 0.3595727256821783
  - 0.32117690353596084
  - 0.38469490266497347
  - 0.3224849689767042
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.623813003849841
  - 0.5816782726432822
  - 0.5865772167669384
  - 0.6196033737777173
  - 0.5807961733382354
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.7062201478925438
  - 0.674140813300612
  - 0.6855438178951593
  - 0.6845576155653968
  - 0.67618358326681
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.5962190358954028
  - 0.5551268693031453
  - 0.5507127464672588
  - 0.6018038169365125
  - 0.5380657058788916
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.8726099706744869
  - 0.8725525525525526
  - 0.8741492537313432
  - 0.8775000000000002
  - 0.8749560117302053
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.8726099706744868
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.8726099706744866
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.7079114077866528
  - 0.6979533727884341
  - 0.7011768353698927
  - 0.7139852841963231
  - 0.7036197476795432
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.1273900293255132
  - -0.12744744744744746
  - -0.12585074626865672
  - -0.1225
  - -0.1250439882697947
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.1273900293255132
  - -0.12744744744744746
  - -0.12585074626865672
  - -0.1225
  - -0.1250439882697947
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.1273900293255132
  - -0.12744744744744743
  - -0.1258507462686567
  - -0.12250000000000001
  - -0.12504398826979474
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.29208859221334715
  - -0.30204662721156594
  - -0.2988231646301072
  - -0.2860147158036768
  - -0.2963802523204569
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.7983505396261539
  - 0.7994584360425355
  - 0.8015209702322379
  - 0.8053961012298372
  - 0.8027207345092923
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.7740089480803246
  - 0.7739186021734498
  - 0.7764344044967653
  - 0.7817371937639198
  - 0.7777082681680743
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.7791514240811114
  - 0.7783750765304345
  - 0.7808837316876931
  - 0.7860233609641886
  - 0.782704977164078
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5829296958444191
  - 0.5735235814758642
  - 0.5759664788021851
  - 0.5886032552666344
  - 0.5776789289946371
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.7062201478925434
  - 0.6771438163036152
  - 0.6885288925220243
  - 0.6845576155653963
  - 0.6879137885454019
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.004821829974467773
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.06424082971465396
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.008158730145438184
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.019464894372851493
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8315355804327947
  - 0.806513528227557
  - 0.8176935069030503
  - 0.813763123109675
  - 0.8063358115823412
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -9.043988269794722
  - -9.345345345345345
  - -9.414925373134329
  - -8.704545454545455
  - -9.266862170087977
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.1273900293255132
  - -0.12744744744744746
  - -0.12585074626865672
  - -0.1225
  - -0.1250439882697947
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.1273900293255132
  - -0.12744744744744746
  - -0.12585074626865672
  - -0.1225
  - -0.1250439882697947
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.1273900293255132
  - -0.12744744744744743
  - -0.1258507462686567
  - -0.12250000000000001
  - -0.12504398826979474
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.29208859221334715
  - -0.30204662721156594
  - -0.2988231646301072
  - -0.2860147158036768
  - -0.2963802523204569
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.12178829756030186
  - -0.12452679856143758
  - -0.12687331507933303
  - -0.11653592195919792
  - -0.12527881980871552
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.8726099706744869
  - 0.8725525525525526
  - 0.8741492537313432
  - 0.8775000000000002
  - 0.8749560117302053
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.8726099706744868
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.8726099706744866
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.7079114077866528
  - 0.6979533727884341
  - 0.7011768353698927
  - 0.7139852841963231
  - 0.7036197476795432
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.8726099706744869
  - 0.8725525525525526
  - 0.8741492537313432
  - 0.8775000000000002
  - 0.8749560117302053
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.8726099706744868
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.8726099706744866
  - 0.8725525525525526
  - 0.8741492537313433
  - 0.8775
  - 0.8749560117302053
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.7079114077866528
  - 0.6979533727884341
  - 0.7011768353698927
  - 0.7139852841963231
  - 0.7036197476795432
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.7758243154755396
  - 0.7653906011644658
  - 0.7356647015284579
  - 0.7812880479413518
  - 0.7521471038788321
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.8810184095220625
  - 0.8737949429513341
  - 0.8691182764721767
  - 0.887903822968758
  - 0.8717249041476771
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.8782502886412724
  - 0.8751519072948747
  - 0.8727468246958784
  - 0.8834640780408022
  - 0.8732871797866029
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.8075797340437272
  - 0.7780780350017449
  - 0.7791097789457635
  - 0.8217154087709303
  - 0.7732933768036506
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.8726099706744869
  - 0.8725525525525526
  - 0.8735522388059701
  - 0.8775000000000002
  - 0.8749560117302053
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.8726099706744868
  - 0.8725525525525526
  - 0.8735522388059701
  - 0.8775
  - 0.8749560117302053
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.8726099706744866
  - 0.8725525525525526
  - 0.8735522388059701
  - 0.8775
  - 0.8749560117302053
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.7079114077866528
  - 0.6979533727884341
  - 0.6987667892830465
  - 0.7139852841963231
  - 0.7036197476795432
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0005970149253731343
  - 0.0
  - 0.0
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0005970149253731343
  - 0.0
  - 0.0
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0005970149253731343
  - 0.0
  - 0.0
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0024100460868462224
  - 0.0
  - 0.0
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.24231945774125296
  - 0.21942476567842803
  - 0.20761260355954317
  - 0.22154065098711034
  - 0.21524993892314864
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.13009161545099976
  - 0.13913405859443645
  - 0.12035744813749778
  - 0.12766161318890662
  - 0.12159053690904714
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.18073426786626412
  - 0.20159201624814718
  - 0.17810752522729137
  - 0.1794381332637517
  - 0.17600145147522095
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.46206106800827634
  - 0.4329313659249832
  - 0.44543465310180513
  - 0.43729895489957044
  - 0.43955781446859615
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.26409090909090904
  - 0.2489149560117302
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.4404902707344339
  - 0.4183231299159668
  - 0.4238862345496314
  - 0.4320817169843144
  - 0.4102738331691912
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.004222873900293255
  - -0.004924924924924925
  - -0.0038208955223880603
  - -0.002954545454545454
  - -0.003284457478005865
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.004222873900293255
  - -0.004924924924924925
  - -0.00382089552238806
  - -0.0029545454545454545
  - -0.003284457478005865
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.004222873900293255
  - -0.0049249249249249255
  - -0.00382089552238806
  - -0.0029545454545454545
  - -0.0032844574780058655
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.007717524559442221
  - -0.007933475416981542
  - -0.007325976350541908
  - -0.004232374768089054
  - -0.005523980346954383
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.7149560117302053
  - -0.7151951951951951
  - -0.7275223880597014
  - -0.7329545454545453
  - -0.7478005865102639
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.7149560117302053
  - -0.7151951951951951
  - -0.7275223880597015
  - -0.7329545454545454
  - -0.7478005865102639
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.7149560117302053
  - -0.7151951951951951
  - -0.7275223880597015
  - -0.7329545454545454
  - -0.7478005865102638
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.5517922047061238
  - -0.5737433946670516
  - -0.5687877890998266
  - -0.5636859082475966
  - -0.5842021864838545
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.1877272383694889
  - 0.19673318207545776
  - 0.18331648417764337
  - 0.173867174396264
  - 0.16488792340768613
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.16334606986899564
  - 0.1627094972067039
  - 0.15517241379310345
  - 0.15213406650955746
  - 0.14214898177920687
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.18300608973352048
  - 0.17578773808372358
  - 0.16580409006863472
  - 0.1670504819172063
  - 0.15299325663019392
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.30800398721847755
  - 0.2909067565039882
  - 0.29770305352764465
  - 0.299743969423235
  - 0.28376691678268146
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.18073426786626426
  - 0.2045950192511503
  - 0.18109259985415715
  - 0.17943813326375185
  - 0.18773165675381354
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.13143337994789178
  - 0.12187194459661513
  - 0.11014035280434496
  - 0.12408067100937487
  - 0.10211807856889411
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.13353135046263093
  - 0.12815707418947755
  - 0.12752258714091158
  - 0.13000213492867702
  - 0.11693389271482274
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.10816913627813333
  - 0.11433442218157942
  - 0.10813721060353236
  - 0.09867580349490868
  - 0.09397986700955084
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.2360997092028551
  - 0.1881875733539181
  - 0.21894322775669295
  - 0.22943300236355466
  - 0.2088592924520635
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.41196401066558014
  - 0.43735875337802577
  - 0.41493000119313234
  - 0.417339928969131
  - 0.40595752164351934
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -16.173020527859236
  - -15.183183183183184
  - -16.149253731343283
  - -15.946022727272727
  - -16.096774193548388
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.7191788856304986
  - -0.72012012012012
  - -0.7313432835820897
  - -0.735909090909091
  - -0.7510850439882699
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.7191788856304986
  - -0.7201201201201202
  - -0.7313432835820896
  - -0.735909090909091
  - -0.7510850439882698
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.7191788856304986
  - -0.7201201201201199
  - -0.7313432835820896
  - -0.7359090909090908
  - -0.7510850439882698
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5595097292655661
  - -0.5816768700840332
  - -0.5761137654503685
  - -0.5679182830156856
  - -0.5897261668308088
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.4632307986243029
  - -0.41444305058138237
  - -0.4702946683957648
  - -0.45225948815022543
  - -0.47737547021905413
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.26409090909090904
  - 0.2489149560117302
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.4404902707344339
  - 0.4183231299159668
  - 0.4238862345496314
  - 0.4320817169843144
  - 0.4102738331691912
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.26409090909090904
  - 0.2489149560117302
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.28082111436950147
  - 0.2798798798798799
  - 0.26865671641791045
  - 0.2640909090909091
  - 0.2489149560117302
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.4404902707344339
  - 0.4183231299159668
  - 0.4238862345496314
  - 0.4320817169843144
  - 0.4102738331691912
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.6176776479851336
  - 0.6295547408249744
  - 0.6132666478664501
  - 0.6259371368709484
  - 0.5934638681808064
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.5651632665136233
  - 0.5918296288722716
  - 0.5311448874006086
  - 0.5705478384049812
  - 0.5402683512897398
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.5394702482111163
  - 0.5868469202136514
  - 0.5313991303750687
  - 0.5524066585728825
  - 0.5199549058093677
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.6859472961270594
  - 0.6661715105234931
  - 0.6789295958730523
  - 0.6774069221336088
  - 0.6593834733590636
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.1576539589442815
  - 0.15735735735735734
  - 0.14602985074626867
  - 0.14454545454545456
  - 0.12715542521994133
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.15765395894428152
  - 0.15735735735735737
  - 0.14602985074626865
  - 0.14454545454545453
  - 0.12715542521994136
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.15765395894428155
  - 0.15735735735735737
  - 0.14602985074626867
  - 0.14454545454545456
  - 0.12715542521994136
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.15611920308052904
  - 0.12420997812138246
  - 0.12997900018321987
  - 0.15029937594872658
  - 0.11941756119568864
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.12316715542521994
  - 0.12252252252252253
  - 0.12262686567164179
  - 0.11954545454545455
  - 0.12175953079178886
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.12316715542521994
  - 0.12252252252252252
  - 0.12262686567164179
  - 0.11954545454545455
  - 0.12175953079178886
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.12316715542521994
  - 0.12252252252252252
  - 0.12262686567164179
  - 0.11954545454545454
  - 0.12175953079178885
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.2843710676539049
  - 0.2941131517945844
  - 0.2939072343664116
  - 0.2817823410355878
  - 0.2908562719735025
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.2648382866229856
  - 0.23765587919519177
  - 0.22906009277057524
  - 0.250374650321689
  - 0.21514329192311854
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.2207992539082294
  - 0.23494705551284287
  - 0.20121716973820492
  - 0.2668461280753638
  - 0.19486109175027286
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.36023890177822077
  - 0.3988229728148632
  - 0.35633764504065973
  - 0.4124236438024171
  - 0.33426379069320944
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.4790207933409982
  - 0.44160551408780613
  - 0.44464764831034653
  - 0.4642764110841473
  - 0.4246777842110082
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.272955223880597
  - 0.27681818181818185
  - 0.24070381231671553
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.2756598240469208
  - 0.28696696696696694
  - 0.272955223880597
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.27295522388059706
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.42984829582583994
  - 0.4243574394375525
  - 0.4152128874043381
  - 0.4436192865575982
  - 0.40459304660720863
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.0036363636363636364
  - -0.005525525525525526
  - -0.004059701492537314
  - -0.004999999999999999
  - -0.001994134897360704
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.0036363636363636364
  - -0.005525525525525526
  - -0.004059701492537314
  - -0.005
  - -0.001994134897360704
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.003636363636363637
  - -0.005525525525525527
  - -0.004059701492537314
  - -0.005
  - -0.001994134897360704
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.00473366709331778
  - -0.006787183036004902
  - -0.006485983679337027
  - -0.005726619160060719
  - -0.0028912865262196497
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.7207038123167154
  - -0.7075075075075077
  - -0.7229850746268655
  - -0.7181818181818183
  - -0.7573020527859237
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.7207038123167155
  - -0.7075075075075075
  - -0.7229850746268657
  - -0.7181818181818181
  - -0.7573020527859238
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.7207038123167155
  - -0.7075075075075075
  - -0.7229850746268657
  - -0.7181818181818183
  - -0.7573020527859238
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.5654180370808423
  - -0.5688553775264427
  - -0.5783011289163249
  - -0.5506540942823411
  - -0.5925156668665716
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.18384983165142096
  - 0.20133809137336717
  - 0.19015780406311578
  - 0.19028280269061718
  - 0.16124111658997176
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.1598639455782313
  - 0.16751980927003715
  - 0.1580475663716814
  - 0.1606436296491691
  - 0.13681824243232432
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.18268588892232215
  - 0.1868915672843708
  - 0.17138949865032233
  - 0.17862574646382057
  - 0.1521121688999336
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.2986262835305197
  - 0.2957816098028809
  - 0.2891465229564389
  - 0.31563210367538064
  - 0.27880000923191844
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.36023890177822115
  - 0.4018259758178662
  - 0.3593227196675252
  - 0.41242364380241714
  - 0.3459939959718019
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.13169568582905708
  - 0.12444012223197638
  - 0.1082802928898535
  - 0.1388715111980068
  - 0.12461897991045948
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.1338871847535681
  - 0.12926089622769957
  - 0.12893040329540306
  - 0.12452446268399982
  - 0.12079212823155319
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.11578680732245925
  - 0.12298406070305111
  - 0.11102010285979484
  - 0.097020426207223
  - 0.09803767137919372
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.23321812590564517
  - 0.19886568092473805
  - 0.20480490130970566
  - 0.2430780709767259
  - 0.21505882331657844
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.5587341341910821
  - 0.5908869015082233
  - 0.5609394611325618
  - 0.6126439879879189
  - 0.5336747128667948
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -14.143695014662757
  - -13.08108108108108
  - -13.564179104477612
  - -13.173295454545455
  - -13.894428152492669
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.7243401759530792
  - -0.7130330330330331
  - -0.7270447761194029
  - -0.7231818181818181
  - -0.7592961876832846
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.7243401759530792
  - -0.713033033033033
  - -0.727044776119403
  - -0.7231818181818181
  - -0.7592961876832844
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.7243401759530792
  - -0.713033033033033
  - -0.727044776119403
  - -0.7231818181818181
  - -0.7592961876832843
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.5701517041741601
  - -0.5756425605624474
  - -0.584787112595662
  - -0.5563807134424017
  - -0.5954069533927913
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.32764508809526177
  - -0.27250060601835174
  - -0.3188916387186478
  - -0.27092173678599224
  - -0.33454332122035646
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.272955223880597
  - 0.27681818181818185
  - 0.24070381231671553
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.2756598240469208
  - 0.28696696696696694
  - 0.272955223880597
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.27295522388059706
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.42984829582583994
  - 0.4243574394375525
  - 0.4152128874043381
  - 0.4436192865575982
  - 0.40459304660720863
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.272955223880597
  - 0.27681818181818185
  - 0.24070381231671553
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.2756598240469208
  - 0.28696696696696694
  - 0.272955223880597
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.2756598240469208
  - 0.286966966966967
  - 0.27295522388059706
  - 0.2768181818181818
  - 0.24070381231671553
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.42984829582583994
  - 0.4243574394375525
  - 0.4152128874043381
  - 0.4436192865575982
  - 0.40459304660720863
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.6727813703490149
  - 0.6713299531242322
  - 0.6478867022346609
  - 0.671261314196521
  - 0.6343011832313452
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.694261268507495
  - 0.7116229390442894
  - 0.6776505218876862
  - 0.7210241658293607
  - 0.6768619673728579
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.6723549119047383
  - 0.7266786090237616
  - 0.680166727527441
  - 0.7291306646992155
  - 0.6615259810159839
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.7152523344656905
  - 0.6835876859383974
  - 0.6847810891990073
  - 0.7021444775198686
  - 0.6665879961090703
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.15190615835777124
  - 0.16504504504504505
  - 0.15056716417910446
  - 0.1593181818181818
  - 0.11765395894428153
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.15190615835777127
  - 0.16504504504504505
  - 0.15056716417910448
  - 0.15931818181818183
  - 0.11765395894428153
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.15190615835777124
  - 0.16504504504504508
  - 0.15056716417910448
  - 0.15931818181818183
  - 0.11765395894428154
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.14249337070581056
  - 0.12909799526199148
  - 0.12046566036672164
  - 0.16333118991398213
  - 0.11110408081297145
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.12375366568914956
  - 0.12192192192192192
  - 0.12238805970149254
  - 0.11750000000000002
  - 0.12304985337243401
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.12375366568914956
  - 0.12192192192192192
  - 0.12238805970149254
  - 0.1175
  - 0.12304985337243401
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.12375366568914957
  - 0.1219219219219219
  - 0.12238805970149254
  - 0.1175
  - 0.12304985337243401
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.28735492512002936
  - 0.295259444175561
  - 0.2947472270376165
  - 0.28028809664361615
  - 0.29348896579423717
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.24273072756783423
  - 0.23064048897229605
  - 0.20475316375648533
  - 0.23112069074029873
  - 0.2016935933574086
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.12961033008639528
  - 0.1403790074100745
  - 0.1202607290915157
  - 0.12801332525952133
  - 0.11894418072474355
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.18010448070237878
  - 0.20253361714584572
  - 0.1775939128989954
  - 0.18189489425046776
  - 0.17275817899006937
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.46261547545335324
  - 0.442994527464714
  - 0.4240414358154899
  - 0.44840112020389716
  - 0.420328014623105
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.23706744868035187
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.2370674486803519
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.26826979472140766
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.2567045454545455
  - 0.23706744868035193
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.4330616807893585
  - 0.4231913345956701
  - 0.4140374614181218
  - 0.42706927812447293
  - 0.3999466308671659
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.002463343108504399
  - -0.0044444444444444444
  - -0.0034626865671641793
  - -0.002954545454545454
  - -0.0024633431085043993
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.002463343108504399
  - -0.0044444444444444444
  - -0.0034626865671641793
  - -0.0029545454545454545
  - -0.002463343108504399
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.0024633431085043993
  - -0.0044444444444444444
  - -0.003462686567164179
  - -0.0029545454545454545
  - -0.0024633431085043993
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.0048227777687767
  - -0.006031479170027709
  - -0.006209744478739448
  - -0.004187573789846517
  - -0.004297040489015311
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.7292668621700881
  - -0.7166366366366367
  - -0.7363582089552239
  - -0.7403409090909091
  - -0.7604692082111435
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.729266862170088
  - -0.7166366366366367
  - -0.7363582089552239
  - -0.7403409090909091
  - -0.7604692082111437
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.729266862170088
  - -0.7166366366366366
  - -0.7363582089552239
  - -0.740340909090909
  - -0.7604692082111437
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.5621155414418647
  - -0.5707771862343023
  - -0.5797527941031388
  - -0.5687431480856805
  - -0.5957563286438189
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.17914900541419004
  - 0.19740087905998988
  - 0.17773334167248542
  - 0.1687131791598431
  - 0.15833526030585773
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.15491431280904966
  - 0.1620603015075377
  - 0.14954361402786356
  - 0.14725246072615866
  - 0.1344733515203939
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.1721698028275012
  - 0.17463756673017272
  - 0.1593011453313115
  - 0.1609728170557367
  - 0.1449681063732699
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.30238163662409084
  - 0.2965689582273769
  - 0.28906915618616663
  - 0.29624218372702393
  - 0.27465875308308996
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.18010448070237892
  - 0.2055366201488489
  - 0.18057898752586107
  - 0.18189489425046787
  - 0.18448838426866185
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.13652400036418338
  - 0.12456323645237787
  - 0.1044675564876886
  - 0.11949193215342742
  - 0.10777250463029041
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.13692309199524058
  - 0.13070000520411829
  - 0.12395716097073856
  - 0.12485980025590429
  - 0.11440273435687062
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.1083650928701325
  - 0.11616826051724082
  - 0.10507058124516701
  - 0.09396189989725677
  - 0.08958632676526901
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.242291398639326
  - 0.2046344898078776
  - 0.20862740396594076
  - 0.2261043120766008
  - 0.201601805451331
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.41110831509496826
  - 0.4390642524381367
  - 0.41406153433229487
  - 0.41710134701051954
  - 0.40334904682251943
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -16.117302052785924
  - -15.132132132132131
  - -16.161194029850748
  - -15.84375
  - -16.410557184750733
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.7317302052785923
  - -0.7210810810810809
  - -0.7398208955223881
  - -0.7432954545454544
  - -0.7629325513196481
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.7317302052785923
  - -0.721081081081081
  - -0.7398208955223881
  - -0.7432954545454545
  - -0.7629325513196481
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.7317302052785923
  - -0.721081081081081
  - -0.739820895522388
  - -0.7432954545454545
  - -0.762932551319648
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.5669383192106415
  - -0.57680866540433
  - -0.5859625385818781
  - -0.5729307218755271
  - -0.6000533691328341
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.4632745598737201
  - -0.4132344055092742
  - -0.47360057257768934
  - -0.4462763748899967
  - -0.4868222493420862
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.23706744868035187
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.2370674486803519
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.26826979472140766
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.2567045454545455
  - 0.23706744868035193
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.4330616807893585
  - 0.4231913345956701
  - 0.4140374614181218
  - 0.42706927812447293
  - 0.3999466308671659
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.23706744868035187
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.2682697947214076
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.25670454545454546
  - 0.2370674486803519
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.26826979472140766
  - 0.2789189189189189
  - 0.26017910447761194
  - 0.2567045454545455
  - 0.23706744868035193
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.4330616807893585
  - 0.4231913345956701
  - 0.4140374614181218
  - 0.42706927812447293
  - 0.3999466308671659
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.6284149839238687
  - 0.6330743597048508
  - 0.6057142279568083
  - 0.6243184172341071
  - 0.5994341706682342
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.5645103192893359
  - 0.5953442434408567
  - 0.5312437561663907
  - 0.5737129633233529
  - 0.5303235548830165
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.5389775221769845
  - 0.588109762403336
  - 0.5275465822196731
  - 0.5564272456867776
  - 0.509602651960525
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.6924491232846294
  - 0.673503867468606
  - 0.6595781337743071
  - 0.6799579076487426
  - 0.6531466722686469
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.14334310850439883
  - 0.15591591591591591
  - 0.13719402985074627
  - 0.1371590909090909
  - 0.11448680351906158
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.14334310850439883
  - 0.15591591591591591
  - 0.13719402985074627
  - 0.1371590909090909
  - 0.11448680351906158
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.14334310850439883
  - 0.15591591591591591
  - 0.1371940298507463
  - 0.13715909090909092
  - 0.11448680351906156
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.1457958663447881
  - 0.12717618655413188
  - 0.11901399517990785
  - 0.14524213611064263
  - 0.1078634190357243
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.1249266862170088
  - 0.123003003003003
  - 0.12298507462686568
  - 0.11954545454545455
  - 0.12258064516129032
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.1249266862170088
  - 0.123003003003003
  - 0.12298507462686567
  - 0.11954545454545455
  - 0.12258064516129032
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.12492668621700878
  - 0.123003003003003
  - 0.12298507462686568
  - 0.11954545454545454
  - 0.12258064516129033
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.28726581444457044
  - 0.2960151480415382
  - 0.295023466238214
  - 0.2818271420138303
  - 0.2920832118314416
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.24362185587004134
  - 0.2239249249159178
  - 0.20908942971460295
  - 0.23768219591963152
  - 0.20972643295602056
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.13027140758760938
  - 0.14103620975704265
  - 0.12142474388691125
  - 0.13130535951920913
  - 0.12152018375097207
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.1795703284484984
  - 0.20322537762643253
  - 0.17816202558584374
  - 0.18282244302128187
  - 0.17453261611258117
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.45898763075149646
  - 0.4440506547810124
  - 0.43841243922553547
  - 0.4625632668116346
  - 0.4278629431577308
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.273900293255132
  - 0.28036036036036033
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014659
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014664
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.26316417910447765
  - 0.2602272727272728
  - 0.24211143695014664
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.43774944238319746
  - 0.42323095951748163
  - 0.4177497780220709
  - 0.4316468839601956
  - 0.40618311664731804
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.0025806451612903226
  - -0.004324324324324324
  - -0.0035820895522388064
  - -0.002954545454545454
  - -0.0030498533724340176
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.0025806451612903226
  - -0.004324324324324324
  - -0.003582089552238806
  - -0.0029545454545454545
  - -0.0030498533724340176
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.0025806451612903226
  - -0.004324324324324324
  - -0.003582089552238806
  - -0.0029545454545454545
  - -0.0030498533724340176
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.005757089699345981
  - -0.0066400047549906175
  - -0.006815779459642298
  - -0.004232374768089054
  - -0.00508107156415575
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.7235190615835776
  - -0.7153153153153152
  - -0.7332537313432836
  - -0.7368181818181817
  - -0.7548387096774194
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.7235190615835777
  - -0.7153153153153153
  - -0.7332537313432835
  - -0.7368181818181818
  - -0.7548387096774194
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.7235190615835778
  - -0.7153153153153153
  - -0.7332537313432835
  - -0.7368181818181818
  - -0.7548387096774193
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.5564934679174566
  - -0.5701290357275277
  - -0.5754344425182868
  - -0.5641207412717152
  - -0.5887358117885262
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.1827805977248992
  - 0.19795025783796583
  - 0.17911999057222389
  - 0.17075036427649284
  - 0.16110793207426327
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.15868161739721373
  - 0.16303436714165967
  - 0.15151931802557403
  - 0.1495754408883083
  - 0.13772854664353396
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.17698591020012583
  - 0.17574891836125936
  - 0.16218709587321076
  - 0.1638456846452857
  - 0.14848166841523444
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.3063485451100585
  - 0.29627998793754773
  - 0.29216565083688334
  - 0.2998624667751372
  - 0.28042560308507514
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.1795703284484985
  - 0.20622838062943558
  - 0.18114710021270947
  - 0.18282244302128195
  - 0.1862628213911736
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.13939584430164792
  - 0.1293067154302354
  - 0.10813269592333487
  - 0.12161233865329209
  - 0.10273858891245093
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.13997945019649813
  - 0.13253249680532997
  - 0.12526226399189658
  - 0.1273254229123071
  - 0.11362865898136594
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.11134148729714684
  - 0.11796465944857484
  - 0.10544418431623381
  - 0.09469524945791517
  - 0.08905942517632023
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.2452640511396891
  - 0.2042591907000661
  - 0.21264551150734812
  - 0.23084118761070044
  - 0.2064399744621601
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.4104467505466442
  - 0.44033430264570794
  - 0.41541001390504545
  - 0.419011065361393
  - 0.4048546833643687
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -16.234604105571847
  - -15.063063063063064
  - -16.18507462686567
  - -15.747159090909092
  - -16.181818181818183
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.726099706744868
  - -0.7196396396396396
  - -0.7368358208955225
  - -0.7397727272727274
  - -0.7578885630498533
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.726099706744868
  - -0.7196396396396396
  - -0.7368358208955224
  - -0.7397727272727272
  - -0.7578885630498534
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.7260997067448679
  - -0.7196396396396396
  - -0.7368358208955224
  - -0.7397727272727272
  - -0.7578885630498534
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.5622505576168025
  - -0.5767690404825184
  - -0.582250221977929
  - -0.5683531160398043
  - -0.5938168833526819
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.4656235023102423
  - -0.41075274977325493
  - -0.4711729124691657
  - -0.4417962070786134
  - -0.48061967329586613
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.273900293255132
  - 0.28036036036036033
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014659
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014664
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.26316417910447765
  - 0.2602272727272728
  - 0.24211143695014664
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.43774944238319746
  - 0.42323095951748163
  - 0.4177497780220709
  - 0.4316468839601956
  - 0.40618311664731804
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.273900293255132
  - 0.28036036036036033
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014659
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.2631641791044776
  - 0.26022727272727275
  - 0.24211143695014664
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.273900293255132
  - 0.2803603603603604
  - 0.26316417910447765
  - 0.2602272727272728
  - 0.24211143695014664
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.43774944238319746
  - 0.42323095951748163
  - 0.4177497780220709
  - 0.4316468839601956
  - 0.40618311664731804
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.6239979711065139
  - 0.6319922903311057
  - 0.6151981067142716
  - 0.6357023697741003
  - 0.6039502000088461
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.566594922929947
  - 0.5970297014287078
  - 0.536138018215602
  - 0.5832176481527132
  - 0.5404043040038514
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.5367629192667285
  - 0.5909018821327351
  - 0.5301934408200251
  - 0.5624253101813438
  - 0.5163325272562301
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.6884127519426662
  - 0.6700070068551854
  - 0.6762003758151495
  - 0.6921943000933652
  - 0.6563998175838704
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.14909090909090908
  - 0.15723723723723723
  - 0.14029850746268654
  - 0.14068181818181819
  - 0.12011730205278592
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.14909090909090908
  - 0.15723723723723723
  - 0.14029850746268657
  - 0.14068181818181819
  - 0.12011730205278592
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.1490909090909091
  - 0.15723723723723723
  - 0.14029850746268657
  - 0.14068181818181819
  - 0.12011730205278592
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.15141793986919633
  - 0.12782433706090632
  - 0.12333234676475975
  - 0.14986454292460788
  - 0.11488393589101692
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.12480938416422287
  - 0.12312312312312314
  - 0.12286567164179106
  - 0.11954545454545455
  - 0.1219941348973607
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.12480938416422288
  - 0.12312312312312312
  - 0.12286567164179105
  - 0.11954545454545455
  - 0.1219941348973607
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.12480938416422285
  - 0.12312312312312312
  - 0.12286567164179103
  - 0.11954545454545454
  - 0.12199413489736069
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.28633150251400113
  - 0.29540662245657534
  - 0.2944174312573112
  - 0.2817823410355878
  - 0.2912991807563012
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.24006707289039744
  - 0.22766335266217147
  - 0.20789247642533273
  - 0.22481716885577582
  - 0.2016732432797465
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.1297679146592782
  - 0.1406855316102159
  - 0.12082973087415375
  - 0.12950057193602177
  - 0.1197638783527078
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.18023684814122568
  - 0.2031902656662179
  - 0.17748340780684246
  - 0.1815302808059779
  - 0.17474789317112394
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.44962302678584576
  - 0.43489512298396177
  - 0.44156133526807384
  - 0.4377309853650763
  - 0.4197252261541936
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914952
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914955
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.2651940298507463
  - 0.26068181818181824
  - 0.24375366568914958
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.43784395370565393
  - 0.4268509791601215
  - 0.4196721773568418
  - 0.43112244897959184
  - 0.40787222219165575
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.0031671554252199413
  - -0.0044444444444444444
  - -0.0035820895522388064
  - -0.003181818181818181
  - -0.0032844574780058655
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.0031671554252199413
  - -0.0044444444444444444
  - -0.003582089552238806
  - -0.003181818181818182
  - -0.003284457478005865
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.0031671554252199413
  - -0.0044444444444444444
  - -0.003582089552238806
  - -0.003181818181818182
  - -0.0032844574780058655
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.006456473485523566
  - -0.006790013387562869
  - -0.006815779459642298
  - -0.004490639230898971
  - -0.005053561701870121
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.7207038123167154
  - -0.7124324324324326
  - -0.7312238805970149
  - -0.7361363636363636
  - -0.7529618768328445
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.7207038123167155
  - -0.7124324324324325
  - -0.7312238805970149
  - -0.7361363636363636
  - -0.7529618768328445
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.7207038123167155
  - -0.7124324324324324
  - -0.7312238805970148
  - -0.7361363636363637
  - -0.7529618768328445
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.5556995728088225
  - -0.5663590074523157
  - -0.5735120431835158
  - -0.5643869117895093
  - -0.5870742161064743
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.184494829304522
  - 0.19957238018611267
  - 0.17991849503144955
  - 0.1711509296387246
  - 0.16203226664884418
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.1601796407185629
  - 0.16490589799202407
  - 0.15286668043223897
  - 0.14987586567359207
  - 0.13879241250333957
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.17885826113754438
  - 0.17810886408287396
  - 0.16363667345153135
  - 0.16439939561999026
  - 0.14966831287010268
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.3062244182901414
  - 0.2992848982420519
  - 0.29350309713198774
  - 0.2993787440468934
  - 0.28174880347714076
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.18023684814122576
  - 0.20619326866922094
  - 0.1804684824337082
  - 0.18153028080597794
  - 0.18647809844971638
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.1366283102500815
  - 0.13004343920043004
  - 0.10851240162561382
  - 0.12079844012012873
  - 0.10112042494871988
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.13744492611508902
  - 0.1336773087702429
  - 0.12672329848109157
  - 0.1259864519471502
  - 0.11307161444373988
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.10945210991958802
  - 0.1186229336529902
  - 0.10625416149925938
  - 0.09334170462601218
  - 0.08826722119160763
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.24159148517193219
  - 0.2080323494680867
  - 0.2138257590012665
  - 0.2287660854275765
  - 0.20668586410322368
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.41128080031918735
  - 0.4392433810492384
  - 0.4129851791102169
  - 0.41876805756076574
  - 0.40447780993404286
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -16.18475073313783
  - -15.093093093093094
  - -16.188059701492538
  - -15.846590909090908
  - -16.287390029325515
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.7238709677419354
  - -0.7168768768768768
  - -0.7348059701492538
  - -0.7393181818181818
  - -0.7562463343108504
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.7238709677419355
  - -0.7168768768768768
  - -0.7348059701492538
  - -0.7393181818181818
  - -0.7562463343108504
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.7238709677419354
  - -0.7168768768768767
  - -0.7348059701492538
  - -0.7393181818181819
  - -0.7562463343108504
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.562156046294346
  - -0.5731490208398785
  - -0.5803278226431582
  - -0.5688775510204082
  - -0.5921277778083444
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.46404695172846777
  - -0.41213275374939123
  - -0.4719925352681252
  - -0.44592349347622756
  - -0.4825742226092739
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914952
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914955
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.2651940298507463
  - 0.26068181818181824
  - 0.24375366568914958
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.43784395370565393
  - 0.4268509791601215
  - 0.4196721773568418
  - 0.43112244897959184
  - 0.40787222219165575
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914952
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.26519402985074625
  - 0.2606818181818182
  - 0.24375366568914955
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.2761290322580645
  - 0.2831231231231231
  - 0.2651940298507463
  - 0.26068181818181824
  - 0.24375366568914958
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.43784395370565393
  - 0.4268509791601215
  - 0.4196721773568418
  - 0.43112244897959184
  - 0.40787222219165575
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.6221439836241971
  - 0.6328787103558651
  - 0.6161820941073991
  - 0.6320132822208313
  - 0.5934093785897071
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.5645589654048137
  - 0.5961754895223939
  - 0.5336843690804585
  - 0.5777871719430161
  - 0.5336890448271691
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.5384895434790068
  - 0.5894179465079447
  - 0.529494743363185
  - 0.5583232079694156
  - 0.5137937790392223
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.6842006059879147
  - 0.669039681998987
  - 0.6775459247856768
  - 0.6799994518917211
  - 0.6528358975495432
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.15190615835777124
  - 0.1601201201201201
  - 0.14232835820895523
  - 0.14136363636363636
  - 0.1219941348973607
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.15190615835777127
  - 0.1601201201201201
  - 0.14232835820895523
  - 0.14136363636363636
  - 0.1219941348973607
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.15190615835777127
  - 0.16012012012012014
  - 0.14232835820895526
  - 0.14136363636363639
  - 0.1219941348973607
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.15221183497783036
  - 0.1315943653361184
  - 0.1252547460995307
  - 0.14959837240681395
  - 0.11654553157306895
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.12422287390029325
  - 0.123003003003003
  - 0.12286567164179106
  - 0.11931818181818182
  - 0.12175953079178886
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.12422287390029325
  - 0.123003003003003
  - 0.12286567164179105
  - 0.11931818181818182
  - 0.12175953079178886
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.12422287390029325
  - 0.123003003003003
  - 0.12286567164179103
  - 0.11931818181818182
  - 0.12175953079178885
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.2856321187278236
  - 0.29525661382400303
  - 0.2944174312573112
  - 0.28152407657277784
  - 0.2913266906185868
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.24530809650209842
  - 0.22208266539285726
  - 0.20704447001297072
  - 0.22060744817456748
  - 0.21200817292113888
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.13040342659934084
  - 0.14045432550628673
  - 0.12049389810434044
  - 0.12977261374056215
  - 0.12016799114731934
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.18094979674579342
  - 0.20253678332751499
  - 0.1767425251972516
  - 0.18063351512659
  - 0.17399799774749616
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.4594909999940916
  - 0.4495449268222832
  - 0.4454888596568878
  - 0.4374840870758538
  - 0.42733079397901447
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.27906158357771266
  - 0.2818018018018018
  - 0.2660298507462686
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.44069549532033936
  - 0.4244423499842915
  - 0.42076022155511394
  - 0.43067180384550513
  - 0.4091404268430232
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.0031671554252199413
  - -0.004084084084084084
  - -0.003940298507462687
  - -0.0028409090909090906
  - -0.0031671554252199418
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.0031671554252199413
  - -0.004084084084084084
  - -0.0039402985074626865
  - -0.002840909090909091
  - -0.0031671554252199413
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.0031671554252199413
  - -0.004084084084084083
  - -0.0039402985074626865
  - -0.002840909090909091
  - -0.0031671554252199413
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.006502378985002403
  - -0.005918265107709029
  - -0.007342888954660127
  - -0.004103242536684095
  - -0.004998541977298862
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.7177712609970675
  - -0.7141141141141142
  - -0.7300298507462686
  - -0.7361363636363636
  - -0.7515542521994135
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.7177712609970675
  - -0.7141141141141141
  - -0.7300298507462687
  - -0.7361363636363636
  - -0.7515542521994135
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.7177712609970675
  - -0.7141141141141141
  - -0.7300298507462687
  - -0.7361363636363637
  - -0.7515542521994134
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.5528021256946583
  - -0.5696393849079995
  - -0.5718968894902259
  - -0.5652249536178108
  - -0.585861031179678
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.18652687714785357
  - 0.198357960905444
  - 0.18091409758469154
  - 0.17139021229820897
  - 0.16361282238191435
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.1621566355394997
  - 0.16401006711409397
  - 0.15342239360969565
  - 0.15010128732928185
  - 0.1397820709940504
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.1812945452029458
  - 0.17710043112555413
  - 0.1641691057317534
  - 0.1644554315983511
  - 0.15081409546485378
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.3085364647447015
  - 0.2966871329700223
  - 0.2947474525899671
  - 0.2988656676749485
  - 0.28327619129924764
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.18094979674579353
  - 0.20553978633051811
  - 0.17972759982411732
  - 0.1806335151265902
  - 0.1857282030260886
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.1382719542919194
  - 0.1286705000232504
  - 0.10557699806805017
  - 0.12214740466192975
  - 0.10414270719193745
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.13947232887380862
  - 0.13516409182616823
  - 0.124795121678303
  - 0.12870744365978315
  - 0.11511054047729516
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.11195420431660091
  - 0.11930611240880047
  - 0.10555629020550564
  - 0.09717093656408386
  - 0.09037070474135832
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.24391624304044313
  - 0.2058701543361297
  - 0.21497422770567057
  - 0.22979659906222064
  - 0.20963587019839347
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.4122229780524765
  - 0.4382091604730861
  - 0.41398923833869755
  - 0.4176218407215615
  - 0.40480647696549743
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -16.146627565982406
  - -15.17117117117117
  - -16.2955223880597
  - -15.849431818181818
  - -16.24926686217009
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.7209384164222874
  - -0.7181981981981983
  - -0.7339701492537313
  - -0.7389772727272728
  - -0.7547214076246334
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.7209384164222874
  - -0.7181981981981982
  - -0.7339701492537314
  - -0.7389772727272728
  - -0.7547214076246335
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.7209384164222873
  - -0.7181981981981981
  - -0.7339701492537313
  - -0.7389772727272728
  - -0.7547214076246335
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.5593045046796606
  - -0.5755576500157086
  - -0.579239778444886
  - -0.5693281961544949
  - -0.5908595731569767
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.4635611775917402
  - -0.4133805475729018
  - -0.47611704964927415
  - -0.44811653573259275
  - -0.4813664964615349
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.27906158357771266
  - 0.2818018018018018
  - 0.2660298507462686
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.44069549532033936
  - 0.4244423499842915
  - 0.42076022155511394
  - 0.43067180384550513
  - 0.4091404268430232
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.2790615835777126
  - 0.2818018018018018
  - 0.26602985074626867
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.27906158357771266
  - 0.2818018018018018
  - 0.2660298507462686
  - 0.2610227272727273
  - 0.24527859237536656
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.44069549532033936
  - 0.4244423499842915
  - 0.42076022155511394
  - 0.43067180384550513
  - 0.4091404268430232
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.6274485034480505
  - 0.6266478497362808
  - 0.6074364244735085
  - 0.6221574886432648
  - 0.6031764046291553
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.5666834885676677
  - 0.5955718256818644
  - 0.5318387757620253
  - 0.5785184031937278
  - 0.5355860945400837
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.5389986459731148
  - 0.5880139265422922
  - 0.5260565395307238
  - 0.5564562760292936
  - 0.5159220733199972
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.6910465977188254
  - 0.6713987059043459
  - 0.6737187976944444
  - 0.676914820498119
  - 0.6558264320541992
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.15483870967741933
  - 0.1584384384384384
  - 0.1435223880597015
  - 0.14136363636363636
  - 0.12340175953079179
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.15483870967741936
  - 0.15843843843843844
  - 0.1435223880597015
  - 0.14136363636363636
  - 0.12340175953079179
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.1548387096774194
  - 0.15843843843843847
  - 0.1435223880597015
  - 0.14136363636363639
  - 0.12340175953079179
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.15510928209199465
  - 0.12831398788043463
  - 0.12686989979282062
  - 0.14876033057851237
  - 0.11775871649986522
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.12422287390029325
  - 0.12336336336336336
  - 0.12250746268656716
  - 0.11965909090909092
  - 0.12187683284457478
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.12422287390029325
  - 0.12336336336336336
  - 0.12250746268656716
  - 0.11965909090909091
  - 0.12187683284457478
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.12422287390029325
  - 0.12336336336336336
  - 0.12250746268656716
  - 0.1196590909090909
  - 0.12187683284457479
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.28558621322834477
  - 0.29612836210385685
  - 0.29389032176229335
  - 0.2819114732669927
  - 0.291381710343158
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.24267852325784203
  - 0.22400480974852818
  - 0.20722801370807756
  - 0.2263322898450518
  - 0.20733560331670473
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.13024942168448783
  - 0.13983086752893464
  - 0.12079881613599328
  - 0.1291661039287891
  - 0.12143308520667942
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.18081328333972568
  - 0.20159106430054477
  - 0.17812328987511064
  - 0.1804643867882121
  - 0.1751612481602476
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.46520876785837173
  - 0.43762704669466146
  - 0.4451642271834716
  - 0.44593728855548626
  - 0.42773356579428523
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.2775366568914956
  - 0.28060060060060066
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.2775366568914956
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.27753665689149565
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.26306818181818187
  - 0.24645161290322581
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.4378817582346365
  - 0.42063552713882585
  - 0.4221245049539836
  - 0.43277481447124305
  - 0.4105819436267902
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0034017595307917884
  - -0.004324324324324324
  - -0.0038208955223880603
  - -0.003181818181818182
  - -0.0032844574780058655
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.003401759530791789
  - -0.004324324324324324
  - -0.00382089552238806
  - -0.003181818181818182
  - -0.003284457478005865
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.0034017595307917893
  - -0.004324324324324324
  - -0.00382089552238806
  - -0.003181818181818182
  - -0.0032844574780058655
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.0067481084233891216
  - -0.006073934443397214
  - -0.007325976350541908
  - -0.0044458382526564345
  - -0.005144344247412698
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.7190615835777127
  - -0.7150750750750752
  - -0.7296716417910447
  - -0.73375
  - -0.7502639296187684
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.7190615835777127
  - -0.7150750750750751
  - -0.7296716417910448
  - -0.73375
  - -0.7502639296187683
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.7190615835777125
  - -0.7150750750750751
  - -0.7296716417910448
  - -0.7337499999999999
  - -0.7502639296187683
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.5553701333419745
  - -0.5732905384177769
  - -0.5705495186954745
  - -0.5627793472761006
  - -0.5842737121257972
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.18512785640227247
  - 0.19730941146662256
  - 0.18147336047095824
  - 0.17268546131635343
  - 0.16371812675934255
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.16112775810405883
  - 0.16319687019700993
  - 0.15374018459842953
  - 0.15145567549885508
  - 0.14054451802796172
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.18043862795071625
  - 0.17603357653450336
  - 0.16442579164408513
  - 0.16616971906904437
  - 0.15183513759091702
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.30579102960037485
  - 0.29333006153534846
  - 0.2962591640572755
  - 0.3005276641835343
  - 0.28445176337608613
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.1808132833397258
  - 0.20459406730354782
  - 0.18110836450197648
  - 0.18046438678821225
  - 0.18689145343883998
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.13484223254568595
  - 0.12482745635498432
  - 0.10860326132199415
  - 0.12190092272270635
  - 0.10274282153087734
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.1368096385488363
  - 0.13270236302504046
  - 0.12598031311033367
  - 0.12765226784277023
  - 0.11509944052320906
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.10987121652745369
  - 0.1179399785058269
  - 0.10686438667562258
  - 0.09526221260073173
  - 0.08992488930364982
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.23828567907496903
  - 0.19825061734058513
  - 0.21729502240179469
  - 0.23028845664147476
  - 0.20998703159277718
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.4120499471594065
  - 0.43761358630448943
  - 0.4137854358731001
  - 0.4171327066281345
  - 0.40590418869986544
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -16.15542521994135
  - -15.096096096096096
  - -16.22089552238806
  - -15.860795454545455
  - -16.181818181818183
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.7224633431085045
  - -0.7193993993993995
  - -0.7334925373134328
  - -0.7369318181818181
  - -0.7535483870967742
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.7224633431085044
  - -0.7193993993993995
  - -0.7334925373134329
  - -0.7369318181818182
  - -0.7535483870967742
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.7224633431085045
  - -0.7193993993993993
  - -0.7334925373134328
  - -0.7369318181818181
  - -0.7535483870967743
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5621182417653635
  - -0.5793644728611742
  - -0.5778754950460163
  - -0.5672251855287569
  - -0.5894180563732099
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.4636198563384862
  - -0.4135294496500581
  - -0.47222705254868236
  - -0.44806362128539345
  - -0.47911649773932563
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.2775366568914956
  - 0.28060060060060066
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.2775366568914956
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.27753665689149565
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.26306818181818187
  - 0.24645161290322581
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.4378817582346365
  - 0.42063552713882585
  - 0.4221245049539836
  - 0.43277481447124305
  - 0.4105819436267902
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.2775366568914956
  - 0.28060060060060066
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.2775366568914956
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.2630681818181818
  - 0.24645161290322581
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.27753665689149565
  - 0.2806006006006006
  - 0.26650746268656716
  - 0.26306818181818187
  - 0.24645161290322581
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.4378817582346365
  - 0.42063552713882585
  - 0.4221245049539836
  - 0.43277481447124305
  - 0.4105819436267902
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.6252141406104752
  - 0.6318189518054412
  - 0.6128254569245972
  - 0.6265358760350257
  - 0.5977425038494772
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.5661517852876817
  - 0.5941066839113628
  - 0.5336000208579538
  - 0.5760846296560582
  - 0.5397273701613851
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.5388927869563647
  - 0.5876773094689814
  - 0.5288029376772029
  - 0.5563096151597888
  - 0.5185665669568775
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.6918278057236724
  - 0.667180030556497
  - 0.6808701264813226
  - 0.682102271816064
  - 0.655574445472381
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.15354838709677418
  - 0.15747747747747748
  - 0.14388059701492537
  - 0.14375
  - 0.12469208211143695
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.15354838709677418
  - 0.15747747747747748
  - 0.14388059701492537
  - 0.14375
  - 0.12469208211143695
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.15354838709677418
  - 0.15747747747747748
  - 0.1438805970149254
  - 0.14375000000000002
  - 0.12469208211143695
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.15254127444467847
  - 0.12466283437065719
  - 0.12821727058757204
  - 0.15120593692022266
  - 0.11934603555374602
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.1239882697947214
  - 0.12312312312312311
  - 0.12262686567164179
  - 0.11931818181818184
  - 0.12175953079178886
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.12398826979472141
  - 0.12312312312312312
  - 0.12262686567164179
  - 0.11931818181818182
  - 0.12175953079178886
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.12398826979472138
  - 0.12312312312312312
  - 0.12262686567164179
  - 0.11931818181818182
  - 0.12175953079178885
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.2853404837899581
  - 0.2959726927681687
  - 0.2939072343664116
  - 0.2815688775510204
  - 0.29123590807304417
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.24112312215589257
  - 0.22463740525394787
  - 0.20507313794427817
  - 0.2324136978591958
  - 0.2092123262537167
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.12941021637761327
  - 0.13993021576527126
  - 0.12053519656907802
  - 0.1284819157325185
  - 0.12024070964843156
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.18045072252512137
  - 0.20189110299813584
  - 0.1776666891146542
  - 0.17976722348611632
  - 0.17483657848268438
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.459657947922624
  - 0.4342957672137756
  - 0.4384309125611236
  - 0.4460477359257023
  - 0.427812298729467
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.27964809384164224
  - 0.28192192192192195
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.2628409090909091
  - 0.24762463343108504
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.4381436896140157
  - 0.42239317545632343
  - 0.42431186841994
  - 0.4309037147917018
  - 0.411426496398959
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.0035190615835777126
  - -0.004684684684684685
  - -0.003701492537313433
  - -0.002954545454545454
  - -0.0034017595307917893
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.0035190615835777126
  - -0.0046846846846846845
  - -0.0037014925373134327
  - -0.0029545454545454545
  - -0.003401759530791789
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.0035190615835777126
  - -0.0046846846846846845
  - -0.0037014925373134327
  - -0.0029545454545454545
  - -0.0034017595307917893
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.007271971182147621
  - -0.006886245340533747
  - -0.006832692063760517
  - -0.004187573789846517
  - -0.005166352137241201
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.7168328445747801
  - -0.7133933933933934
  - -0.729313432835821
  - -0.7342045454545455
  - -0.7489736070381232
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.71683284457478
  - -0.7133933933933934
  - -0.7293134328358208
  - -0.7342045454545455
  - -0.7489736070381232
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.71683284457478
  - -0.7133933933933934
  - -0.729313432835821
  - -0.7342045454545455
  - -0.7489736070381232
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.5545843392038365
  - -0.5707205792031429
  - -0.5688554395162995
  - -0.5649087114184517
  - -0.5834071514637998
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.18624287544011472
  - 0.19824265723230142
  - 0.1813398986699495
  - 0.17235678263163512
  - 0.16462490785644865
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.1625528433110596
  - 0.164091449346291
  - 0.15405815075099905
  - 0.15130503041800222
  - 0.14130798580895643
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.18242157959983168
  - 0.17712069043201523
  - 0.16476462026827418
  - 0.16594279283249141
  - 0.1521709006172519
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.3054791082574665
  - 0.29492941418158125
  - 0.29801698308879637
  - 0.2985346898278678
  - 0.28543966744976845
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.18045072252512145
  - 0.20489410600113897
  - 0.18065176374152003
  - 0.17976722348611632
  - 0.1865667837612768
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.13486431344353297
  - 0.12382147083446926
  - 0.10884575209677315
  - 0.12202898978087251
  - 0.10078571102852911
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.1374758661309175
  - 0.13122269650500734
  - 0.12716403470677237
  - 0.12913918147158165
  - 0.11509300105012805
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.11162604784309053
  - 0.11628639122279684
  - 0.10717729794495473
  - 0.09745444012797115
  - 0.0921198171527031
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.2359004104421642
  - 0.19775991168072776
  - 0.22153076056563356
  - 0.2276950302618375
  - 0.2116131164697963
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.4114194836748319
  - 0.43886308683750963
  - 0.415251688597026
  - 0.41517103317072307
  - 0.4041790701624407
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -16.190615835777127
  - -15.12012012012012
  - -16.235820895522387
  - -15.877840909090908
  - -16.15542521994135
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.7203519061583578
  - -0.718078078078078
  - -0.7330149253731342
  - -0.7371590909090909
  - -0.7523753665689149
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.7203519061583578
  - -0.7180780780780781
  - -0.7330149253731343
  - -0.7371590909090909
  - -0.7523753665689149
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.7203519061583578
  - -0.718078078078078
  - -0.7330149253731343
  - -0.7371590909090908
  - -0.7523753665689151
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.5618563103859842
  - -0.5776068245436766
  - -0.57568813158006
  - -0.5690962852082982
  - -0.5885735036010409
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.46412687019527965
  - -0.4137441543754641
  - -0.4708635057350178
  - -0.449188632466827
  - -0.48053024481699225
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.27964809384164224
  - 0.28192192192192195
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.2628409090909091
  - 0.24762463343108504
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.4381436896140157
  - 0.42239317545632343
  - 0.42431186841994
  - 0.4309037147917018
  - 0.411426496398959
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.27964809384164224
  - 0.28192192192192195
  - 0.26698507462686566
  - 0.26284090909090907
  - 0.24762463343108504
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.27964809384164224
  - 0.2819219219219219
  - 0.26698507462686566
  - 0.2628409090909091
  - 0.24762463343108504
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.4381436896140157
  - 0.42239317545632343
  - 0.42431186841994
  - 0.4309037147917018
  - 0.411426496398959
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.6218792347326693
  - 0.6213577687740571
  - 0.6105340366741935
  - 0.6317519337356178
  - 0.6007984436239608
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.5631516320462289
  - 0.5937987861588478
  - 0.5318947927912021
  - 0.5745569365699236
  - 0.5355167976432516
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.5382719106917362
  - 0.5879357716303292
  - 0.5310454726771408
  - 0.554254332963052
  - 0.5159164448317651
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.685711067202764
  - 0.663152897897207
  - 0.6724398283669902
  - 0.6790588239239418
  - 0.6551520625929934
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.15577712609970673
  - 0.15915915915915915
  - 0.14423880597014924
  - 0.14329545454545456
  - 0.1259824046920821
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.15577712609970676
  - 0.15915915915915915
  - 0.14423880597014926
  - 0.14329545454545456
  - 0.1259824046920821
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.15577712609970676
  - 0.15915915915915915
  - 0.14423880597014926
  - 0.14329545454545456
  - 0.1259824046920821
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.15332706858281622
  - 0.12723279358529124
  - 0.12991134976674698
  - 0.14907657277787148
  - 0.12021259621574333
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.12387096774193548
  - 0.12276276276276275
  - 0.12274626865671642
  - 0.11954545454545455
  - 0.12164222873900293
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.12387096774193548
  - 0.12276276276276277
  - 0.12274626865671642
  - 0.11954545454545455
  - 0.12164222873900293
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.12387096774193547
  - 0.12276276276276277
  - 0.12274626865671641
  - 0.11954545454545454
  - 0.12164222873900292
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.28481662103119953
  - 0.29516038187103216
  - 0.29440051865319294
  - 0.2818271420138303
  - 0.2912139001832157
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.24300059599026466
  - 0.21846521691347603
  - 0.21220212784168824
  - 0.2182811806801435
  - 0.2121886179577769
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.13015783273443113
  - 0.13981762349451432
  - 0.12127269939903644
  - 0.129104328837432
  - 0.12209519644632204
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.18049116840693627
  - 0.20140839016787146
  - 0.17937795020692637
  - 0.17932918856521443
  - 0.17443747821864536
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.45782535978332356
  - 0.4331738062487948
  - 0.444187007637879
  - 0.4344507048624709
  - 0.4261219987860717
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.27941348973607044
  - 0.2808408408408409
  - 0.26650746268656716
  - 0.2623863636363637
  - 0.24762463343108507
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.4391590112495477
  - 0.4209100712399487
  - 0.42253040745282083
  - 0.4305031413391804
  - 0.40950630801142207
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.004105571847507331
  - -0.004924924924924925
  - -0.0038208955223880603
  - -0.0030681818181818176
  - -0.0031671554252199413
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.004105571847507331
  - -0.004924924924924925
  - -0.00382089552238806
  - -0.003068181818181818
  - -0.0031671554252199413
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.004105571847507331
  - -0.0049249249249249255
  - -0.00382089552238806
  - -0.0030681818181818184
  - -0.0031671554252199413
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.008044263702791593
  - -0.007800448893757093
  - -0.007314701281129762
  - -0.004316706021251475
  - -0.005350668214554918
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.7164809384164224
  - -0.7142342342342343
  - -0.7296716417910448
  - -0.7345454545454545
  - -0.7492082111436951
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.7164809384164222
  - -0.7142342342342343
  - -0.7296716417910448
  - -0.7345454545454545
  - -0.7492082111436951
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.7164809384164222
  - -0.7142342342342342
  - -0.7296716417910448
  - -0.7345454545454544
  - -0.7492082111436948
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.5527967250476608
  - -0.5712894798662942
  - -0.5701548912660493
  - -0.5651801526395683
  - -0.5851430237740229
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.18629404042181794
  - 0.19766068436504913
  - 0.18131206620769166
  - 0.17224492402536096
  - 0.16426200141410585
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.16239432778838286
  - 0.16335941866964784
  - 0.15374018459842953
  - 0.15100385847884376
  - 0.14130798580895643
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.18187617119102706
  - 0.1763110336552346
  - 0.16422854868936793
  - 0.165325995550788
  - 0.15215331237411095
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.30660901584853234
  - 0.29368686877286676
  - 0.29659700895924956
  - 0.29823437566119776
  - 0.2833975576715846
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.1804911684069365
  - 0.20441139317087467
  - 0.18236302483379221
  - 0.1793291885652146
  - 0.18616768349723786
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.13150097376500233
  - 0.12192227982051675
  - 0.1087175664927298
  - 0.12143799345747754
  - 0.10241066933136782
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.13333115514086233
  - 0.12884636644880423
  - 0.12598031311033367
  - 0.12800046789437786
  - 0.11685843195843408
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.10739643102119918
  - 0.11519112844246361
  - 0.10657713178958536
  - 0.09644672026364805
  - 0.09406943196568919
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.2344746235931273
  - 0.19319486003626388
  - 0.21809568167410773
  - 0.22709079358027853
  - 0.2087541352019019
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.4121237006071337
  - 0.4377961308936395
  - 0.41646930156465795
  - 0.4176868489021474
  - 0.4050254552170735
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -16.219941348973606
  - -15.117117117117116
  - -16.13134328358209
  - -15.9375
  - -16.167155425219942
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.7205865102639295
  - -0.7191591591591591
  - -0.7334925373134328
  - -0.7376136363636364
  - -0.752375366568915
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.7205865102639296
  - -0.7191591591591592
  - -0.7334925373134329
  - -0.7376136363636364
  - -0.7523753665689149
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.7205865102639295
  - -0.7191591591591591
  - -0.7334925373134328
  - -0.7376136363636363
  - -0.752375366568915
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.5608409887504523
  - -0.5790899287600514
  - -0.5774695925471792
  - -0.5694968586608197
  - -0.5904936919885779
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.4640245226249764
  - -0.4141998713885912
  - -0.46832416330780346
  - -0.4496185952392033
  - -0.47921127979217876
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.27941348973607044
  - 0.2808408408408409
  - 0.26650746268656716
  - 0.2623863636363637
  - 0.24762463343108507
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.4391590112495477
  - 0.4209100712399487
  - 0.42253040745282083
  - 0.4305031413391804
  - 0.40950630801142207
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.2794134897360704
  - 0.2808408408408408
  - 0.26650746268656716
  - 0.26238636363636364
  - 0.24762463343108504
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.27941348973607044
  - 0.2808408408408409
  - 0.26650746268656716
  - 0.2623863636363637
  - 0.24762463343108507
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.4391590112495477
  - 0.4209100712399487
  - 0.42253040745282083
  - 0.4305031413391804
  - 0.40950630801142207
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.623623268615286
  - 0.6354913730927002
  - 0.6095097953026564
  - 0.6222399682171786
  - 0.6042718167744277
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.5655598004345719
  - 0.5937361815800073
  - 0.5349147431141648
  - 0.5754114211906419
  - 0.5418250161546032
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.5386908287171511
  - 0.5871760541860642
  - 0.5334240871679724
  - 0.5554443523497805
  - 0.5184858482118827
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.6870572362425551
  - 0.6705011952439941
  - 0.6764493075071265
  - 0.6757981400138529
  - 0.66077846886376
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.15612903225806452
  - 0.1583183183183183
  - 0.14388059701492537
  - 0.14295454545454545
  - 0.12574780058651025
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.15612903225806452
  - 0.15831831831831833
  - 0.14388059701492537
  - 0.14295454545454545
  - 0.12574780058651028
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.15612903225806452
  - 0.15831831831831833
  - 0.1438805970149254
  - 0.14295454545454547
  - 0.1257478005865103
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.15511468273899212
  - 0.12666389292213986
  - 0.12861189801699716
  - 0.14880513155675493
  - 0.11847672390552012
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.12328445747800586
  - 0.12252252252252252
  - 0.12262686567164181
  - 0.11943181818181818
  - 0.12187683284457478
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.12328445747800587
  - 0.12252252252252252
  - 0.12262686567164179
  - 0.11943181818181818
  - 0.12187683284457478
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.12328445747800584
  - 0.12252252252252252
  - 0.12262686567164179
  - 0.11943181818181818
  - 0.12187683284457479
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.2840443285105556
  - 0.29424617831780886
  - 0.2939185094358237
  - 0.2816980097824253
  - 0.29102958410590196
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.23997046211158893
  - 0.2198584233517352
  - 0.20604539015882406
  - 0.22292652004825556
  - 0.21092325115930002
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.13011424920568035
  - 0.1398552252294536
  - 0.11996911729435666
  - 0.128575641887678
  - 0.12071904187425317
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.1806688312417634
  - 0.20228467626284688
  - 0.17633099230910257
  - 0.17971159195726585
  - 0.17417253103926508
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.4581516074260124
  - 0.43899164166227966
  - 0.4355979907815744
  - 0.4417161567775158
  - 0.42948557158363115
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337238
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337244
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.2788269794721408
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.2485630498533724
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.43856494007982155
  - 0.4200807782334644
  - 0.4224373881301706
  - 0.42945954208129533
  - 0.40869751806022453
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.004340175953079178
  - -0.0046846846846846845
  - -0.003940298507462687
  - -0.0028409090909090906
  - -0.003284457478005865
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.004340175953079179
  - -0.0046846846846846845
  - -0.0039402985074626865
  - -0.002840909090909091
  - -0.003284457478005865
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.004340175953079179
  - -0.0046846846846846845
  - -0.0039402985074626865
  - -0.002840909090909091
  - -0.0032844574780058655
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.008179279877729352
  - -0.007163619793214515
  - -0.007342888954660127
  - -0.004103242536684095
  - -0.005523980346954383
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.7168328445747801
  - -0.715075075075075
  - -0.7289552238805969
  - -0.7345454545454545
  - -0.7481524926686218
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.71683284457478
  - -0.7150750750750751
  - -0.728955223880597
  - -0.7345454545454545
  - -0.7481524926686217
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.71683284457478
  - -0.715075075075075
  - -0.728955223880597
  - -0.7345454545454544
  - -0.7481524926686217
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.5532557800424491
  - -0.5727556019733211
  - -0.5702197229151693
  - -0.5664372153820206
  - -0.585778501592821
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.1859340172078029
  - 0.19728518785112686
  - 0.18182612137170182
  - 0.172597329728111
  - 0.1647505205748321
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.16199822803789274
  - 0.16295313263951947
  - 0.15413766967546338
  - 0.15115442474982013
  - 0.1419194963498761
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.18137647419933886
  - 0.1762053737074879
  - 0.16466243670145558
  - 0.16586421897235623
  - 0.15285270050321093
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.3061957152188562
  - 0.29284342177154843
  - 0.29628574934239615
  - 0.29726346593746206
  - 0.28264643000288164
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.1806688312417634
  - 0.20528767926584984
  - 0.17931606693596838
  - 0.17971159195726608
  - 0.18590273631785748
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.12892849938030324
  - 0.12391256526774405
  - 0.10650797715274858
  - 0.12288017210994476
  - 0.10142837878268558
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.1313296545557356
  - 0.1300252669126092
  - 0.12557097129596492
  - 0.12980680633133043
  - 0.11667279532743927
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.10564573954634524
  - 0.11580493378130255
  - 0.10635982703692323
  - 0.0993175486477388
  - 0.09414700858735885
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.2326103112979387
  - 0.19398368278823858
  - 0.21594903639646273
  - 0.226460483770952
  - 0.2058364062187285
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.41133698454577033
  - 0.43852670704645924
  - 0.4127339994862578
  - 0.41669617937452585
  - 0.4046705079987009
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -16.2316715542522
  - -15.102102102102101
  - -16.328358208955223
  - -15.980113636363637
  - -16.187683284457478
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.7211730205278591
  - -0.7197597597597597
  - -0.7328955223880597
  - -0.7373863636363638
  - -0.7514369501466276
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.7211730205278593
  - -0.7197597597597598
  - -0.7328955223880597
  - -0.7373863636363637
  - -0.7514369501466276
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.7211730205278593
  - -0.7197597597597597
  - -0.7328955223880597
  - -0.7373863636363637
  - -0.7514369501466276
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5614350599201785
  - -0.5799192217665357
  - -0.5775626118698294
  - -0.5705404579187047
  - -0.5913024819397754
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.4651003225604978
  - -0.41151591792795184
  - -0.47703701154051237
  - -0.4489740777856206
  - -0.48028865050592934
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337238
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337244
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.2788269794721408
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.2485630498533724
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.43856494007982155
  - 0.4200807782334644
  - 0.4224373881301706
  - 0.42945954208129533
  - 0.40869751806022453
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337238
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.27882697947214075
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.24856304985337244
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.2788269794721408
  - 0.28024024024024025
  - 0.2671044776119403
  - 0.2626136363636364
  - 0.2485630498533724
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.43856494007982155
  - 0.4200807782334644
  - 0.4224373881301706
  - 0.42945954208129533
  - 0.40869751806022453
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.6222379455505386
  - 0.6274584889903124
  - 0.6152183069608586
  - 0.6204373779074417
  - 0.6056669152000322
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.5653038822570906
  - 0.5937314456895871
  - 0.5298373931481621
  - 0.573698667854512
  - 0.5371216307685265
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.5371410321920893
  - 0.5896022004975743
  - 0.5246624890431328
  - 0.5554851731271746
  - 0.516552568984713
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.6883792479582901
  - 0.665292510591261
  - 0.6752064658348049
  - 0.677440576175111
  - 0.659429653636499
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.15577712609970673
  - 0.15747747747747748
  - 0.14459701492537314
  - 0.14295454545454545
  - 0.12680351906158358
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.15577712609970676
  - 0.15747747747747748
  - 0.14459701492537314
  - 0.14295454545454545
  - 0.12680351906158358
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.15577712609970676
  - 0.15747747747747748
  - 0.14459701492537314
  - 0.14295454545454545
  - 0.1268035190615836
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.15465562774420374
  - 0.12519777081511294
  - 0.12854706636787733
  - 0.1475480688143026
  - 0.1178412460867221
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.12304985337243401
  - 0.12276276276276278
  - 0.12250746268656716
  - 0.11965909090909092
  - 0.12175953079178886
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.12304985337243401
  - 0.12276276276276277
  - 0.12250746268656716
  - 0.11965909090909091
  - 0.12175953079178886
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.123049853372434
  - 0.12276276276276277
  - 0.12250746268656716
  - 0.1196590909090909
  - 0.12175953079178885
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.2839093123356178
  - 0.2948830074183514
  - 0.29389032176229335
  - 0.2819114732669927
  - 0.2908562719735025
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.5402144347636771
  - 0.5247825345493952
  - 0.5359355228418601
  - 0.5382278478807713
  - 0.5425233454447296
  train_level0__average_precision_macro_masked:
  - 0.30350856951837873
  - 0.2809682252883552
  - 0.29456128705481166
  - 0.28950182667208385
  - 0.2977888214800764
  train_level0__average_precision_macro_oob:
  - 0.33418242794482916
  - 0.31829799321503416
  - 0.32516176430466487
  - 0.3237608650304906
  - 0.32726326760651064
  train_level0__average_precision_micro:
  - 0.684606027905272
  - 0.6776149977917314
  - 0.6799151048130421
  - 0.673652554191214
  - 0.6819306281229821
  train_level0__average_precision_micro_masked:
  - 0.5411087962430381
  - 0.5293748804573932
  - 0.534469642539353
  - 0.528492137850149
  - 0.537789786356774
  train_level0__average_precision_micro_oob:
  - 0.6022485915671266
  - 0.5944063397957231
  - 0.6018545369394466
  - 0.5935566182504658
  - 0.5970543214737869
  train_level0__average_precision_samples:
  - 0.7320378792963369
  - 0.728980595896605
  - 0.7305763771099925
  - 0.7296425361896629
  - 0.7292842482031728
  train_level0__average_precision_samples_masked:
  - 0.6076992072960028
  - 0.6140969535396545
  - 0.6136651064123247
  - 0.6085685559880425
  - 0.6093071144032333
  train_level0__average_precision_samples_oob:
  - 0.6818304951295993
  - 0.6834819661688618
  - 0.6859485245284427
  - 0.6844070387570036
  - 0.6830902196046349
  train_level0__average_precision_weighted:
  - 0.7010430147189606
  - 0.6929307822079214
  - 0.6997127178536172
  - 0.6983952152656587
  - 0.7002847457401331
  train_level0__average_precision_weighted_masked:
  - 0.5122918422494972
  - 0.4955625686794753
  - 0.505596275572096
  - 0.5015694461286065
  - 0.5033953207982488
  train_level0__average_precision_weighted_oob:
  - 0.5614569586483187
  - 0.546340699639131
  - 0.5561658814946876
  - 0.5527542716292316
  - 0.5512368538445941
  train_level0__f1_macro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__f1_macro_masked:
  - 0.9037139388308871
  - 0.9037567689983678
  - 0.9036042896015711
  - 0.9025912847262566
  - 0.9032117765535106
  train_level0__f1_macro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624727
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__f1_micro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__f1_micro_masked:
  - 0.9092325552975681
  - 0.9091903055336209
  - 0.9090466630163655
  - 0.9081890443034075
  - 0.9087048183568089
  train_level0__f1_micro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__f1_samples:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8747915142648134
  - 0.8734222222222221
  - 0.8740925789860395
  train_level0__f1_samples_masked:
  - 0.9096265423020047
  - 0.9093850681453501
  - 0.9092621292599028
  - 0.9084177015148028
  - 0.9090594118517624
  train_level0__f1_samples_oob:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111109
  - 0.8740925789860395
  train_level0__f1_weighted:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7079829049658554
  - 0.7026511998890276
  - 0.7052800057078917
  train_level0__f1_weighted_masked:
  - 0.7622240116659752
  - 0.7645222451656802
  - 0.764389004499905
  - 0.7608242728529009
  - 0.7631681868775483
  train_level0__f1_weighted_oob:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7069334312114791
  - 0.7030070051324733
  - 0.7052800057078917
  train_level0__fn_macro:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518653
  - -0.1265777777777778
  - -0.12590742101396032
  train_level0__fn_macro_masked:
  - -0.0962860611691129
  - -0.09624323100163223
  - -0.09639571039842887
  - -0.09740871527374327
  - -0.09678822344648932
  train_level0__fn_macro_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12544257498171177
  - -0.12648888888888887
  - -0.12590742101396032
  train_level0__fn_micro:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518653
  - -0.1265777777777778
  - -0.12590742101396032
  train_level0__fn_micro_masked:
  - -0.09076744470243187
  - -0.09080969446637915
  - -0.09095333698363449
  - -0.09181095569659252
  - -0.09129518164319106
  train_level0__fn_micro_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12544257498171177
  - -0.1264888888888889
  - -0.12590742101396032
  train_level0__fn_samples:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518656
  - -0.12657777777777776
  - -0.12590742101396032
  train_level0__fn_samples_masked:
  - -0.09037345769799529
  - -0.09061493185464985
  - -0.09073787074009713
  - -0.09158229848519703
  - -0.09094058814823766
  train_level0__fn_samples_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.1254425749817118
  - -0.1264888888888889
  - -0.12590742101396032
  train_level0__fn_weighted:
  - -0.29577013370314564
  - -0.2933570019011721
  - -0.29201709503414447
  - -0.29734880011097237
  - -0.2947199942921082
  train_level0__fn_weighted_masked:
  - -0.23777598833402488
  - -0.23547775483431976
  - -0.2356109955000951
  - -0.23917572714709925
  - -0.23683181312245186
  train_level0__fn_weighted_oob:
  - -0.29577013370314564
  - -0.2933570019011721
  - -0.29294996059359024
  - -0.29699299486752667
  - -0.2947199942921082
  train_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -0.0
  - -0.0
  - -2.926115581565472e-05
  - -0.0
  - -0.0
  train_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -0.0
  - -0.0
  - -2.9261155815654717e-05
  - -0.0
  - -0.0
  train_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -0.0
  - -0.0
  - -2.9261155815654717e-05
  - -0.0
  - -0.0
  train_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.0
  - -0.0
  - -0.00011660819493071447
  - -0.0
  - -0.0
  train_level0__jaccard_macro:
  - 0.8020775956394427
  - 0.8017964177460983
  - 0.8017090453687509
  - 0.8002713856016928
  - 0.8009914279049939
  train_level0__jaccard_macro_masked:
  - 0.8429788199057252
  - 0.8427889216238016
  - 0.8425478095784881
  - 0.8413089864324493
  - 0.8420413891737248
  train_level0__jaccard_macro_oob:
  - 0.8020775956394427
  - 0.8017964177460983
  - 0.8014733484891531
  - 0.8003498159490087
  - 0.8009914279049939
  train_level0__jaccard_micro:
  - 0.7772728459870981
  - 0.777275795814509
  - 0.777448379882457
  - 0.7752879911630108
  - 0.7763449842073664
  train_level0__jaccard_micro_masked:
  - 0.8335714085651066
  - 0.8335003897984186
  - 0.8332589783627036
  - 0.831818951408093
  - 0.8326847159615869
  train_level0__jaccard_micro_oob:
  - 0.7772728459870981
  - 0.777275795814509
  - 0.7770324727660349
  - 0.7754280754359663
  - 0.7763449842073664
  train_level0__jaccard_samples:
  - 0.7818155165022022
  - 0.7819887896906659
  - 0.782184711042865
  - 0.7800454300087123
  - 0.7809251699913339
  train_level0__jaccard_samples_masked:
  - 0.8387036825400758
  - 0.8381093795113126
  - 0.8379193725920392
  - 0.8366623986550541
  - 0.8376389105296032
  train_level0__jaccard_samples_oob:
  - 0.7818155165022022
  - 0.7819887896906659
  - 0.7817496692959696
  - 0.7801792255448067
  - 0.7809251699913339
  train_level0__jaccard_weighted:
  - 0.5793409494296345
  - 0.5816082076567464
  - 0.5830071346625081
  - 0.5779121572899959
  - 0.5805944597414996
  train_level0__jaccard_weighted_masked:
  - 0.6447237786199153
  - 0.6471550889929945
  - 0.647160223479117
  - 0.6433097110333669
  - 0.6459539620961195
  train_level0__jaccard_weighted_oob:
  - 0.5793409494296345
  - 0.5816082076567464
  - 0.5820678625485199
  - 0.5782260989892232
  - 0.5805944597414996
  train_level0__label_ranking_average_precision_score:
  - 0.736446402441083
  - 0.7326328968462035
  - 0.7342340215869501
  - 0.7340869806341076
  - 0.730753755918089
  train_level0__label_ranking_average_precision_score_oob:
  - 0.6862390182743446
  - 0.6871342671184607
  - 0.6896061690054002
  - 0.688851483201448
  - 0.6845597273195504
  train_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.003761519068246673
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0014523723923850229
  - 0.0018627127383874281
  - 0.0
  train_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.04945984250995295
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.024621583446341997
  - 0.024767172380129147
  - 0.0
  train_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.004831806360040631
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0014003113765662968
  - 0.0009953056571535915
  - 0.0
  train_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.014989973448384552
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.005787827525002072
  - 0.007456083292702486
  - 0.0
  train_level0__ndcg:
  - 0.8425895085538749
  - 0.8416635093576381
  - 0.8417714093187311
  - 0.841751893841425
  - 0.8422688011298399
  train_level0__ndcg_oob:
  - 0.8115608111356014
  - 0.8144276607658878
  - 0.8151773845570023
  - 0.8152135292372517
  - 0.8138236519797415
  train_level0__neg_coverage_error:
  - -7.808963997060984
  - -7.9802775748721695
  - -7.814923189465984
  - -8.005925925925926
  - -7.988978692138134
  train_level0__neg_coverage_error_oob:
  - -9.155033063923586
  - -9.27027027027027
  - -9.145574250182882
  - -9.294814814814815
  - -9.299044819985305
  train_level0__neg_hamming_loss_macro:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518653
  - -0.1265777777777778
  - -0.12590742101396032
  train_level0__neg_hamming_loss_macro_masked:
  - -0.0962860611691129
  - -0.09624323100163223
  - -0.09639571039842887
  - -0.09740871527374327
  - -0.09678822344648932
  train_level0__neg_hamming_loss_macro_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.1254718361375274
  - -0.12648888888888887
  - -0.12590742101396032
  train_level0__neg_hamming_loss_micro:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518653
  - -0.1265777777777778
  - -0.12590742101396032
  train_level0__neg_hamming_loss_micro_masked:
  - -0.09076744470243187
  - -0.09080969446637915
  - -0.09095333698363449
  - -0.09181095569659252
  - -0.09129518164319106
  train_level0__neg_hamming_loss_micro_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12547183613752744
  - -0.1264888888888889
  - -0.12590742101396032
  train_level0__neg_hamming_loss_samples:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12520848573518656
  - -0.12657777777777776
  - -0.12590742101396032
  train_level0__neg_hamming_loss_samples_masked:
  - -0.09037345769799529
  - -0.09061493185464985
  - -0.09073787074009713
  - -0.09158229848519703
  - -0.09094058814823766
  train_level0__neg_hamming_loss_samples_oob:
  - -0.12531961792799412
  - -0.12531775018261504
  - -0.12547183613752744
  - -0.1264888888888889
  - -0.12590742101396032
  train_level0__neg_hamming_loss_weighted:
  - -0.29577013370314564
  - -0.2933570019011721
  - -0.29201709503414447
  - -0.29734880011097237
  - -0.2947199942921082
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.23777598833402488
  - -0.23547775483431976
  - -0.2356109955000951
  - -0.23917572714709925
  - -0.23683181312245186
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.29577013370314564
  - -0.2933570019011721
  - -0.29306656878852094
  - -0.29699299486752667
  - -0.2947199942921082
  train_level0__neg_label_ranking_loss:
  - -0.09380805427454979
  - -0.09790661296216588
  - -0.0949148605251692
  - -0.09685456257923018
  - -0.0967379994572232
  train_level0__neg_label_ranking_loss_oob:
  - -0.12357672154532195
  - -0.12568841770009218
  - -0.12358385956046344
  - -0.12635971837332272
  - -0.12550165294974125
  train_level0__precision_macro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__precision_macro_masked:
  - 0.9037139388308871
  - 0.9037567689983678
  - 0.9036042896015711
  - 0.9025912847262566
  - 0.9032117765535106
  train_level0__precision_macro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624727
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__precision_micro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__precision_micro_masked:
  - 0.9092325552975681
  - 0.9091903055336209
  - 0.9090466630163655
  - 0.9081890443034075
  - 0.9087048183568089
  train_level0__precision_micro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__precision_samples:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8747915142648134
  - 0.8734222222222221
  - 0.8740925789860395
  train_level0__precision_samples_masked:
  - 0.9096265423020047
  - 0.9093850681453501
  - 0.9092621292599028
  - 0.9084177015148028
  - 0.9090594118517624
  train_level0__precision_samples_oob:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111109
  - 0.8740925789860395
  train_level0__precision_weighted:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7079829049658554
  - 0.7026511998890276
  - 0.7052800057078917
  train_level0__precision_weighted_masked:
  - 0.7622240116659752
  - 0.7645222451656802
  - 0.764389004499905
  - 0.7608242728529009
  - 0.7631681868775483
  train_level0__precision_weighted_oob:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7069334312114791
  - 0.7030070051324733
  - 0.7052800057078917
  train_level0__recall_macro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__recall_macro_masked:
  - 0.9037139388308871
  - 0.9037567689983678
  - 0.9036042896015711
  - 0.9025912847262566
  - 0.9032117765535106
  train_level0__recall_macro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624727
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__recall_micro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8747915142648135
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__recall_micro_masked:
  - 0.9092325552975681
  - 0.9091903055336209
  - 0.9090466630163655
  - 0.9081890443034075
  - 0.9087048183568089
  train_level0__recall_micro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111111
  - 0.8740925789860396
  train_level0__recall_samples:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8747915142648134
  - 0.8734222222222221
  - 0.8740925789860395
  train_level0__recall_samples_masked:
  - 0.9096265423020047
  - 0.9093850681453501
  - 0.9092621292599028
  - 0.9084177015148028
  - 0.9090594118517624
  train_level0__recall_samples_oob:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8745281638624726
  - 0.8735111111111109
  - 0.8740925789860395
  train_level0__recall_weighted:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7079829049658554
  - 0.7026511998890276
  - 0.7052800057078917
  train_level0__recall_weighted_masked:
  - 0.7622240116659752
  - 0.7645222451656802
  - 0.764389004499905
  - 0.7608242728529009
  - 0.7631681868775483
  train_level0__recall_weighted_oob:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7069334312114791
  - 0.7030070051324733
  - 0.7052800057078917
  train_level0__roc_auc_macro:
  - 0.8343949676314568
  - 0.8298101833038514
  - 0.83364055840151
  - 0.833873833681491
  - 0.8284657477821107
  train_level0__roc_auc_macro_masked:
  - 0.7669224436885576
  - 0.7607185519190129
  - 0.7656683883599784
  - 0.7664811992625445
  - 0.7588324847088903
  train_level0__roc_auc_macro_oob:
  - 0.7532145361639021
  - 0.7491947551248548
  - 0.754583222543592
  - 0.7487013214325468
  - 0.7495051439157521
  train_level0__roc_auc_micro:
  - 0.9067911840880187
  - 0.9047559718290447
  - 0.9076623544075233
  - 0.9053960614123959
  - 0.9053229223500705
  train_level0__roc_auc_micro_masked:
  - 0.8793229040180998
  - 0.8767357151220263
  - 0.8807646422353725
  - 0.8782120018068303
  - 0.8775364788114721
  train_level0__roc_auc_micro_oob:
  - 0.8760738063772974
  - 0.8742770930670595
  - 0.8768075640944097
  - 0.8741595847966858
  - 0.8743826055578302
  train_level0__roc_auc_samples:
  - 0.9057765595072603
  - 0.9017344918290284
  - 0.9047410705161866
  - 0.902713050980684
  - 0.9031307831154312
  train_level0__roc_auc_samples_masked:
  - 0.8791570489262686
  - 0.8729026152433647
  - 0.8810006924123215
  - 0.8756883038177354
  - 0.8753627173713365
  train_level0__roc_auc_samples_oob:
  - 0.8758984391196457
  - 0.8738730639287953
  - 0.8760061584363953
  - 0.8731156328117893
  - 0.8743685987197038
  train_level0__roc_auc_weighted:
  - 0.8504062091323187
  - 0.8491635740159486
  - 0.850701355705157
  - 0.8500236753543535
  - 0.8485187564090301
  train_level0__roc_auc_weighted_masked:
  - 0.7974748408962065
  - 0.7962737006695432
  - 0.7969122154226554
  - 0.7963824662654603
  - 0.7945575105589316
  train_level0__roc_auc_weighted_oob:
  - 0.7888429063550849
  - 0.7866261746927532
  - 0.7902495743401208
  - 0.7858190632661973
  - 0.7855093458232913
  train_level0__tn_macro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8744403803950257
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__tn_macro_masked:
  - 0.9037139388308871
  - 0.9037567689983678
  - 0.9036042896015711
  - 0.9025912847262566
  - 0.9032117765535106
  train_level0__tn_macro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.87441111923921
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__tn_micro:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.8744403803950256
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__tn_micro_masked:
  - 0.9092325552975681
  - 0.9091903055336209
  - 0.9090466630163655
  - 0.9081890443034075
  - 0.9087048183568089
  train_level0__tn_micro_oob:
  - 0.8746803820720058
  - 0.874682249817385
  - 0.87441111923921
  - 0.8734222222222222
  - 0.8740925789860396
  train_level0__tn_samples:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8744403803950256
  - 0.8734222222222221
  - 0.8740925789860395
  train_level0__tn_samples_masked:
  - 0.9096265423020047
  - 0.9093850681453501
  - 0.9092621292599028
  - 0.9084177015148028
  - 0.9090594118517624
  train_level0__tn_samples_oob:
  - 0.8746803820720059
  - 0.874682249817385
  - 0.8744111192392099
  - 0.8734222222222221
  - 0.8740925789860395
  train_level0__tn_weighted:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7065836066266868
  - 0.7026511998890276
  - 0.7052800057078917
  train_level0__tn_weighted_masked:
  - 0.7622240116659752
  - 0.7645222451656802
  - 0.764389004499905
  - 0.7608242728529009
  - 0.7631681868775483
  train_level0__tn_weighted_oob:
  - 0.7042298662968542
  - 0.7066429980988279
  - 0.7064669984317562
  - 0.7026511998890276
  - 0.7052800057078917
  train_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0003511338697878566
  - 0.0
  - 0.0
  train_level0__tp_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 0.0
  - 0.0
  - 0.00011704462326261888
  - 8.888888888888889e-05
  - 0.0
  train_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0003511338697878566
  - 0.0
  - 0.0
  train_level0__tp_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 0.0
  - 0.0
  - 0.00011704462326261887
  - 8.888888888888889e-05
  - 0.0
  train_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0003511338697878566
  - 0.0
  - 0.0
  train_level0__tp_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 0.0
  - 0.0
  - 0.00011704462326261887
  - 8.888888888888888e-05
  - 0.0
  train_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0013992983391685734
  - 0.0
  - 0.0
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0
  - 0.0
  - 0.00046643277972285786
  - 0.0003558052434456929
  - 0.0
  train_level10__average_precision_macro:
  - 0.21287111841663464
  - 0.2252831312492903
  - 0.22098649956058758
  - 0.21016755752393884
  - 0.21649944106179375
  train_level10__average_precision_macro_masked:
  - 0.17453031253797047
  - 0.18151567382120798
  - 0.18235893276329088
  - 0.17435306022183655
  - 0.1784279269644799
  train_level10__average_precision_macro_oob:
  - 0.20821585896741354
  - 0.2239633432049671
  - 0.21898048793932215
  - 0.20592640645184201
  - 0.2145227322375186
  train_level10__average_precision_micro:
  - 0.12643408406016712
  - 0.13924440613937816
  - 0.12238048739413766
  - 0.13204727087875742
  - 0.12373713001406098
  train_level10__average_precision_micro_masked:
  - 0.09152589659497427
  - 0.10101668772976824
  - 0.08817003266129803
  - 0.0958673241686773
  - 0.08941613028000575
  train_level10__average_precision_micro_oob:
  - 0.1259333727913744
  - 0.13860572779859226
  - 0.12200690735032814
  - 0.13173371022132135
  - 0.1237788212578873
  train_level10__average_precision_samples:
  - 0.17869202196448408
  - 0.1996770425619253
  - 0.1782973519818192
  - 0.18625942786892433
  - 0.18195648349424806
  train_level10__average_precision_samples_masked:
  - 0.14133568853620815
  - 0.15933336149574648
  - 0.1408818201046049
  - 0.1489639123415592
  - 0.14395962348252414
  train_level10__average_precision_samples_oob:
  - 0.17804397862652713
  - 0.19818014837278555
  - 0.17738876700769088
  - 0.18533439620803316
  - 0.1813724810158356
  train_level10__average_precision_weighted:
  - 0.4296760970582804
  - 0.44928650932215214
  - 0.45180213189684587
  - 0.422208477278367
  - 0.45167852846859724
  train_level10__average_precision_weighted_masked:
  - 0.3644243610264983
  - 0.3860098153719791
  - 0.3878687440473409
  - 0.35966069017435354
  - 0.3881181458570033
  train_level10__average_precision_weighted_oob:
  - 0.4230126901890763
  - 0.44410392567916646
  - 0.44497662261196874
  - 0.41798098281407264
  - 0.44771623096284086
  train_level10__f1_macro:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.2761667885881492
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__f1_macro_masked:
  - 0.23581667367059264
  - 0.2626956424048845
  - 0.253072103470918
  - 0.23783864539303756
  - 0.23640450817703182
  train_level10__f1_macro_oob:
  - 0.2551947097722263
  - 0.28108108108108104
  - 0.27160204828090706
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__f1_micro:
  - 0.2593093313739897
  - 0.28593133674214755
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.2597795738427627
  train_level10__f1_micro_masked:
  - 0.23047781987046315
  - 0.25833687663244853
  - 0.2480379631319584
  - 0.23211534906648593
  - 0.23089614714778942
  train_level10__f1_micro_oob:
  - 0.2551947097722263
  - 0.2810810810810811
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__f1_samples:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__f1_samples_masked:
  - 0.2287745106377506
  - 0.2567748876503283
  - 0.24641479175383948
  - 0.2306908331067751
  - 0.2291659593131371
  train_level10__f1_samples_oob:
  - 0.25519470977222636
  - 0.28108108108108115
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__f1_weighted:
  - 0.41839390112942554
  - 0.42036033878774265
  - 0.42593632203773846
  - 0.42784141351088917
  - 0.42178473152670326
  train_level10__f1_weighted_masked:
  - 0.37278232942466943
  - 0.37491201119026224
  - 0.38182552837711214
  - 0.382732632156605
  - 0.3767690892475925
  train_level10__f1_weighted_oob:
  - 0.41091247330830855
  - 0.4140857726145042
  - 0.4189532982474505
  - 0.4222119919545013
  - 0.41175904601370306
  train_level10__fn_macro:
  - -0.002321822189566495
  - -0.002951059167275384
  - -0.0029553767373811267
  - -0.0028444444444444446
  - -0.002321822189566495
  train_level10__fn_macro_masked:
  - -0.0021069880210823795
  - -0.002535508406889889
  - -0.002698447803414267
  - -0.002517824278047718
  - -0.00209845596821952
  train_level10__fn_macro_oob:
  - -0.002615723732549595
  - -0.003126369612856099
  - -0.0030138990490124356
  - -0.002814814814814815
  - -0.0024099926524614253
  train_level10__fn_micro:
  - -0.002321822189566495
  - -0.0029510591672753834
  - -0.0029553767373811267
  - -0.0028444444444444446
  - -0.002321822189566495
  train_level10__fn_micro_masked:
  - -0.0019858242698276916
  - -0.0024904330923889934
  - -0.0025552108048914036
  - -0.002433914597325775
  - -0.001986006294112255
  train_level10__fn_micro_oob:
  - -0.002615723732549596
  - -0.003126369612856099
  - -0.003013899049012436
  - -0.0028148148148148147
  - -0.0024099926524614253
  train_level10__fn_samples:
  - -0.002321822189566495
  - -0.0029510591672753834
  - -0.002955376737381127
  - -0.002844444444444444
  - -0.002321822189566495
  train_level10__fn_samples_masked:
  - -0.001967565173967116
  - -0.002481430871560131
  - -0.0025354057644697255
  - -0.002416654467379105
  - -0.001956657266851178
  train_level10__fn_samples_oob:
  - -0.002615723732549596
  - -0.0031263696128560996
  - -0.003013899049012436
  - -0.0028148148148148147
  - -0.0024099926524614257
  train_level10__fn_weighted:
  - -0.0053760754218631305
  - -0.0044178450283319445
  - -0.006562450081378541
  - -0.004806318490775419
  - -0.005045172612272928
  train_level10__fn_weighted_masked:
  - -0.005218281311424803
  - -0.003697464930223513
  - -0.00636621818374632
  - -0.004648870901569596
  - -0.004963596477548774
  train_level10__fn_weighted_oob:
  - -0.005648161805757547
  - -0.004179751452788071
  - -0.006672239083623247
  - -0.00449438202247191
  - -0.005171404834282477
  train_level10__fp_macro:
  - -0.7383688464364436
  - -0.7111176040905771
  - -0.7208778346744696
  - -0.7361481481481481
  - -0.7378986039676708
  train_level10__fp_macro_masked:
  - -0.7620763383083251
  - -0.7347688491882256
  - -0.7442294487256678
  - -0.7596435303289146
  - -0.7614970358547487
  train_level10__fp_macro_oob:
  - -0.7421895664952242
  - -0.7157925493060627
  - -0.7253840526700803
  - -0.7408296296296296
  - -0.7456576047024245
  train_level10__fp_micro:
  - -0.7383688464364437
  - -0.7111176040905771
  - -0.7208778346744696
  - -0.7361481481481481
  - -0.7378986039676708
  train_level10__fp_micro_masked:
  - -0.7675363558597091
  - -0.7391726902751625
  - -0.7494068260631502
  - -0.7654507363361883
  - -0.7671178465580983
  train_level10__fp_micro_oob:
  - -0.742189566495224
  - -0.7157925493060628
  - -0.7253840526700804
  - -0.7408296296296296
  - -0.7456576047024247
  train_level10__fp_samples:
  - -0.7383688464364437
  - -0.711117604090577
  - -0.7208778346744696
  - -0.7361481481481481
  - -0.7378986039676708
  train_level10__fp_samples_masked:
  - -0.7692579241882822
  - -0.7407436814781115
  - -0.7510498024816908
  - -0.7668925124258458
  - -0.7688773834200118
  train_level10__fp_samples_oob:
  - -0.742189566495224
  - -0.7157925493060628
  - -0.7253840526700804
  - -0.7408296296296295
  - -0.7456576047024246
  train_level10__fp_weighted:
  - -0.5762300234487113
  - -0.5752218161839252
  - -0.567501227880883
  - -0.5673522679983355
  - -0.5731700958610239
  train_level10__fp_weighted_masked:
  - -0.6219993892639056
  - -0.6213905238795143
  - -0.6118082534391415
  - -0.6126184969418254
  - -0.6182673142748587
  train_level10__fp_weighted_oob:
  - -0.583439364885934
  - -0.5817344759327078
  - -0.5743744626689263
  - -0.5732936260230267
  - -0.5830695491520145
  train_level10__jaccard_macro:
  - 0.170650167451225
  - 0.20100393167684352
  - 0.18523469743668733
  - 0.1707093745440844
  - 0.17092706661043408
  train_level10__jaccard_macro_masked:
  - 0.15319700187192253
  - 0.1839012394216721
  - 0.1680676449862311
  - 0.1532258279496548
  - 0.15347502965636192
  train_level10__jaccard_macro_oob:
  - 0.17000990087166343
  - 0.19912838938274774
  - 0.1835222622999727
  - 0.1693280922654937
  - 0.16588954737742234
  train_level10__jaccard_micro:
  - 0.14896922011920238
  - 0.1668144006545752
  - 0.16020505160239001
  - 0.1500911553730555
  - 0.14927969465133167
  train_level10__jaccard_micro_masked:
  - 0.1302486187845304
  - 0.14832769504411816
  - 0.14157724762996146
  - 0.13129552821442264
  - 0.13051588055473998
  train_level10__jaccard_micro_oob:
  - 0.1462597065709906
  - 0.16352201257861634
  - 0.1571409223268098
  - 0.14702283849918435
  - 0.14412051514845825
  train_level10__jaccard_samples:
  - 0.16386802126663158
  - 0.18109099926782332
  - 0.17326635594938652
  - 0.1626762044163613
  - 0.163187694657761
  train_level10__jaccard_samples_masked:
  - 0.1450703947089166
  - 0.16251108448869986
  - 0.1544902374343198
  - 0.14381910134014042
  - 0.144302199425689
  train_level10__jaccard_samples_oob:
  - 0.16018967815043364
  - 0.17704668019740355
  - 0.1691540779095079
  - 0.1587397762597108
  - 0.15702948936945627
  train_level10__jaccard_weighted:
  - 0.2877829819069718
  - 0.29180604137337157
  - 0.29632119891220743
  - 0.29698794155976593
  - 0.29197311086908007
  train_level10__jaccard_weighted_masked:
  - 0.24795909537974492
  - 0.25242862520227993
  - 0.2574784414665582
  - 0.25708414830501103
  - 0.252296159771917
  train_level10__jaccard_weighted_oob:
  - 0.2824137854585916
  - 0.2870145036066693
  - 0.29111412043451845
  - 0.2930506147322477
  - 0.28386844664286526
  train_level10__label_ranking_average_precision_score:
  - 0.18310054510923057
  - 0.2033293435115235
  - 0.18195499645877602
  - 0.1907038723133685
  - 0.18342599120916367
  train_level10__label_ranking_average_precision_score_oob:
  - 0.18245250177127362
  - 0.20183244932238376
  - 0.18104641148464767
  - 0.18977884065247744
  - 0.18284198873075094
  train_level10__matthews_corrcoef_macro:
  - 0.12319871129403193
  - 0.13210207066645643
  - 0.12754781654700842
  - 0.11500549865589484
  - 0.12541847421591315
  train_level10__matthews_corrcoef_macro_masked:
  - 0.10591865451773481
  - 0.11021955076478117
  - 0.10897012421692284
  - 0.09865256291262352
  - 0.10839927349393115
  train_level10__matthews_corrcoef_macro_oob:
  - 0.1213975122556757
  - 0.12891470858755086
  - 0.12523295325142167
  - 0.11276379794654506
  - 0.11856553967648256
  train_level10__matthews_corrcoef_micro:
  - 0.1315594957757796
  - 0.14525828471754612
  - 0.1386842645274812
  - 0.12902651283697544
  - 0.1319248313646408
  train_level10__matthews_corrcoef_micro_masked:
  - 0.10971598286979689
  - 0.1213583216884568
  - 0.11506925278814621
  - 0.10710019996464362
  - 0.11011514769842762
  train_level10__matthews_corrcoef_micro_oob:
  - 0.12649145355810612
  - 0.14080627224897427
  - 0.13514294793181453
  - 0.12591264614546133
  - 0.12571539040103843
  train_level10__matthews_corrcoef_samples:
  - 0.10717142636206055
  - 0.1276051456785129
  - 0.11325422452125967
  - 0.09972623026648156
  - 0.10972652122587365
  train_level10__matthews_corrcoef_samples_masked:
  - 0.0830667739940508
  - 0.10029048059226334
  - 0.08841850481853432
  - 0.077887878733107
  - 0.08434535366101657
  train_level10__matthews_corrcoef_samples_oob:
  - 0.10441273655094772
  - 0.1232437869262146
  - 0.11116901524876865
  - 0.0986068343691807
  - 0.10389553313316187
  train_level10__matthews_corrcoef_weighted:
  - 0.21636597430593665
  - 0.21738351854430715
  - 0.22609085421011665
  - 0.21797172516913807
  - 0.22470517213454966
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.19222116933910718
  - 0.19528030356152437
  - 0.20136913562539885
  - 0.1942047755410702
  - 0.1998402011374744
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.2057645271390469
  - 0.21029531642846508
  - 0.21864634942826874
  - 0.21097172431428032
  - 0.2117558288319591
  train_level10__ndcg:
  - 0.41039680117107935
  - 0.43326307572186545
  - 0.4140761907665061
  - 0.4251763406917967
  - 0.4168638540376833
  train_level10__ndcg_oob:
  - 0.41075867306361896
  - 0.43275976414952194
  - 0.414418352678215
  - 0.4262094238636788
  - 0.4177880245740095
  train_level10__neg_coverage_error:
  - -15.938280675973548
  - -14.8772826880935
  - -15.94147768836869
  - -15.666666666666666
  - -15.952240999265246
  train_level10__neg_coverage_error_oob:
  - -16.046289493019838
  - -14.981738495252008
  - -16.029992684711047
  - -15.745925925925926
  - -16.0139603232917
  train_level10__neg_hamming_loss_macro:
  - -0.7406906686260103
  - -0.7140686632578525
  - -0.7238332114118508
  - -0.7389925925925926
  - -0.7402204261572372
  train_level10__neg_hamming_loss_macro_masked:
  - -0.7641833263294073
  - -0.7373043575951155
  - -0.746927896529082
  - -0.7621613546069625
  - -0.763595491822968
  train_level10__neg_hamming_loss_macro_oob:
  - -0.7448052902277736
  - -0.718918918918919
  - -0.7283979517190928
  - -0.7436444444444444
  - -0.7480675973548861
  train_level10__neg_hamming_loss_micro:
  - -0.7406906686260103
  - -0.7140686632578525
  - -0.7238332114118508
  - -0.7389925925925926
  - -0.7402204261572374
  train_level10__neg_hamming_loss_micro_masked:
  - -0.7695221801295369
  - -0.7416631233675515
  - -0.7519620368680416
  - -0.7678846509335141
  - -0.7691038528522106
  train_level10__neg_hamming_loss_micro_oob:
  - -0.7448052902277736
  - -0.7189189189189189
  - -0.7283979517190929
  - -0.7436444444444444
  - -0.7480675973548861
  train_level10__neg_hamming_loss_samples:
  - -0.7406906686260102
  - -0.7140686632578525
  - -0.7238332114118508
  - -0.7389925925925926
  - -0.7402204261572373
  train_level10__neg_hamming_loss_samples_masked:
  - -0.7712254893622494
  - -0.7432251123496716
  - -0.7535852082461604
  - -0.7693091668932249
  - -0.770834040686863
  train_level10__neg_hamming_loss_samples_oob:
  - -0.7448052902277738
  - -0.7189189189189189
  - -0.7283979517190929
  - -0.7436444444444444
  - -0.748067597354886
  train_level10__neg_hamming_loss_weighted:
  - -0.5816060988705745
  - -0.5796396612122573
  - -0.5740636779622615
  - -0.5721585864891109
  - -0.5782152684732969
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.6272176705753305
  - -0.6250879888097377
  - -0.618174471622888
  - -0.617267367843395
  - -0.6232309107524074
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.5890875266916915
  - -0.5859142273854958
  - -0.5810467017525496
  - -0.5777880080454986
  - -0.5882409539862969
  train_level10__neg_label_ranking_loss:
  - -0.4548536383870429
  - -0.40953763138150107
  - -0.4651469102360319
  - -0.4399629087566166
  - -0.4697908965122005
  train_level10__neg_label_ranking_loss_oob:
  - -0.45760024653377546
  - -0.4142594154930034
  - -0.46886225103433493
  - -0.44295953030322094
  - -0.4724898958037944
  train_level10__precision_macro:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.2761667885881492
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__precision_macro_masked:
  - 0.23581667367059264
  - 0.2626956424048845
  - 0.253072103470918
  - 0.23783864539303756
  - 0.23640450817703182
  train_level10__precision_macro_oob:
  - 0.2551947097722263
  - 0.28108108108108104
  - 0.27160204828090706
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__precision_micro:
  - 0.2593093313739897
  - 0.28593133674214755
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.2597795738427627
  train_level10__precision_micro_masked:
  - 0.23047781987046315
  - 0.25833687663244853
  - 0.2480379631319584
  - 0.23211534906648593
  - 0.23089614714778942
  train_level10__precision_micro_oob:
  - 0.2551947097722263
  - 0.2810810810810811
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__precision_samples:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__precision_samples_masked:
  - 0.2287745106377506
  - 0.2567748876503283
  - 0.24641479175383948
  - 0.2306908331067751
  - 0.2291659593131371
  train_level10__precision_samples_oob:
  - 0.25519470977222636
  - 0.28108108108108115
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__precision_weighted:
  - 0.41839390112942554
  - 0.42036033878774265
  - 0.42593632203773846
  - 0.42784141351088917
  - 0.42178473152670326
  train_level10__precision_weighted_masked:
  - 0.37278232942466943
  - 0.37491201119026224
  - 0.38182552837711214
  - 0.382732632156605
  - 0.3767690892475925
  train_level10__precision_weighted_oob:
  - 0.41091247330830855
  - 0.4140857726145042
  - 0.4189532982474505
  - 0.4222119919545013
  - 0.41175904601370306
  train_level10__recall_macro:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.2761667885881492
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__recall_macro_masked:
  - 0.23581667367059264
  - 0.2626956424048845
  - 0.253072103470918
  - 0.23783864539303756
  - 0.23640450817703182
  train_level10__recall_macro_oob:
  - 0.2551947097722263
  - 0.28108108108108104
  - 0.27160204828090706
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__recall_micro:
  - 0.2593093313739897
  - 0.28593133674214755
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.2597795738427627
  train_level10__recall_micro_masked:
  - 0.23047781987046315
  - 0.25833687663244853
  - 0.2480379631319584
  - 0.23211534906648593
  - 0.23089614714778942
  train_level10__recall_micro_oob:
  - 0.2551947097722263
  - 0.2810810810810811
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__recall_samples:
  - 0.25930933137398976
  - 0.2859313367421476
  - 0.27616678858814925
  - 0.2610074074074074
  - 0.25977957384276273
  train_level10__recall_samples_masked:
  - 0.2287745106377506
  - 0.2567748876503283
  - 0.24641479175383948
  - 0.2306908331067751
  - 0.2291659593131371
  train_level10__recall_samples_oob:
  - 0.25519470977222636
  - 0.28108108108108115
  - 0.2716020482809071
  - 0.25635555555555556
  - 0.2519324026451139
  train_level10__recall_weighted:
  - 0.41839390112942554
  - 0.42036033878774265
  - 0.42593632203773846
  - 0.42784141351088917
  - 0.42178473152670326
  train_level10__recall_weighted_masked:
  - 0.37278232942466943
  - 0.37491201119026224
  - 0.38182552837711214
  - 0.382732632156605
  - 0.3767690892475925
  train_level10__recall_weighted_oob:
  - 0.41091247330830855
  - 0.4140857726145042
  - 0.4189532982474505
  - 0.4222119919545013
  - 0.41175904601370306
  train_level10__roc_auc_macro:
  - 0.6269230991521847
  - 0.653131658730816
  - 0.64309116782547
  - 0.6266578189160871
  - 0.6304260593380123
  train_level10__roc_auc_macro_masked:
  - 0.620790467266972
  - 0.6374451296391925
  - 0.6387425786921912
  - 0.6207654789438507
  - 0.6276257671367684
  train_level10__roc_auc_macro_oob:
  - 0.6203382966295824
  - 0.6473373800043973
  - 0.6387011914230335
  - 0.6224319919404967
  - 0.626832980169091
  train_level10__roc_auc_micro:
  - 0.5609500583226736
  - 0.60289749709616
  - 0.5448867330123304
  - 0.5720368089209168
  - 0.5473752842427894
  train_level10__roc_auc_micro_masked:
  - 0.5582838896356976
  - 0.5993032181027441
  - 0.5405187516591466
  - 0.5700035767773123
  - 0.5442052328881107
  train_level10__roc_auc_micro_oob:
  - 0.5586198148753928
  - 0.5998966871924113
  - 0.5428992960616051
  - 0.5696411171741612
  - 0.5466894770416153
  train_level10__roc_auc_samples:
  - 0.5462158659179791
  - 0.5916996263165695
  - 0.5366180302212545
  - 0.5628301933121704
  - 0.5334978595291574
  train_level10__roc_auc_samples_masked:
  - 0.5367106392299904
  - 0.5799643975437211
  - 0.5235252757354575
  - 0.5554433610481809
  - 0.5232065243969313
  train_level10__roc_auc_samples_oob:
  - 0.5440797516748
  - 0.587420471621041
  - 0.5340099862633474
  - 0.561228101621488
  - 0.5321534018254652
  train_level10__roc_auc_weighted:
  - 0.6743185013805261
  - 0.6972160150444306
  - 0.6980845593465688
  - 0.6634281584981007
  - 0.6861251473446817
  train_level10__roc_auc_weighted_masked:
  - 0.6684731117089441
  - 0.6899620699659114
  - 0.6937978995745295
  - 0.6602318023854995
  - 0.6814720256984107
  train_level10__roc_auc_weighted_oob:
  - 0.6675553580294918
  - 0.6912839242546144
  - 0.6914320453592072
  - 0.6595869320290485
  - 0.6819539903379152
  train_level10__tn_macro:
  - 0.1363115356355621
  - 0.1635646457268079
  - 0.15356254572055594
  - 0.13727407407407408
  - 0.13619397501836886
  train_level10__tn_macro_masked:
  - 0.1416376005225621
  - 0.16898791981014216
  - 0.1593748408759034
  - 0.14294775439734198
  - 0.14171474069876205
  train_level10__tn_macro_oob:
  - 0.1324908155767818
  - 0.15888970051132215
  - 0.14905632772494515
  - 0.13259259259259262
  - 0.12843497428361497
  train_level10__tn_micro:
  - 0.1363115356355621
  - 0.1635646457268079
  - 0.15356254572055597
  - 0.13727407407407408
  - 0.13619397501836886
  train_level10__tn_micro_masked:
  - 0.14169619943785897
  - 0.17001761525845835
  - 0.15963983695321532
  - 0.14273830796721917
  - 0.14158697179871063
  train_level10__tn_micro_oob:
  - 0.13249081557678177
  - 0.15888970051132215
  - 0.14905632772494515
  - 0.1325925925925926
  - 0.128434974283615
  train_level10__tn_samples:
  - 0.13631153563556211
  - 0.1635646457268079
  - 0.15356254572055597
  - 0.13727407407407408
  - 0.13619397501836886
  train_level10__tn_samples_masked:
  - 0.14036861811372242
  - 0.16864138666723863
  - 0.1582123267782121
  - 0.1415251890889572
  - 0.1401820284317506
  train_level10__tn_samples_oob:
  - 0.13249081557678177
  - 0.15888970051132215
  - 0.14905632772494515
  - 0.1325925925925926
  - 0.128434974283615
  train_level10__tn_weighted:
  - 0.12799984284814306
  - 0.13142118191490249
  - 0.13908237874580384
  - 0.1352989318906922
  - 0.13210990984686796
  train_level10__tn_weighted_masked:
  - 0.14022462240206937
  - 0.14313172128616602
  - 0.15258075106076333
  - 0.14820577591107537
  - 0.1449008726026894
  train_level10__tn_weighted_oob:
  - 0.1207905014109204
  - 0.12490852216612015
  - 0.13220914395776057
  - 0.12935757386600083
  - 0.12221045655587731
  train_level10__tp_macro:
  - 0.12299779573842763
  - 0.12236669101533967
  - 0.12260424286759328
  - 0.12373333333333333
  - 0.12358559882439384
  train_level10__tp_macro_masked:
  - 0.09417907314803052
  - 0.09370772259474235
  - 0.09369726259501464
  - 0.09489089099569556
  - 0.0946897674782698
  train_level10__tp_macro_oob:
  - 0.12270389419544454
  - 0.12219138056975895
  - 0.12254572055596195
  - 0.12376296296296296
  - 0.12349742836149889
  train_level10__tp_micro:
  - 0.12299779573842763
  - 0.12236669101533966
  - 0.12260424286759326
  - 0.12373333333333333
  - 0.12358559882439382
  train_level10__tp_micro_masked:
  - 0.08878162043260418
  - 0.08831926137399015
  - 0.08839812617874308
  - 0.08937704109926674
  - 0.0893091753490788
  train_level10__tp_micro_oob:
  - 0.12270389419544453
  - 0.12219138056975895
  - 0.12254572055596195
  - 0.12376296296296296
  - 0.12349742836149889
  train_level10__tp_samples:
  - 0.12299779573842765
  - 0.12236669101533967
  - 0.12260424286759329
  - 0.12373333333333335
  - 0.12358559882439384
  train_level10__tp_samples_masked:
  - 0.08840589252402817
  - 0.0881335009830897
  - 0.0882024649756274
  - 0.08916564401781793
  - 0.08898393088138648
  train_level10__tp_samples_oob:
  - 0.12270389419544453
  - 0.12219138056975896
  - 0.12254572055596197
  - 0.12376296296296298
  - 0.1234974283614989
  train_level10__tp_weighted:
  - 0.29039405828128245
  - 0.28893915687284016
  - 0.28685394329193464
  - 0.29254248162019697
  - 0.28967482167983527
  train_level10__tp_weighted_masked:
  - 0.2325577070226001
  - 0.23178028990409627
  - 0.22924477731634874
  - 0.2345268562455297
  - 0.2318682166449031
  train_level10__tp_weighted_oob:
  - 0.29012197189738803
  - 0.28917725044838405
  - 0.28674415428968997
  - 0.2928544180885005
  - 0.28954858945782574
  train_level1__average_precision_macro:
  - 0.23072797406312073
  - 0.2540501048066843
  - 0.24926774262642687
  - 0.24368644041648388
  - 0.24226987256887333
  train_level1__average_precision_macro_masked:
  - 0.18664166985137431
  - 0.19697725470139205
  - 0.2030761943089194
  - 0.19806100642101343
  - 0.1995448429606081
  train_level1__average_precision_macro_oob:
  - 0.22652364048386986
  - 0.2466768217903158
  - 0.24218332858797756
  - 0.2375263904507203
  - 0.23844274652349656
  train_level1__average_precision_micro:
  - 0.21755246848936372
  - 0.26243301424583737
  - 0.22964777726409716
  - 0.26502286874593034
  - 0.21905126265526229
  train_level1__average_precision_micro_masked:
  - 0.1588271593028959
  - 0.1976669214114502
  - 0.16749446524430425
  - 0.19885424275975802
  - 0.161965694700109
  train_level1__average_precision_micro_oob:
  - 0.20537597129163465
  - 0.25296714350443994
  - 0.2189051332253801
  - 0.25422004708263585
  - 0.2118346102244522
  train_level1__average_precision_samples:
  - 0.3628772465536978
  - 0.423505905224195
  - 0.3758026866329534
  - 0.42366209007877775
  - 0.36770787856101506
  train_level1__average_precision_samples_masked:
  - 0.2915271919023301
  - 0.3512073076451772
  - 0.3082676640978366
  - 0.34947339195738264
  - 0.29557946395046625
  train_level1__average_precision_samples_oob:
  - 0.3478389205122741
  - 0.41066473384556745
  - 0.36833858760731736
  - 0.41106777020632146
  - 0.3593048538749863
  train_level1__average_precision_weighted:
  - 0.4502696148895675
  - 0.46263216618355885
  - 0.4677252582318031
  - 0.44665850079941327
  - 0.4623377165295542
  train_level1__average_precision_weighted_masked:
  - 0.3800401867079092
  - 0.39475967068865964
  - 0.3996877298786291
  - 0.3786773194752671
  - 0.39807516417156086
  train_level1__average_precision_weighted_oob:
  - 0.4443709167785598
  - 0.456829043143121
  - 0.45987550484824313
  - 0.44156487813419226
  - 0.45655956423094324
  train_level1__f1_macro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.2744592592592593
  - 0.2624834680382072
  train_level1__f1_macro_masked:
  - 0.24406456479567396
  - 0.27554444597531186
  - 0.26623102175117885
  - 0.2517934410903255
  - 0.23911496489131842
  train_level1__f1_macro_oob:
  - 0.25863335782512853
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__f1_micro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__f1_micro_masked:
  - 0.2390321398020286
  - 0.2713053513940351
  - 0.26154407738638435
  - 0.24613346478526096
  - 0.2336765559595466
  train_level1__f1_micro_oob:
  - 0.2586333578251286
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.26986666666666664
  - 0.2520205731080088
  train_level1__f1_samples:
  - 0.2675679647318149
  - 0.2981446311176041
  - 0.289070958302853
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__f1_samples_masked:
  - 0.23713453394298684
  - 0.2694446887102586
  - 0.2599244603132838
  - 0.24445821221183545
  - 0.23179287700218096
  train_level1__f1_samples_oob:
  - 0.2586333578251286
  - 0.28949598246895547
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__f1_weighted:
  - 0.41968420058642464
  - 0.42932410206959176
  - 0.43015143551677637
  - 0.4399198918019143
  - 0.4230230421828296
  train_level1__f1_weighted_masked:
  - 0.37324060303800594
  - 0.38462144533820725
  - 0.38593091601179413
  - 0.39522014678354933
  - 0.3775088235844287
  train_level1__f1_weighted_oob:
  - 0.4103705406437436
  - 0.42076874250316054
  - 0.42232828718757226
  - 0.4365093979747538
  - 0.4125353055745933
  train_level1__fn_macro:
  - -0.002321822189566495
  - -0.00391526661796932
  - -0.003686905632772494
  - -0.003466666666666667
  - -0.002263041880969875
  train_level1__fn_macro_masked:
  - -0.0020953803451771533
  - -0.0032219557656181647
  - -0.0033382550986059715
  - -0.003114782220765858
  - -0.002046283635809183
  train_level1__fn_macro_oob:
  - -0.0025569434239529755
  - -0.004032140248356465
  - -0.0038332114118507675
  - -0.0040888888888888884
  - -0.002174871418074945
  train_level1__fn_micro:
  - -0.002321822189566495
  - -0.00391526661796932
  - -0.0036869056327724944
  - -0.0034666666666666665
  - -0.002263041880969875
  train_level1__fn_micro_masked:
  - -0.002016375412440425
  - -0.0032193403389418696
  - -0.0032244326823629614
  - -0.003050095508041161
  - -0.001955452351125913
  train_level1__fn_micro_oob:
  - -0.002556943423952976
  - -0.004032140248356465
  - -0.003833211411850768
  - -0.004088888888888889
  - -0.002174871418074945
  train_level1__fn_samples:
  - -0.002321822189566495
  - -0.003915266617969321
  - -0.0036869056327724944
  - -0.003466666666666667
  - -0.002263041880969875
  train_level1__fn_samples_masked:
  - -0.0019850212826924324
  - -0.003206453511976426
  - -0.0032138413307905367
  - -0.003032372029473479
  - -0.0019387288855071496
  train_level1__fn_samples_oob:
  - -0.002556943423952976
  - -0.004032140248356465
  - -0.0038332114118507683
  - -0.0040888888888888884
  - -0.002174871418074945
  train_level1__fn_weighted:
  - -0.004132301185669405
  - -0.004077565368863662
  - -0.006382764354102264
  - -0.004885733111388542
  - -0.004358270371582383
  train_level1__fn_weighted_masked:
  - -0.004124906777682601
  - -0.003302539420508075
  - -0.006253234358709122
  - -0.004765929233106533
  - -0.004355474000588339
  train_level1__fn_weighted_oob:
  - -0.003933965892532944
  - -0.0041262740688676304
  - -0.006087152351163875
  - -0.005466084061589679
  - -0.0037950276853332557
  train_level1__fp_macro:
  - -0.7301102130786187
  - -0.6979401022644267
  - -0.7072421360643745
  - -0.7220740740740742
  - -0.735253490080823
  train_level1__fp_macro_masked:
  - -0.7538400548591488
  - -0.7212335982590699
  - -0.7304307231502152
  - -0.7450917766889087
  - -0.7588387514728726
  train_level1__fp_macro_oob:
  - -0.7388096987509185
  - -0.706471877282688
  - -0.7120409656181418
  - -0.7260444444444444
  - -0.7458045554739162
  train_level1__fp_micro:
  - -0.7301102130786187
  - -0.6979401022644266
  - -0.7072421360643746
  - -0.7220740740740741
  - -0.735253490080823
  train_level1__fp_micro_masked:
  - -0.758951484785531
  - -0.725475308267023
  - -0.7352314899312526
  - -0.7508164397066979
  - -0.7643679916893275
  train_level1__fp_micro_oob:
  - -0.7388096987509184
  - -0.7064718772826881
  - -0.7120409656181419
  - -0.7260444444444445
  - -0.7458045554739162
  train_level1__fp_samples:
  - -0.7301102130786187
  - -0.6979401022644265
  - -0.7072421360643745
  - -0.7220740740740741
  - -0.7352534900808229
  train_level1__fp_samples_masked:
  - -0.7608804447743207
  - -0.7273488577777649
  - -0.7368616983559256
  - -0.7525094157586911
  - -0.766268394112312
  train_level1__fp_samples_oob:
  - -0.7388096987509185
  - -0.7064718772826881
  - -0.7120409656181419
  - -0.7260444444444444
  - -0.7458045554739162
  train_level1__fp_weighted:
  - -0.576183498227906
  - -0.5665983325615446
  - -0.5634658001291214
  - -0.5551943750866972
  - -0.5726186874455882
  train_level1__fp_weighted_masked:
  - -0.6226344901843115
  - -0.6120760152412846
  - -0.6078158496294968
  - -0.6000139239833441
  - -0.618135702414983
  train_level1__fp_weighted_oob:
  - -0.5856954934637234
  - -0.5751049834279718
  - -0.5715845604612637
  - -0.5580245179636565
  - -0.5836696667400735
  train_level1__jaccard_macro:
  - 0.1794490634897776
  - 0.21013652510820977
  - 0.19901708910873553
  - 0.18782220679926617
  - 0.17420454460361207
  train_level1__jaccard_macro_masked:
  - 0.16219058388357632
  - 0.19375195115967586
  - 0.18220524753189996
  - 0.17095879970564187
  - 0.1569871073168858
  train_level1__jaccard_macro_oob:
  - 0.17302471586558718
  - 0.20415697081253673
  - 0.19685231840524403
  - 0.18671983688124608
  - 0.1671765200099969
  train_level1__jaccard_micro:
  - 0.15444644250670106
  - 0.1751879957421969
  - 0.1689555506148347
  - 0.15905695691742364
  - 0.15106818450921022
  train_level1__jaccard_micro_masked:
  - 0.13573907009021513
  - 0.15694232154465118
  - 0.15044619422572178
  - 0.14033762537987246
  - 0.1322954506140806
  train_level1__jaccard_micro_oob:
  - 0.14852320675105485
  - 0.16924601141061119
  - 0.16558663028649387
  - 0.155980271270037
  - 0.14417822614543926
  train_level1__jaccard_samples:
  - 0.17400878451813412
  - 0.19726225063302227
  - 0.18684550910038436
  - 0.1753241224064296
  - 0.1719024340851604
  train_level1__jaccard_samples_masked:
  - 0.1552164120055491
  - 0.17911987756129252
  - 0.16826462016657975
  - 0.1564510682984846
  - 0.15306506358928262
  train_level1__jaccard_samples_oob:
  - 0.16675102422206886
  - 0.19018084638523236
  - 0.18227390734302548
  - 0.17119222184263808
  - 0.16369729687023446
  train_level1__jaccard_weighted:
  - 0.2895755470868148
  - 0.29963580758544645
  - 0.3005795658448084
  - 0.31127012051064906
  - 0.2933419337349964
  train_level1__jaccard_weighted_masked:
  - 0.24929950583848892
  - 0.26068321306493436
  - 0.26164763877395536
  - 0.27163602907427575
  - 0.2534739085487827
  train_level1__jaccard_weighted_oob:
  - 0.28175257494669426
  - 0.2922306368967237
  - 0.29409800844706246
  - 0.30987218685783596
  - 0.2849921296714447
  train_level1__label_ranking_average_precision_score:
  - 0.36728576969844406
  - 0.427158206173794
  - 0.37946033110991007
  - 0.4281065345232215
  - 0.3691773862759307
  train_level1__label_ranking_average_precision_score_oob:
  - 0.3522474436570207
  - 0.414317034795166
  - 0.37199623208427424
  - 0.415512214650766
  - 0.3607743615899028
  train_level1__matthews_corrcoef_macro:
  - 0.13707282171257762
  - 0.13830574558936465
  - 0.13674045576152363
  - 0.1405356719133678
  - 0.13889925626677982
  train_level1__matthews_corrcoef_macro_masked:
  - 0.11904419492289332
  - 0.11165767990731959
  - 0.11569481871483418
  - 0.12160651492230161
  - 0.12099321124150154
  train_level1__matthews_corrcoef_macro_oob:
  - 0.12888543262096466
  - 0.1250628425351281
  - 0.1308553952632803
  - 0.13769014328862073
  - 0.132776581803972
  train_level1__matthews_corrcoef_micro:
  - 0.13725547371311897
  - 0.14699880593504777
  - 0.14246966210249998
  - 0.13410546332078002
  - 0.13423544057171524
  train_level1__matthews_corrcoef_micro_masked:
  - 0.11438763055560244
  - 0.12279898430965025
  - 0.11733249402473618
  - 0.11020141195854265
  - 0.1119996560525368
  train_level1__matthews_corrcoef_micro_oob:
  - 0.12935964560982616
  - 0.14040927262620714
  - 0.13812450011640764
  - 0.12653659204573509
  - 0.12754540843485473
  train_level1__matthews_corrcoef_samples:
  - 0.1189794665588348
  - 0.13655182503915891
  - 0.12081568639227949
  - 0.11120687151490553
  - 0.11717832007071997
  train_level1__matthews_corrcoef_samples_masked:
  - 0.09148544905882221
  - 0.1065373589796742
  - 0.09172728483243961
  - 0.08484768116366874
  - 0.08675529611762847
  train_level1__matthews_corrcoef_samples_oob:
  - 0.1099752678965799
  - 0.1293827636299145
  - 0.11609928969501096
  - 0.10270705258707151
  - 0.10892564401494952
  train_level1__matthews_corrcoef_weighted:
  - 0.220638829768072
  - 0.22992789334400687
  - 0.23182806966858524
  - 0.2364907810010538
  - 0.2304785422754546
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.1962071292836537
  - 0.2061343792758338
  - 0.20601617492967533
  - 0.21044310373039096
  - 0.20525441070953246
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.20926133599379784
  - 0.21752837542328635
  - 0.2222456079960416
  - 0.23045312930692832
  - 0.21981859220844407
  train_level1__ndcg:
  - 0.5626520127319632
  - 0.608573423392334
  - 0.5761400594351688
  - 0.6231635862466626
  - 0.5652584103021366
  train_level1__ndcg_oob:
  - 0.5505823150032902
  - 0.5986718257343647
  - 0.5706475243333523
  - 0.6132949545977748
  - 0.5586124136259457
  train_level1__neg_coverage_error:
  - -13.56502571638501
  - -12.565376186997808
  - -12.945135332845647
  - -12.698518518518519
  - -13.230712711241734
  train_level1__neg_coverage_error_oob:
  - -13.841293166789125
  - -12.785244704163624
  - -13.1441111923921
  - -12.948888888888888
  - -13.443791329904482
  train_level1__neg_hamming_loss_macro:
  - -0.7324320352681852
  - -0.701855368882396
  - -0.710929041697147
  - -0.7255407407407408
  - -0.7375165319617928
  train_level1__neg_hamming_loss_macro_masked:
  - -0.755935435204326
  - -0.7244555540246883
  - -0.7337689782488213
  - -0.7482065589096746
  - -0.7608850351086816
  train_level1__neg_hamming_loss_macro_oob:
  - -0.7413666421748715
  - -0.7105040175310445
  - -0.7158741770299928
  - -0.7301333333333332
  - -0.7479794268919912
  train_level1__neg_hamming_loss_micro:
  - -0.7324320352681851
  - -0.7018553688823959
  - -0.710929041697147
  - -0.7255407407407407
  - -0.7375165319617928
  train_level1__neg_hamming_loss_micro_masked:
  - -0.7609678601979714
  - -0.7286946486059649
  - -0.7384559226136156
  - -0.753866535214739
  - -0.7663234440404534
  train_level1__neg_hamming_loss_micro_oob:
  - -0.7413666421748715
  - -0.7105040175310445
  - -0.7158741770299927
  - -0.7301333333333333
  - -0.7479794268919912
  train_level1__neg_hamming_loss_samples:
  - -0.7324320352681851
  - -0.7018553688823959
  - -0.710929041697147
  - -0.7255407407407407
  - -0.7375165319617928
  train_level1__neg_hamming_loss_samples_masked:
  - -0.7628654660570132
  - -0.7305553112897414
  - -0.7400755396867161
  - -0.7555417877881646
  - -0.768207122997819
  train_level1__neg_hamming_loss_samples_oob:
  - -0.7413666421748715
  - -0.7105040175310444
  - -0.7158741770299926
  - -0.7301333333333333
  - -0.7479794268919912
  train_level1__neg_hamming_loss_weighted:
  - -0.5803157994135754
  - -0.5706758979304082
  - -0.5698485644832236
  - -0.5600801081980857
  - -0.5769769578171705
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.6267593969619941
  - -0.6153785546617927
  - -0.6140690839882059
  - -0.6047798532164507
  - -0.6224911764155714
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.5896294593562564
  - -0.5792312574968395
  - -0.5776717128124277
  - -0.5634906020252461
  - -0.5874646944254067
  train_level1__neg_label_ranking_loss:
  - -0.29996930596832644
  - -0.24911508257140602
  - -0.2933243666819071
  - -0.25533085671141637
  - -0.30364031334632424
  train_level1__neg_label_ranking_loss_oob:
  - -0.3143249493054045
  - -0.2602068051000103
  - -0.3039376207534111
  - -0.2662208869550743
  - -0.31313371090886505
  train_level1__precision_macro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.2744592592592593
  - 0.2624834680382072
  train_level1__precision_macro_masked:
  - 0.24406456479567396
  - 0.27554444597531186
  - 0.26623102175117885
  - 0.2517934410903255
  - 0.23911496489131842
  train_level1__precision_macro_oob:
  - 0.25863335782512853
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__precision_micro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__precision_micro_masked:
  - 0.2390321398020286
  - 0.2713053513940351
  - 0.26154407738638435
  - 0.24613346478526096
  - 0.2336765559595466
  train_level1__precision_micro_oob:
  - 0.2586333578251286
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.26986666666666664
  - 0.2520205731080088
  train_level1__precision_samples:
  - 0.2675679647318149
  - 0.2981446311176041
  - 0.289070958302853
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__precision_samples_masked:
  - 0.23713453394298684
  - 0.2694446887102586
  - 0.2599244603132838
  - 0.24445821221183545
  - 0.23179287700218096
  train_level1__precision_samples_oob:
  - 0.2586333578251286
  - 0.28949598246895547
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__precision_weighted:
  - 0.41968420058642464
  - 0.42932410206959176
  - 0.43015143551677637
  - 0.4399198918019143
  - 0.4230230421828296
  train_level1__precision_weighted_masked:
  - 0.37324060303800594
  - 0.38462144533820725
  - 0.38593091601179413
  - 0.39522014678354933
  - 0.3775088235844287
  train_level1__precision_weighted_oob:
  - 0.4103705406437436
  - 0.42076874250316054
  - 0.42232828718757226
  - 0.4365093979747538
  - 0.4125353055745933
  train_level1__recall_macro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.2744592592592593
  - 0.2624834680382072
  train_level1__recall_macro_masked:
  - 0.24406456479567396
  - 0.27554444597531186
  - 0.26623102175117885
  - 0.2517934410903255
  - 0.23911496489131842
  train_level1__recall_macro_oob:
  - 0.25863335782512853
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__recall_micro:
  - 0.2675679647318148
  - 0.2981446311176041
  - 0.28907095830285295
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__recall_micro_masked:
  - 0.2390321398020286
  - 0.2713053513940351
  - 0.26154407738638435
  - 0.24613346478526096
  - 0.2336765559595466
  train_level1__recall_micro_oob:
  - 0.2586333578251286
  - 0.2894959824689554
  - 0.2841258229700073
  - 0.26986666666666664
  - 0.2520205731080088
  train_level1__recall_samples:
  - 0.2675679647318149
  - 0.2981446311176041
  - 0.289070958302853
  - 0.27445925925925924
  - 0.2624834680382072
  train_level1__recall_samples_masked:
  - 0.23713453394298684
  - 0.2694446887102586
  - 0.2599244603132838
  - 0.24445821221183545
  - 0.23179287700218096
  train_level1__recall_samples_oob:
  - 0.2586333578251286
  - 0.28949598246895547
  - 0.2841258229700073
  - 0.2698666666666667
  - 0.2520205731080088
  train_level1__recall_weighted:
  - 0.41968420058642464
  - 0.42932410206959176
  - 0.43015143551677637
  - 0.4399198918019143
  - 0.4230230421828296
  train_level1__recall_weighted_masked:
  - 0.37324060303800594
  - 0.38462144533820725
  - 0.38593091601179413
  - 0.39522014678354933
  - 0.3775088235844287
  train_level1__recall_weighted_oob:
  - 0.4103705406437436
  - 0.42076874250316054
  - 0.42232828718757226
  - 0.4365093979747538
  - 0.4125353055745933
  train_level1__roc_auc_macro:
  - 0.6806205804342932
  - 0.6964918484766209
  - 0.6958718817182588
  - 0.6820470982854728
  - 0.6855182668790344
  train_level1__roc_auc_macro_masked:
  - 0.6639071145338465
  - 0.6758260422135013
  - 0.6778537733770961
  - 0.6642668726239528
  - 0.6638963528975479
  train_level1__roc_auc_macro_oob:
  - 0.6687086188573875
  - 0.6880512124817705
  - 0.6875304842128426
  - 0.6727269017862778
  - 0.6781268897579972
  train_level1__roc_auc_micro:
  - 0.7032673817674302
  - 0.7395448325044154
  - 0.7122685773166381
  - 0.7313133192963305
  - 0.7040307582634278
  train_level1__roc_auc_micro_masked:
  - 0.6965471223903127
  - 0.7328659445613295
  - 0.7031494129586463
  - 0.7257676922978847
  - 0.6972949687410638
  train_level1__roc_auc_micro_oob:
  - 0.6906432163792939
  - 0.7297501164838295
  - 0.7000864267804593
  - 0.7204559197387856
  - 0.6957458840658306
  train_level1__roc_auc_samples:
  - 0.6987024166620721
  - 0.7500490992963817
  - 0.7056338228737411
  - 0.7435663147242347
  - 0.6959475044239334
  train_level1__roc_auc_samples_masked:
  - 0.6868573443647462
  - 0.7382448326484874
  - 0.6896351226912232
  - 0.7317224503480934
  - 0.6818783924672717
  train_level1__roc_auc_samples_oob:
  - 0.6843012115860443
  - 0.7389671013506804
  - 0.6950454076547082
  - 0.7326502151716787
  - 0.6864513193517687
  train_level1__roc_auc_weighted:
  - 0.7057170951312975
  - 0.7146136250165924
  - 0.7183225644064848
  - 0.6958521895336364
  - 0.7075474617369341
  train_level1__roc_auc_weighted_masked:
  - 0.6947262035929028
  - 0.7041540408147787
  - 0.7070989583100498
  - 0.6859699618621017
  - 0.6967131581392947
  train_level1__roc_auc_weighted_oob:
  - 0.6980745119673327
  - 0.7097871429381597
  - 0.7115869236801001
  - 0.6918400245336062
  - 0.7018146037062644
  train_level1__tn_macro:
  - 0.1445701689933872
  - 0.17674214755295836
  - 0.16719824433065106
  - 0.15134814814814815
  - 0.13883908890521673
  train_level1__tn_macro_masked:
  - 0.1498738839717382
  - 0.18252317073929786
  - 0.17317356645135595
  - 0.15749950803734802
  - 0.1443730250806383
  train_level1__tn_macro_oob:
  - 0.13587068332108743
  - 0.16821037253469687
  - 0.1623994147768837
  - 0.14737777777777777
  - 0.12828802351212343
  train_level1__tn_micro:
  - 0.1445701689933872
  - 0.17674214755295836
  - 0.16719824433065106
  - 0.15134814814814815
  - 0.13883908890521676
  train_level1__tn_micro_masked:
  - 0.15028107051203715
  - 0.18371499726659782
  - 0.17381517308511285
  - 0.1573726045967096
  - 0.14433682666748143
  train_level1__tn_micro_oob:
  - 0.13587068332108743
  - 0.16821037253469687
  - 0.1623994147768837
  - 0.14737777777777777
  - 0.12828802351212343
  train_level1__tn_samples:
  - 0.1445701689933872
  - 0.1767421475529584
  - 0.16719824433065109
  - 0.15134814814814818
  - 0.13883908890521676
  train_level1__tn_samples_masked:
  - 0.14874609752768395
  - 0.18203621036758522
  - 0.17240043090397722
  - 0.15590828575611185
  - 0.14279101773945044
  train_level1__tn_samples_oob:
  - 0.13587068332108745
  - 0.16821037253469687
  - 0.1623994147768837
  - 0.14737777777777777
  - 0.12828802351212346
  train_level1__tn_weighted:
  - 0.1280463680689483
  - 0.1400446655372833
  - 0.14311780649756548
  - 0.1474568248023304
  - 0.1326613182623037
  train_level1__tn_weighted_masked:
  - 0.13958952148166368
  - 0.15244622992439566
  - 0.1565731548704082
  - 0.16081034886955664
  - 0.14503248446256525
  train_level1__tn_weighted_oob:
  - 0.11853437283313092
  - 0.13153801467085607
  - 0.13499904616542302
  - 0.14462668192537106
  - 0.12161033896781834
  train_level1__tp_macro:
  - 0.12299779573842763
  - 0.12140248356464572
  - 0.1218727139722019
  - 0.1231111111111111
  - 0.12364437913299044
  train_level1__tp_macro_masked:
  - 0.09419068082393574
  - 0.09302127523601408
  - 0.09305745529982291
  - 0.09429393305297744
  - 0.09474193981068015
  train_level1__tp_macro_oob:
  - 0.12276267450404116
  - 0.12128560993425859
  - 0.12172640819312361
  - 0.12248888888888888
  - 0.1237325495958854
  train_level1__tp_micro:
  - 0.12299779573842763
  - 0.12140248356464572
  - 0.1218727139722019
  - 0.12311111111111112
  - 0.12364437913299045
  train_level1__tp_micro_masked:
  - 0.08875106928999145
  - 0.08759035412743728
  - 0.08772890430127152
  - 0.08876086018855135
  - 0.08933972929206514
  train_level1__tp_micro_oob:
  - 0.12276267450404114
  - 0.12128560993425859
  - 0.12172640819312362
  - 0.12248888888888888
  - 0.12373254959588538
  train_level1__tp_samples:
  - 0.12299779573842763
  - 0.12140248356464572
  - 0.1218727139722019
  - 0.1231111111111111
  - 0.12364437913299045
  train_level1__tp_samples_masked:
  - 0.08838843641530286
  - 0.0874084783426734
  - 0.08752402940930659
  - 0.08854992645572356
  - 0.08900185926273052
  train_level1__tp_samples_oob:
  - 0.12276267450404116
  - 0.12128560993425858
  - 0.12172640819312361
  - 0.1224888888888889
  - 0.12373254959588538
  train_level1__tp_weighted:
  - 0.29163783251747627
  - 0.2892794365323084
  - 0.28703362901921087
  - 0.29246306699958385
  - 0.2903617239205258
  train_level1__tp_weighted_masked:
  - 0.23365108155634223
  - 0.23217521541381173
  - 0.22935776114138592
  - 0.23440979791399272
  - 0.2324763391218635
  train_level1__tp_weighted_oob:
  - 0.2918361678106127
  - 0.28923072783230447
  - 0.28732924102214924
  - 0.29188271604938276
  - 0.29092496660677497
  train_level2__average_precision_macro:
  - 0.2204891317307979
  - 0.22882677301956547
  - 0.22402333211959496
  - 0.21245471209982378
  - 0.21763501655074818
  train_level2__average_precision_macro_masked:
  - 0.17952568534871502
  - 0.18290074004062112
  - 0.1852634991559409
  - 0.1744365294983515
  - 0.17914183897845576
  train_level2__average_precision_macro_oob:
  - 0.21736066150813546
  - 0.2259717415526576
  - 0.2218402919076464
  - 0.21016911767380964
  - 0.21595967226079185
  train_level2__average_precision_micro:
  - 0.12624226898328306
  - 0.13984107251262035
  - 0.1227199082387111
  - 0.13192044643074285
  - 0.12160127567635752
  train_level2__average_precision_micro_masked:
  - 0.09127910412846008
  - 0.10140530173131002
  - 0.08838354543912942
  - 0.09548083580367747
  - 0.08772206961858414
  train_level2__average_precision_micro_oob:
  - 0.12584542530601903
  - 0.1390265656854383
  - 0.12258665721282869
  - 0.13152241822094482
  - 0.12139094867078262
  train_level2__average_precision_samples:
  - 0.17859441028873102
  - 0.20001971346051564
  - 0.17770433874165179
  - 0.18814207166543906
  - 0.18141596878430513
  train_level2__average_precision_samples_masked:
  - 0.14083236978335234
  - 0.1599081191841644
  - 0.13980651492014987
  - 0.15009729179490164
  - 0.14363439677839057
  train_level2__average_precision_samples_oob:
  - 0.1779115188355178
  - 0.1988979379557285
  - 0.17753050162418577
  - 0.18680451477936033
  - 0.18073546814379113
  train_level2__average_precision_weighted:
  - 0.44190007670839737
  - 0.4494312968513226
  - 0.45333822578485444
  - 0.41540274129495885
  - 0.4492391165308239
  train_level2__average_precision_weighted_masked:
  - 0.37323961011728235
  - 0.38777780805092094
  - 0.39003637717053585
  - 0.349916021522224
  - 0.3855578770030959
  train_level2__average_precision_weighted_oob:
  - 0.4365532832291193
  - 0.4438751092906845
  - 0.4483014036556923
  - 0.4133657816383603
  - 0.4451638964461489
  train_level2__f1_macro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__f1_macro_masked:
  - 0.23273126855170176
  - 0.2640119075172982
  - 0.24952016276751376
  - 0.2340605059157502
  - 0.22835058950209358
  train_level2__f1_macro_oob:
  - 0.24796473181484202
  - 0.27859751643535424
  - 0.2687637161667886
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__f1_micro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.25751111111111114
  - 0.2519324026451139
  train_level2__f1_micro_masked:
  - 0.22730050103873886
  - 0.25955172204336996
  - 0.24435724280586482
  - 0.22826421837451477
  - 0.22267713648446333
  train_level2__f1_micro_oob:
  - 0.24796473181484202
  - 0.2785975164353543
  - 0.26876371616678857
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__f1_samples:
  - 0.2563703159441587
  - 0.2871292914536158
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__f1_samples_masked:
  - 0.2255318183823439
  - 0.25795300733608606
  - 0.24275367963991096
  - 0.2267443245428753
  - 0.2209786398122055
  train_level2__f1_samples_oob:
  - 0.24796473181484205
  - 0.27859751643535424
  - 0.2687637161667887
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__f1_weighted:
  - 0.41766931389429196
  - 0.42381048160131046
  - 0.4256074664704557
  - 0.4260935982799279
  - 0.4183025402176545
  train_level2__f1_weighted_masked:
  - 0.3720321427758893
  - 0.37882879769350764
  - 0.38153599667688937
  - 0.38079273571323413
  - 0.3728398412141017
  train_level2__f1_weighted_oob:
  - 0.4072483536964461
  - 0.4139549744270809
  - 0.41732487503403204
  - 0.4176957622416424
  - 0.40901589634139235
  train_level2__fn_macro:
  - -0.0021160911094783245
  - -0.0029510591672753834
  - -0.0026627651792245793
  - -0.0025185185185185185
  - -0.002057310800881705
  train_level2__fn_macro_masked:
  - -0.002012399777727022
  - -0.0025586172715370043
  - -0.0024800009342289997
  - -0.002396143636238715
  - -0.001869769655643773
  train_level2__fn_macro_oob:
  - -0.002321822189566495
  - -0.0030679327976625274
  - -0.002750548646671543
  - -0.0025185185185185185
  - -0.002027920646583395
  train_level2__fn_micro:
  - -0.002116091109478325
  - -0.0029510591672753834
  - -0.0026627651792245793
  - -0.0025185185185185185
  - -0.002057310800881705
  train_level2__fn_micro_masked:
  - -0.0018941708419894904
  - -0.00252080422766203
  - -0.0023422765711504532
  - -0.0023106784151826977
  - -0.0017721286932078585
  train_level2__fn_micro_oob:
  - -0.002321822189566495
  - -0.0030679327976625274
  - -0.0027505486466715434
  - -0.0025185185185185185
  - -0.0020279206465833944
  train_level2__fn_samples:
  - -0.0021160911094783245
  - -0.0029510591672753834
  - -0.0026627651792245793
  - -0.002518518518518519
  - -0.002057310800881705
  train_level2__fn_samples_masked:
  - -0.0018730587901274417
  - -0.0025093259817114103
  - -0.0023254743200037562
  - -0.0022941101839652565
  - -0.001746027827713289
  train_level2__fn_samples_oob:
  - -0.002321822189566495
  - -0.003067932797662527
  - -0.002750548646671544
  - -0.002518518518518519
  - -0.002027920646583395
  train_level2__fn_weighted:
  - -0.0051572345684458365
  - -0.004172428116773488
  - -0.006103518413610291
  - -0.004549001248439451
  - -0.00437593602221687
  train_level2__fn_weighted_masked:
  - -0.005047023269901963
  - -0.0035338289626159138
  - -0.006006291092602058
  - -0.00456700982295371
  - -0.004356277245709578
  train_level2__fn_weighted_oob:
  - -0.0052228868244710265
  - -0.003697603446804735
  - -0.00589911311284724
  - -0.004420689416007768
  - -0.004247817177324029
  train_level2__fp_macro:
  - -0.741513592946363
  - -0.7099196493791089
  - -0.7246232626188734
  - -0.7399703703703703
  - -0.7460102865540044
  train_level2__fp_macro_masked:
  - -0.7652563316705713
  - -0.7334294752111649
  - -0.7479998362982572
  - -0.763543350448011
  - -0.7697796408422627
  train_level2__fp_macro_oob:
  - -0.7497134459955916
  - -0.7183345507669832
  - -0.7284857351865399
  - -0.7473185185185184
  - -0.7542983100661277
  train_level2__fp_micro:
  - -0.741513592946363
  - -0.7099196493791088
  - -0.7246232626188734
  - -0.7399703703703704
  - -0.7460102865540044
  train_level2__fp_micro_masked:
  - -0.7708053281192717
  - -0.7379274737289679
  - -0.7533004806229847
  - -0.7694251032103026
  - -0.7755507348223288
  train_level2__fp_micro_oob:
  - -0.7497134459955915
  - -0.7183345507669832
  - -0.7284857351865399
  - -0.7473185185185185
  - -0.7542983100661278
  train_level2__fp_samples:
  - -0.7415135929463629
  - -0.7099196493791088
  - -0.7246232626188734
  - -0.7399703703703704
  - -0.7460102865540044
  train_level2__fp_samples_masked:
  - -0.7725951228275285
  - -0.7395376666822026
  - -0.7549208460400851
  - -0.7709615652731595
  - -0.7772753323600812
  train_level2__fp_samples_oob:
  - -0.7497134459955914
  - -0.718334550766983
  - -0.7284857351865398
  - -0.7473185185185184
  - -0.7542983100661278
  train_level2__fp_weighted:
  - -0.5771734515372622
  - -0.5720170902819162
  - -0.5682890151159339
  - -0.5693574004716326
  - -0.5773215237601286
  train_level2__fp_weighted_masked:
  - -0.6229208339542087
  - -0.6176373733438765
  - -0.6124577122305086
  - -0.6146402544638122
  - -0.6228038815401887
  train_level2__fp_weighted_oob:
  - -0.587528759479083
  - -0.5823474221261142
  - -0.5767760118531208
  - -0.5778835483423499
  - -0.5867362864812837
  train_level2__jaccard_macro:
  - 0.16895247188908027
  - 0.2037243134220946
  - 0.18326688797215232
  - 0.16807039656202055
  - 0.16604927056879895
  train_level2__jaccard_macro_masked:
  - 0.15139423862521617
  - 0.18681093055006262
  - 0.16601629240266283
  - 0.15038852862200983
  - 0.1484815260135392
  train_level2__jaccard_macro_oob:
  - 0.1651067020665568
  - 0.1981617428950677
  - 0.18269398599536232
  - 0.16509063779600858
  - 0.16162128718726407
  train_level2__jaccard_micro:
  - 0.14703254841808958
  - 0.16763045221158931
  - 0.15788582076910046
  - 0.1477835025251237
  - 0.14412051514845825
  train_level2__jaccard_micro_masked:
  - 0.12822280435681788
  - 0.14912923603113112
  - 0.13918392099107685
  - 0.12883648947084703
  - 0.12528794911466393
  train_level2__jaccard_micro_oob:
  - 0.1415295321490279
  - 0.16184333361622677
  - 0.15524380968477985
  - 0.14296357756066172
  - 0.13874060810923877
  train_level2__jaccard_samples:
  - 0.16167547332407078
  - 0.18193417704588183
  - 0.17126396651437284
  - 0.15998654047542357
  - 0.15794210077888882
  train_level2__jaccard_samples_masked:
  - 0.14277052069667287
  - 0.1633396072014846
  - 0.1524312140328149
  - 0.14091151308827896
  - 0.13897687757481075
  train_level2__jaccard_samples_oob:
  - 0.15437438154848804
  - 0.1748945938651914
  - 0.16717219012426474
  - 0.15402765777109373
  - 0.15148511254021077
  train_level2__jaccard_weighted:
  - 0.2876474619806585
  - 0.29581111859696696
  - 0.2966592940265848
  - 0.29558937126511997
  - 0.2893842775894895
  train_level2__jaccard_weighted_masked:
  - 0.24780267597282365
  - 0.25665806276495284
  - 0.25776004268217556
  - 0.25554081235885423
  - 0.24939290328458474
  train_level2__jaccard_weighted_oob:
  - 0.27980025427031835
  - 0.28745236028022386
  - 0.2900346365601943
  - 0.2894007047341592
  - 0.2825969697398159
  train_level2__label_ranking_average_precision_score:
  - 0.18300293343347726
  - 0.20367201441011393
  - 0.18136198321860852
  - 0.19258651610988345
  - 0.1828854764992205
  train_level2__label_ranking_average_precision_score_oob:
  - 0.1823200419802639
  - 0.20255023890532653
  - 0.1811881461011428
  - 0.19124895922380464
  - 0.18220497585870635
  train_level2__matthews_corrcoef_macro:
  - 0.12426549695209502
  - 0.13729055131963916
  - 0.12888904644583973
  - 0.11632852725591718
  - 0.12417559474579065
  train_level2__matthews_corrcoef_macro_masked:
  - 0.10627162155468707
  - 0.11194578610672334
  - 0.11025719513430055
  - 0.09858504550730157
  - 0.10800397295445288
  train_level2__matthews_corrcoef_macro_oob:
  - 0.12063211752294674
  - 0.1209958665228994
  - 0.12588761530863968
  - 0.11284381127974374
  - 0.12064910071757805
  train_level2__matthews_corrcoef_micro:
  - 0.13102925921557268
  - 0.1460563738785158
  - 0.1383735380572842
  - 0.128917756079333
  - 0.12836856189362242
  train_level2__matthews_corrcoef_micro_masked:
  - 0.10866623751443313
  - 0.12179036125431644
  - 0.11473891987002463
  - 0.10586831654501576
  - 0.10717093958338031
  train_level2__matthews_corrcoef_micro_oob:
  - 0.12351790907461987
  - 0.13952361358136187
  - 0.1350430519913206
  - 0.12363335631761757
  - 0.12266825867160855
  train_level2__matthews_corrcoef_samples:
  - 0.10464716198659874
  - 0.12827692791584444
  - 0.1129707195496486
  - 0.09788032149257847
  - 0.10383278324365135
  train_level2__matthews_corrcoef_samples_masked:
  - 0.08034145767573617
  - 0.10067940766475264
  - 0.08797921681771304
  - 0.07547197761066068
  - 0.07956904805208315
  train_level2__matthews_corrcoef_samples_oob:
  - 0.10091940850651406
  - 0.12225262096015174
  - 0.11059908431753622
  - 0.09642122027217967
  - 0.09954990000844413
  train_level2__matthews_corrcoef_weighted:
  - 0.2181164481921908
  - 0.22549867395468107
  - 0.2295399271423201
  - 0.21928263752996108
  - 0.2238306613125041
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.19371611485058401
  - 0.201976600525936
  - 0.20452763925769663
  - 0.19449842593554503
  - 0.19925550034806874
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.20459304772082496
  - 0.21138733150938935
  - 0.21943797230198211
  - 0.2101757443936091
  - 0.21421429132843112
  train_level2__ndcg:
  - 0.409922126169389
  - 0.43466220395035754
  - 0.4137592413997786
  - 0.4254516096004166
  - 0.41596037567537386
  train_level2__ndcg_oob:
  - 0.40966635600902823
  - 0.43407409305083317
  - 0.41449617316514376
  - 0.4256612454450359
  - 0.4167631497947937
  train_level2__neg_coverage_error:
  - -15.79426891991183
  - -14.919649379108838
  - -15.866861741038772
  - -15.589629629629629
  - -15.955180014695078
  train_level2__neg_coverage_error_oob:
  - -15.893460690668626
  - -15.013148283418554
  - -15.92026335040234
  - -15.688148148148148
  - -16.03894195444526
  train_level2__neg_hamming_loss_macro:
  - -0.7436296840558413
  - -0.7128707085463843
  - -0.7272860277980979
  - -0.7424888888888889
  - -0.7480675973548861
  train_level2__neg_hamming_loss_macro_masked:
  - -0.7672687314482982
  - -0.7359880924827017
  - -0.750479837232486
  - -0.7659394940842499
  - -0.7716494104979063
  train_level2__neg_hamming_loss_macro_oob:
  - -0.752035268185158
  - -0.7214024835646455
  - -0.7312362838332114
  - -0.7498370370370371
  - -0.7563262307127112
  train_level2__neg_hamming_loss_micro:
  - -0.7436296840558413
  - -0.7128707085463842
  - -0.727286027798098
  - -0.7424888888888889
  - -0.7480675973548861
  train_level2__neg_hamming_loss_micro_masked:
  - -0.7726994989612611
  - -0.74044827795663
  - -0.7556427571941352
  - -0.7717357816254853
  - -0.7773228635155367
  train_level2__neg_hamming_loss_micro_oob:
  - -0.752035268185158
  - -0.7214024835646458
  - -0.7312362838332114
  - -0.7498370370370371
  - -0.7563262307127112
  train_level2__neg_hamming_loss_samples:
  - -0.7436296840558413
  - -0.7128707085463841
  - -0.7272860277980979
  - -0.7424888888888889
  - -0.7480675973548861
  train_level2__neg_hamming_loss_samples_masked:
  - -0.7744681816176561
  - -0.7420469926639139
  - -0.7572463203600889
  - -0.7732556754571247
  - -0.7790213601877946
  train_level2__neg_hamming_loss_samples_oob:
  - -0.752035268185158
  - -0.7214024835646456
  - -0.7312362838332114
  - -0.749837037037037
  - -0.7563262307127112
  train_level2__neg_hamming_loss_weighted:
  - -0.582330686105708
  - -0.5761895183986895
  - -0.5743925335295443
  - -0.5739064017200721
  - -0.5816974597823454
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.6279678572241107
  - -0.6211712023064924
  - -0.6184640033231107
  - -0.6192072642867659
  - -0.6271601587858983
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.5927516463035538
  - -0.586045025572919
  - -0.582675124965968
  - -0.5823042377583576
  - -0.5909841036586078
  train_level2__neg_label_ranking_loss:
  - -0.4537533946055098
  - -0.4087297016811375
  - -0.4667611147451918
  - -0.4379232776233614
  - -0.4712472456752706
  train_level2__neg_label_ranking_loss_oob:
  - -0.4562404206638362
  - -0.4126284621465669
  - -0.468378219497499
  - -0.4416920590468682
  - -0.47441466845030916
  train_level2__precision_macro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__precision_macro_masked:
  - 0.23273126855170176
  - 0.2640119075172982
  - 0.24952016276751376
  - 0.2340605059157502
  - 0.22835058950209358
  train_level2__precision_macro_oob:
  - 0.24796473181484202
  - 0.27859751643535424
  - 0.2687637161667886
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__precision_micro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.25751111111111114
  - 0.2519324026451139
  train_level2__precision_micro_masked:
  - 0.22730050103873886
  - 0.25955172204336996
  - 0.24435724280586482
  - 0.22826421837451477
  - 0.22267713648446333
  train_level2__precision_micro_oob:
  - 0.24796473181484202
  - 0.2785975164353543
  - 0.26876371616678857
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__precision_samples:
  - 0.2563703159441587
  - 0.2871292914536158
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__precision_samples_masked:
  - 0.2255318183823439
  - 0.25795300733608606
  - 0.24275367963991096
  - 0.2267443245428753
  - 0.2209786398122055
  train_level2__precision_samples_oob:
  - 0.24796473181484205
  - 0.27859751643535424
  - 0.2687637161667887
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__precision_weighted:
  - 0.41766931389429196
  - 0.42381048160131046
  - 0.4256074664704557
  - 0.4260935982799279
  - 0.4183025402176545
  train_level2__precision_weighted_masked:
  - 0.3720321427758893
  - 0.37882879769350764
  - 0.38153599667688937
  - 0.38079273571323413
  - 0.3728398412141017
  train_level2__precision_weighted_oob:
  - 0.4072483536964461
  - 0.4139549744270809
  - 0.41732487503403204
  - 0.4176957622416424
  - 0.40901589634139235
  train_level2__recall_macro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__recall_macro_masked:
  - 0.23273126855170176
  - 0.2640119075172982
  - 0.24952016276751376
  - 0.2340605059157502
  - 0.22835058950209358
  train_level2__recall_macro_oob:
  - 0.24796473181484202
  - 0.27859751643535424
  - 0.2687637161667886
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__recall_micro:
  - 0.2563703159441587
  - 0.28712929145361576
  - 0.27271397220190197
  - 0.25751111111111114
  - 0.2519324026451139
  train_level2__recall_micro_masked:
  - 0.22730050103873886
  - 0.25955172204336996
  - 0.24435724280586482
  - 0.22826421837451477
  - 0.22267713648446333
  train_level2__recall_micro_oob:
  - 0.24796473181484202
  - 0.2785975164353543
  - 0.26876371616678857
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__recall_samples:
  - 0.2563703159441587
  - 0.2871292914536158
  - 0.27271397220190197
  - 0.2575111111111111
  - 0.2519324026451139
  train_level2__recall_samples_masked:
  - 0.2255318183823439
  - 0.25795300733608606
  - 0.24275367963991096
  - 0.2267443245428753
  - 0.2209786398122055
  train_level2__recall_samples_oob:
  - 0.24796473181484205
  - 0.27859751643535424
  - 0.2687637161667887
  - 0.250162962962963
  - 0.24367376928728876
  train_level2__recall_weighted:
  - 0.41766931389429196
  - 0.42381048160131046
  - 0.4256074664704557
  - 0.4260935982799279
  - 0.4183025402176545
  train_level2__recall_weighted_masked:
  - 0.3720321427758893
  - 0.37882879769350764
  - 0.38153599667688937
  - 0.38079273571323413
  - 0.3728398412141017
  train_level2__recall_weighted_oob:
  - 0.4072483536964461
  - 0.4139549744270809
  - 0.41732487503403204
  - 0.4176957622416424
  - 0.40901589634139235
  train_level2__roc_auc_macro:
  - 0.6319532213020684
  - 0.6573319541672062
  - 0.6459005828659018
  - 0.6312865981879673
  - 0.6351459715649094
  train_level2__roc_auc_macro_masked:
  - 0.6240634640354092
  - 0.6436687424102311
  - 0.640336367382215
  - 0.6208064039443273
  - 0.6279337451244217
  train_level2__roc_auc_macro_oob:
  - 0.6270864824751601
  - 0.6491953207534409
  - 0.6420351288904151
  - 0.6284519197151375
  - 0.6291790708453513
  train_level2__roc_auc_micro:
  - 0.5607903076876426
  - 0.6044255062077563
  - 0.5463360642741306
  - 0.5730123190010553
  - 0.5396918521059388
  train_level2__roc_auc_micro_masked:
  - 0.5573781888610612
  - 0.6006540430063512
  - 0.5417065607976259
  - 0.5695711988146319
  - 0.5357680118049054
  train_level2__roc_auc_micro_oob:
  - 0.5589051241116454
  - 0.6012288132768262
  - 0.5452647775546999
  - 0.5707143680502669
  - 0.5381492744817686
  train_level2__roc_auc_samples:
  - 0.5469747544727267
  - 0.592665167290063
  - 0.5346952528175551
  - 0.5640735684666639
  - 0.5311293900489872
  train_level2__roc_auc_samples_masked:
  - 0.5368647160364403
  - 0.5818683457820483
  - 0.5204815313885092
  - 0.5560411116263547
  - 0.519958102130973
  train_level2__roc_auc_samples_oob:
  - 0.5447238512347329
  - 0.5889611070201589
  - 0.5338699878837113
  - 0.5612383438343006
  - 0.5289973258183753
  train_level2__roc_auc_weighted:
  - 0.683320658296812
  - 0.6987961136311203
  - 0.6965320393483307
  - 0.6647167525514422
  - 0.6873695679036773
  train_level2__roc_auc_weighted_masked:
  - 0.6762790497391188
  - 0.6920787635382921
  - 0.6911455949504307
  - 0.6579810830462128
  - 0.6795508756038543
  train_level2__roc_auc_weighted_oob:
  - 0.6777886427625988
  - 0.6918469492897428
  - 0.6920329994247048
  - 0.6617452409289669
  - 0.6812061765443375
  train_level2__tn_macro:
  - 0.13316678912564292
  - 0.16476260043827612
  - 0.14981711777615214
  - 0.13345185185185188
  - 0.12808229243203528
  train_level2__tn_macro_masked:
  - 0.13845760716031594
  - 0.170327293787203
  - 0.15560445330331388
  - 0.13904793427824566
  - 0.133432135711248
  train_level2__tn_macro_oob:
  - 0.1249669360764144
  - 0.15634769905040174
  - 0.14595464520848572
  - 0.12610370370370372
  - 0.11979426891991184
  train_level2__tn_micro:
  - 0.13316678912564292
  - 0.16476260043827612
  - 0.14981711777615217
  - 0.13345185185185185
  - 0.12808229243203526
  train_level2__tn_micro_masked:
  - 0.13842722717829647
  - 0.17126283180465285
  - 0.15574618239338078
  - 0.13876394109310494
  - 0.13315408353448013
  train_level2__tn_micro_oob:
  - 0.1249669360764144
  - 0.15634769905040174
  - 0.14595464520848572
  - 0.1261037037037037
  - 0.11979426891991182
  train_level2__tn_samples:
  - 0.13316678912564292
  - 0.16476260043827615
  - 0.14981711777615217
  - 0.13345185185185185
  - 0.12808229243203526
  train_level2__tn_samples_masked:
  - 0.13703141947447606
  - 0.16984740146314764
  - 0.1543412832198176
  - 0.1374561362416435
  - 0.13178407949168106
  train_level2__tn_samples_oob:
  - 0.12496693607641442
  - 0.15634769905040177
  - 0.14595464520848575
  - 0.12610370370370372
  - 0.11979426891991185
  train_level2__tn_weighted:
  - 0.12705641475959212
  - 0.13462590781691183
  - 0.1382945915107529
  - 0.13329379941739494
  - 0.1279584819477632
  train_level2__tn_weighted_masked:
  - 0.13930317771176637
  - 0.14688487182180374
  - 0.1519312922693964
  - 0.14618401838908857
  - 0.14036430533735944
  train_level2__tn_weighted_oob:
  - 0.11670110681777139
  - 0.12429557597271358
  - 0.12980759477356615
  - 0.12476765154667774
  - 0.1185437192266081
  train_level2__tp_macro:
  - 0.12320352681851582
  - 0.12236669101533966
  - 0.12289685442574981
  - 0.12405925925925926
  - 0.12385011021307861
  train_level2__tp_macro_masked:
  - 0.09427366139138586
  - 0.09368461373009523
  - 0.09391570946419989
  - 0.09501257163750458
  - 0.09491845379084556
  train_level2__tp_macro_oob:
  - 0.12299779573842763
  - 0.12224981738495252
  - 0.12280907095830287
  - 0.12405925925925924
  - 0.12387950036737692
  train_level2__tp_micro:
  - 0.12320352681851579
  - 0.12236669101533966
  - 0.12289685442574981
  - 0.12405925925925926
  - 0.12385011021307862
  train_level2__tp_micro_masked:
  - 0.08887327386044239
  - 0.08828889023871712
  - 0.08861106041248402
  - 0.08950027728140982
  - 0.0895230529499832
  train_level2__tp_micro_oob:
  - 0.12299779573842763
  - 0.12224981738495252
  - 0.12280907095830285
  - 0.12405925925925926
  - 0.12387950036737692
  train_level2__tp_samples:
  - 0.1232035268185158
  - 0.12236669101533967
  - 0.12289685442574981
  - 0.12405925925925927
  - 0.12385011021307862
  train_level2__tp_samples_masked:
  - 0.08850039890786784
  - 0.08810560587293842
  - 0.08841239642009338
  - 0.08928818830123178
  - 0.08919456032052438
  train_level2__tp_samples_oob:
  - 0.12299779573842763
  - 0.12224981738495252
  - 0.12280907095830285
  - 0.12405925925925927
  - 0.12387950036737695
  train_level2__tp_weighted:
  - 0.29061289913469984
  - 0.2891845737843986
  - 0.28731287495970287
  - 0.29279979886253293
  - 0.2903440582698914
  train_level2__tp_weighted_masked:
  - 0.23272896506412288
  - 0.23194392587170387
  - 0.229604704407493
  - 0.23460871732414557
  - 0.23247553587674227
  train_level2__tp_weighted_oob:
  - 0.29054724687867467
  - 0.28965939845436733
  - 0.2875172802604659
  - 0.2929281106949646
  - 0.29047217711478424
  train_level3__average_precision_macro:
  - 0.2145777758283266
  - 0.22741149834696606
  - 0.22550976607430123
  - 0.21468185069376042
  - 0.21755763593055055
  train_level3__average_precision_macro_masked:
  - 0.17540043132976266
  - 0.18383641658356065
  - 0.18514979771288942
  - 0.17815754447234697
  - 0.180680898546408
  train_level3__average_precision_macro_oob:
  - 0.20972998748921817
  - 0.22467491077736784
  - 0.22294264503500572
  - 0.21139368108255002
  - 0.21549865463757142
  train_level3__average_precision_micro:
  - 0.12634252658539222
  - 0.14046187658936168
  - 0.12314157196571897
  - 0.1336998857083611
  - 0.12278346527908375
  train_level3__average_precision_micro_masked:
  - 0.09140793299140197
  - 0.10207374975736896
  - 0.08861297289395278
  - 0.09722234136959698
  - 0.08872070615163805
  train_level3__average_precision_micro_oob:
  - 0.12585219784853663
  - 0.13969698988396329
  - 0.12292946279447133
  - 0.1336629609683685
  - 0.12271485244629564
  train_level3__average_precision_samples:
  - 0.17863538700626283
  - 0.20110429331135446
  - 0.17863244018249066
  - 0.1883989195983473
  - 0.18112766689590698
  train_level3__average_precision_samples_masked:
  - 0.14088814889252707
  - 0.1605076024433123
  - 0.14067414055076738
  - 0.1504561127634913
  - 0.14338520907668095
  train_level3__average_precision_samples_oob:
  - 0.17780962957669147
  - 0.20004607250018397
  - 0.1779981218779071
  - 0.18789125496770015
  - 0.18040476973069247
  train_level3__average_precision_weighted:
  - 0.4283386281846124
  - 0.45134156477846554
  - 0.4576516917824783
  - 0.4145729769032752
  - 0.4492003841163092
  train_level3__average_precision_weighted_masked:
  - 0.3634473967073456
  - 0.3910324244974759
  - 0.39243974851750724
  - 0.35131483866305985
  - 0.3867340825503316
  train_level3__average_precision_weighted_oob:
  - 0.42215352689241376
  - 0.44432800245233633
  - 0.45147057382335093
  - 0.41243897199183893
  - 0.4438484407885976
  train_level3__f1_macro:
  - 0.2581925055106539
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__f1_macro_masked:
  - 0.2346905576322202
  - 0.263718342157107
  - 0.25147248677205464
  - 0.23566125523351403
  - 0.2309347822261889
  train_level3__f1_macro_oob:
  - 0.25316678912564294
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887584
  train_level3__f1_micro:
  - 0.2581925055106539
  - 0.2868371073776479
  - 0.2746159473299195
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__f1_micro_masked:
  - 0.2292557741659538
  - 0.2592176395553666
  - 0.24633448926203078
  - 0.22983547969683898
  - 0.22527422163830244
  train_level3__f1_micro_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887582
  train_level3__f1_samples:
  - 0.258192505510654
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.2588148148148148
  - 0.25443056576047024
  train_level3__f1_samples_masked:
  - 0.22751105622699397
  - 0.2576278150661229
  - 0.24470525223427486
  - 0.22836164404570203
  - 0.22357339961905354
  train_level3__f1_samples_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887587
  train_level3__f1_weighted:
  - 0.4194629473141508
  - 0.4244188294209404
  - 0.42699142162608084
  - 0.4280175821889306
  - 0.42024747689916037
  train_level3__f1_weighted_masked:
  - 0.3741026269649382
  - 0.3795709458160433
  - 0.38286598986720505
  - 0.38313565376836206
  - 0.37512497629263086
  train_level3__f1_weighted_oob:
  - 0.41248623198095424
  - 0.41653823862869
  - 0.42004453955702864
  - 0.424163718962408
  - 0.4118434295099377
  train_level3__fn_macro:
  - -0.0020573108008817044
  - -0.002863403944485026
  - -0.002692026335040234
  - -0.0027851851851851857
  - -0.002057310800881705
  train_level3__fn_macro_masked:
  - -0.0018891829100943086
  - -0.002504192190208126
  - -0.0024994378276311817
  - -0.00245603126490089
  - -0.0018774918936764707
  train_level3__fn_macro_oob:
  - -0.002263041880969875
  - -0.0030387143900657415
  - -0.0027798098024871976
  - -0.0026370370370370367
  - -0.002233651726671565
  train_level3__fn_micro:
  - -0.002057310800881705
  - -0.0028634039444850254
  - -0.002692026335040234
  - -0.0027851851851851852
  - -0.002057310800881705
  train_level3__fn_micro_masked:
  - -0.0017719662715385556
  - -0.002460061957115957
  - -0.0023726957473991605
  - -0.0023722965062542363
  - -0.0017721286932078585
  train_level3__fn_micro_oob:
  - -0.002263041880969875
  - -0.0030387143900657415
  - -0.002779809802487198
  - -0.002637037037037037
  - -0.002233651726671565
  train_level3__fn_samples:
  - -0.0020573108008817044
  - -0.0028634039444850254
  - -0.0026920263350402344
  - -0.0027851851851851852
  - -0.002057310800881705
  train_level3__fn_samples_masked:
  - -0.0017554981729342013
  - -0.0024496717328679725
  - -0.0023599448482562887
  - -0.0023533694432245154
  - -0.0017484770072381482
  train_level3__fn_samples_oob:
  - -0.002263041880969875
  - -0.0030387143900657415
  - -0.0027798098024871985
  - -0.0026370370370370376
  - -0.002233651726671565
  train_level3__fn_weighted:
  - -0.005065734967528843
  - -0.004300841962238496
  - -0.005775174285779068
  - -0.0047281176307393535
  - -0.004660301544080772
  train_level3__fn_weighted_masked:
  - -0.004898304798174205
  - -0.003640872377647132
  - -0.005745152397455058
  - -0.004581663241409124
  - -0.004560930440189019
  train_level3__fn_weighted_oob:
  - -0.005232364184264689
  - -0.003974357424100009
  - -0.005846775808982138
  - -0.004454154529060896
  - -0.004795623858164378
  train_level3__fp_macro:
  - -0.7397501836884643
  - -0.710299488677867
  - -0.7226920263350404
  - -0.7384000000000001
  - -0.7435121234386481
  train_level3__fp_macro_masked:
  - -0.7634202594576854
  - -0.7337774656526848
  - -0.7460280754003142
  - -0.7618827135015852
  - -0.7671877258801346
  train_level3__fp_macro_oob:
  - -0.7445701689933872
  - -0.7162600438276114
  - -0.7268471104608633
  - -0.7428148148148148
  - -0.7503894195444525
  train_level3__fp_micro:
  - -0.7397501836884643
  - -0.7102994886778671
  - -0.7226920263350403
  - -0.7384
  - -0.743512123438648
  train_level3__fp_micro_masked:
  - -0.7689722595625076
  - -0.7383222984875175
  - -0.7512928149905701
  - -0.7677922237969068
  - -0.7729536496684897
  train_level3__fp_micro_oob:
  - -0.7445701689933872
  - -0.7162600438276114
  - -0.7268471104608633
  - -0.7428148148148148
  - -0.7503894195444526
  train_level3__fp_samples:
  - -0.7397501836884643
  - -0.710299488677867
  - -0.7226920263350401
  - -0.7384
  - -0.7435121234386479
  train_level3__fp_samples_masked:
  - -0.7707334456000718
  - -0.7399225132010091
  - -0.7529348029174688
  - -0.7692849865110734
  - -0.7746781233737083
  train_level3__fp_samples_oob:
  - -0.7445701689933872
  - -0.7162600438276113
  - -0.7268471104608631
  - -0.7428148148148148
  - -0.7503894195444526
  train_level3__fp_weighted:
  - -0.5754713177183205
  - -0.5712803286168211
  - -0.56723340408814
  - -0.5672543001803302
  - -0.5750922215567588
  train_level3__fp_weighted_masked:
  - -0.6209990682368877
  - -0.6167881818063096
  - -0.61138885773534
  - -0.6122826829902288
  - -0.6203140932671801
  train_level3__fp_weighted_oob:
  - -0.5822814038347811
  - -0.5794874039472099
  - -0.5741086846339891
  - -0.5713821265085308
  - -0.583360946631898
  train_level3__jaccard_macro:
  - 0.1700252961339385
  - 0.20210678756114553
  - 0.18424764591817622
  - 0.16874836200146393
  - 0.16732915971092807
  train_level3__jaccard_macro_masked:
  - 0.15252916789795265
  - 0.18507228363174297
  - 0.16697933142408666
  - 0.15126697829894664
  - 0.14975905074980403
  train_level3__jaccard_macro_oob:
  - 0.1689795674934962
  - 0.19909695047593634
  - 0.18281395528179112
  - 0.1678773777479542
  - 0.16350003972101124
  train_level3__jaccard_micro:
  - 0.14823251497511178
  - 0.16743131001313252
  - 0.15916221487322987
  - 0.14864289968518676
  - 0.14575791759971715
  train_level3__jaccard_micro_masked:
  - 0.1294685990338164
  - 0.14890870073451157
  - 0.1404683434518647
  - 0.129838485101643
  - 0.12693466471550313
  train_level3__jaccard_micro_oob:
  - 0.14492899925970792
  - 0.1632649592984722
  - 0.15631872779563524
  - 0.145835101597379
  - 0.14114668052923718
  train_level3__jaccard_samples:
  - 0.16312697119701491
  - 0.18171333494356237
  - 0.17261222022266165
  - 0.1610352675668563
  - 0.1598934672358927
  train_level3__jaccard_samples_masked:
  - 0.14428597986012204
  - 0.163081370038863
  - 0.15376889628360405
  - 0.142119136184209
  - 0.14095559426799173
  train_level3__jaccard_samples_oob:
  - 0.15849754014826106
  - 0.1765822928217642
  - 0.1685216351508667
  - 0.15743535798377006
  - 0.15437906005304697
  train_level3__jaccard_weighted:
  - 0.28913756066319535
  - 0.2958844913786435
  - 0.2975269436762042
  - 0.2972146609239557
  - 0.29081251181334755
  train_level3__jaccard_weighted_masked:
  - 0.24941937182884705
  - 0.25676820626599467
  - 0.2584927948542449
  - 0.2574118609845536
  - 0.25101803007683043
  train_level3__jaccard_weighted_oob:
  - 0.2844630663792755
  - 0.2895879546720241
  - 0.29230058225791766
  - 0.2952374171836659
  - 0.28466940843610977
  train_level3__label_ranking_average_precision_score:
  - 0.18304391015100924
  - 0.20475659426095255
  - 0.1822900846594474
  - 0.1928433640427914
  - 0.18259717461082234
  train_level3__label_ranking_average_precision_score_oob:
  - 0.18221815272143765
  - 0.20369837344978192
  - 0.18165576635486394
  - 0.1923356994121445
  - 0.1818742774456079
  train_level3__matthews_corrcoef_macro:
  - 0.1258205804116144
  - 0.13459163074579292
  - 0.12811257612830523
  - 0.11455198842231376
  - 0.12510618665581913
  train_level3__matthews_corrcoef_macro_masked:
  - 0.10849910701060378
  - 0.1118902579025883
  - 0.10935893174585753
  - 0.09843621924884786
  - 0.10824267462778153
  train_level3__matthews_corrcoef_macro_oob:
  - 0.12543019133194702
  - 0.13002402876564964
  - 0.12608866498822613
  - 0.11428622088789848
  - 0.12060021460654811
  train_level3__matthews_corrcoef_micro:
  - 0.13273292704182074
  - 0.14645457809438236
  - 0.1394631586892636
  - 0.1278940921116334
  - 0.13013225494585248
  train_level3__matthews_corrcoef_micro_masked:
  - 0.11088451197862043
  - 0.12209481291707532
  - 0.11561407779033218
  - 0.10627221734381068
  - 0.10870409105894013
  train_level3__matthews_corrcoef_micro_oob:
  - 0.12767969158646764
  - 0.14114988808624274
  - 0.1359449092832513
  - 0.12592239728676022
  - 0.12376901179856124
  train_level3__matthews_corrcoef_samples:
  - 0.1067339423940666
  - 0.12888554985888764
  - 0.11316758697037131
  - 0.09654915583382945
  - 0.1057783109847027
  train_level3__matthews_corrcoef_samples_masked:
  - 0.08251288938295946
  - 0.10112350756126114
  - 0.08786591206184956
  - 0.07557619587962121
  - 0.08066325297448511
  train_level3__matthews_corrcoef_samples_oob:
  - 0.1051882044758064
  - 0.12364368589605457
  - 0.11087434479540835
  - 0.09743662957952813
  - 0.09990978602857119
  train_level3__matthews_corrcoef_weighted:
  - 0.22094308252015304
  - 0.22557573669311368
  - 0.23052812708685386
  - 0.22058817263265465
  - 0.22515755321956432
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.19691783412463937
  - 0.20260219146612443
  - 0.20516840036948258
  - 0.19671734227893808
  - 0.20047539999703148
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.21282231079176134
  - 0.21519964001543818
  - 0.22274674882102355
  - 0.2176366696841295
  - 0.21549746660645422
  train_level3__ndcg:
  - 0.4097088613083921
  - 0.43535161042545606
  - 0.4151274651870567
  - 0.42605101524332695
  - 0.41570515011558856
  train_level3__ndcg_oob:
  - 0.40951881943368557
  - 0.43496458993498577
  - 0.41560409696764244
  - 0.4272260218491902
  - 0.41647143249920315
  train_level3__neg_coverage_error:
  - -15.863335782512857
  - -14.840029218407597
  - -15.878566203365033
  - -15.520740740740742
  - -15.930198383541514
  train_level3__neg_coverage_error_oob:
  - -15.988243938280675
  - -14.965668371073777
  - -15.953913679590343
  - -15.563703703703704
  - -16.01983835415136
  train_level3__neg_hamming_loss_macro:
  - -0.741807494489346
  - -0.7131628926223521
  - -0.7253840526700804
  - -0.7411851851851853
  - -0.7455694342395297
  train_level3__neg_hamming_loss_macro_masked:
  - -0.7653094423677796
  - -0.7362816578428929
  - -0.7485275132279453
  - -0.764338744766486
  - -0.7690652177738112
  train_level3__neg_hamming_loss_macro_oob:
  - -0.7468332108743571
  - -0.7192987582176771
  - -0.7296269202633503
  - -0.7454518518518518
  - -0.7526230712711243
  train_level3__neg_hamming_loss_micro:
  - -0.741807494489346
  - -0.7131628926223521
  - -0.7253840526700804
  - -0.7411851851851852
  - -0.7455694342395297
  train_level3__neg_hamming_loss_micro_masked:
  - -0.7707442258340462
  - -0.7407823604446334
  - -0.7536655107379692
  - -0.770164520303161
  - -0.7747257783616975
  train_level3__neg_hamming_loss_micro_oob:
  - -0.7468332108743571
  - -0.7192987582176771
  - -0.7296269202633504
  - -0.7454518518518518
  - -0.7526230712711242
  train_level3__neg_hamming_loss_samples:
  - -0.741807494489346
  - -0.713162892622352
  - -0.7253840526700804
  - -0.7411851851851852
  - -0.7455694342395298
  train_level3__neg_hamming_loss_samples_masked:
  - -0.7724889437730059
  - -0.7423721849338771
  - -0.7552947477657251
  - -0.771638355954298
  - -0.7764266003809465
  train_level3__neg_hamming_loss_samples_oob:
  - -0.746833210874357
  - -0.7192987582176771
  - -0.7296269202633505
  - -0.7454518518518518
  - -0.7526230712711243
  train_level3__neg_hamming_loss_weighted:
  - -0.5805370526858493
  - -0.5755811705790594
  - -0.573008578373919
  - -0.5719824178110694
  - -0.5797525231008396
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.6258973730350619
  - -0.6204290541839568
  - -0.617134010132795
  - -0.616864346231638
  - -0.6248750237073692
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.5875137680190458
  - -0.5834617613713099
  - -0.5799554604429714
  - -0.5758362810375919
  - -0.5881565704900623
  train_level3__neg_label_ranking_loss:
  - -0.4542883414822033
  - -0.40550152066901624
  - -0.46574189436592434
  - -0.4363980268441015
  - -0.4710896813693463
  train_level3__neg_label_ranking_loss_oob:
  - -0.45735601135416765
  - -0.40933526857042446
  - -0.4686693402678692
  - -0.4384894280682633
  - -0.4739025060987842
  train_level3__precision_macro:
  - 0.2581925055106539
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__precision_macro_masked:
  - 0.2346905576322202
  - 0.263718342157107
  - 0.25147248677205464
  - 0.23566125523351403
  - 0.2309347822261889
  train_level3__precision_macro_oob:
  - 0.25316678912564294
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887584
  train_level3__precision_micro:
  - 0.2581925055106539
  - 0.2868371073776479
  - 0.2746159473299195
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__precision_micro_masked:
  - 0.2292557741659538
  - 0.2592176395553666
  - 0.24633448926203078
  - 0.22983547969683898
  - 0.22527422163830244
  train_level3__precision_micro_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887582
  train_level3__precision_samples:
  - 0.258192505510654
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.2588148148148148
  - 0.25443056576047024
  train_level3__precision_samples_masked:
  - 0.22751105622699397
  - 0.2576278150661229
  - 0.24470525223427486
  - 0.22836164404570203
  - 0.22357339961905354
  train_level3__precision_samples_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887587
  train_level3__precision_weighted:
  - 0.4194629473141508
  - 0.4244188294209404
  - 0.42699142162608084
  - 0.4280175821889306
  - 0.42024747689916037
  train_level3__precision_weighted_masked:
  - 0.3741026269649382
  - 0.3795709458160433
  - 0.38286598986720505
  - 0.38313565376836206
  - 0.37512497629263086
  train_level3__precision_weighted_oob:
  - 0.41248623198095424
  - 0.41653823862869
  - 0.42004453955702864
  - 0.424163718962408
  - 0.4118434295099377
  train_level3__recall_macro:
  - 0.2581925055106539
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__recall_macro_masked:
  - 0.2346905576322202
  - 0.263718342157107
  - 0.25147248677205464
  - 0.23566125523351403
  - 0.2309347822261889
  train_level3__recall_macro_oob:
  - 0.25316678912564294
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887584
  train_level3__recall_micro:
  - 0.2581925055106539
  - 0.2868371073776479
  - 0.2746159473299195
  - 0.25881481481481483
  - 0.25443056576047024
  train_level3__recall_micro_masked:
  - 0.2292557741659538
  - 0.2592176395553666
  - 0.24633448926203078
  - 0.22983547969683898
  - 0.22527422163830244
  train_level3__recall_micro_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887582
  train_level3__recall_samples:
  - 0.258192505510654
  - 0.28683710737764795
  - 0.27461594732991956
  - 0.2588148148148148
  - 0.25443056576047024
  train_level3__recall_samples_masked:
  - 0.22751105622699397
  - 0.2576278150661229
  - 0.24470525223427486
  - 0.22836164404570203
  - 0.22357339961905354
  train_level3__recall_samples_oob:
  - 0.2531667891256429
  - 0.28070124178232286
  - 0.2703730797366496
  - 0.25454814814814813
  - 0.24737692872887587
  train_level3__recall_weighted:
  - 0.4194629473141508
  - 0.4244188294209404
  - 0.42699142162608084
  - 0.4280175821889306
  - 0.42024747689916037
  train_level3__recall_weighted_masked:
  - 0.3741026269649382
  - 0.3795709458160433
  - 0.38286598986720505
  - 0.38313565376836206
  - 0.37512497629263086
  train_level3__recall_weighted_oob:
  - 0.41248623198095424
  - 0.41653823862869
  - 0.42004453955702864
  - 0.424163718962408
  - 0.4118434295099377
  train_level3__roc_auc_macro:
  - 0.6334009537107113
  - 0.6579248293891828
  - 0.6550320776397485
  - 0.6351080468672841
  - 0.6392784456916596
  train_level3__roc_auc_macro_masked:
  - 0.625306017864653
  - 0.6420182812708657
  - 0.647199358295041
  - 0.6307433228306037
  - 0.6366438092411214
  train_level3__roc_auc_macro_oob:
  - 0.6284021932861596
  - 0.6530321366330728
  - 0.6516202955423218
  - 0.6310837621874938
  - 0.6344564434641876
  train_level3__roc_auc_micro:
  - 0.5610369292562328
  - 0.6060964915095468
  - 0.5477431440722507
  - 0.5787676664791339
  - 0.5443409293825238
  train_level3__roc_auc_micro_masked:
  - 0.5580589912471206
  - 0.6029566531230951
  - 0.5427647438546102
  - 0.5768015881255546
  - 0.5413170339360422
  train_level3__roc_auc_micro_oob:
  - 0.5587564017668463
  - 0.6029953432014254
  - 0.5464472180647483
  - 0.5774253494893545
  - 0.5433209737500012
  train_level3__roc_auc_samples:
  - 0.5464129913756234
  - 0.5959027263247385
  - 0.5362025325271034
  - 0.5662432025018302
  - 0.531842301416665
  train_level3__roc_auc_samples_masked:
  - 0.5360310424695428
  - 0.5840155231754849
  - 0.5221046890828023
  - 0.5592243665596855
  - 0.5209299227802866
  train_level3__roc_auc_samples_oob:
  - 0.5438397344017791
  - 0.5922559274678797
  - 0.534132857745346
  - 0.5654918256514085
  - 0.5301989964909094
  train_level3__roc_auc_weighted:
  - 0.6796318542967227
  - 0.6983143012854095
  - 0.7045146250098634
  - 0.6679121415882772
  - 0.6889126708324633
  train_level3__roc_auc_weighted_masked:
  - 0.6737055697475731
  - 0.6917248548074357
  - 0.6982378214183287
  - 0.6641518920459283
  - 0.6840778019375439
  train_level3__roc_auc_weighted_oob:
  - 0.6736163647339601
  - 0.6927597132559908
  - 0.7005314684686804
  - 0.6658316928789055
  - 0.6833133321947272
  train_level3__tn_macro:
  - 0.1349301983835415
  - 0.1643827611395179
  - 0.15174835405998535
  - 0.13502222222222224
  - 0.13058045554739162
  train_level3__tn_macro_masked:
  - 0.14029367937320159
  - 0.16997930334568287
  - 0.15757621420125695
  - 0.14070857122467162
  - 0.13602405067337606
  train_level3__tn_macro_oob:
  - 0.13011021307861867
  - 0.15842220598977358
  - 0.14759326993416239
  - 0.1306074074074074
  - 0.12370315944158708
  train_level3__tn_micro:
  - 0.1349301983835415
  - 0.16438276113951789
  - 0.15174835405998538
  - 0.1350222222222222
  - 0.13058045554739162
  train_level3__tn_micro_masked:
  - 0.1402602957350605
  - 0.1708680070461034
  - 0.15775384802579545
  - 0.1403968205065007
  - 0.13575116868831924
  train_level3__tn_micro_oob:
  - 0.13011021307861867
  - 0.15842220598977355
  - 0.1475932699341624
  - 0.1306074074074074
  - 0.12370315944158707
  train_level3__tn_samples:
  - 0.13493019838354153
  - 0.1643827611395179
  - 0.15174835405998538
  - 0.13502222222222224
  - 0.13058045554739164
  train_level3__tn_samples_masked:
  - 0.13889309670193292
  - 0.16946255494434107
  - 0.15632732634243401
  - 0.13913271500372948
  - 0.13438128847805406
  train_level3__tn_samples_oob:
  - 0.1301102130786187
  - 0.15842220598977358
  - 0.14759326993416239
  - 0.13060740740740742
  - 0.12370315944158708
  train_level3__tn_weighted:
  - 0.12875854857853386
  - 0.13536266948200681
  - 0.13935020253854677
  - 0.13539689970869745
  - 0.1301877841511329
  train_level3__tn_weighted_masked:
  - 0.14122494342908748
  - 0.14773406335937062
  - 0.15300014676456494
  - 0.14854158986267196
  - 0.14285409361036797
  train_level3__tn_weighted_oob:
  - 0.12194846246207333
  - 0.12715559415161792
  - 0.13247492199269767
  - 0.13126907338049656
  - 0.12191905907599386
  train_level3__tp_macro:
  - 0.12326230712711243
  - 0.12245434623813001
  - 0.12286759326993416
  - 0.12379259259259259
  - 0.12385011021307861
  train_level3__tp_macro_masked:
  - 0.09439687825901859
  - 0.0937390388114241
  - 0.0938962725707977
  - 0.09495268400884241
  - 0.09491073155281286
  train_level3__tp_macro_oob:
  - 0.12305657604702425
  - 0.12227903579254934
  - 0.12277980980248719
  - 0.12394074074074073
  - 0.12367376928728875
  train_level3__tp_micro:
  - 0.12326230712711242
  - 0.12245434623813002
  - 0.12286759326993416
  - 0.12379259259259259
  - 0.12385011021307862
  train_level3__tp_micro_masked:
  - 0.08899547843089331
  - 0.0883496325092632
  - 0.08858064123623532
  - 0.08943865919033828
  - 0.0895230529499832
  train_level3__tp_micro_oob:
  - 0.12305657604702425
  - 0.12227903579254931
  - 0.12277980980248719
  - 0.12394074074074074
  - 0.12367376928728877
  train_level3__tp_samples:
  - 0.1232623071271124
  - 0.12245434623813004
  - 0.12286759326993417
  - 0.12379259259259259
  - 0.12385011021307862
  train_level3__tp_samples_masked:
  - 0.08861795952506109
  - 0.08816526012178186
  - 0.08837792589184086
  - 0.08922892904197252
  - 0.08919211114099952
  train_level3__tp_samples_oob:
  - 0.12305657604702426
  - 0.12227903579254931
  - 0.12277980980248722
  - 0.12394074074074074
  - 0.12367376928728875
  train_level3__tp_weighted:
  - 0.2907043987356168
  - 0.2890561599389336
  - 0.2876412190875341
  - 0.292620682480233
  - 0.29005969274802745
  train_level3__tp_weighted_masked:
  - 0.23287768353585067
  - 0.23183688245667267
  - 0.22986584310264
  - 0.2345940639056901
  - 0.23227088268226284
  train_level3__tp_weighted_oob:
  - 0.290537769518881
  - 0.28938264447707207
  - 0.287569617564331
  - 0.2928946455819115
  - 0.2899243704339438
  train_level4__average_precision_macro:
  - 0.2159568112339419
  - 0.2257086405339281
  - 0.2213761564338533
  - 0.21185437563394313
  - 0.21993006999380263
  train_level4__average_precision_macro_masked:
  - 0.17517520592130187
  - 0.1831758137795779
  - 0.18205723707895355
  - 0.17356466380929159
  - 0.18468529099923361
  train_level4__average_precision_macro_oob:
  - 0.2106828514049967
  - 0.22328192363814525
  - 0.21784699109054095
  - 0.20796485880621735
  - 0.2166023776751337
  train_level4__average_precision_micro:
  - 0.12612919905778874
  - 0.1406792750952184
  - 0.12218803267036524
  - 0.13324643355987492
  - 0.12260617981141608
  train_level4__average_precision_micro_masked:
  - 0.09120339193019256
  - 0.10204613242897866
  - 0.08795439014825984
  - 0.09660645711790308
  - 0.08882030851331181
  train_level4__average_precision_micro_oob:
  - 0.1255867785131795
  - 0.1399473931577329
  - 0.12190012144964754
  - 0.13276884239130265
  - 0.12260592790545248
  train_level4__average_precision_samples:
  - 0.17851056186357228
  - 0.20122022538031803
  - 0.1776831543960556
  - 0.187501531102
  - 0.18209153958227323
  train_level4__average_precision_samples_masked:
  - 0.14115165607360955
  - 0.16029765325494108
  - 0.14020245568725345
  - 0.14981721432093204
  - 0.14426348302021128
  train_level4__average_precision_samples_oob:
  - 0.17761707539100016
  - 0.199845103431538
  - 0.17659335188820102
  - 0.18659999298103888
  - 0.18103341224927955
  train_level4__average_precision_weighted:
  - 0.43043185815578633
  - 0.450701884749566
  - 0.4524292006248195
  - 0.4194422066630036
  - 0.45241988287963936
  train_level4__average_precision_weighted_masked:
  - 0.3625701005860497
  - 0.39014121864677903
  - 0.3875930282655032
  - 0.354412563837405
  - 0.39164012815573845
  train_level4__average_precision_weighted_oob:
  - 0.42274327832379355
  - 0.4437058248352815
  - 0.4474191452314551
  - 0.41425921429284107
  - 0.445847678163189
  train_level4__f1_macro:
  - 0.2590742101396033
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__f1_macro_masked:
  - 0.235633832433305
  - 0.26493985734753256
  - 0.25232544825466335
  - 0.23642456290423475
  - 0.23258974794862936
  train_level4__f1_macro_oob:
  - 0.2541366642174871
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.2542518518518519
  - 0.24781778104335048
  train_level4__f1_micro:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__f1_micro_masked:
  - 0.23023341072956127
  - 0.26046285610156106
  - 0.247247064549492
  - 0.23066732392630476
  - 0.22695468850255127
  train_level4__f1_micro_oob:
  - 0.25413666421748715
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.25425185185185184
  - 0.24781778104335048
  train_level4__f1_samples:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.25958518518518525
  - 0.256017634092579
  train_level4__f1_samples_masked:
  - 0.2285125217241947
  - 0.2588539316095133
  - 0.24562868664471663
  - 0.22919617988023783
  - 0.2252381191119365
  train_level4__f1_samples_oob:
  - 0.2541366642174872
  - 0.28368151935719504
  - 0.26978785662033655
  - 0.25425185185185184
  - 0.2478177810433505
  train_level4__f1_weighted:
  - 0.4195215346292388
  - 0.4248360892636317
  - 0.4263555319081107
  - 0.4272601955888473
  - 0.4211057187998883
  train_level4__f1_weighted_masked:
  - 0.3741795594753101
  - 0.38018165797463854
  - 0.3821968693310523
  - 0.382177536876168
  - 0.37613873133237313
  train_level4__f1_weighted_oob:
  - 0.41261150544586317
  - 0.42034381870417487
  - 0.4171325738002866
  - 0.4225988347898461
  - 0.41093939412649705
  train_level4__fn_macro:
  - -0.002233651726671565
  - -0.0029802775748721698
  - -0.002779809802487198
  - -0.002814814814814815
  - -0.0021160911094783245
  train_level4__fn_macro_masked:
  - -0.002011691304769493
  - -0.002539523248273659
  - -0.0025699943321140896
  - -0.0024520793118749835
  - -0.0019071905029049885
  train_level4__fn_macro_oob:
  - -0.002292432035268185
  - -0.003214024835646457
  - -0.0028383321141185074
  - -0.002785185185185185
  - -0.002292432035268185
  train_level4__fn_micro:
  - -0.002233651726671565
  - -0.0029802775748721693
  - -0.002779809802487198
  - -0.0028148148148148147
  - -0.002116091109478325
  train_level4__fn_micro_masked:
  - -0.0018941708419894904
  - -0.0024904330923889934
  - -0.0024335340998965747
  - -0.0023722965062542363
  - -0.001802682636194201
  train_level4__fn_micro_oob:
  - -0.002292432035268185
  - -0.003214024835646457
  - -0.002838332114118508
  - -0.0027851851851851852
  - -0.002292432035268185
  train_level4__fn_samples:
  - -0.002233651726671565
  - -0.0029802775748721693
  - -0.0027798098024871985
  - -0.002814814814814815
  - -0.002116091109478325
  train_level4__fn_samples_masked:
  - -0.0018768390454810284
  - -0.002481325007764491
  - -0.002415922711555802
  - -0.002354711364856292
  - -0.0017766425717740289
  train_level4__fn_samples_oob:
  - -0.002292432035268185
  - -0.0032140248356464576
  - -0.002838332114118508
  - -0.0027851851851851852
  - -0.002292432035268185
  train_level4__fn_weighted:
  - -0.005236672075079989
  - -0.004629029601775723
  - -0.006168812183578805
  - -0.004677486475239284
  - -0.004760978601580235
  train_level4__fn_weighted_masked:
  - -0.005028875101081524
  - -0.0038036031538911516
  - -0.006063899706043113
  - -0.004478378253588191
  - -0.004569207249214818
  train_level4__fn_weighted_oob:
  - -0.005216511146064379
  - -0.004494995521694873
  - -0.006092607705312679
  - -0.004442190317658483
  - -0.004882408510795942
  train_level4__fp_macro:
  - -0.7386921381337251
  - -0.709072315558802
  - -0.7217556693489393
  - -0.7375999999999999
  - -0.7418662747979426
  train_level4__fp_macro_masked:
  - -0.7623544762619254
  - -0.732520619404194
  - -0.7451045574132225
  - -0.7611233577838903
  - -0.7655030615484657
  train_level4__fp_macro_oob:
  - -0.7435709037472447
  - -0.7131044558071585
  - -0.727373811265545
  - -0.7429629629629629
  - -0.7498897869213813
  train_level4__fp_micro:
  - -0.7386921381337253
  - -0.709072315558802
  - -0.7217556693489393
  - -0.7376
  - -0.7418662747979426
  train_level4__fp_micro_masked:
  - -0.7678724184284492
  - -0.7370467108060499
  - -0.7503194013506114
  - -0.766960379567441
  - -0.7712426288612545
  train_level4__fp_micro_oob:
  - -0.7435709037472447
  - -0.7131044558071585
  - -0.727373811265545
  - -0.7429629629629629
  - -0.7498897869213813
  train_level4__fp_samples:
  - -0.7386921381337251
  - -0.709072315558802
  - -0.7217556693489393
  - -0.7376
  - -0.7418662747979426
  train_level4__fp_samples_masked:
  - -0.7696106392303244
  - -0.7386647433827221
  - -0.7519553906437276
  - -0.7684491087549058
  - -0.7729852383162895
  train_level4__fp_samples_oob:
  - -0.7435709037472447
  - -0.7131044558071584
  - -0.7273738112655449
  - -0.7429629629629629
  - -0.7498897869213813
  train_level4__fp_weighted:
  - -0.5752417932956814
  - -0.5705348811345926
  - -0.5674756559083105
  - -0.5680623179359134
  - -0.5741333025985315
  train_level4__fp_weighted_masked:
  - -0.6207915654236084
  - -0.6160147388714703
  - -0.6117392309629046
  - -0.6133440848702438
  - -0.6192920614184121
  train_level4__fp_weighted_oob:
  - -0.5821719834080724
  - -0.5751611857741303
  - -0.5767748184944007
  - -0.5729589748924955
  - -0.584178197362707
  train_level4__jaccard_macro:
  - 0.17090119976572038
  - 0.20245514861302097
  - 0.18463518874124651
  - 0.16955585161236983
  - 0.16833457513485434
  train_level4__jaccard_macro_masked:
  - 0.15345640887120848
  - 0.18548310942166288
  - 0.167384301767711
  - 0.15207259863271363
  - 0.15083036414672862
  train_level4__jaccard_macro_oob:
  - 0.16987269978275818
  - 0.20113229323916193
  - 0.18180136425259785
  - 0.16780033900232322
  - 0.16346614192861497
  train_level4__jaccard_micro:
  - 0.1488140457499789
  - 0.1681884119805444
  - 0.1597325912854622
  - 0.1491513304618737
  - 0.14680058646084362
  train_level4__jaccard_micro_masked:
  - 0.13009252865626295
  - 0.14973112647531253
  - 0.14106213120444291
  - 0.1303696738581553
  - 0.12800275719455453
  train_level4__jaccard_micro_oob:
  - 0.14556503880275407
  - 0.1652848947072743
  - 0.15592761711483172
  - 0.14564062526519458
  - 0.1414337951625348
  train_level4__jaccard_samples:
  - 0.16365222198693638
  - 0.182557050577089
  - 0.17300220457186485
  - 0.16160928868574093
  - 0.16114028501114472
  train_level4__jaccard_samples_masked:
  - 0.1448662033872982
  - 0.16399674279319973
  - 0.15419102797032122
  - 0.14274224567368526
  - 0.14221829332156252
  train_level4__jaccard_samples_oob:
  - 0.15928978439114225
  - 0.1790713614918099
  - 0.1679129980955807
  - 0.1571526672550859
  - 0.1547181399224459
  train_level4__jaccard_weighted:
  - 0.28923034917002105
  - 0.29593836767523224
  - 0.2966553804003323
  - 0.29654523491710666
  - 0.2913959375606034
  train_level4__jaccard_weighted_masked:
  - 0.24953801487920138
  - 0.2569757822308633
  - 0.25768816283824303
  - 0.2566718101169986
  - 0.2517397366324292
  train_level4__jaccard_weighted_oob:
  - 0.2845501445012292
  - 0.29287381260257794
  - 0.2890867380996778
  - 0.2936898263827052
  - 0.2835499586360071
  train_level4__label_ranking_average_precision_score:
  - 0.1829190850083186
  - 0.20487252632991618
  - 0.18134079887301255
  - 0.1919459755464445
  - 0.1835610472971884
  train_level4__label_ranking_average_precision_score_oob:
  - 0.18202559853574637
  - 0.20349740438113595
  - 0.18025099636515796
  - 0.1910444374254832
  - 0.18250291996419482
  train_level4__matthews_corrcoef_macro:
  - 0.12487512087005971
  - 0.1340875750641406
  - 0.12817198626816675
  - 0.11426080983179723
  - 0.12571928747388794
  train_level4__matthews_corrcoef_macro_masked:
  - 0.10775207946165523
  - 0.11198188547597036
  - 0.1094255643126832
  - 0.0984972266975659
  - 0.1087755976455322
  train_level4__matthews_corrcoef_macro_oob:
  - 0.12537836373315406
  - 0.1315018104946399
  - 0.12351206323670041
  - 0.11250612504016569
  - 0.11932545580331606
  train_level4__matthews_corrcoef_micro:
  - 0.13204406435627916
  - 0.146403440167036
  - 0.13942716892045048
  - 0.12822830868058405
  - 0.13080881955917492
  train_level4__matthews_corrcoef_micro_masked:
  - 0.11037715326037037
  - 0.12254234258116067
  - 0.11562783916933012
  - 0.10676961282855287
  - 0.10941949790174027
  train_level4__matthews_corrcoef_micro_oob:
  - 0.1281460102124344
  - 0.14196555085363272
  - 0.13512781094640555
  - 0.12461130729298694
  - 0.12363952789698014
  train_level4__matthews_corrcoef_samples:
  - 0.1067559521924003
  - 0.12841811598161923
  - 0.11353121104142923
  - 0.09776764226917563
  - 0.10670390953478527
  train_level4__matthews_corrcoef_samples_masked:
  - 0.08256278267541214
  - 0.10093551115251174
  - 0.08837728081117871
  - 0.0762855746282056
  - 0.08183035064988892
  train_level4__matthews_corrcoef_samples_oob:
  - 0.10625836618784798
  - 0.12409059172497866
  - 0.11022679724055004
  - 0.0964887158715814
  - 0.0997949590360014
  train_level4__matthews_corrcoef_weighted:
  - 0.21974524721652217
  - 0.2241460417599494
  - 0.22814176360159813
  - 0.2178018434225849
  - 0.22590379445314215
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.19590023788308905
  - 0.2019431625499065
  - 0.20301883312962107
  - 0.19431655189136432
  - 0.20139790227180604
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.21251087190509502
  - 0.21944202614605443
  - 0.21665813902126402
  - 0.2141207341826463
  - 0.21322942196555084
  train_level4__ndcg:
  - 0.4098395990184711
  - 0.43555024894795474
  - 0.41394032355200977
  - 0.425116904045918
  - 0.4166926385751783
  train_level4__ndcg_oob:
  - 0.40952644658777376
  - 0.43509122058406174
  - 0.414147302643312
  - 0.42561956224201786
  - 0.41728733434620635
  train_level4__neg_coverage_error:
  - -15.88611315209405
  - -14.883856829802776
  - -15.937820043891733
  - -15.57037037037037
  - -15.969140337986774
  train_level4__neg_coverage_error_oob:
  - -16.02865540044085
  - -14.987582176771365
  - -16.033650329188003
  - -15.63037037037037
  - -16.047759000734754
  train_level4__neg_hamming_loss_macro:
  - -0.7409257898603968
  - -0.7120525931336742
  - -0.7245354791514267
  - -0.7404148148148146
  - -0.7439823659074211
  train_level4__neg_hamming_loss_macro_masked:
  - -0.7643661675666951
  - -0.7350601426524673
  - -0.7476745517453367
  - -0.7635754370957654
  - -0.7674102520513706
  train_level4__neg_hamming_loss_macro_oob:
  - -0.7458633357825128
  - -0.7163184806428049
  - -0.7302121433796634
  - -0.7457481481481482
  - -0.7521822189566495
  train_level4__neg_hamming_loss_micro:
  - -0.7409257898603968
  - -0.7120525931336742
  - -0.7245354791514265
  - -0.7404148148148149
  - -0.7439823659074211
  train_level4__neg_hamming_loss_micro_masked:
  - -0.7697665892704387
  - -0.7395371438984389
  - -0.752752935450508
  - -0.7693326760736953
  - -0.7730453114974487
  train_level4__neg_hamming_loss_micro_oob:
  - -0.7458633357825128
  - -0.716318480642805
  - -0.7302121433796634
  - -0.7457481481481482
  - -0.7521822189566495
  train_level4__neg_hamming_loss_samples:
  - -0.7409257898603967
  - -0.7120525931336742
  - -0.7245354791514264
  - -0.7404148148148147
  - -0.743982365907421
  train_level4__neg_hamming_loss_samples_masked:
  - -0.7714874782758053
  - -0.7411460683904868
  - -0.7543713133552834
  - -0.7708038201197622
  - -0.7747618808880635
  train_level4__neg_hamming_loss_samples_oob:
  - -0.745863335782513
  - -0.7163184806428049
  - -0.7302121433796634
  - -0.7457481481481482
  - -0.7521822189566495
  train_level4__neg_hamming_loss_weighted:
  - -0.5804784653707612
  - -0.5751639107363682
  - -0.5736444680918893
  - -0.5727398044111528
  - -0.5788942812001117
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.6258204405246899
  - -0.6198183420253615
  - -0.6178031306689477
  - -0.617822463123832
  - -0.6238612686676269
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.5873884945541368
  - -0.5796561812958252
  - -0.5828674261997134
  - -0.5774011652101539
  - -0.5890606058735031
  train_level4__neg_label_ranking_loss:
  - -0.4546291042364772
  - -0.4074192019317222
  - -0.46790630902483876
  - -0.43800391879748457
  - -0.47063765126973633
  train_level4__neg_label_ranking_loss_oob:
  - -0.45794328076102125
  - -0.41125759943777723
  - -0.47153960476721585
  - -0.4408288143726262
  - -0.47378030606266486
  train_level4__precision_macro:
  - 0.2590742101396033
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__precision_macro_masked:
  - 0.235633832433305
  - 0.26493985734753256
  - 0.25232544825466335
  - 0.23642456290423475
  - 0.23258974794862936
  train_level4__precision_macro_oob:
  - 0.2541366642174871
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.2542518518518519
  - 0.24781778104335048
  train_level4__precision_micro:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__precision_micro_masked:
  - 0.23023341072956127
  - 0.26046285610156106
  - 0.247247064549492
  - 0.23066732392630476
  - 0.22695468850255127
  train_level4__precision_micro_oob:
  - 0.25413666421748715
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.25425185185185184
  - 0.24781778104335048
  train_level4__precision_samples:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.25958518518518525
  - 0.256017634092579
  train_level4__precision_samples_masked:
  - 0.2285125217241947
  - 0.2588539316095133
  - 0.24562868664471663
  - 0.22919617988023783
  - 0.2252381191119365
  train_level4__precision_samples_oob:
  - 0.2541366642174872
  - 0.28368151935719504
  - 0.26978785662033655
  - 0.25425185185185184
  - 0.2478177810433505
  train_level4__precision_weighted:
  - 0.4195215346292388
  - 0.4248360892636317
  - 0.4263555319081107
  - 0.4272601955888473
  - 0.4211057187998883
  train_level4__precision_weighted_masked:
  - 0.3741795594753101
  - 0.38018165797463854
  - 0.3821968693310523
  - 0.382177536876168
  - 0.37613873133237313
  train_level4__precision_weighted_oob:
  - 0.41261150544586317
  - 0.42034381870417487
  - 0.4171325738002866
  - 0.4225988347898461
  - 0.41093939412649705
  train_level4__recall_macro:
  - 0.2590742101396033
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__recall_macro_masked:
  - 0.235633832433305
  - 0.26493985734753256
  - 0.25232544825466335
  - 0.23642456290423475
  - 0.23258974794862936
  train_level4__recall_macro_oob:
  - 0.2541366642174871
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.2542518518518519
  - 0.24781778104335048
  train_level4__recall_micro:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.2595851851851852
  - 0.256017634092579
  train_level4__recall_micro_masked:
  - 0.23023341072956127
  - 0.26046285610156106
  - 0.247247064549492
  - 0.23066732392630476
  - 0.22695468850255127
  train_level4__recall_micro_oob:
  - 0.25413666421748715
  - 0.28368151935719504
  - 0.2697878566203365
  - 0.25425185185185184
  - 0.24781778104335048
  train_level4__recall_samples:
  - 0.25907421013960324
  - 0.2879474068663258
  - 0.27546452084857354
  - 0.25958518518518525
  - 0.256017634092579
  train_level4__recall_samples_masked:
  - 0.2285125217241947
  - 0.2588539316095133
  - 0.24562868664471663
  - 0.22919617988023783
  - 0.2252381191119365
  train_level4__recall_samples_oob:
  - 0.2541366642174872
  - 0.28368151935719504
  - 0.26978785662033655
  - 0.25425185185185184
  - 0.2478177810433505
  train_level4__recall_weighted:
  - 0.4195215346292388
  - 0.4248360892636317
  - 0.4263555319081107
  - 0.4272601955888473
  - 0.4211057187998883
  train_level4__recall_weighted_masked:
  - 0.3741795594753101
  - 0.38018165797463854
  - 0.3821968693310523
  - 0.382177536876168
  - 0.37613873133237313
  train_level4__recall_weighted_oob:
  - 0.41261150544586317
  - 0.42034381870417487
  - 0.4171325738002866
  - 0.4225988347898461
  - 0.41093939412649705
  train_level4__roc_auc_macro:
  - 0.6228261796253046
  - 0.6537041873812054
  - 0.6438193523043307
  - 0.631928318736356
  - 0.6368466781512891
  train_level4__roc_auc_macro_masked:
  - 0.614257282210263
  - 0.6373062408732664
  - 0.635796734701294
  - 0.623806475481008
  - 0.6375098261637349
  train_level4__roc_auc_macro_oob:
  - 0.6171294610040088
  - 0.6480635266207977
  - 0.6393492775977563
  - 0.6271839002487106
  - 0.6346196650094909
  train_level4__roc_auc_micro:
  - 0.560023473118836
  - 0.606580585563183
  - 0.5440279708432771
  - 0.5770932801279084
  - 0.5437389928568179
  train_level4__roc_auc_micro_masked:
  - 0.556756643476684
  - 0.6029278235039656
  - 0.5393097513283246
  - 0.5742753553895955
  - 0.5417221096258654
  train_level4__roc_auc_micro_oob:
  - 0.5575224034653055
  - 0.6035019458313743
  - 0.5423954173335687
  - 0.5745512134295291
  - 0.5429844785722591
  train_level4__roc_auc_samples:
  - 0.5460948803199234
  - 0.5944729697172184
  - 0.5340449964201798
  - 0.5648213660558126
  - 0.5316886322401706
  train_level4__roc_auc_samples_masked:
  - 0.5369539488513148
  - 0.5826670114810256
  - 0.5205523360097053
  - 0.5574217506343454
  - 0.5208773658399847
  train_level4__roc_auc_samples_oob:
  - 0.5430802737798824
  - 0.5908816946821204
  - 0.5312388085994616
  - 0.5631673102578988
  - 0.5297936575727916
  train_level4__roc_auc_weighted:
  - 0.6735123384865351
  - 0.6966503113405144
  - 0.6979940523394577
  - 0.6665468088916449
  - 0.6908436811304509
  train_level4__roc_auc_weighted_masked:
  - 0.667237772474112
  - 0.6889873337524463
  - 0.6920156658464103
  - 0.6615262904291668
  - 0.6882080062416839
  train_level4__roc_auc_weighted_oob:
  - 0.6660596311111785
  - 0.6900596845307649
  - 0.6928765426292252
  - 0.6626814996152448
  - 0.6875754625034903
  train_level4__tn_macro:
  - 0.13598824393828068
  - 0.16560993425858292
  - 0.1526847110460863
  - 0.13582222222222223
  - 0.132226304188097
  train_level4__tn_macro_masked:
  - 0.14135946256896165
  - 0.17123614959417396
  - 0.1584997321883486
  - 0.14146792694236646
  - 0.137708715005045
  train_level4__tn_macro_oob:
  - 0.1311094783247612
  - 0.16157779401022648
  - 0.1470665691294806
  - 0.13045925925925925
  - 0.12420279206465835
  train_level4__tn_micro:
  - 0.13598824393828068
  - 0.16560993425858292
  - 0.15268471104608633
  - 0.13582222222222223
  - 0.132226304188097
  train_level4__tn_micro_masked:
  - 0.1413601368691189
  - 0.1721435947275709
  - 0.1587272616657541
  - 0.14122866473596649
  - 0.1374621894955544
  train_level4__tn_micro_oob:
  - 0.1311094783247612
  - 0.16157779401022646
  - 0.1470665691294806
  - 0.13045925925925925
  - 0.12420279206465834
  train_level4__tn_samples:
  - 0.13598824393828068
  - 0.16560993425858292
  - 0.15268471104608633
  - 0.13582222222222223
  - 0.132226304188097
  train_level4__tn_samples_masked:
  - 0.14001590307168046
  - 0.17072032476262794
  - 0.15730673861617533
  - 0.1399685927598971
  - 0.13607417353547285
  train_level4__tn_samples_oob:
  - 0.1311094783247612
  - 0.16157779401022646
  - 0.14706656912948063
  - 0.13045925925925927
  - 0.12420279206465835
  train_level4__tn_weighted:
  - 0.12898807300117313
  - 0.1361081169642354
  - 0.13910795071837637
  - 0.13458888195311416
  - 0.13114670310936033
  train_level4__tn_weighted_masked:
  - 0.14143244624236675
  - 0.14850750629420997
  - 0.1526497735370004
  - 0.14748018798265683
  - 0.14387612545913606
  train_level4__tn_weighted_oob:
  - 0.12205788288878198
  - 0.13148181232469766
  - 0.12980878813228622
  - 0.1296922249965321
  - 0.12110180834518475
  train_level4__tp_macro:
  - 0.12308596620132256
  - 0.12233747260774289
  - 0.12277980980248719
  - 0.12376296296296296
  - 0.123791329904482
  train_level4__tp_macro_masked:
  - 0.0942743698643434
  - 0.0937037077533586
  - 0.09382571606631479
  - 0.09495663596186832
  - 0.09488103294358434
  train_level4__tp_macro_oob:
  - 0.12302718589272596
  - 0.1221037253469686
  - 0.12272128749085588
  - 0.12379259259259259
  - 0.12361498897869212
  train_level4__tp_micro:
  - 0.12308596620132256
  - 0.12233747260774287
  - 0.12277980980248719
  - 0.12376296296296296
  - 0.123791329904482
  train_level4__tp_micro_masked:
  - 0.08887327386044239
  - 0.08831926137399015
  - 0.08851980288373791
  - 0.08943865919033828
  - 0.08949249900699685
  train_level4__tp_micro_oob:
  - 0.12302718589272593
  - 0.12210372534696859
  - 0.12272128749085588
  - 0.12379259259259259
  - 0.12361498897869214
  train_level4__tp_samples:
  - 0.12308596620132256
  - 0.12233747260774289
  - 0.1227798098024872
  - 0.12376296296296295
  - 0.12379132990448201
  train_level4__tp_samples_masked:
  - 0.08849661865251425
  - 0.08813360684688534
  - 0.08832194802854133
  - 0.08922758712034073
  - 0.08916394557646364
  train_level4__tp_samples_oob:
  - 0.12302718589272596
  - 0.1221037253469686
  - 0.12272128749085591
  - 0.12379259259259259
  - 0.12361498897869215
  train_level4__tp_weighted:
  - 0.29053346162806565
  - 0.2887279722993964
  - 0.28724758118973437
  - 0.29267131363573307
  - 0.289959015690528
  train_level4__tp_weighted_masked:
  - 0.23274711323294336
  - 0.23167415168042865
  - 0.22954709579405194
  - 0.2346973488935111
  - 0.23226260587323702
  train_level4__tp_weighted_oob:
  - 0.2905536225570813
  - 0.28886200637947723
  - 0.2873237856680005
  - 0.2929066097933139
  - 0.28983758578131225
  train_level5__average_precision_macro:
  - 0.21421020071589417
  - 0.22419190262296473
  - 0.22168634622409336
  - 0.21047760570561327
  - 0.21853051152395195
  train_level5__average_precision_macro_masked:
  - 0.17553734995763962
  - 0.1823650800268144
  - 0.18295547035026083
  - 0.17227116291033137
  - 0.18209152690619795
  train_level5__average_precision_macro_oob:
  - 0.21045977541040056
  - 0.22044560519687675
  - 0.21933501701056685
  - 0.20537296502644742
  - 0.21691171220792418
  train_level5__average_precision_micro:
  - 0.1264224764278575
  - 0.139829295703511
  - 0.12280184008445583
  - 0.13357270319811226
  - 0.12263579600001741
  train_level5__average_precision_micro_masked:
  - 0.09151506199659226
  - 0.10165085821281684
  - 0.08852240574650214
  - 0.09691672447918342
  - 0.08867507843773084
  train_level5__average_precision_micro_oob:
  - 0.1259785248569194
  - 0.13911379285002246
  - 0.12252001456175576
  - 0.13344772575355757
  - 0.12276541827241294
  train_level5__average_precision_samples:
  - 0.17941457782382902
  - 0.20013188353979441
  - 0.17870076763601264
  - 0.18743217950073907
  - 0.18149248738327456
  train_level5__average_precision_samples_masked:
  - 0.14183467712387546
  - 0.16033051165989148
  - 0.14075363660255474
  - 0.14947986528057822
  - 0.14371987805706907
  train_level5__average_precision_samples_oob:
  - 0.17864885921575926
  - 0.1990225778425186
  - 0.17772629283967534
  - 0.18670255465247962
  - 0.18078178635141517
  train_level5__average_precision_weighted:
  - 0.4264919176733028
  - 0.4482584575626518
  - 0.4493145540537901
  - 0.41628182854170603
  - 0.45197790124982545
  train_level5__average_precision_weighted_masked:
  - 0.3601768451742759
  - 0.3877492668477599
  - 0.38407341602058404
  - 0.35190074608103844
  - 0.3899314299865847
  train_level5__average_precision_weighted_oob:
  - 0.42058881898948325
  - 0.44169012168275423
  - 0.44436283281050715
  - 0.4107866225803085
  - 0.4502525392515241
  train_level5__f1_macro:
  - 0.2583100661278472
  - 0.2874214755295837
  - 0.2756400877834675
  - 0.25970370370370366
  - 0.255165319617928
  train_level5__f1_macro_masked:
  - 0.23484232487091794
  - 0.2643560810925711
  - 0.2525296757417911
  - 0.23657245434340393
  - 0.23171006328622443
  train_level5__f1_macro_oob:
  - 0.2547538574577517
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__f1_micro:
  - 0.2583100661278472
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__f1_micro_masked:
  - 0.22943908102163021
  - 0.25991617566664643
  - 0.24742957960698425
  - 0.23079056010844784
  - 0.22612973204192002
  train_level5__f1_micro_oob:
  - 0.25475385745775164
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__f1_samples:
  - 0.25831006612784724
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__f1_samples_masked:
  - 0.2277344861210625
  - 0.2583147054298641
  - 0.24582491345364665
  - 0.2293573017964322
  - 0.22442155214803539
  train_level5__f1_samples_oob:
  - 0.2547538574577517
  - 0.2819284149013879
  - 0.2716313094367228
  - 0.25475555555555557
  - 0.2484055841293167
  train_level5__f1_weighted:
  - 0.4188558793404585
  - 0.4235296401806582
  - 0.4269834090746748
  - 0.4279220418920793
  - 0.41913985775549506
  train_level5__f1_weighted_masked:
  - 0.37345036322498504
  - 0.37865082353552726
  - 0.3829621422420684
  - 0.38295319041432924
  - 0.3738664603053656
  train_level5__f1_weighted_oob:
  - 0.4121609000665828
  - 0.4162907779954531
  - 0.4197598382623879
  - 0.4230860729643501
  - 0.4111966608833099
  train_level5__fn_macro:
  - -0.002174871418074945
  - -0.002863403944485026
  - -0.0028090709583028528
  - -0.002814814814814815
  - -0.002204261572373255
  train_level5__fn_macro_masked:
  - -0.001951362034683334
  - -0.0024154732945781254
  - -0.002599623961743719
  - -0.002452322534139463
  - -0.0019379124691108257
  train_level5__fn_macro_oob:
  - -0.002321822189566495
  - -0.003155588020452885
  - -0.0029553767373811262
  - -0.0028148148148148156
  - -0.002263041880969875
  train_level5__fn_micro:
  - -0.002174871418074945
  - -0.0028634039444850254
  - -0.0028090709583028528
  - -0.0028148148148148147
  - -0.002204261572373255
  train_level5__fn_micro_masked:
  - -0.0018330685567640229
  - -0.0023689485512968476
  - -0.002463953276145282
  - -0.0023722965062542363
  - -0.0018332365791805432
  train_level5__fn_micro_oob:
  - -0.002321822189566495
  - -0.0031555880204528854
  - -0.0029553767373811267
  - -0.0028148148148148147
  - -0.002263041880969875
  train_level5__fn_samples:
  - -0.002174871418074945
  - -0.0028634039444850254
  - -0.002809070958302853
  - -0.0028148148148148147
  - -0.002204261572373255
  train_level5__fn_samples_masked:
  - -0.0018168341471219787
  - -0.002359581642777882
  - -0.002445183867371457
  - -0.0023534767969550577
  - -0.0018072573158347685
  train_level5__fn_samples_oob:
  - -0.002321822189566495
  - -0.0031555880204528854
  - -0.0029553767373811267
  - -0.002814814814814815
  - -0.002263041880969875
  train_level5__fn_weighted:
  - -0.005197728742109666
  - -0.00445292891714599
  - -0.006178188573522064
  - -0.00468771674296019
  - -0.004760292556895401
  train_level5__fn_weighted_masked:
  - -0.004988509516012958
  - -0.0036135302921409744
  - -0.006073313802413731
  - -0.004484730362801591
  - -0.00460442235438717
  train_level5__fn_weighted_oob:
  - -0.005288711396128826
  - -0.004444583720292164
  - -0.006359238139335542
  - -0.004645755305867666
  - -0.004730106590762683
  train_level5__fp_macro:
  - -0.7395150624540778
  - -0.7097151205259314
  - -0.7215508412582295
  - -0.7374814814814816
  - -0.7426304188096988
  train_level5__fp_macro_masked:
  - -0.7632063130943988
  - -0.7332284456128508
  - -0.7448707002964653
  - -0.7609752231224567
  - -0.7663520242446648
  train_level5__fp_macro_oob:
  - -0.7429243203526817
  - -0.7149159970781593
  - -0.725413313825896
  - -0.7424296296296294
  - -0.7493313739897134
  train_level5__fp_micro:
  - -0.7395150624540778
  - -0.7097151205259313
  - -0.7215508412582297
  - -0.7374814814814815
  - -0.7426304188096987
  train_level5__fp_micro_masked:
  - -0.7687278504216057
  - -0.7377148757820567
  - -0.7501064671168705
  - -0.766837143385298
  - -0.7720370313788995
  train_level5__fp_micro_oob:
  - -0.7429243203526819
  - -0.7149159970781592
  - -0.7254133138258961
  - -0.7424296296296297
  - -0.7493313739897135
  train_level5__fp_samples:
  - -0.7395150624540778
  - -0.7097151205259312
  - -0.7215508412582297
  - -0.7374814814814815
  - -0.7426304188096988
  train_level5__fp_samples_masked:
  - -0.7704486797318156
  - -0.7393257129273582
  - -0.751729902678982
  - -0.7682892214066127
  - -0.7737711905361299
  train_level5__fp_samples_oob:
  - -0.7429243203526819
  - -0.7149159970781592
  - -0.725413313825896
  - -0.7424296296296297
  - -0.7493313739897133
  train_level5__fp_weighted:
  - -0.5759463919174319
  - -0.5720174309021959
  - -0.5668384023518032
  - -0.5673902413649605
  - -0.5760998496876096
  train_level5__fp_weighted_masked:
  - -0.621561127259002
  - -0.6177356461723317
  - -0.6109645439555178
  - -0.6125620792228691
  - -0.6215291173402472
  train_level5__fp_weighted_oob:
  - -0.5825503885372884
  - -0.5792646382842547
  - -0.5738809235982766
  - -0.5722681717297823
  - -0.5840732325259272
  train_level5__jaccard_macro:
  - 0.1698751453717296
  - 0.2019091458371766
  - 0.1847503524084219
  - 0.16985520807441037
  - 0.1675647493296693
  train_level5__jaccard_macro_masked:
  - 0.15240795431915577
  - 0.18487853146096975
  - 0.16751519856907315
  - 0.15241350960532826
  - 0.1500880777634651
  train_level5__jaccard_macro_oob:
  - 0.16991742592434522
  - 0.19944310661190198
  - 0.1835652822869432
  - 0.16805741250075648
  - 0.16414868790107523
  train_level5__jaccard_micro:
  - 0.1483100183932097
  - 0.16782966236159214
  - 0.15985067028678093
  - 0.1492295905337533
  - 0.14624039886807708
  train_level5__jaccard_micro_masked:
  - 0.1295855333540394
  - 0.14936991657067059
  - 0.14118096296039157
  - 0.1304484109708315
  - 0.12747816800730316
  train_level5__jaccard_micro_oob:
  - 0.14597015930753426
  - 0.16409584871005595
  - 0.15716051263819053
  - 0.14597127432005705
  - 0.1418168394912581
  train_level5__jaccard_samples:
  - 0.16315852656701735
  - 0.1824493959528554
  - 0.173167042223885
  - 0.16155511124254832
  - 0.1604228622688517
  train_level5__jaccard_samples_masked:
  - 0.14437377274110005
  - 0.16390050496626302
  - 0.1543636156086735
  - 0.14267251721188934
  - 0.14156836519932262
  train_level5__jaccard_samples_oob:
  - 0.1597866919886103
  - 0.17795703868309445
  - 0.16930565346842597
  - 0.15749627269571573
  - 0.155223940245286
  train_level5__jaccard_weighted:
  - 0.2884188422738831
  - 0.29467126333439964
  - 0.2974026029784236
  - 0.2973149596828209
  - 0.2895846208867647
  train_level5__jaccard_weighted_masked:
  - 0.24869405807920514
  - 0.2555959391057403
  - 0.2585086942761338
  - 0.2575056659147458
  - 0.24979036671428362
  train_level5__jaccard_weighted_oob:
  - 0.28384391124538066
  - 0.2890175561279135
  - 0.29181323404653303
  - 0.2940536358125516
  - 0.28393440521456587
  train_level5__label_ranking_average_precision_score:
  - 0.18382310096857554
  - 0.20378418448939237
  - 0.18235841211296924
  - 0.19187662394518343
  - 0.1829619950981898
  train_level5__label_ranking_average_precision_score_oob:
  - 0.18305738236050556
  - 0.2026748787921168
  - 0.18138393731663224
  - 0.19114699909692368
  - 0.18225129406633042
  train_level5__matthews_corrcoef_macro:
  - 0.12398736163110723
  - 0.13388860989529372
  - 0.12797122416121642
  - 0.1149051953017046
  - 0.12347037602291014
  train_level5__matthews_corrcoef_macro_masked:
  - 0.1069952930221473
  - 0.11257940464414419
  - 0.10915315276748373
  - 0.09889275673790066
  - 0.10749915965426522
  train_level5__matthews_corrcoef_macro_oob:
  - 0.12440351493615691
  - 0.1295000019697483
  - 0.1251326601307339
  - 0.1131961180662131
  - 0.12026907639498687
  train_level5__matthews_corrcoef_micro:
  - 0.13194572975507038
  - 0.14684257930071856
  - 0.13934271992637492
  - 0.12831286873935074
  - 0.1295530505554994
  train_level5__matthews_corrcoef_micro_masked:
  - 0.11045269923667848
  - 0.1232187380818799
  - 0.11547908133885117
  - 0.1068432007919668
  - 0.10866414594071272
  train_level5__matthews_corrcoef_micro_oob:
  - 0.12836285027323324
  - 0.14117967260656672
  - 0.13557428072325653
  - 0.12475705117110833
  - 0.12428816277474826
  train_level5__matthews_corrcoef_samples:
  - 0.10684843299559008
  - 0.12936590488999802
  - 0.11314520182700061
  - 0.09760363961386596
  - 0.10529016055333157
  train_level5__matthews_corrcoef_samples_masked:
  - 0.08293383160528336
  - 0.10221821495436637
  - 0.08792930056515044
  - 0.0762154516698206
  - 0.08110977460870836
  train_level5__matthews_corrcoef_samples_oob:
  - 0.10611743668419198
  - 0.12362195079362309
  - 0.11114754012953192
  - 0.09650780680272782
  - 0.10083864375793597
  train_level5__matthews_corrcoef_weighted:
  - 0.2187223719966125
  - 0.22236695655341468
  - 0.2291889513022801
  - 0.21934232140687937
  - 0.22211788672214636
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.19498278000599958
  - 0.20067015761786566
  - 0.20403595984124562
  - 0.1957393420791819
  - 0.19823214559631036
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.21093716043580965
  - 0.21305043626289338
  - 0.22007356760557595
  - 0.21472441042677984
  - 0.21385362791931462
  train_level5__ndcg:
  - 0.4104200251685562
  - 0.43466685827296675
  - 0.4154553659058333
  - 0.42565242792502667
  - 0.4158537247739174
  train_level5__ndcg_oob:
  - 0.41025682631446564
  - 0.4341334713670549
  - 0.4158165523757283
  - 0.42699735793653903
  - 0.4172041350367941
  train_level5__neg_coverage_error:
  - -15.920646583394563
  - -14.918188458728999
  - -15.899780541331383
  - -15.56962962962963
  - -15.930933137398972
  train_level5__neg_coverage_error_oob:
  - -16.04849375459221
  - -15.003652300949598
  - -15.977322604242868
  - -15.648148148148149
  - -15.987509184423217
  train_level5__neg_hamming_loss_macro:
  - -0.7416899338721528
  - -0.7125785244704165
  - -0.7243599122165325
  - -0.7402962962962962
  - -0.7448346803820719
  train_level5__neg_hamming_loss_macro_masked:
  - -0.7651576751290822
  - -0.7356439189074289
  - -0.747470324258209
  - -0.7634275456565962
  - -0.7682899367137757
  train_level5__neg_hamming_loss_macro_oob:
  - -0.7452461425422483
  - -0.7180715850986121
  - -0.7283686905632772
  - -0.7452444444444444
  - -0.7515944158706833
  train_level5__neg_hamming_loss_micro:
  - -0.7416899338721529
  - -0.7125785244704164
  - -0.7243599122165325
  - -0.7402962962962963
  - -0.744834680382072
  train_level5__neg_hamming_loss_micro_masked:
  - -0.7705609189783698
  - -0.7400838243333536
  - -0.7525704203930158
  - -0.7692094398915521
  - -0.77387026795808
  train_level5__neg_hamming_loss_micro_oob:
  - -0.7452461425422483
  - -0.7180715850986121
  - -0.7283686905632772
  - -0.7452444444444445
  - -0.7515944158706833
  train_level5__neg_hamming_loss_samples:
  - -0.7416899338721529
  - -0.7125785244704163
  - -0.7243599122165325
  - -0.7402962962962962
  - -0.7448346803820719
  train_level5__neg_hamming_loss_samples_masked:
  - -0.7722655138789376
  - -0.741685294570136
  - -0.7541750865463532
  - -0.7706426982035678
  - -0.7755784478519644
  train_level5__neg_hamming_loss_samples_oob:
  - -0.7452461425422483
  - -0.7180715850986121
  - -0.7283686905632772
  - -0.7452444444444444
  - -0.7515944158706832
  train_level5__neg_hamming_loss_weighted:
  - -0.5811441206595415
  - -0.5764703598193418
  - -0.5730165909253252
  - -0.5720779581079206
  - -0.580860142244505
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.6265496367750149
  - -0.6213491764644727
  - -0.6170378577579316
  - -0.6170468095856707
  - -0.6261335396946344
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.5878390999334172
  - -0.583709222004547
  - -0.5802401617376122
  - -0.5769139270356499
  - -0.5888033391166901
  train_level5__neg_label_ranking_loss:
  - -0.45286342153966835
  - -0.40913738494375734
  - -0.46529634198825925
  - -0.43808188586403385
  - -0.4704665030863833
  train_level5__neg_label_ranking_loss_oob:
  - -0.4564581699823225
  - -0.4130193413268142
  - -0.4688457475854894
  - -0.44099746647181476
  - -0.47340836454768503
  train_level5__precision_macro:
  - 0.2583100661278472
  - 0.2874214755295837
  - 0.2756400877834675
  - 0.25970370370370366
  - 0.255165319617928
  train_level5__precision_macro_masked:
  - 0.23484232487091794
  - 0.2643560810925711
  - 0.2525296757417911
  - 0.23657245434340393
  - 0.23171006328622443
  train_level5__precision_macro_oob:
  - 0.2547538574577517
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__precision_micro:
  - 0.2583100661278472
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__precision_micro_masked:
  - 0.22943908102163021
  - 0.25991617566664643
  - 0.24742957960698425
  - 0.23079056010844784
  - 0.22612973204192002
  train_level5__precision_micro_oob:
  - 0.25475385745775164
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__precision_samples:
  - 0.25831006612784724
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__precision_samples_masked:
  - 0.2277344861210625
  - 0.2583147054298641
  - 0.24582491345364665
  - 0.2293573017964322
  - 0.22442155214803539
  train_level5__precision_samples_oob:
  - 0.2547538574577517
  - 0.2819284149013879
  - 0.2716313094367228
  - 0.25475555555555557
  - 0.2484055841293167
  train_level5__precision_weighted:
  - 0.4188558793404585
  - 0.4235296401806582
  - 0.4269834090746748
  - 0.4279220418920793
  - 0.41913985775549506
  train_level5__precision_weighted_masked:
  - 0.37345036322498504
  - 0.37865082353552726
  - 0.3829621422420684
  - 0.38295319041432924
  - 0.3738664603053656
  train_level5__precision_weighted_oob:
  - 0.4121609000665828
  - 0.4162907779954531
  - 0.4197598382623879
  - 0.4230860729643501
  - 0.4111966608833099
  train_level5__recall_macro:
  - 0.2583100661278472
  - 0.2874214755295837
  - 0.2756400877834675
  - 0.25970370370370366
  - 0.255165319617928
  train_level5__recall_macro_masked:
  - 0.23484232487091794
  - 0.2643560810925711
  - 0.2525296757417911
  - 0.23657245434340393
  - 0.23171006328622443
  train_level5__recall_macro_oob:
  - 0.2547538574577517
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__recall_micro:
  - 0.2583100661278472
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__recall_micro_masked:
  - 0.22943908102163021
  - 0.25991617566664643
  - 0.24742957960698425
  - 0.23079056010844784
  - 0.22612973204192002
  train_level5__recall_micro_oob:
  - 0.25475385745775164
  - 0.28192841490138787
  - 0.27163130943672276
  - 0.25475555555555557
  - 0.24840558412931668
  train_level5__recall_samples:
  - 0.25831006612784724
  - 0.28742147552958364
  - 0.27564008778346744
  - 0.2597037037037037
  - 0.255165319617928
  train_level5__recall_samples_masked:
  - 0.2277344861210625
  - 0.2583147054298641
  - 0.24582491345364665
  - 0.2293573017964322
  - 0.22442155214803539
  train_level5__recall_samples_oob:
  - 0.2547538574577517
  - 0.2819284149013879
  - 0.2716313094367228
  - 0.25475555555555557
  - 0.2484055841293167
  train_level5__recall_weighted:
  - 0.4188558793404585
  - 0.4235296401806582
  - 0.4269834090746748
  - 0.4279220418920793
  - 0.41913985775549506
  train_level5__recall_weighted_masked:
  - 0.37345036322498504
  - 0.37865082353552726
  - 0.3829621422420684
  - 0.38295319041432924
  - 0.3738664603053656
  train_level5__recall_weighted_oob:
  - 0.4121609000665828
  - 0.4162907779954531
  - 0.4197598382623879
  - 0.4230860729643501
  - 0.4111966608833099
  train_level5__roc_auc_macro:
  - 0.6246380989394854
  - 0.6504212846770538
  - 0.6467020503323387
  - 0.6296349497616256
  - 0.6326398234375127
  train_level5__roc_auc_macro_masked:
  - 0.6180380760554097
  - 0.6348937697659452
  - 0.6439188905055887
  - 0.62178599951274
  - 0.6279205346553615
  train_level5__roc_auc_macro_oob:
  - 0.6180354605623127
  - 0.6427137353754027
  - 0.6425566748161051
  - 0.6255108832005295
  - 0.6293713082013573
  train_level5__roc_auc_micro:
  - 0.5609344201362033
  - 0.6043003733214833
  - 0.5462708856596161
  - 0.578007132945969
  - 0.5436315055930581
  train_level5__roc_auc_micro_masked:
  - 0.5582146292333117
  - 0.6013659854512369
  - 0.5420107861881998
  - 0.5754179718147217
  - 0.5406283518121442
  train_level5__roc_auc_micro_oob:
  - 0.5587685490404386
  - 0.6013358458408324
  - 0.5447352773456885
  - 0.5764389484394252
  - 0.5432330257007817
  train_level5__roc_auc_samples:
  - 0.5476774381700442
  - 0.5922414630191065
  - 0.5373238294266458
  - 0.5650345214200807
  - 0.5322928412309179
  train_level5__roc_auc_samples_masked:
  - 0.5373910678813001
  - 0.5822730643961327
  - 0.5237776065884701
  - 0.5578039299894566
  - 0.5214246954216403
  train_level5__roc_auc_samples_oob:
  - 0.5443908705702357
  - 0.5886365031957949
  - 0.5348470477434502
  - 0.5637965593965466
  - 0.5308532039821788
  train_level5__roc_auc_weighted:
  - 0.6719032587411242
  - 0.6936938642934408
  - 0.69829628947725
  - 0.6642832423450411
  - 0.6875870524912384
  train_level5__roc_auc_weighted_masked:
  - 0.6664831071874734
  - 0.6873679667629587
  - 0.6941679580593709
  - 0.6598541118757447
  - 0.6819930794635973
  train_level5__roc_auc_weighted_oob:
  - 0.6648088558384032
  - 0.6877997984644881
  - 0.6925299140423875
  - 0.6608433519033254
  - 0.684174351256447
  train_level5__tn_macro:
  - 0.135165319617928
  - 0.1649671292914536
  - 0.15288953913679593
  - 0.13594074074074075
  - 0.13146216017634094
  train_level5__tn_macro_masked:
  - 0.14050762573648837
  - 0.17052832338551696
  - 0.15873358930510592
  - 0.1416160616038001
  - 0.13685975230884598
  train_level5__tn_macro_oob:
  - 0.13175606171932402
  - 0.15976625273922568
  - 0.14902706656912945
  - 0.1309925925925926
  - 0.12476120499632624
  train_level5__tn_micro:
  - 0.135165319617928
  - 0.16496712929145363
  - 0.1528895391367959
  - 0.13594074074074075
  - 0.13146216017634094
  train_level5__tn_micro_masked:
  - 0.14050470487596237
  - 0.1714754297515641
  - 0.15894019589949504
  - 0.14135190091810956
  - 0.1366677869779095
  train_level5__tn_micro_oob:
  - 0.13175606171932402
  - 0.1597662527392257
  - 0.14902706656912948
  - 0.1309925925925926
  - 0.12476120499632623
  train_level5__tn_samples:
  - 0.135165319617928
  - 0.16496712929145363
  - 0.15288953913679593
  - 0.13594074074074078
  - 0.13146216017634094
  train_level5__tn_samples_masked:
  - 0.1391778625701892
  - 0.17005935521799212
  - 0.15753222658092095
  - 0.14012848010819026
  - 0.1352882213156325
  train_level5__tn_samples_oob:
  - 0.13175606171932405
  - 0.15976625273922573
  - 0.1490270665691295
  - 0.1309925925925926
  - 0.12476120499632624
  train_level5__tn_weighted:
  - 0.1282834743794225
  - 0.13462556719663207
  - 0.13974520427488368
  - 0.13526095852406717
  - 0.1291801560202822
  train_level5__tn_weighted_masked:
  - 0.14066288440697314
  - 0.14678659899334848
  - 0.15342446054438705
  - 0.1482621936300316
  - 0.141639069537301
  train_level5__tn_weighted_oob:
  - 0.12167947775956593
  - 0.12737835981457313
  - 0.1327026830284103
  - 0.1303830281592454
  - 0.12120677318196442
  train_level5__tp_macro:
  - 0.12314474650991919
  - 0.12245434623813002
  - 0.12275054864667155
  - 0.12376296296296296
  - 0.12370315944158707
  train_level5__tp_macro_masked:
  - 0.09433469913442956
  - 0.09382775770705411
  - 0.09379608643668517
  - 0.09495639273960384
  - 0.0948503109773785
  train_level5__tp_macro_oob:
  - 0.12299779573842763
  - 0.12216216216216218
  - 0.12260424286759326
  - 0.12376296296296296
  - 0.12364437913299044
  train_level5__tp_micro:
  - 0.12314474650991918
  - 0.12245434623813002
  - 0.12275054864667154
  - 0.12376296296296296
  - 0.12370315944158707
  train_level5__tp_micro_masked:
  - 0.08893437614566785
  - 0.0884407459150823
  - 0.0884893837074892
  - 0.08943865919033828
  - 0.0894619450640105
  train_level5__tp_micro_oob:
  - 0.12299779573842763
  - 0.12216216216216216
  - 0.12260424286759326
  - 0.12376296296296296
  - 0.12364437913299045
  train_level5__tp_samples:
  - 0.12314474650991919
  - 0.12245434623813001
  - 0.12275054864667155
  - 0.12376296296296298
  - 0.12370315944158708
  train_level5__tp_samples_masked:
  - 0.0885566235508733
  - 0.08825535021187195
  - 0.08829268687272568
  - 0.08922882168824196
  - 0.08913333083240288
  train_level5__tp_samples_oob:
  - 0.12299779573842763
  - 0.12216216216216216
  - 0.12260424286759329
  - 0.12376296296296295
  - 0.12364437913299046
  train_level5__tp_weighted:
  - 0.290572404961036
  - 0.2889040729840261
  - 0.28723820479979106
  - 0.29266108336801216
  - 0.2899597017352128
  train_level5__tp_weighted_masked:
  - 0.23278747881801193
  - 0.23186422454217884
  - 0.22953768169768132
  - 0.2346909967842977
  - 0.23222739076806467
  train_level5__tp_weighted_oob:
  - 0.2904814223070168
  - 0.2889124181808799
  - 0.2870571552339776
  - 0.29270304480510473
  - 0.28998988770134554
  train_level6__average_precision_macro:
  - 0.21047928215130426
  - 0.22499043280642167
  - 0.22274816131965747
  - 0.21031311319806967
  - 0.21354622478748145
  train_level6__average_precision_macro_masked:
  - 0.1716089730725689
  - 0.18201990521241398
  - 0.1833139719311703
  - 0.17273719961026693
  - 0.17693904648862496
  train_level6__average_precision_macro_oob:
  - 0.2085316345293793
  - 0.22319166416012046
  - 0.22067802701304834
  - 0.20837273321731994
  - 0.21016773140580697
  train_level6__average_precision_micro:
  - 0.12615641265926256
  - 0.13955314393214888
  - 0.1224325161515679
  - 0.13394050499141516
  - 0.12286511714332478
  train_level6__average_precision_micro_masked:
  - 0.09133270263601403
  - 0.10146101246760043
  - 0.08813475367804066
  - 0.09693837049971063
  - 0.08886262830759314
  train_level6__average_precision_micro_oob:
  - 0.12573325906394076
  - 0.13884119669674258
  - 0.12205849190153673
  - 0.13359922794702236
  - 0.12274205940413029
  train_level6__average_precision_samples:
  - 0.17850443383104966
  - 0.2004962928477343
  - 0.17883218252578376
  - 0.18720887784851825
  - 0.18179106957314115
  train_level6__average_precision_samples_masked:
  - 0.14101806591391997
  - 0.16015153977030558
  - 0.14098905185064467
  - 0.1493721926859382
  - 0.1438070522517548
  train_level6__average_precision_samples_oob:
  - 0.17774037359904113
  - 0.19937195112348857
  - 0.177469363897056
  - 0.1864359342073757
  - 0.18124076213352297
  train_level6__average_precision_weighted:
  - 0.42561689119933666
  - 0.44790813375847427
  - 0.45017399312803763
  - 0.4176237466873738
  - 0.44589992114454513
  train_level6__average_precision_weighted_masked:
  - 0.35944216471773427
  - 0.3876875165695043
  - 0.3850189434752936
  - 0.3532498147789963
  - 0.38486764766232495
  train_level6__average_precision_weighted_oob:
  - 0.4212366882603448
  - 0.44317318757614926
  - 0.44507162037622994
  - 0.41371229201740556
  - 0.439509853886892
  train_level6__f1_macro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856722994
  train_level6__f1_macro_masked:
  - 0.23478275181136093
  - 0.26499095662529265
  - 0.25174239193583836
  - 0.2371159436603248
  - 0.2334528273899615
  train_level6__f1_macro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148143
  - 0.24911094783247612
  train_level6__f1_micro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__f1_micro_masked:
  - 0.22940852987901747
  - 0.26058434064265323
  - 0.24666910020076657
  - 0.2313451229280917
  - 0.22784075284915517
  train_level6__f1_micro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.2558814814814815
  - 0.24911094783247612
  train_level6__f1_samples:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__f1_samples_masked:
  - 0.22770447087972562
  - 0.2590203336854336
  - 0.24507211817475488
  - 0.2299278478365435
  - 0.22614688987136053
  train_level6__f1_samples_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148154
  - 0.24911094783247614
  train_level6__f1_weighted:
  - 0.41815972418470587
  - 0.423386579663164
  - 0.4257087314818429
  - 0.4281427729227355
  - 0.4215041392506059
  train_level6__f1_weighted_masked:
  - 0.37265276956703
  - 0.37843567090729113
  - 0.3814893883628081
  - 0.38321557294222164
  - 0.37643607866891504
  train_level6__f1_weighted_oob:
  - 0.4118998418831755
  - 0.4166712508479316
  - 0.41831110077624584
  - 0.42346875433485925
  - 0.4113798348141608
  train_level6__fn_macro:
  - -0.002263041880969875
  - -0.0030094959824689556
  - -0.002779809802487198
  - -0.0028444444444444446
  - -0.0021160911094783245
  train_level6__fn_macro_masked:
  - -0.0020499783101617618
  - -0.0025640262389401884
  - -0.0025696838419832398
  - -0.0024526909727656475
  - -0.0019071905029049885
  train_level6__fn_macro_oob:
  - -0.002556943423952976
  - -0.003214024835646457
  - -0.0029261155815654715
  - -0.002874074074074074
  - -0.002263041880969875
  train_level6__fn_micro:
  - -0.002263041880969875
  - -0.0030094959824689556
  - -0.002779809802487198
  - -0.0028444444444444446
  - -0.002116091109478325
  train_level6__fn_micro_masked:
  - -0.001924721984602224
  - -0.00252080422766203
  - -0.0024335340998965747
  - -0.0023722965062542363
  - -0.001802682636194201
  train_level6__fn_micro_oob:
  - -0.002556943423952976
  - -0.003214024835646457
  - -0.002926115581565472
  - -0.002874074074074074
  - -0.002263041880969875
  train_level6__fn_samples:
  - -0.002263041880969875
  - -0.0030094959824689548
  - -0.0027798098024871985
  - -0.002844444444444444
  - -0.002116091109478325
  train_level6__fn_samples_masked:
  - -0.001908784865370496
  - -0.0025106492791569174
  - -0.00241470349673015
  - -0.0023534767969550577
  - -0.0017766425717740289
  train_level6__fn_samples_oob:
  - -0.002556943423952976
  - -0.0032140248356464576
  - -0.002926115581565472
  - -0.002874074074074074
  - -0.0022630418809698755
  train_level6__fn_weighted:
  - -0.005438625996501303
  - -0.004516454599318998
  - -0.006160799632172747
  - -0.004731932306838675
  - -0.0046663044350730735
  train_level6__fn_weighted_masked:
  - -0.005265258565965495
  - -0.003678351359512108
  - -0.006055539985499066
  - -0.004494884447884177
  - -0.004569207249214818
  train_level6__fn_weighted_oob:
  - -0.005478430907634685
  - -0.004607229903871848
  - -0.006024415778452612
  - -0.004582813150228881
  - -0.004829583070063685
  train_level6__fp_macro:
  - -0.7394562821454812
  - -0.7089262235208181
  - -0.7223116313094369
  - -0.736948148148148
  - -0.7410139603232916
  train_level6__fp_macro_masked:
  - -0.7631672698784773
  - -0.7324450171357672
  - -0.7456879242221784
  - -0.7604313653669095
  - -0.7646399821071336
  train_level6__fp_macro_oob:
  - -0.743041880969875
  - -0.7144485025566106
  - -0.7271104608632042
  - -0.7412444444444445
  - -0.7486260102865541
  train_level6__fp_micro:
  - -0.7394562821454813
  - -0.7089262235208181
  - -0.7223116313094368
  - -0.7369481481481481
  - -0.7410139603232917
  train_level6__fp_micro_masked:
  - -0.7686667481363803
  - -0.7368948551296848
  - -0.7508973656993368
  - -0.7662825805656541
  - -0.7703565645146506
  train_level6__fp_micro_oob:
  - -0.7430418809698751
  - -0.7144485025566106
  - -0.7271104608632041
  - -0.7412444444444445
  - -0.748626010286554
  train_level6__fp_samples:
  - -0.7394562821454812
  - -0.7089262235208181
  - -0.7223116313094367
  - -0.736948148148148
  - -0.7410139603232917
  train_level6__fp_samples_masked:
  - -0.7703867442549038
  - -0.7384690170354095
  - -0.7525131783285148
  - -0.7677186753665014
  - -0.7720764675568654
  train_level6__fp_samples_oob:
  - -0.7430418809698751
  - -0.7144485025566106
  - -0.7271104608632041
  - -0.7412444444444444
  - -0.748626010286554
  train_level6__fp_weighted:
  - -0.5764016498187928
  - -0.572096965737517
  - -0.5681304688859842
  - -0.567125294770426
  - -0.5738295563143211
  train_level6__fp_weighted_masked:
  - -0.6220819718670046
  - -0.6178859777331966
  - -0.6124550716516928
  - -0.6122895426098942
  - -0.6189947140818701
  train_level6__fp_weighted_oob:
  - -0.5826217272091898
  - -0.5787215192481965
  - -0.5756644834453016
  - -0.5719484325149118
  - -0.5837905821157756
  train_level6__jaccard_macro:
  - 0.17017403571201536
  - 0.20216451116693876
  - 0.18439274354790677
  - 0.170132714058244
  - 0.168893258395878
  train_level6__jaccard_macro_masked:
  - 0.15270732600857
  - 0.18512245338456393
  - 0.16714169976870188
  - 0.15272022642275038
  - 0.15137605142109828
  train_level6__jaccard_macro_oob:
  - 0.1697523424898397
  - 0.19956332579550812
  - 0.1822142892965869
  - 0.16916628658287397
  - 0.16437478090589466
  train_level6__jaccard_micro:
  - 0.14829064155782795
  - 0.16826816405249953
  - 0.15935883300822662
  - 0.14956231479273818
  - 0.1473613218681504
  train_level6__jaccard_micro_masked:
  - 0.12956604261927357
  - 0.14981142617684035
  - 0.1406859938583251
  - 0.13080286376225897
  - 0.12856674884915778
  train_level6__jaccard_micro_oob:
  - 0.14573862679731958
  - 0.1643730756799973
  - 0.15604492253568772
  - 0.1467110627888013
  - 0.14227683217510995
  train_level6__jaccard_samples:
  - 0.1629939166023103
  - 0.182803630579423
  - 0.17234644561197623
  - 0.16205297332024973
  - 0.16145564167494675
  train_level6__jaccard_samples_masked:
  - 0.14420344655039563
  - 0.16426088192594282
  - 0.15353225675575152
  - 0.14319463755220987
  - 0.142557998704331
  train_level6__jaccard_samples_oob:
  - 0.15952114788105956
  - 0.1780169028631873
  - 0.16788131023909403
  - 0.15828767731514767
  - 0.15540065855730767
  train_level6__jaccard_weighted:
  - 0.28795703382602283
  - 0.2943308035164377
  - 0.2962415924451227
  - 0.2974354100102222
  - 0.29164703541245557
  train_level6__jaccard_weighted_masked:
  - 0.24819619902893053
  - 0.2552129279831649
  - 0.25725445093002397
  - 0.25766388106327953
  - 0.2518817892651641
  train_level6__jaccard_weighted_oob:
  - 0.2836205232862322
  - 0.28927992831772953
  - 0.2906732774482805
  - 0.2944698544709539
  - 0.28379373178826034
  train_level6__label_ranking_average_precision_score:
  - 0.18291295697579588
  - 0.20414859379733258
  - 0.18248982700274052
  - 0.1916533222929623
  - 0.18326057728805625
  train_level6__label_ranking_average_precision_score_oob:
  - 0.18214889674378743
  - 0.20302425207308678
  - 0.18112700837401283
  - 0.19088037865181987
  - 0.18271026984843836
  train_level6__matthews_corrcoef_macro:
  - 0.12382162794630737
  - 0.13225338403715703
  - 0.12776248787614894
  - 0.11504890301938107
  - 0.12530749041218595
  train_level6__matthews_corrcoef_macro_masked:
  - 0.1067625349905844
  - 0.11025329467671119
  - 0.10910300592115128
  - 0.09913989204175029
  - 0.10877317228777422
  train_level6__matthews_corrcoef_macro_oob:
  - 0.12230133309909358
  - 0.12987961405203655
  - 0.1234025818142545
  - 0.11316996889536302
  - 0.1199644376488976
  train_level6__matthews_corrcoef_micro:
  - 0.1312746085764968
  - 0.14628435248021887
  - 0.1390489343732556
  - 0.12845679218393513
  - 0.1314061121747696
  train_level6__matthews_corrcoef_micro_masked:
  - 0.10962867300655658
  - 0.12236531776658216
  - 0.11529790706393513
  - 0.10717402919858973
  - 0.10993828498182541
  train_level6__matthews_corrcoef_micro_oob:
  - 0.12636244079811768
  - 0.1410576823157836
  - 0.13462866278062383
  - 0.12513487867005987
  - 0.12479663856675131
  train_level6__matthews_corrcoef_samples:
  - 0.1066806605345003
  - 0.12861417060846847
  - 0.11334597899789021
  - 0.09794895007731805
  - 0.10823886247643881
  train_level6__matthews_corrcoef_samples_masked:
  - 0.08251980176842577
  - 0.10110998029343608
  - 0.08830371635779095
  - 0.0768356642501693
  - 0.08329205164711698
  train_level6__matthews_corrcoef_samples_oob:
  - 0.10455688407737666
  - 0.12360557841385944
  - 0.10970095064850488
  - 0.09769930008330915
  - 0.10194574859456666
  train_level6__matthews_corrcoef_weighted:
  - 0.21713924915343916
  - 0.22133062135616832
  - 0.22739819677767933
  - 0.21921087697717873
  - 0.22555750264553448
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.19321948650888102
  - 0.19941829185768298
  - 0.20240404636626852
  - 0.19572823914130089
  - 0.20101404645656595
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.2087892940455187
  - 0.2128837077690136
  - 0.21911125947653007
  - 0.21416178449771867
  - 0.21310761968852926
  train_level6__ndcg:
  - 0.4096688047699906
  - 0.4330913542467091
  - 0.4144432293570902
  - 0.42627509147149506
  - 0.4160127613438862
  train_level6__ndcg_oob:
  - 0.4096670338227412
  - 0.4322657805956727
  - 0.4148511140403954
  - 0.4270694170337373
  - 0.4166111738171023
  train_level6__neg_coverage_error:
  - -15.941954445260837
  - -14.843681519357196
  - -15.896122896854425
  - -15.557037037037038
  - -15.928728875826598
  train_level6__neg_coverage_error_oob:
  - -16.033063923585598
  - -14.965668371073777
  - -15.992684711046087
  - -15.658518518518518
  - -15.986774430565761
  train_level6__neg_hamming_loss_macro:
  - -0.741719324026451
  - -0.7119357195032872
  - -0.7250914411119238
  - -0.7397925925925926
  - -0.74313005143277
  train_level6__neg_hamming_loss_macro_masked:
  - -0.765217248188639
  - -0.7350090433747073
  - -0.7482576080641617
  - -0.7628840563396752
  - -0.7665471726100386
  train_level6__neg_hamming_loss_macro_oob:
  - -0.7455988243938281
  - -0.7176625273922571
  - -0.7300365764447696
  - -0.7441185185185185
  - -0.7508890521675238
  train_level6__neg_hamming_loss_micro:
  - -0.7417193240264511
  - -0.711935719503287
  - -0.7250914411119239
  - -0.7397925925925926
  - -0.74313005143277
  train_level6__neg_hamming_loss_micro_masked:
  - -0.7705914701209825
  - -0.7394156593573468
  - -0.7533308997992334
  - -0.7686548770719083
  - -0.7721592471508448
  train_level6__neg_hamming_loss_micro_oob:
  - -0.7455988243938281
  - -0.7176625273922571
  - -0.7300365764447696
  - -0.7441185185185185
  - -0.7508890521675239
  train_level6__neg_hamming_loss_samples:
  - -0.741719324026451
  - -0.7119357195032869
  - -0.7250914411119239
  - -0.7397925925925926
  - -0.7431300514327699
  train_level6__neg_hamming_loss_samples_masked:
  - -0.7722955291202744
  - -0.7409796663145665
  - -0.7549278818252452
  - -0.7700721521634565
  - -0.7738531101286396
  train_level6__neg_hamming_loss_samples_oob:
  - -0.7455988243938281
  - -0.717662527392257
  - -0.7300365764447695
  - -0.7441185185185185
  - -0.7508890521675238
  train_level6__neg_hamming_loss_weighted:
  - -0.5818402758152942
  - -0.576613420336836
  - -0.574291268518157
  - -0.5718572270772645
  - -0.5784958607493941
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.6273472304329699
  - -0.6215643290927088
  - -0.6185106116371919
  - -0.6167844270577784
  - -0.623563921331085
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.5881001581168245
  - -0.5833287491520684
  - -0.5816888992237542
  - -0.5765312456651409
  - -0.5886201651858392
  train_level6__neg_label_ranking_loss:
  - -0.45568559003358816
  - -0.4070925500472783
  - -0.4650269286396972
  - -0.4381085979621927
  - -0.47084763433332827
  train_level6__neg_label_ranking_loss_oob:
  - -0.4579637958048453
  - -0.41139333457416716
  - -0.46915057580693736
  - -0.4416905101110782
  - -0.47283182140737706
  train_level6__precision_macro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856722994
  train_level6__precision_macro_masked:
  - 0.23478275181136093
  - 0.26499095662529265
  - 0.25174239193583836
  - 0.2371159436603248
  - 0.2334528273899615
  train_level6__precision_macro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148143
  - 0.24911094783247612
  train_level6__precision_micro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__precision_micro_masked:
  - 0.22940852987901747
  - 0.26058434064265323
  - 0.24666910020076657
  - 0.2313451229280917
  - 0.22784075284915517
  train_level6__precision_micro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.2558814814814815
  - 0.24911094783247612
  train_level6__precision_samples:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__precision_samples_masked:
  - 0.22770447087972562
  - 0.2590203336854336
  - 0.24507211817475488
  - 0.2299278478365435
  - 0.22614688987136053
  train_level6__precision_samples_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148154
  - 0.24911094783247614
  train_level6__precision_weighted:
  - 0.41815972418470587
  - 0.423386579663164
  - 0.4257087314818429
  - 0.4281427729227355
  - 0.4215041392506059
  train_level6__precision_weighted_masked:
  - 0.37265276956703
  - 0.37843567090729113
  - 0.3814893883628081
  - 0.38321557294222164
  - 0.37643607866891504
  train_level6__precision_weighted_oob:
  - 0.4118998418831755
  - 0.4166712508479316
  - 0.41831110077624584
  - 0.42346875433485925
  - 0.4113798348141608
  train_level6__recall_macro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856722994
  train_level6__recall_macro_masked:
  - 0.23478275181136093
  - 0.26499095662529265
  - 0.25174239193583836
  - 0.2371159436603248
  - 0.2334528273899615
  train_level6__recall_macro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148143
  - 0.24911094783247612
  train_level6__recall_micro:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__recall_micro_masked:
  - 0.22940852987901747
  - 0.26058434064265323
  - 0.24666910020076657
  - 0.2313451229280917
  - 0.22784075284915517
  train_level6__recall_micro_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.2558814814814815
  - 0.24911094783247612
  train_level6__recall_samples:
  - 0.25828067597354887
  - 0.28806428049671295
  - 0.2749085588880761
  - 0.2602074074074074
  - 0.25686994856723
  train_level6__recall_samples_masked:
  - 0.22770447087972562
  - 0.2590203336854336
  - 0.24507211817475488
  - 0.2299278478365435
  - 0.22614688987136053
  train_level6__recall_samples_oob:
  - 0.2544011756061719
  - 0.2823374726077429
  - 0.26996342355523045
  - 0.25588148148148154
  - 0.24911094783247614
  train_level6__recall_weighted:
  - 0.41815972418470587
  - 0.423386579663164
  - 0.4257087314818429
  - 0.4281427729227355
  - 0.4215041392506059
  train_level6__recall_weighted_masked:
  - 0.37265276956703
  - 0.37843567090729113
  - 0.3814893883628081
  - 0.38321557294222164
  - 0.37643607866891504
  train_level6__recall_weighted_oob:
  - 0.4118998418831755
  - 0.4166712508479316
  - 0.41831110077624584
  - 0.42346875433485925
  - 0.4113798348141608
  train_level6__roc_auc_macro:
  - 0.6241538000057095
  - 0.6528276041259738
  - 0.6509014401463382
  - 0.6292466904805828
  - 0.6290038537760992
  train_level6__roc_auc_macro_masked:
  - 0.6173089174612049
  - 0.6394424366625555
  - 0.6444505559615388
  - 0.6194450176204813
  - 0.625003989533844
  train_level6__roc_auc_macro_oob:
  - 0.6186184982007122
  - 0.6470977176755422
  - 0.6463018237235728
  - 0.6251262481923523
  - 0.6267378437647844
  train_level6__roc_auc_micro:
  - 0.5599438007155567
  - 0.6041976049254809
  - 0.5451293046076617
  - 0.5781774497670198
  - 0.5444053589515785
  train_level6__roc_auc_micro_masked:
  - 0.5572395945434521
  - 0.6013427307129233
  - 0.5402637802625
  - 0.5747804471176547
  - 0.5415656101423953
  train_level6__roc_auc_micro_oob:
  - 0.557874185829283
  - 0.6014216510260358
  - 0.542974452665743
  - 0.5759666980428241
  - 0.5433259497941942
  train_level6__roc_auc_samples:
  - 0.5449361036617414
  - 0.5935820727035028
  - 0.5364793100304244
  - 0.5655085341722703
  - 0.5317522470592015
  train_level6__roc_auc_samples_masked:
  - 0.5351732691601448
  - 0.5821340625233732
  - 0.5227472564074831
  - 0.557968324628194
  - 0.5210627353798646
  train_level6__roc_auc_samples_oob:
  - 0.5431404717300394
  - 0.5894267716542524
  - 0.5335235815288804
  - 0.5632919714610238
  - 0.5307796448415939
  train_level6__roc_auc_weighted:
  - 0.6744413982911485
  - 0.6957742063482063
  - 0.7002289823631016
  - 0.6634244649308999
  - 0.6846005473034718
  train_level6__roc_auc_weighted_masked:
  - 0.6689465945212547
  - 0.6903635320339163
  - 0.6938164483264884
  - 0.6575580011108154
  - 0.6802726509484939
  train_level6__roc_auc_weighted_oob:
  - 0.6677612248354188
  - 0.6907643600891976
  - 0.6946934869612853
  - 0.6601761765446071
  - 0.6793942975441971
  train_level6__tn_macro:
  - 0.13522409992652462
  - 0.16575602629656683
  - 0.15212874908558888
  - 0.13647407407407408
  - 0.13307861866274798
  train_level6__tn_macro_masked:
  - 0.14054666895240983
  - 0.17131175186260061
  - 0.15791636537939266
  - 0.14215991935934713
  - 0.13857179444637718
  train_level6__tn_macro_oob:
  - 0.13163850110213077
  - 0.16023374726077427
  - 0.1473299195318215
  - 0.13217777777777778
  - 0.12546656869948566
  train_level6__tn_micro:
  - 0.13522409992652462
  - 0.16575602629656683
  - 0.15212874908558888
  - 0.13647407407407408
  - 0.13307861866274798
  train_level6__tn_micro_masked:
  - 0.14056580716118783
  - 0.1722954504039361
  - 0.15814929731702865
  - 0.1419064637377534
  - 0.13834825384215832
  train_level6__tn_micro_oob:
  - 0.1316385011021308
  - 0.1602337472607743
  - 0.1473299195318215
  - 0.13217777777777778
  - 0.12546656869948566
  train_level6__tn_samples:
  - 0.13522409992652462
  - 0.16575602629656686
  - 0.15212874908558888
  - 0.13647407407407408
  - 0.13307861866274798
  train_level6__tn_samples_masked:
  - 0.13923979804710085
  - 0.17091605110994065
  - 0.15674895093138788
  - 0.14069902614830151
  - 0.1369829442948969
  train_level6__tn_samples_oob:
  - 0.1316385011021308
  - 0.1602337472607743
  - 0.14732991953182153
  - 0.13217777777777778
  - 0.12546656869948566
  train_level6__tn_weighted:
  - 0.12782821647806145
  - 0.1345460323613109
  - 0.1384531377407026
  - 0.13552590511860174
  - 0.1314504493935708
  train_level6__tn_weighted_masked:
  - 0.14014203979897055
  - 0.1466362674324835
  - 0.15193393284821222
  - 0.14853473024300656
  - 0.14417347279567802
  train_level6__tn_weighted_oob:
  - 0.12160813908766456
  - 0.12792147885063138
  - 0.13091912318138524
  - 0.1307027673741157
  - 0.12148942359211626
  train_level6__tp_macro:
  - 0.12305657604702425
  - 0.12230825420014609
  - 0.12277980980248719
  - 0.12373333333333333
  - 0.123791329904482
  train_level6__tp_macro_masked:
  - 0.09423608285895113
  - 0.09367920476269205
  - 0.09382602655644565
  - 0.09495602430097766
  - 0.09488103294358434
  train_level6__tp_macro_oob:
  - 0.12276267450404114
  - 0.12210372534696859
  - 0.12263350402340892
  - 0.1237037037037037
  - 0.12364437913299044
  train_level6__tp_micro:
  - 0.12305657604702425
  - 0.12230825420014609
  - 0.12277980980248719
  - 0.12373333333333333
  - 0.123791329904482
  train_level6__tp_micro_masked:
  - 0.08884272271782964
  - 0.08828889023871712
  - 0.08851980288373791
  - 0.08943865919033828
  - 0.08949249900699685
  train_level6__tp_micro_oob:
  - 0.12276267450404114
  - 0.12210372534696859
  - 0.12263350402340892
  - 0.1237037037037037
  - 0.12364437913299045
  train_level6__tp_samples:
  - 0.12305657604702426
  - 0.12230825420014609
  - 0.12277980980248722
  - 0.12373333333333335
  - 0.12379132990448201
  train_level6__tp_samples_masked:
  - 0.0884646728326248
  - 0.08810428257549291
  - 0.08832316724336699
  - 0.08922882168824196
  - 0.08916394557646364
  train_level6__tp_samples_oob:
  - 0.12276267450404116
  - 0.1221037253469686
  - 0.12263350402340893
  - 0.1237037037037037
  - 0.12364437913299045
  train_level6__tp_weighted:
  - 0.29033150770664434
  - 0.2888405473018531
  - 0.28725559374114046
  - 0.2926168678041337
  - 0.29005368985703517
  train_level6__tp_weighted_masked:
  - 0.23251072976805942
  - 0.23179940347480768
  - 0.229555455514596
  - 0.23468084269921508
  - 0.23226260587323702
  train_level6__tp_weighted_oob:
  - 0.2902917027955109
  - 0.28874977199730023
  - 0.28739197759486057
  - 0.29276598696074346
  - 0.2898904112220445
  train_level7__average_precision_macro:
  - 0.2118371708014797
  - 0.22665572391072317
  - 0.22024451550396784
  - 0.21776572789223372
  - 0.2192913458498108
  train_level7__average_precision_macro_masked:
  - 0.1726867786351294
  - 0.1843560835818468
  - 0.18078992974925742
  - 0.17960077701741317
  - 0.18418395686871808
  train_level7__average_precision_macro_oob:
  - 0.21029886590874178
  - 0.22407715277758766
  - 0.21717196180282172
  - 0.214965535896229
  - 0.2169564381049469
  train_level7__average_precision_micro:
  - 0.1262937991733105
  - 0.13997246299699462
  - 0.12258191043368227
  - 0.13316978077997232
  - 0.1226858196507136
  train_level7__average_precision_micro_masked:
  - 0.09142978219774418
  - 0.1016230945444151
  - 0.08829931472201663
  - 0.09654747153528251
  - 0.08862558293944872
  train_level7__average_precision_micro_oob:
  - 0.12584493307776784
  - 0.13932321380756166
  - 0.12221821559048233
  - 0.1328595504075224
  - 0.12240261356248885
  train_level7__average_precision_samples:
  - 0.17903568104028442
  - 0.20011530863030158
  - 0.1785443836529493
  - 0.18732879035874245
  - 0.181329690334665
  train_level7__average_precision_samples_masked:
  - 0.14180868379103637
  - 0.1599238116532532
  - 0.1403382845482025
  - 0.14951808772937
  - 0.14354955707560926
  train_level7__average_precision_samples_oob:
  - 0.17849151270904384
  - 0.19888363883425433
  - 0.17767149990677625
  - 0.1864376183072116
  - 0.18045570667046462
  train_level7__average_precision_weighted:
  - 0.42994141526793395
  - 0.45141659043262244
  - 0.44963452299817247
  - 0.4264264166905135
  - 0.45389938340821817
  train_level7__average_precision_weighted_masked:
  - 0.3641466573684884
  - 0.3901802666879279
  - 0.3835661498651571
  - 0.3618930828911439
  - 0.3933622360014311
  train_level7__average_precision_weighted_oob:
  - 0.4284117278011564
  - 0.44542227068205714
  - 0.4425153326189352
  - 0.4227837464949617
  - 0.44782865880719486
  train_level7__f1_macro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.26020740740740744
  - 0.258486407053637
  train_level7__f1_macro_masked:
  - 0.2351783049408607
  - 0.2642335735115897
  - 0.2521174406094988
  - 0.23708368936471666
  - 0.23508223955783905
  train_level7__f1_macro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__f1_micro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__f1_micro_masked:
  - 0.229805694732983
  - 0.2598250622608273
  - 0.24703413031575105
  - 0.2313451229280917
  - 0.229521219713404
  train_level7__f1_micro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__f1_samples:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.27528895391367963
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__f1_samples_masked:
  - 0.22812805585622886
  - 0.2582454945674687
  - 0.24542780602877287
  - 0.22992724344898255
  - 0.22782221855719942
  train_level7__f1_samples_oob:
  - 0.2551065393093314
  - 0.28292184075967863
  - 0.2711631309436723
  - 0.25561481481481485
  - 0.2496105804555474
  train_level7__f1_weighted:
  - 0.41849057019932095
  - 0.42260025774736565
  - 0.4262946706133881
  - 0.4274424330697739
  - 0.4217399671110178
  train_level7__f1_weighted_masked:
  - 0.3730036616331412
  - 0.3777212202989697
  - 0.38212224590366733
  - 0.3823681671717407
  - 0.37678287321407194
  train_level7__f1_weighted_oob:
  - 0.41115440445649576
  - 0.4171789453748961
  - 0.42004760819373743
  - 0.4227581842141767
  - 0.41089548726666764
  train_level7__fn_macro:
  - -0.002263041880969875
  - -0.0030679327976625274
  - -0.0027505486466715434
  - -0.0029629629629629632
  - -0.002086700955180015
  train_level7__fn_macro_masked:
  - -0.002045048949106393
  - -0.002534087556426362
  - -0.0025782547008623884
  - -0.00257948390969312
  - -0.001872690351477188
  train_level7__fn_macro_oob:
  - -0.0025569434239529755
  - -0.0033016800584368157
  - -0.0029261155815654715
  - -0.0027555555555555554
  - -0.0021748714180749446
  train_level7__fn_micro:
  - -0.002263041880969875
  - -0.0030679327976625274
  - -0.0027505486466715434
  - -0.002962962962962963
  - -0.002086700955180015
  train_level7__fn_micro_masked:
  - -0.001924721984602224
  - -0.0024904330923889934
  - -0.0024335340998965747
  - -0.0024955326883973135
  - -0.0017721286932078585
  train_level7__fn_micro_oob:
  - -0.002556943423952976
  - -0.0033016800584368153
  - -0.002926115581565472
  - -0.0027555555555555554
  - -0.002174871418074945
  train_level7__fn_samples:
  - -0.002263041880969875
  - -0.003067932797662527
  - -0.002750548646671544
  - -0.002962962962962963
  - -0.002086700955180015
  train_level7__fn_samples_masked:
  - -0.0019100094551329258
  - -0.0024788901404647584
  - -0.002414597478049658
  - -0.0024783828624408335
  - -0.0017472524174757184
  train_level7__fn_samples_oob:
  - -0.002556943423952976
  - -0.0033016800584368157
  - -0.002926115581565472
  - -0.0027555555555555554
  - -0.002174871418074945
  train_level7__fn_weighted:
  - -0.005323002207018622
  - -0.00463022177275484
  - -0.006330427050237164
  - -0.004910355111665973
  - -0.004647095183897708
  train_level7__fn_weighted_masked:
  - -0.0051342132667559215
  - -0.0036588695880795156
  - -0.006283171662145134
  - -0.004711787889858512
  - -0.004434206450532317
  train_level7__fn_weighted_oob:
  - -0.005595605537810875
  - -0.004554433760510903
  - -0.0062397317875132734
  - -0.004454154529060896
  - -0.004763379757977157
  train_level7__fp_macro:
  - -0.7390742101396032
  - -0.7096859021183346
  - -0.721960497439649
  - -0.7368296296296297
  - -0.7394268919911829
  train_level7__fp_macro_masked:
  - -0.762776646110033
  - -0.7332323389319839
  - -0.7453043046896388
  - -0.7603368267255902
  - -0.7630450700906838
  train_level7__fp_macro_oob:
  - -0.7423365172667157
  - -0.7137764791818846
  - -0.7259107534747623
  - -0.7416296296296296
  - -0.7482145481263777
  train_level7__fp_micro:
  - -0.7390742101396033
  - -0.7096859021183346
  - -0.7219604974396489
  - -0.7368296296296296
  - -0.7394268919911829
  train_level7__fp_micro_masked:
  - -0.7682695832824148
  - -0.7376845046467837
  - -0.7505323355843524
  - -0.766159344383511
  - -0.7687066515933881
  train_level7__fp_micro_oob:
  - -0.7423365172667157
  - -0.7137764791818846
  - -0.7259107534747623
  - -0.7416296296296296
  - -0.7482145481263777
  train_level7__fp_samples:
  - -0.7390742101396033
  - -0.7096859021183345
  - -0.7219604974396489
  - -0.7368296296296296
  - -0.7394268919911828
  train_level7__fp_samples_masked:
  - -0.7699619346886383
  - -0.7392756152920665
  - -0.7521575964931775
  - -0.7675943736885766
  - -0.7704305290253248
  train_level7__fp_samples_oob:
  - -0.7423365172667156
  - -0.7137764791818846
  - -0.7259107534747622
  - -0.7416296296296295
  - -0.7482145481263777
  train_level7__fp_weighted:
  - -0.5761864275936605
  - -0.5727695204798795
  - -0.5673749023363749
  - -0.5676472118185603
  - -0.5736129377050845
  train_level7__fp_weighted_masked:
  - -0.6218621251001029
  - -0.6186199101129508
  - -0.6115945824341876
  - -0.6129200449384008
  - -0.6187829203353957
  train_level7__fp_weighted_oob:
  - -0.5832499900056932
  - -0.5782666208645931
  - -0.5737126600187494
  - -0.5727876612567623
  - -0.5843411329753553
  train_level7__jaccard_macro:
  - 0.1703817546965386
  - 0.20157191059203813
  - 0.1843180771711032
  - 0.17019498102853486
  - 0.17010517920557203
  train_level7__jaccard_macro_masked:
  - 0.15291790978542585
  - 0.1846194400812558
  - 0.16701065322601086
  - 0.15275924028553245
  - 0.15261149005979488
  train_level7__jaccard_macro_oob:
  - 0.17004318302347549
  - 0.1999158768591248
  - 0.1828381618953491
  - 0.1689060380838003
  - 0.1645065180842994
  train_level7__jaccard_micro:
  - 0.14854259143614237
  - 0.16771012811545744
  - 0.1596145363238438
  - 0.14956231479273818
  - 0.14842629313981942
  train_level7__jaccard_micro_masked:
  - 0.12981947464706087
  - 0.14930973698448435
  - 0.14092352543078765
  - 0.13080286376225897
  - 0.1296379387705795
  train_level7__jaccard_micro_oob:
  - 0.1462017854135085
  - 0.16476934333894874
  - 0.1568471472335528
  - 0.1465357634229613
  - 0.14260288463152945
  train_level7__jaccard_samples:
  - 0.16337387483773277
  - 0.18226374973189954
  - 0.17279948202706202
  - 0.16199076831113926
  - 0.16228634502852632
  train_level7__jaccard_samples_masked:
  - 0.14458486395307352
  - 0.16381168384021144
  - 0.15397223830367518
  - 0.14316665226703507
  - 0.14336712480279198
  train_level7__jaccard_samples_oob:
  - 0.16009148030399073
  - 0.1786440886221463
  - 0.16893589049001675
  - 0.15818010955685308
  - 0.1555648684814735
  train_level7__jaccard_weighted:
  - 0.28821522861559196
  - 0.2936849173826483
  - 0.29655368400348014
  - 0.29673893424043984
  - 0.29190617128140556
  train_level7__jaccard_weighted_masked:
  - 0.24846766504166684
  - 0.25467843697599546
  - 0.2575476670000141
  - 0.2568840545739452
  - 0.2522717802294624
  train_level7__jaccard_weighted_oob:
  - 0.2827170298353628
  - 0.2897155049371054
  - 0.29203073661643075
  - 0.2937192883144476
  - 0.2831186188589546
  train_level7__label_ranking_average_precision_score:
  - 0.18344420418503057
  - 0.20376760957989964
  - 0.18220202812990596
  - 0.19177323480318667
  - 0.18279919804958034
  train_level7__label_ranking_average_precision_score_oob:
  - 0.18290003585379014
  - 0.20253593978385243
  - 0.181329144383733
  - 0.1908820627516558
  - 0.18192521438537995
  train_level7__matthews_corrcoef_macro:
  - 0.12345456593825166
  - 0.13108525462478907
  - 0.12789813932806118
  - 0.11357824249556067
  - 0.1266301497677347
  train_level7__matthews_corrcoef_macro_masked:
  - 0.10628395975122283
  - 0.11015985768367591
  - 0.10899342213103015
  - 0.09767523393994763
  - 0.10961575988021487
  train_level7__matthews_corrcoef_macro_oob:
  - 0.1222179307605338
  - 0.12730770075114178
  - 0.12421365500913664
  - 0.11351273121372554
  - 0.12028913744703568
  train_level7__matthews_corrcoef_micro:
  - 0.13154110773959657
  - 0.1453455416886089
  - 0.13951183260032615
  - 0.12759710181451747
  - 0.13275189025759032
  train_level7__matthews_corrcoef_micro_masked:
  - 0.10986014535819306
  - 0.12218763491015086
  - 0.11550633512204884
  - 0.1061071533096811
  - 0.11118729591655428
  train_level7__matthews_corrcoef_micro_oob:
  - 0.12686457006266363
  - 0.1408564802057439
  - 0.1354572594238203
  - 0.1258150381755328
  - 0.12582469476679728
  train_level7__matthews_corrcoef_samples:
  - 0.10688929604271176
  - 0.1274306290133207
  - 0.1137991635446859
  - 0.09814758079223625
  - 0.11074109378046056
  train_level7__matthews_corrcoef_samples_masked:
  - 0.08269748019939495
  - 0.10059518549109507
  - 0.08839019258781546
  - 0.07675206118091431
  - 0.08534712163287253
  train_level7__matthews_corrcoef_samples_oob:
  - 0.1053309107753209
  - 0.12304520951323003
  - 0.11050268194556365
  - 0.09857224141876042
  - 0.10356795352962948
  train_level7__matthews_corrcoef_weighted:
  - 0.2175028759946847
  - 0.2193499955211119
  - 0.22778817378137156
  - 0.21681516740726703
  - 0.22587496511005803
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.19367645360834596
  - 0.19852654481238513
  - 0.20242078012061712
  - 0.1932682300722794
  - 0.2014731793178157
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.20679471569752902
  - 0.21289890724223193
  - 0.22061691541820086
  - 0.21327467550853738
  - 0.2121881369917268
  train_level7__ndcg:
  - 0.41015649156595
  - 0.43425923562298724
  - 0.4150079411741606
  - 0.42550684345448525
  - 0.4148196212405782
  train_level7__ndcg_oob:
  - 0.41008371305960234
  - 0.4336727218207032
  - 0.4152510694554048
  - 0.42604180581082096
  - 0.4152831221377236
  train_level7__neg_coverage_error:
  - -15.906686260102866
  - -14.888970051132214
  - -15.948061448427213
  - -15.604444444444445
  - -15.952975753122704
  train_level7__neg_coverage_error_oob:
  - -16.017634092578987
  - -14.993425858290722
  - -16.024871982443308
  - -15.670370370370371
  - -16.01028655400441
  train_level7__neg_hamming_loss_macro:
  - -0.7413372520205731
  - -0.7127538349159971
  - -0.7247110460863204
  - -0.7397925925925927
  - -0.741513592946363
  train_level7__neg_hamming_loss_macro_masked:
  - -0.7648216950591391
  - -0.7357664264884103
  - -0.7478825593905012
  - -0.7629163106352834
  - -0.764917760442161
  train_level7__neg_hamming_loss_macro_oob:
  - -0.7448934606906686
  - -0.7170781592403215
  - -0.7288368690563277
  - -0.7443851851851853
  - -0.7503894195444525
  train_level7__neg_hamming_loss_micro:
  - -0.7413372520205731
  - -0.7127538349159971
  - -0.7247110460863204
  - -0.7397925925925926
  - -0.741513592946363
  train_level7__neg_hamming_loss_micro_masked:
  - -0.7701943052670169
  - -0.7401749377391726
  - -0.752965869684249
  - -0.7686548770719083
  - -0.770478780286596
  train_level7__neg_hamming_loss_micro_oob:
  - -0.7448934606906686
  - -0.7170781592403214
  - -0.7288368690563277
  - -0.7443851851851851
  - -0.7503894195444526
  train_level7__neg_hamming_loss_samples:
  - -0.7413372520205731
  - -0.7127538349159971
  - -0.7247110460863204
  - -0.7397925925925927
  - -0.741513592946363
  train_level7__neg_hamming_loss_samples_masked:
  - -0.7718719441437712
  - -0.7417545054325312
  - -0.754572193971227
  - -0.7700727565510175
  - -0.7721777814428005
  train_level7__neg_hamming_loss_samples_oob:
  - -0.7448934606906686
  - -0.7170781592403214
  - -0.7288368690563277
  - -0.7443851851851851
  - -0.7503894195444526
  train_level7__neg_hamming_loss_weighted:
  - -0.5815094298006791
  - -0.5773997422526342
  - -0.5737053293866118
  - -0.5725575669302262
  - -0.5782600328889821
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.6269963383668588
  - -0.6222787797010303
  - -0.6178777540963327
  - -0.6176318328282593
  - -0.623217126785928
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.5888455955435041
  - -0.5828210546251039
  - -0.5799523918062627
  - -0.5772418157858232
  - -0.5891045127333323
  train_level7__neg_label_ranking_loss:
  - -0.4541668594353042
  - -0.4087847290409383
  - -0.46564795059049613
  - -0.4386220420821069
  - -0.4712982666429387
  train_level7__neg_label_ranking_loss_oob:
  - -0.45629549012933074
  - -0.4125302225816645
  - -0.4689724708497967
  - -0.44157024650560645
  - -0.47392151398150145
  train_level7__precision_macro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.26020740740740744
  - 0.258486407053637
  train_level7__precision_macro_masked:
  - 0.2351783049408607
  - 0.2642335735115897
  - 0.2521174406094988
  - 0.23708368936471666
  - 0.23508223955783905
  train_level7__precision_macro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__precision_micro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__precision_micro_masked:
  - 0.229805694732983
  - 0.2598250622608273
  - 0.24703413031575105
  - 0.2313451229280917
  - 0.229521219713404
  train_level7__precision_micro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__precision_samples:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.27528895391367963
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__precision_samples_masked:
  - 0.22812805585622886
  - 0.2582454945674687
  - 0.24542780602877287
  - 0.22992724344898255
  - 0.22782221855719942
  train_level7__precision_samples_oob:
  - 0.2551065393093314
  - 0.28292184075967863
  - 0.2711631309436723
  - 0.25561481481481485
  - 0.2496105804555474
  train_level7__precision_weighted:
  - 0.41849057019932095
  - 0.42260025774736565
  - 0.4262946706133881
  - 0.4274424330697739
  - 0.4217399671110178
  train_level7__precision_weighted_masked:
  - 0.3730036616331412
  - 0.3777212202989697
  - 0.38212224590366733
  - 0.3823681671717407
  - 0.37678287321407194
  train_level7__precision_weighted_oob:
  - 0.41115440445649576
  - 0.4171789453748961
  - 0.42004760819373743
  - 0.4227581842141767
  - 0.41089548726666764
  train_level7__recall_macro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.26020740740740744
  - 0.258486407053637
  train_level7__recall_macro_masked:
  - 0.2351783049408607
  - 0.2642335735115897
  - 0.2521174406094988
  - 0.23708368936471666
  - 0.23508223955783905
  train_level7__recall_macro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__recall_micro:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.2752889539136796
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__recall_micro_masked:
  - 0.229805694732983
  - 0.2598250622608273
  - 0.24703413031575105
  - 0.2313451229280917
  - 0.229521219713404
  train_level7__recall_micro_oob:
  - 0.25510653930933136
  - 0.2829218407596786
  - 0.2711631309436723
  - 0.2556148148148148
  - 0.2496105804555474
  train_level7__recall_samples:
  - 0.2586627479794269
  - 0.2872461650840029
  - 0.27528895391367963
  - 0.2602074074074074
  - 0.258486407053637
  train_level7__recall_samples_masked:
  - 0.22812805585622886
  - 0.2582454945674687
  - 0.24542780602877287
  - 0.22992724344898255
  - 0.22782221855719942
  train_level7__recall_samples_oob:
  - 0.2551065393093314
  - 0.28292184075967863
  - 0.2711631309436723
  - 0.25561481481481485
  - 0.2496105804555474
  train_level7__recall_weighted:
  - 0.41849057019932095
  - 0.42260025774736565
  - 0.4262946706133881
  - 0.4274424330697739
  - 0.4217399671110178
  train_level7__recall_weighted_masked:
  - 0.3730036616331412
  - 0.3777212202989697
  - 0.38212224590366733
  - 0.3823681671717407
  - 0.37678287321407194
  train_level7__recall_weighted_oob:
  - 0.41115440445649576
  - 0.4171789453748961
  - 0.42004760819373743
  - 0.4227581842141767
  - 0.41089548726666764
  train_level7__roc_auc_macro:
  - 0.6250287585506055
  - 0.6518150007378106
  - 0.6489479088185353
  - 0.63218445574603
  - 0.6318451601383838
  train_level7__roc_auc_macro_masked:
  - 0.6190993346100541
  - 0.6364989903416494
  - 0.6443473838101511
  - 0.6250404720126794
  - 0.6275329257967076
  train_level7__roc_auc_macro_oob:
  - 0.6195973849240076
  - 0.6457262591548921
  - 0.6438493171052039
  - 0.6296039891116512
  - 0.6277910913239866
  train_level7__roc_auc_micro:
  - 0.560393198617403
  - 0.6048291846730085
  - 0.5454503549044966
  - 0.5762310234281237
  - 0.5438659604702422
  train_level7__roc_auc_micro_masked:
  - 0.5577113377299514
  - 0.6014221085249425
  - 0.5409060686829654
  - 0.5734199569147461
  - 0.5405801106986704
  train_level7__roc_auc_micro_oob:
  - 0.558251728451044
  - 0.6019689988521715
  - 0.5436404396073736
  - 0.5742607703631198
  - 0.5421463016014606
  train_level7__roc_auc_samples:
  - 0.5464212883441748
  - 0.5925206328756003
  - 0.5363178337909026
  - 0.563781827312308
  - 0.5309183871699127
  train_level7__roc_auc_samples_masked:
  - 0.5377460165368192
  - 0.5812303362272873
  - 0.5222295657816262
  - 0.5563287054168313
  - 0.5204756356670668
  train_level7__roc_auc_samples_oob:
  - 0.5446166562715479
  - 0.5891447835922541
  - 0.533889072661148
  - 0.5619859296241871
  - 0.5292923041328165
  train_level7__roc_auc_weighted:
  - 0.6747583013371679
  - 0.6973896857696291
  - 0.700933352655568
  - 0.6690938037790571
  - 0.6895406198967933
  train_level7__roc_auc_weighted_masked:
  - 0.6694967898558234
  - 0.6906891703960968
  - 0.695089369192934
  - 0.6639539075519613
  - 0.6834130290549394
  train_level7__roc_auc_weighted_oob:
  - 0.6694540583943763
  - 0.6913395543837966
  - 0.6952844000222707
  - 0.6659637480865377
  - 0.6844464936764951
  train_level7__tn_macro:
  - 0.13560617193240265
  - 0.1649963476990504
  - 0.15247988295537673
  - 0.1365925925925926
  - 0.13466568699485673
  train_level7__tn_macro_masked:
  - 0.1409372927208542
  - 0.17052443006638382
  - 0.15829998491193228
  - 0.14225445800066644
  - 0.14016670646282686
  train_level7__tn_macro_oob:
  - 0.13234386480529023
  - 0.16090577063550035
  - 0.14852962692026334
  - 0.1317925925925926
  - 0.125878030859662
  train_level7__tn_micro:
  - 0.13560617193240265
  - 0.1649963476990504
  - 0.15247988295537673
  - 0.1365925925925926
  - 0.13466568699485673
  train_level7__tn_micro_masked:
  - 0.14096297201515337
  - 0.17150580088683715
  - 0.15851432743201313
  - 0.14202969991989647
  - 0.1399981667634208
  train_level7__tn_micro_oob:
  - 0.13234386480529023
  - 0.16090577063550038
  - 0.14852962692026336
  - 0.1317925925925926
  - 0.125878030859662
  train_level7__tn_samples:
  - 0.13560617193240265
  - 0.16499634769905042
  - 0.15247988295537673
  - 0.1365925925925926
  - 0.13466568699485673
  train_level7__tn_samples_masked:
  - 0.13966460761336652
  - 0.17010945285328366
  - 0.15710453276672545
  - 0.1408233278262264
  - 0.13862888282643746
  train_level7__tn_samples_oob:
  - 0.13234386480529023
  - 0.16090577063550038
  - 0.14852962692026336
  - 0.1317925925925926
  - 0.12587803085966204
  train_level7__tn_weighted:
  - 0.1280434387031939
  - 0.1338734776189484
  - 0.13920870429031212
  - 0.13500398807046746
  - 0.1316670680028073
  train_level7__tn_weighted_masked:
  - 0.14036188656587226
  - 0.14590233505272943
  - 0.15279442206571736
  - 0.14790422791449995
  - 0.1443852665421524
  train_level7__tn_weighted_oob:
  - 0.12097987629116105
  - 0.12837637723423487
  - 0.13287094660793752
  - 0.12986353863226527
  - 0.12093887273253656
  train_level7__tp_macro:
  - 0.12305657604702425
  - 0.12224981738495254
  - 0.12280907095830285
  - 0.12361481481481482
  - 0.12382072005878031
  train_level7__tp_macro_masked:
  - 0.09424101222000651
  - 0.09370914344520587
  - 0.0938174556975665
  - 0.09482923136405018
  - 0.09491553309501213
  train_level7__tp_macro_oob:
  - 0.12276267450404114
  - 0.12201607012417824
  - 0.12263350402340895
  - 0.12382222222222222
  - 0.12373254959588538
  train_level7__tp_micro:
  - 0.12305657604702425
  - 0.12224981738495252
  - 0.12280907095830285
  - 0.12361481481481482
  - 0.12382072005878031
  train_level7__tp_micro_masked:
  - 0.08884272271782964
  - 0.08831926137399015
  - 0.08851980288373791
  - 0.0893154230081952
  - 0.0895230529499832
  train_level7__tp_micro_oob:
  - 0.12276267450404114
  - 0.12201607012417823
  - 0.12263350402340892
  - 0.12382222222222222
  - 0.12373254959588538
  train_level7__tp_samples:
  - 0.12305657604702426
  - 0.12224981738495252
  - 0.12280907095830285
  - 0.12361481481481482
  - 0.12382072005878034
  train_level7__tp_samples_masked:
  - 0.08846344824286236
  - 0.08813604171418508
  - 0.08832327326204747
  - 0.0891039156227562
  - 0.08919333573076195
  train_level7__tp_samples_oob:
  - 0.12276267450404117
  - 0.12201607012417824
  - 0.12263350402340893
  - 0.12382222222222222
  - 0.12373254959588541
  train_level7__tp_weighted:
  - 0.290447131496127
  - 0.28872678012841724
  - 0.28708596632307604
  - 0.2924384449993064
  - 0.29007289910821055
  train_level7__tp_weighted_masked:
  - 0.232641775067269
  - 0.23181888524624028
  - 0.22932782383794992
  - 0.23446393925724077
  - 0.23239760667191955
  train_level7__tp_weighted_oob:
  - 0.2901745281653348
  - 0.2888025681406612
  - 0.28717666158579985
  - 0.2928946455819115
  - 0.2899566145341311
  train_level8__average_precision_macro:
  - 0.21287864560865558
  - 0.22571306295583038
  - 0.2239665312249356
  - 0.2103352135529386
  - 0.21613426845631334
  train_level8__average_precision_macro_masked:
  - 0.17526347330434677
  - 0.18285760425132497
  - 0.18346988702298275
  - 0.1716247797151379
  - 0.17864352158729058
  train_level8__average_precision_macro_oob:
  - 0.2084796883623272
  - 0.22340842992066276
  - 0.22234707409756763
  - 0.2063675708577299
  - 0.2131772215713346
  train_level8__average_precision_micro:
  - 0.12649053771774157
  - 0.13996556969606147
  - 0.12259893353239855
  - 0.13312226957007034
  - 0.12325200582455018
  train_level8__average_precision_micro_masked:
  - 0.09158813483759697
  - 0.10167108691982943
  - 0.08831024956903222
  - 0.09630897981455275
  - 0.08888790411515188
  train_level8__average_precision_micro_oob:
  - 0.12591771977297242
  - 0.13923094852259352
  - 0.12237661714764314
  - 0.13303425779290567
  - 0.1230019812851469
  train_level8__average_precision_samples:
  - 0.17888662244418943
  - 0.20007927764351396
  - 0.178428442487435
  - 0.18698455543546658
  - 0.18105354500316237
  train_level8__average_precision_samples_masked:
  - 0.1415322313476536
  - 0.1599284740073678
  - 0.14048256511861731
  - 0.14910619346461804
  - 0.1433130543191425
  train_level8__average_precision_samples_oob:
  - 0.17815118240608543
  - 0.19829889750845683
  - 0.17760805432161234
  - 0.186233521420808
  - 0.1801540185413718
  train_level8__average_precision_weighted:
  - 0.4271621418408955
  - 0.4488416940878028
  - 0.45164837433267224
  - 0.4212579812278738
  - 0.44953408193245636
  train_level8__average_precision_weighted_masked:
  - 0.36267685769268293
  - 0.38737015917998824
  - 0.3847763968923074
  - 0.35499605162549214
  - 0.3851913023971556
  train_level8__average_precision_weighted_oob:
  - 0.4198402022410671
  - 0.4441802944674418
  - 0.44579926281931587
  - 0.41579470102757904
  - 0.44255734433575844
  train_level8__f1_macro:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__f1_macro_masked:
  - 0.23538326058335834
  - 0.26408065992212015
  - 0.2522064108562844
  - 0.23744931221992624
  - 0.23591107256118182
  train_level8__f1_macro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__f1_micro:
  - 0.25886847905951504
  - 0.28715850986121255
  - 0.2753182150694952
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__f1_micro_masked:
  - 0.23001955273127214
  - 0.2597035777197352
  - 0.24712538784449717
  - 0.23171483147452093
  - 0.23034617617403527
  train_level8__f1_micro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__f1_samples:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.25925055106539313
  train_level8__f1_samples_masked:
  - 0.2283207126600731
  - 0.2581098445493275
  - 0.24552678823567156
  - 0.2303285567894264
  - 0.22864882425298697
  train_level8__f1_samples_oob:
  - 0.2558119030124908
  - 0.282191380569759
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__f1_weighted:
  - 0.418491431777484
  - 0.4218578758476549
  - 0.42630541084186857
  - 0.42786343459564435
  - 0.4225501858838073
  train_level8__f1_weighted_masked:
  - 0.3729825703995328
  - 0.37676526506182423
  - 0.38215646052094365
  - 0.38262462847940915
  - 0.3777184851565966
  train_level8__f1_weighted_oob:
  - 0.41251879963551796
  - 0.41524405187578733
  - 0.41996270924479656
  - 0.4225717852684145
  - 0.4127563834742812
  train_level8__fn_macro:
  - -0.002204261572373255
  - -0.003038714390065741
  - -0.0028383321141185074
  - -0.002785185185185185
  - -0.002292432035268185
  train_level8__fn_macro_masked:
  - -0.0019846517750103996
  - -0.002534541203865182
  - -0.0026036594891668003
  - -0.002478361444967228
  - -0.002067233307234155
  train_level8__fn_macro_oob:
  - -0.002556943423952976
  - -0.003155588020452885
  - -0.002867593269934162
  - -0.0028444444444444446
  - -0.0022042615723732546
  train_level8__fn_micro:
  - -0.002204261572373255
  - -0.0030387143900657415
  - -0.002838332114118508
  - -0.0027851851851851852
  - -0.002292432035268185
  train_level8__fn_micro_masked:
  - -0.0018636196993767568
  - -0.0024904330923889934
  - -0.002463953276145282
  - -0.0024031055517900056
  - -0.001955452351125913
  train_level8__fn_micro_oob:
  - -0.002556943423952976
  - -0.0031555880204528854
  - -0.0028675932699341626
  - -0.0028444444444444446
  - -0.002204261572373255
  train_level8__fn_samples:
  - -0.002204261572373255
  - -0.0030387143900657415
  - -0.002838332114118508
  - -0.002785185185185185
  - -0.002292432035268185
  train_level8__fn_samples_masked:
  - -0.0018500045567738758
  - -0.002481430871560131
  - -0.0024451838673714564
  - -0.0023790660225442833
  - -0.0019272671125528682
  train_level8__fn_samples_oob:
  - -0.002556943423952976
  - -0.0031555880204528854
  - -0.0028675932699341626
  - -0.002844444444444444
  - -0.0022042615723732555
  train_level8__fn_weighted:
  - -0.00528233571772218
  - -0.004550516627293802
  - -0.006283033661069417
  - -0.004462130669995838
  - -0.0050851347151645385
  train_level8__fn_weighted_masked:
  - -0.005092032708559162
  - -0.003670815384432522
  - -0.006180758850739194
  - -0.004390565851118693
  - -0.0049155193986175965
  train_level8__fn_weighted_oob:
  - -0.005573549136836532
  - -0.004373734702104574
  - -0.00589041864217258
  - -0.004479816895547232
  - -0.00483404236051511
  train_level8__fp_macro:
  - -0.7389272593681117
  - -0.7098027757487216
  - -0.7218434528163863
  - -0.7365629629629629
  - -0.7384570168993386
  train_level8__fp_macro_masked:
  - -0.7626320876416314
  - -0.7333847988740148
  - -0.7451899296545487
  - -0.7600723263351064
  - -0.7620216941315842
  train_level8__fp_macro_oob:
  - -0.7416311535635561
  - -0.7146530314097882
  - -0.7260570592538406
  - -0.7418074074074075
  - -0.7466274797942688
  train_level8__fp_micro:
  - -0.7389272593681117
  - -0.7098027757487217
  - -0.7218434528163863
  - -0.736562962962963
  - -0.7384570168993387
  train_level8__fp_micro_masked:
  - -0.7681168275693511
  - -0.7378059891878759
  - -0.7504106588793575
  - -0.7658820629736891
  - -0.7676983714748389
  train_level8__fp_micro_oob:
  - -0.7416311535635562
  - -0.7146530314097882
  - -0.7260570592538406
  - -0.7418074074074074
  - -0.7466274797942689
  train_level8__fp_samples:
  - -0.7389272593681117
  - -0.7098027757487215
  - -0.7218434528163863
  - -0.7365629629629629
  - -0.7384570168993387
  train_level8__fp_samples_masked:
  - -0.7698292827831531
  - -0.7394087245791123
  - -0.7520280278969569
  - -0.7672923771880293
  - -0.7694239086344601
  train_level8__fp_samples_oob:
  - -0.7416311535635561
  - -0.7146530314097881
  - -0.7260570592538406
  - -0.7418074074074075
  - -0.7466274797942688
  train_level8__fp_weighted:
  - -0.5762262325047938
  - -0.5735916075250513
  - -0.567411555497062
  - -0.5676744347343599
  - -0.5723646794010281
  train_level8__fp_weighted_masked:
  - -0.6219253968919081
  - -0.6195639195537432
  - -0.6116627806283172
  - -0.6129848056694721
  - -0.6173659954447858
  train_level8__fp_weighted_oob:
  - -0.5819076512276455
  - -0.580382213422108
  - -0.5741468721130308
  - -0.5729483978360382
  - -0.5824095741652038
  train_level8__jaccard_macro:
  - 0.1704192790391016
  - 0.20164133900365822
  - 0.184655910417336
  - 0.17068357443714896
  - 0.17053131139181127
  train_level8__jaccard_macro_masked:
  - 0.15294846070470483
  - 0.18465837903808102
  - 0.16746721616170668
  - 0.15315031943060015
  - 0.15306007204105815
  train_level8__jaccard_macro_oob:
  - 0.17061256317202125
  - 0.19954472364602516
  - 0.18308890143367823
  - 0.1686994719651765
  - 0.16571259630963694
  train_level8__jaccard_micro:
  - 0.1486783025556193
  - 0.16765037016819623
  - 0.15963421048166812
  - 0.1498560550568114
  - 0.14893042259703862
  train_level8__jaccard_micro_masked:
  - 0.12995598515577803
  - 0.14922950733844087
  - 0.1409829237817576
  - 0.1310392891366844
  - 0.1301645401336349
  train_level8__jaccard_micro_oob:
  - 0.14666531863984092
  - 0.16427405089127772
  - 0.15678841011407102
  - 0.1463605176454604
  - 0.14362059693465987
  train_level8__jaccard_samples:
  - 0.16352516725524527
  - 0.1822890115650545
  - 0.17285631302085794
  - 0.1622233752068611
  - 0.16281277645834527
  train_level8__jaccard_samples_masked:
  - 0.14474486181343474
  - 0.16379238498358883
  - 0.15406187995803156
  - 0.14334475006300582
  - 0.14394614693986438
  train_level8__jaccard_samples_oob:
  - 0.16062974873579508
  - 0.17802793636221922
  - 0.1686961782576177
  - 0.15789130723794914
  - 0.15649261671625456
  train_level8__jaccard_weighted:
  - 0.28808172061928394
  - 0.29310432415952203
  - 0.29678232062656634
  - 0.29724057662943465
  - 0.2925346040173856
  train_level8__jaccard_weighted_masked:
  - 0.2483092607887415
  - 0.2539805604478703
  - 0.2578574161979571
  - 0.257194204385434
  - 0.2529450525610182
  train_level8__jaccard_weighted_oob:
  - 0.28401268139920627
  - 0.2879595969141805
  - 0.2921737923015201
  - 0.2935693080726358
  - 0.28491033211011874
  train_level8__label_ranking_average_precision_score:
  - 0.18329514558893567
  - 0.20373157859311214
  - 0.18208608696439182
  - 0.19142899987991085
  - 0.18252305271807773
  train_level8__label_ranking_average_precision_score_oob:
  - 0.18255970555083156
  - 0.20195119845805512
  - 0.18126569879856874
  - 0.19067796586525226
  - 0.18162352625628686
  train_level8__matthews_corrcoef_macro:
  - 0.12401331337229352
  - 0.1313810956439769
  - 0.12793833925900214
  - 0.11461649691769704
  - 0.1254766482932984
  train_level8__matthews_corrcoef_macro_masked:
  - 0.10696532122585972
  - 0.1102566074893658
  - 0.10946064199660822
  - 0.09831068331481674
  - 0.10875466313774107
  train_level8__matthews_corrcoef_macro_oob:
  - 0.12294801513987366
  - 0.12921616408806288
  - 0.12449409548722774
  - 0.11202785260146687
  - 0.12082707703463359
  train_level8__matthews_corrcoef_micro:
  - 0.13211739405238604
  - 0.14548415090773473
  - 0.13891981250697732
  - 0.12920323763750866
  - 0.13177051834628
  train_level8__matthews_corrcoef_micro_masked:
  - 0.11052113369475867
  - 0.12212002345373967
  - 0.11530536183305434
  - 0.10712770820985701
  - 0.11006059388297579
  train_level8__matthews_corrcoef_micro_oob:
  - 0.12736564418288374
  - 0.14135739235225264
  - 0.13580890376577426
  - 0.12496732245327184
  - 0.12671652572518816
  train_level8__matthews_corrcoef_samples:
  - 0.10747228733120105
  - 0.12804638316400763
  - 0.1136809450348918
  - 0.09940311176208015
  - 0.10967066799872367
  train_level8__matthews_corrcoef_samples_masked:
  - 0.08338062927603293
  - 0.1010457597047134
  - 0.08884226108737556
  - 0.07746466512953214
  - 0.0842977178914083
  train_level8__matthews_corrcoef_samples_oob:
  - 0.10511924715520232
  - 0.12393211587591949
  - 0.11102991333584016
  - 0.09745130982613878
  - 0.10514157088085793
  train_level8__matthews_corrcoef_weighted:
  - 0.2176488049354579
  - 0.21865036043338174
  - 0.2277514977244105
  - 0.21823433376053364
  - 0.22545910739427047
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.19388658047834045
  - 0.19745441486247564
  - 0.20275950625893308
  - 0.19416219268312693
  - 0.20097429132362707
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.20904554648670648
  - 0.2106146779521377
  - 0.2217658551135966
  - 0.21238246451749765
  - 0.2149710113639504
  train_level8__ndcg:
  - 0.4100722642206486
  - 0.4349862832636428
  - 0.41540615899470656
  - 0.42497483601581937
  - 0.4153679206793292
  train_level8__ndcg_oob:
  - 0.4098767025643567
  - 0.4339465081762411
  - 0.41599273013478993
  - 0.4258835829560837
  - 0.4154066989701558
  train_level8__neg_coverage_error:
  - -15.919177075679647
  - -14.887509130752374
  - -15.94659839063643
  - -15.594074074074074
  - -15.881704628949302
  train_level8__neg_coverage_error_oob:
  - -16.049963262307127
  - -15.027757487216947
  - -16.01609363569861
  - -15.702222222222222
  - -15.960323291697282
  train_level8__neg_hamming_loss_macro:
  - -0.7411315209404848
  - -0.7128414901387873
  - -0.7246817849305047
  - -0.7393481481481481
  - -0.7407494489346068
  train_level8__neg_hamming_loss_macro_masked:
  - -0.7646167394166414
  - -0.7359193400778798
  - -0.7477935891437155
  - -0.7625506877800737
  - -0.7640889274388182
  train_level8__neg_hamming_loss_macro_oob:
  - -0.7441880969875092
  - -0.7178086194302409
  - -0.7289246525237748
  - -0.7446518518518519
  - -0.7488317413666422
  train_level8__neg_hamming_loss_micro:
  - -0.741131520940485
  - -0.7128414901387874
  - -0.7246817849305047
  - -0.7393481481481482
  - -0.7407494489346069
  train_level8__neg_hamming_loss_micro_masked:
  - -0.7699804472687278
  - -0.7402964222802648
  - -0.7528746121555028
  - -0.7682851685254791
  - -0.7696538238259647
  train_level8__neg_hamming_loss_micro_oob:
  - -0.7441880969875092
  - -0.7178086194302411
  - -0.7289246525237747
  - -0.7446518518518519
  - -0.7488317413666422
  train_level8__neg_hamming_loss_samples:
  - -0.741131520940485
  - -0.7128414901387874
  - -0.7246817849305046
  - -0.7393481481481481
  - -0.7407494489346069
  train_level8__neg_hamming_loss_samples_masked:
  - -0.7716792873399269
  - -0.7418901554506725
  - -0.7544732117643282
  - -0.7696714432105736
  - -0.7713511757470131
  train_level8__neg_hamming_loss_samples_oob:
  - -0.7441880969875091
  - -0.717808619430241
  - -0.7289246525237746
  - -0.7446518518518518
  - -0.7488317413666421
  train_level8__neg_hamming_loss_weighted:
  - -0.5815085682225161
  - -0.5781421241523451
  - -0.5736945891581314
  - -0.5721365654043558
  - -0.5774498141161927
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.6270174296004672
  - -0.6232347349381758
  - -0.6178435394790563
  - -0.6173753715205909
  - -0.6222815148434033
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.5874812003644819
  - -0.5847559481242127
  - -0.5800372907552034
  - -0.5774282147315856
  - -0.5872436165257189
  train_level8__neg_label_ranking_loss:
  - -0.4539272666617072
  - -0.4092915449364792
  - -0.46626038874315584
  - -0.43952990972153116
  - -0.4707114928780377
  train_level8__neg_label_ranking_loss_oob:
  - -0.45692095168945873
  - -0.4142220884823651
  - -0.46961971261789254
  - -0.44326231997507926
  - -0.4737953049582777
  train_level8__precision_macro:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__precision_macro_masked:
  - 0.23538326058335834
  - 0.26408065992212015
  - 0.2522064108562844
  - 0.23744931221992624
  - 0.23591107256118182
  train_level8__precision_macro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__precision_micro:
  - 0.25886847905951504
  - 0.28715850986121255
  - 0.2753182150694952
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__precision_micro_masked:
  - 0.23001955273127214
  - 0.2597035777197352
  - 0.24712538784449717
  - 0.23171483147452093
  - 0.23034617617403527
  train_level8__precision_micro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__precision_samples:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.25925055106539313
  train_level8__precision_samples_masked:
  - 0.2283207126600731
  - 0.2581098445493275
  - 0.24552678823567156
  - 0.2303285567894264
  - 0.22864882425298697
  train_level8__precision_samples_oob:
  - 0.2558119030124908
  - 0.282191380569759
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__precision_weighted:
  - 0.418491431777484
  - 0.4218578758476549
  - 0.42630541084186857
  - 0.42786343459564435
  - 0.4225501858838073
  train_level8__precision_weighted_masked:
  - 0.3729825703995328
  - 0.37676526506182423
  - 0.38215646052094365
  - 0.38262462847940915
  - 0.3777184851565966
  train_level8__precision_weighted_oob:
  - 0.41251879963551796
  - 0.41524405187578733
  - 0.41996270924479656
  - 0.4225717852684145
  - 0.4127563834742812
  train_level8__recall_macro:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__recall_macro_masked:
  - 0.23538326058335834
  - 0.26408065992212015
  - 0.2522064108562844
  - 0.23744931221992624
  - 0.23591107256118182
  train_level8__recall_macro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__recall_micro:
  - 0.25886847905951504
  - 0.28715850986121255
  - 0.2753182150694952
  - 0.26065185185185186
  - 0.2592505510653931
  train_level8__recall_micro_masked:
  - 0.23001955273127214
  - 0.2597035777197352
  - 0.24712538784449717
  - 0.23171483147452093
  - 0.23034617617403527
  train_level8__recall_micro_oob:
  - 0.2558119030124908
  - 0.28219138056975895
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__recall_samples:
  - 0.2588684790595151
  - 0.28715850986121255
  - 0.2753182150694953
  - 0.26065185185185186
  - 0.25925055106539313
  train_level8__recall_samples_masked:
  - 0.2283207126600731
  - 0.2581098445493275
  - 0.24552678823567156
  - 0.2303285567894264
  - 0.22864882425298697
  train_level8__recall_samples_oob:
  - 0.2558119030124908
  - 0.282191380569759
  - 0.2710753474762253
  - 0.25534814814814816
  - 0.25116825863335784
  train_level8__recall_weighted:
  - 0.418491431777484
  - 0.4218578758476549
  - 0.42630541084186857
  - 0.42786343459564435
  - 0.4225501858838073
  train_level8__recall_weighted_masked:
  - 0.3729825703995328
  - 0.37676526506182423
  - 0.38215646052094365
  - 0.38262462847940915
  - 0.3777184851565966
  train_level8__recall_weighted_oob:
  - 0.41251879963551796
  - 0.41524405187578733
  - 0.41996270924479656
  - 0.4225717852684145
  - 0.4127563834742812
  train_level8__roc_auc_macro:
  - 0.6225495709529056
  - 0.6532821884800795
  - 0.6495673288763666
  - 0.6238639920648852
  - 0.6307563716532083
  train_level8__roc_auc_macro_masked:
  - 0.6161933644742714
  - 0.6384205831977543
  - 0.6446725440026393
  - 0.6152292818292058
  - 0.6254050517689129
  train_level8__roc_auc_macro_oob:
  - 0.6161413741013642
  - 0.6486641535236269
  - 0.6473811145948081
  - 0.6229499948275402
  - 0.6272094990265703
  train_level8__roc_auc_micro:
  - 0.5609912321822389
  - 0.6040752564046168
  - 0.5453889857842619
  - 0.5758410647704516
  - 0.5457162208774659
  train_level8__roc_auc_micro_masked:
  - 0.5584255149441363
  - 0.6007962527416348
  - 0.5408926220404517
  - 0.5725000751328143
  - 0.5416891274230217
  train_level8__roc_auc_micro_oob:
  - 0.5583871451380678
  - 0.6011825850226034
  - 0.5437489419587791
  - 0.5742629302929652
  - 0.5441986647499635
  train_level8__roc_auc_samples:
  - 0.5467063017984178
  - 0.5925868602368034
  - 0.535793404903421
  - 0.5636330030475081
  - 0.5323762999344769
  train_level8__roc_auc_samples_masked:
  - 0.5373476462637671
  - 0.5820504753506822
  - 0.5213725276607928
  - 0.5554629317361746
  - 0.5221968636545417
  train_level8__roc_auc_samples_oob:
  - 0.5441569942663955
  - 0.5877741715155766
  - 0.5334665762592278
  - 0.5614000885759848
  - 0.5301953764264425
  train_level8__roc_auc_weighted:
  - 0.6714014822175518
  - 0.6966601551861545
  - 0.7002249391346134
  - 0.661691179713088
  - 0.6865597643868883
  train_level8__roc_auc_weighted_masked:
  - 0.6662916030931945
  - 0.6900704598823185
  - 0.6956903570570696
  - 0.6562585464805509
  - 0.6796542359336084
  train_level8__roc_auc_weighted_oob:
  - 0.6639004193304251
  - 0.6924034330567327
  - 0.6965684350741537
  - 0.6603245010464747
  - 0.6812710037577276
  train_level8__tn_macro:
  - 0.1357531227038942
  - 0.16487947406866327
  - 0.15259692757863935
  - 0.13685925925925926
  - 0.13563556208670094
  train_level8__tn_macro_masked:
  - 0.14108185118925587
  - 0.17037197012435307
  - 0.15841435994702235
  - 0.1425189583911502
  - 0.1411900824219266
  train_level8__tn_macro_oob:
  - 0.13304922850844966
  - 0.1600292184075968
  - 0.14838332114118508
  - 0.13161481481481482
  - 0.12746509919177076
  train_level8__tn_micro:
  - 0.1357531227038942
  - 0.16487947406866327
  - 0.15259692757863935
  - 0.13685925925925926
  - 0.13563556208670097
  train_level8__tn_micro_masked:
  - 0.14111572772821704
  - 0.171384316345745
  - 0.15863600413700796
  - 0.14230698132971842
  - 0.14100644688197012
  train_level8__tn_micro_oob:
  - 0.13304922850844966
  - 0.1600292184075968
  - 0.14838332114118508
  - 0.13161481481481482
  - 0.12746509919177076
  train_level8__tn_samples:
  - 0.1357531227038942
  - 0.16487947406866327
  - 0.15259692757863938
  - 0.13685925925925926
  - 0.13563556208670097
  train_level8__tn_samples_masked:
  - 0.1397972595188517
  - 0.1699763435662378
  - 0.15723410136294586
  - 0.14112532432677358
  - 0.1396355032173022
  train_level8__tn_samples_oob:
  - 0.1330492285084497
  - 0.16002921840759682
  - 0.1483833211411851
  - 0.13161481481481482
  - 0.12746509919177076
  train_level8__tn_weighted:
  - 0.12800363379206053
  - 0.13305139057377657
  - 0.13917205112962486
  - 0.13497676515466778
  - 0.13291532630686365
  train_level8__tn_weighted_masked:
  - 0.1402986147740671
  - 0.14495832561193703
  - 0.15272622387158777
  - 0.14783946718342855
  - 0.14580219143276238
  train_level8__tn_weighted_oob:
  - 0.12232221506920886
  - 0.12626078467671983
  - 0.132436734513656
  - 0.12970280205298934
  - 0.12287043154268809
  train_level8__tp_macro:
  - 0.12311535635562088
  - 0.1222790357925493
  - 0.12272128749085588
  - 0.12379259259259259
  - 0.12361498897869215
  train_level8__tp_macro_masked:
  - 0.0943014093941025
  - 0.09370868979776706
  - 0.0937920509092621
  - 0.09493035382877606
  - 0.09472099013925517
  train_level8__tp_macro_oob:
  - 0.12276267450404114
  - 0.12216216216216216
  - 0.12269202633504024
  - 0.1237333333333333
  - 0.12370315944158708
  train_level8__tp_micro:
  - 0.12311535635562086
  - 0.12227903579254931
  - 0.12272128749085588
  - 0.12379259259259259
  - 0.12361498897869214
  train_level8__tp_micro_masked:
  - 0.08890382500305512
  - 0.08831926137399015
  - 0.0884893837074892
  - 0.08940785014480251
  - 0.08933972929206514
  train_level8__tp_micro_oob:
  - 0.12276267450404114
  - 0.12216216216216216
  - 0.12269202633504023
  - 0.12373333333333333
  - 0.12370315944158707
  train_level8__tp_samples:
  - 0.12311535635562089
  - 0.12227903579254933
  - 0.12272128749085588
  - 0.12379259259259259
  - 0.12361498897869215
  train_level8__tp_samples_masked:
  - 0.0885234531412214
  - 0.0881335009830897
  - 0.08829268687272568
  - 0.08920323246265274
  - 0.0890133210356848
  train_level8__tp_samples_oob:
  - 0.12276267450404116
  - 0.12216216216216216
  - 0.12269202633504026
  - 0.12373333333333335
  - 0.12370315944158708
  train_level8__tp_weighted:
  - 0.29048779798542346
  - 0.2888064852738783
  - 0.28713335971224374
  - 0.2928866694409765
  - 0.2896348595769437
  train_level8__tp_weighted_masked:
  - 0.23268395562546576
  - 0.23180693944988728
  - 0.22943023664935588
  - 0.23478516129598057
  - 0.23191629372383424
  train_level8__tp_weighted_oob:
  - 0.2901965845663091
  - 0.2889832671990675
  - 0.28752597473114055
  - 0.2928689832154252
  - 0.2898859519315931
  train_level9__average_precision_macro:
  - 0.21331255413435066
  - 0.22557044657966266
  - 0.22260377442652843
  - 0.20952740262708316
  - 0.2155939489687252
  train_level9__average_precision_macro_masked:
  - 0.17600275895534698
  - 0.18359018716165074
  - 0.18411563149190374
  - 0.17180206232887713
  - 0.17955260263323844
  train_level9__average_precision_macro_oob:
  - 0.20833260013645002
  - 0.22061567658549502
  - 0.21889679071277082
  - 0.20602795478599295
  - 0.21150789667756242
  train_level9__average_precision_micro:
  - 0.1265248537616429
  - 0.13941616223842299
  - 0.12204617867243106
  - 0.1329115580935125
  - 0.12332615544515647
  train_level9__average_precision_micro_masked:
  - 0.0917001012423745
  - 0.1011931119396391
  - 0.08790657677477454
  - 0.0962681835819191
  - 0.08918748405979557
  train_level9__average_precision_micro_oob:
  - 0.12599727900551255
  - 0.13862759311041975
  - 0.12157134305031947
  - 0.13261718132132222
  - 0.12323724800484243
  train_level9__average_precision_samples:
  - 0.17863508719789398
  - 0.19960620729368694
  - 0.1775171580231652
  - 0.18618862350849014
  - 0.18163992164783047
  train_level9__average_precision_samples_masked:
  - 0.1414094901815299
  - 0.1593367042281869
  - 0.13954314573130247
  - 0.14847713573861
  - 0.1439381337457089
  train_level9__average_precision_samples_oob:
  - 0.1775921103621404
  - 0.1979965542957473
  - 0.17638529452342397
  - 0.18521249708479073
  - 0.18084086990670273
  train_level9__average_precision_weighted:
  - 0.4315037821439347
  - 0.44858824525365815
  - 0.4507071567175599
  - 0.418682536538931
  - 0.44884354343199934
  train_level9__average_precision_weighted_masked:
  - 0.36662306928172345
  - 0.3874811470941522
  - 0.3867949829582192
  - 0.3540626577396987
  - 0.38626484735237293
  train_level9__average_precision_weighted_oob:
  - 0.42475622832341087
  - 0.44187185131959666
  - 0.44483301628377103
  - 0.41231421345873104
  - 0.4418581464199302
  train_level9__f1_macro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__f1_macro_masked:
  - 0.23548744440094996
  - 0.2629493101360177
  - 0.2526329240643184
  - 0.2373956583178386
  - 0.23642919490189865
  train_level9__f1_macro_oob:
  - 0.2559294636296841
  - 0.28128560993425855
  - 0.27089978054133135
  - 0.2551703703703703
  - 0.2513445995591477
  train_level9__f1_micro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__f1_micro_masked:
  - 0.2301417573017231
  - 0.2585798457146328
  - 0.2475816754882278
  - 0.23168402242898514
  - 0.23089614714778942
  train_level9__f1_micro_oob:
  - 0.25592946362968405
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.2513445995591477
  train_level9__f1_samples:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.260562962962963
  - 0.259808963997061
  train_level9__f1_samples_masked:
  - 0.22845363631246776
  - 0.257024045655068
  - 0.24597676869105897
  - 0.2302603906560428
  - 0.2292100279493534
  train_level9__f1_samples_oob:
  - 0.2559294636296841
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.25134459955914773
  train_level9__f1_weighted:
  - 0.4182114188744894
  - 0.42058208258985863
  - 0.4260263353811938
  - 0.42717592592592596
  - 0.4224145205473813
  train_level9__f1_weighted_masked:
  - 0.37262581747947615
  - 0.37543891704630705
  - 0.3818172364489271
  - 0.3819933639012732
  - 0.37742581480445164
  train_level9__f1_weighted_oob:
  - 0.4127019711529846
  - 0.4148279842040752
  - 0.4178354620863968
  - 0.4210063809127479
  - 0.4119274699838299
  train_level9__fn_macro:
  - -0.002321822189566495
  - -0.0030971512052593133
  - -0.0028090709583028528
  - -0.0029333333333333334
  - -0.002263041880969875
  train_level9__fn_macro_masked:
  - -0.0021061831782032974
  - -0.002564449932305475
  - -0.0025991465512184083
  - -0.002574334245017515
  - -0.002067233307234155
  train_level9__fn_macro_oob:
  - -0.002556943423952976
  - -0.0032432432432432435
  - -0.0029553767373811262
  - -0.0028444444444444446
  - -0.002233651726671565
  train_level9__fn_micro:
  - -0.002321822189566495
  - -0.0030971512052593133
  - -0.0028090709583028528
  - -0.0029333333333333334
  - -0.002263041880969875
  train_level9__fn_micro_masked:
  - -0.0019858242698276916
  - -0.00252080422766203
  - -0.002463953276145282
  - -0.0024955326883973135
  - -0.001955452351125913
  train_level9__fn_micro_oob:
  - -0.002556943423952976
  - -0.003243243243243243
  - -0.0029553767373811267
  - -0.0028444444444444446
  - -0.002233651726671565
  train_level9__fn_samples:
  - -0.002321822189566495
  - -0.0030971512052593137
  - -0.002809070958302853
  - -0.0029333333333333334
  - -0.002263041880969875
  train_level9__fn_samples_masked:
  - -0.001968789763729546
  - -0.0025081085480615443
  - -0.002445183867371457
  - -0.002474571805006588
  - -0.0019272671125528682
  train_level9__fn_samples_oob:
  - -0.002556943423952976
  - -0.0032432432432432435
  - -0.002955376737381127
  - -0.002844444444444444
  - -0.002233651726671565
  train_level9__fn_weighted:
  - -0.005382278784637165
  - -0.004647934027301738
  - -0.006166425466138702
  - -0.004783257039811347
  - -0.004963018761263997
  train_level9__fn_weighted_masked:
  - -0.005196432322794445
  - -0.003688918179322626
  - -0.006060835664436128
  - -0.0045755770845340915
  - -0.0049155193986175965
  train_level9__fn_weighted_oob:
  - -0.005613181732337303
  - -0.004151650279708859
  - -0.006327017453894159
  - -0.0044900471632681365
  - -0.0047589204675257315
  train_level9__fp_macro:
  - -0.7386921381337251
  - -0.7108546384222059
  - -0.7214045354791514
  - -0.7365037037037035
  - -0.737927994121969
  train_level9__fp_macro_masked:
  - -0.7624063724208466
  - -0.7344862399316768
  - -0.7447679293844632
  - -0.760030007437144
  - -0.7615035717908673
  train_level9__fp_macro_oob:
  - -0.741513592946363
  - -0.7154711468224982
  - -0.7261448427212875
  - -0.7419851851851853
  - -0.7464217487141807
  train_level9__fp_micro:
  - -0.7386921381337253
  - -0.710854638422206
  - -0.7214045354791514
  - -0.7365037037037037
  - -0.7379279941219692
  train_level9__fp_micro_masked:
  - -0.7678724184284492
  - -0.7388993500577051
  - -0.7499543712356269
  - -0.7658204448826176
  - -0.7671484005010847
  train_level9__fp_micro_oob:
  - -0.741513592946363
  - -0.7154711468224981
  - -0.7261448427212875
  - -0.7419851851851852
  - -0.7464217487141808
  train_level9__fp_samples:
  - -0.7386921381337251
  - -0.710854638422206
  - -0.7214045354791513
  - -0.7365037037037037
  - -0.7379279941219691
  train_level9__fp_samples_masked:
  - -0.7695775739238025
  - -0.7404678457968705
  - -0.7515780474415695
  - -0.7672650375389505
  - -0.7688627049380936
  train_level9__fp_samples_oob:
  - -0.7415135929463629
  - -0.7154711468224982
  - -0.7261448427212874
  - -0.7419851851851852
  - -0.7464217487141807
  train_level9__fp_weighted:
  - -0.5764063023408734
  - -0.5747699833828397
  - -0.5678072391526676
  - -0.5680408170342628
  - -0.5726224606913545
  train_level9__fp_weighted_masked:
  - -0.6221777501977294
  - -0.6208721647743702
  - -0.6121219278866368
  - -0.6134310590141927
  - -0.6176586657969307
  train_level9__fp_weighted_oob:
  - -0.5816848471146782
  - -0.581020365516216
  - -0.5758375204597089
  - -0.5745035719239839
  - -0.5833136095486443
  train_level9__jaccard_macro:
  - 0.17045738532372007
  - 0.20110328594550392
  - 0.18491786131045967
  - 0.170399246406614
  - 0.17094273370044177
  train_level9__jaccard_macro_masked:
  - 0.1529767695883039
  - 0.1841379608647107
  - 0.16766633580168644
  - 0.15291338497656728
  - 0.1534736526574727
  train_level9__jaccard_macro_oob:
  - 0.17091054764528787
  - 0.1990559254214546
  - 0.182892452457739
  - 0.16824783544842206
  - 0.16558518443720233
  train_level9__jaccard_micro:
  - 0.1487558661669874
  - 0.16689396522332084
  - 0.15994908782350445
  - 0.14979729499540081
  - 0.1492991048809323
  train_level9__jaccard_micro_masked:
  - 0.1300340059726226
  - 0.14848791377446022
  - 0.14128000833203144
  - 0.13101958324621926
  - 0.13051588055473998
  train_level9__jaccard_micro_oob:
  - 0.14674261062990798
  - 0.1636604729442565
  - 0.15667095376700738
  - 0.14624371688629262
  - 0.14373592389660156
  train_level9__jaccard_samples:
  - 0.16349232883736822
  - 0.18113827863006285
  - 0.1731850991657405
  - 0.16234119306941452
  - 0.16315218895025047
  train_level9__jaccard_samples_masked:
  - 0.14470159527247006
  - 0.16265580908870655
  - 0.15437759190104156
  - 0.14350977280706526
  - 0.14423917491613136
  train_level9__jaccard_samples_oob:
  - 0.16034569214489977
  - 0.177154116289518
  - 0.1686863478971299
  - 0.15804071000244826
  - 0.15647115174449447
  train_level9__jaccard_weighted:
  - 0.2876798065386751
  - 0.29208768430342824
  - 0.2964154867958641
  - 0.2963645070055596
  - 0.29245431484627826
  train_level9__jaccard_weighted_masked:
  - 0.24786635276098704
  - 0.2529842649605227
  - 0.25743334171722254
  - 0.2564427004783343
  - 0.2527595674450307
  train_level9__jaccard_weighted_oob:
  - 0.2842361001090815
  - 0.28771786329541515
  - 0.29004218896942374
  - 0.2917760634806661
  - 0.2841062862286906
  train_level9__label_ranking_average_precision_score:
  - 0.18304361034264024
  - 0.20325850824328515
  - 0.18117480250012194
  - 0.19063306795293425
  - 0.18310942936274596
  train_level9__label_ranking_average_precision_score_oob:
  - 0.1820006335068868
  - 0.20164885524534545
  - 0.18004293900038057
  - 0.18965694152923482
  - 0.18231037762161803
  train_level9__matthews_corrcoef_macro:
  - 0.12285445810954214
  - 0.13007199888929333
  - 0.12766292879974428
  - 0.11346543774428448
  - 0.1260274089038557
  train_level9__matthews_corrcoef_macro_masked:
  - 0.10552507423453986
  - 0.10884743612666016
  - 0.10882375965626931
  - 0.09719858677650885
  - 0.10882135126289186
  train_level9__matthews_corrcoef_macro_oob:
  - 0.1232697980519958
  - 0.1261642874341077
  - 0.12349449355491805
  - 0.11153487423989712
  - 0.12011107511708216
  train_level9__matthews_corrcoef_micro:
  - 0.1313339837796713
  - 0.14434772025226206
  - 0.1394422161885118
  - 0.12806596134224818
  - 0.13237625113412757
  train_level9__matthews_corrcoef_micro_masked:
  - 0.10951996288896775
  - 0.12124819779758383
  - 0.11556589662394368
  - 0.10631011296143651
  - 0.1103819842914996
  train_level9__matthews_corrcoef_micro_oob:
  - 0.12744905486569086
  - 0.14014572420349972
  - 0.13506949606486818
  - 0.12483868390454889
  - 0.12662081544358464
  train_level9__matthews_corrcoef_samples:
  - 0.10664293254641419
  - 0.127038818684065
  - 0.11377418057065349
  - 0.09877837933777242
  - 0.11042273667281235
  train_level9__matthews_corrcoef_samples_masked:
  - 0.08228528644515888
  - 0.10037391816780972
  - 0.08836643249830638
  - 0.07690980361070766
  - 0.08466596345904928
  train_level9__matthews_corrcoef_samples_oob:
  - 0.10580669738422437
  - 0.12267088237439802
  - 0.11065495937289174
  - 0.09789672882935299
  - 0.10476516566163341
  train_level9__matthews_corrcoef_weighted:
  - 0.21622648923458893
  - 0.21670142650153523
  - 0.2274112443714013
  - 0.21596468575446012
  - 0.22589244233185327
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.19229001158633874
  - 0.19588835289342485
  - 0.20234776941972724
  - 0.19232099283512266
  - 0.20066770105533713
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.20929141924882586
  - 0.21070824569837418
  - 0.21690941554291476
  - 0.20971147572894436
  - 0.21386891376947148
  train_level9__ndcg:
  - 0.4100221717616846
  - 0.43327468855074064
  - 0.414994029990714
  - 0.42489623206039784
  - 0.41602491398051406
  train_level9__ndcg_oob:
  - 0.4099071149944071
  - 0.43261969931114375
  - 0.41485167697672626
  - 0.4256539423744851
  - 0.41610372801362355
  train_level9__neg_coverage_error:
  - -15.981631153563557
  - -14.89627465303141
  - -16.017556693489393
  - -15.64074074074074
  - -15.91182953710507
  train_level9__neg_coverage_error_oob:
  - -16.12637766348273
  - -15.036523009495982
  - -16.104608632040964
  - -15.715555555555556
  - -15.975753122703894
  train_level9__neg_hamming_loss_macro:
  - -0.7410139603232918
  - -0.7139517896274654
  - -0.7242136064374542
  - -0.739437037037037
  - -0.7401910360029389
  train_level9__neg_hamming_loss_macro_masked:
  - -0.7645125555990501
  - -0.7370506898639824
  - -0.7473670759356815
  - -0.7626043416821615
  - -0.7635708050981013
  train_level9__neg_hamming_loss_macro_oob:
  - -0.744070536370316
  - -0.7187143900657414
  - -0.7291002194586685
  - -0.7448296296296294
  - -0.7486554004408522
  train_level9__neg_hamming_loss_micro:
  - -0.7410139603232917
  - -0.7139517896274653
  - -0.7242136064374542
  - -0.739437037037037
  - -0.740191036002939
  train_level9__neg_hamming_loss_micro_masked:
  - -0.769858242698277
  - -0.7414201542853672
  - -0.7524183245117723
  - -0.7683159775710149
  - -0.7691038528522106
  train_level9__neg_hamming_loss_micro_oob:
  - -0.744070536370316
  - -0.7187143900657414
  - -0.7291002194586687
  - -0.7448296296296296
  - -0.7486554004408523
  train_level9__neg_hamming_loss_samples:
  - -0.7410139603232917
  - -0.7139517896274653
  - -0.7242136064374542
  - -0.739437037037037
  - -0.740191036002939
  train_level9__neg_hamming_loss_samples_masked:
  - -0.7715463636875324
  - -0.7429759543449319
  - -0.754023231308941
  - -0.7697396093439571
  - -0.7707899720506465
  train_level9__neg_hamming_loss_samples_oob:
  - -0.744070536370316
  - -0.7187143900657413
  - -0.7291002194586685
  - -0.7448296296296296
  - -0.7486554004408523
  train_level9__neg_hamming_loss_weighted:
  - -0.5817885811255105
  - -0.5794179174101413
  - -0.5739736646188063
  - -0.572824074074074
  - -0.5775854794526186
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.6273741825205239
  - -0.624561082953693
  - -0.6181827635510729
  - -0.6180066360987269
  - -0.6225741851955484
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.5872980288470154
  - -0.5851720157959249
  - -0.5821645379136031
  - -0.5789936190872519
  - -0.5880725300161701
  train_level9__neg_label_ranking_loss:
  - -0.45507196616450674
  - -0.40873010345008326
  - -0.4687702600051224
  - -0.4397585465100833
  - -0.47053456875646493
  train_level9__neg_label_ranking_loss_oob:
  - -0.45884221524452695
  - -0.41411913178036086
  - -0.47238689226036307
  - -0.4435267242193911
  - -0.4732552488148155
  train_level9__precision_macro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__precision_macro_masked:
  - 0.23548744440094996
  - 0.2629493101360177
  - 0.2526329240643184
  - 0.2373956583178386
  - 0.23642919490189865
  train_level9__precision_macro_oob:
  - 0.2559294636296841
  - 0.28128560993425855
  - 0.27089978054133135
  - 0.2551703703703703
  - 0.2513445995591477
  train_level9__precision_micro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__precision_micro_masked:
  - 0.2301417573017231
  - 0.2585798457146328
  - 0.2475816754882278
  - 0.23168402242898514
  - 0.23089614714778942
  train_level9__precision_micro_oob:
  - 0.25592946362968405
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.2513445995591477
  train_level9__precision_samples:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.260562962962963
  - 0.259808963997061
  train_level9__precision_samples_masked:
  - 0.22845363631246776
  - 0.257024045655068
  - 0.24597676869105897
  - 0.2302603906560428
  - 0.2292100279493534
  train_level9__precision_samples_oob:
  - 0.2559294636296841
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.25134459955914773
  train_level9__precision_weighted:
  - 0.4182114188744894
  - 0.42058208258985863
  - 0.4260263353811938
  - 0.42717592592592596
  - 0.4224145205473813
  train_level9__precision_weighted_masked:
  - 0.37262581747947615
  - 0.37543891704630705
  - 0.3818172364489271
  - 0.3819933639012732
  - 0.37742581480445164
  train_level9__precision_weighted_oob:
  - 0.4127019711529846
  - 0.4148279842040752
  - 0.4178354620863968
  - 0.4210063809127479
  - 0.4119274699838299
  train_level9__recall_macro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__recall_macro_masked:
  - 0.23548744440094996
  - 0.2629493101360177
  - 0.2526329240643184
  - 0.2373956583178386
  - 0.23642919490189865
  train_level9__recall_macro_oob:
  - 0.2559294636296841
  - 0.28128560993425855
  - 0.27089978054133135
  - 0.2551703703703703
  - 0.2513445995591477
  train_level9__recall_micro:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.26056296296296294
  - 0.259808963997061
  train_level9__recall_micro_masked:
  - 0.2301417573017231
  - 0.2585798457146328
  - 0.2475816754882278
  - 0.23168402242898514
  - 0.23089614714778942
  train_level9__recall_micro_oob:
  - 0.25592946362968405
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.2513445995591477
  train_level9__recall_samples:
  - 0.2589860396767083
  - 0.2860482103725347
  - 0.2757863935625457
  - 0.260562962962963
  - 0.259808963997061
  train_level9__recall_samples_masked:
  - 0.22845363631246776
  - 0.257024045655068
  - 0.24597676869105897
  - 0.2302603906560428
  - 0.2292100279493534
  train_level9__recall_samples_oob:
  - 0.2559294636296841
  - 0.2812856099342586
  - 0.2708997805413314
  - 0.2551703703703704
  - 0.25134459955914773
  train_level9__recall_weighted:
  - 0.4182114188744894
  - 0.42058208258985863
  - 0.4260263353811938
  - 0.42717592592592596
  - 0.4224145205473813
  train_level9__recall_weighted_masked:
  - 0.37262581747947615
  - 0.37543891704630705
  - 0.3818172364489271
  - 0.3819933639012732
  - 0.37742581480445164
  train_level9__recall_weighted_oob:
  - 0.4127019711529846
  - 0.4148279842040752
  - 0.4178354620863968
  - 0.4210063809127479
  - 0.4119274699838299
  train_level9__roc_auc_macro:
  - 0.6259728552838039
  - 0.6502549015234314
  - 0.651264885450501
  - 0.6283518516553741
  - 0.6304821649296573
  train_level9__roc_auc_macro_masked:
  - 0.6215178882871034
  - 0.6359290815921476
  - 0.645956230403377
  - 0.6205210839794337
  - 0.6275929784520302
  train_level9__roc_auc_macro_oob:
  - 0.6180710037989668
  - 0.6434844136927073
  - 0.6446168369826387
  - 0.6252038722082368
  - 0.6293400335197802
  train_level9__roc_auc_micro:
  - 0.5612012622069265
  - 0.603463992789031
  - 0.5429061703076802
  - 0.5750125649154209
  - 0.5458597412940497
  train_level9__roc_auc_micro_masked:
  - 0.5590358072095758
  - 0.5999719021538032
  - 0.5384192791838587
  - 0.5718418433767691
  - 0.5428853877566012
  train_level9__roc_auc_micro_oob:
  - 0.5586891760834107
  - 0.6001413413977486
  - 0.5405562387257296
  - 0.5728236824809106
  - 0.5449436821678448
  train_level9__roc_auc_samples:
  - 0.5455950799201944
  - 0.592319869495956
  - 0.5334750099492361
  - 0.5634211327696138
  - 0.5324792399027424
  train_level9__roc_auc_samples_masked:
  - 0.5368654727357828
  - 0.5812332607149743
  - 0.5188380781188131
  - 0.5554683502352113
  - 0.5223108499905378
  train_level9__roc_auc_samples_oob:
  - 0.5423470691182675
  - 0.5872779320288822
  - 0.5307610836973014
  - 0.5612370770701983
  - 0.530575927501427
  train_level9__roc_auc_weighted:
  - 0.6748978724167394
  - 0.6932054159891637
  - 0.7005729972147029
  - 0.6647241901125746
  - 0.6870149454989591
  train_level9__roc_auc_weighted_masked:
  - 0.6706222330721815
  - 0.6864198333743879
  - 0.6954825853757586
  - 0.6593339416637184
  - 0.6821034512224339
  train_level9__roc_auc_weighted_oob:
  - 0.6672596252335967
  - 0.6864080022448612
  - 0.6940038844029418
  - 0.6606227598418848
  - 0.6839376394914088
  train_level9__tn_macro:
  - 0.13598824393828068
  - 0.16382761139517896
  - 0.1530358449158742
  - 0.13691851851851852
  - 0.13616458486407054
  train_level9__tn_macro_masked:
  - 0.1413075664100404
  - 0.16927052906669085
  - 0.15883636021710795
  - 0.1425612772891128
  - 0.14170820476264348
  train_level9__tn_macro_oob:
  - 0.1331667891256429
  - 0.15921110299488678
  - 0.1482955376737381
  - 0.13143703703703705
  - 0.1276708302718589
  train_level9__tn_micro:
  - 0.13598824393828068
  - 0.16382761139517896
  - 0.1530358449158742
  - 0.13691851851851852
  - 0.13616458486407054
  train_level9__tn_micro_masked:
  - 0.1413601368691189
  - 0.1702909554759157
  - 0.15909229178073858
  - 0.14236859942078994
  - 0.1415564178557243
  train_level9__tn_micro_oob:
  - 0.13316678912564292
  - 0.15921110299488678
  - 0.14829553767373813
  - 0.13143703703703705
  - 0.12767083027185894
  train_level9__tn_samples:
  - 0.13598824393828068
  - 0.16382761139517898
  - 0.15303584491587416
  - 0.13691851851851855
  - 0.13616458486407054
  train_level9__tn_samples_masked:
  - 0.140048968378202
  - 0.1689172223484797
  - 0.15768408181833327
  - 0.14115266397585238
  - 0.14019670691366865
  train_level9__tn_samples_oob:
  - 0.13316678912564292
  - 0.1592111029948868
  - 0.14829553767373813
  - 0.13143703703703705
  - 0.1276708302718589
  train_level9__tn_weighted:
  - 0.12782356395598093
  - 0.13187301471598825
  - 0.1387763674740193
  - 0.13461038285476487
  - 0.1326575450165371
  train_level9__tn_weighted_masked:
  - 0.14004626146824573
  - 0.1436500803913099
  - 0.15226707661326816
  - 0.14739321383870796
  - 0.1455095210806174
  train_level9__tn_weighted_oob:
  - 0.12254501918217622
  - 0.12562263258261194
  - 0.13074608616697783
  - 0.1281476279650437
  - 0.12196639615924745
  train_level9__tp_macro:
  - 0.12299779573842763
  - 0.12222059897735577
  - 0.12275054864667155
  - 0.12364444444444445
  - 0.12364437913299046
  train_level9__tp_macro_masked:
  - 0.09417987799090959
  - 0.09367878106932677
  - 0.09379656384721048
  - 0.09483438102872578
  - 0.09472099013925517
  train_level9__tp_macro_oob:
  - 0.12276267450404114
  - 0.12207450693937183
  - 0.12260424286759328
  - 0.1237333333333333
  - 0.12367376928728877
  train_level9__tp_micro:
  - 0.12299779573842763
  - 0.12222059897735574
  - 0.12275054864667154
  - 0.12364444444444445
  - 0.12364437913299045
  train_level9__tp_micro_masked:
  - 0.08878162043260418
  - 0.08828889023871712
  - 0.0884893837074892
  - 0.0893154230081952
  - 0.08933972929206514
  train_level9__tp_micro_oob:
  - 0.12276267450404114
  - 0.1220745069393718
  - 0.12260424286759326
  - 0.12373333333333333
  - 0.12367376928728877
  train_level9__tp_samples:
  - 0.12299779573842765
  - 0.12222059897735572
  - 0.12275054864667155
  - 0.12364444444444446
  - 0.12364437913299046
  train_level9__tp_samples_masked:
  - 0.08840466793426573
  - 0.08810682330658828
  - 0.08829268687272568
  - 0.08910772668019044
  - 0.0890133210356848
  train_level9__tp_samples_oob:
  - 0.12276267450404116
  - 0.1220745069393718
  - 0.12260424286759329
  - 0.12373333333333335
  - 0.12367376928728875
  train_level9__tp_weighted:
  - 0.2903878549185085
  - 0.2887090678738704
  - 0.28724996790717444
  - 0.292565543071161
  - 0.28975697553084423
  train_level9__tp_weighted_masked:
  - 0.23257955601123045
  - 0.2317888366549971
  - 0.22955015983565893
  - 0.23460015006256518
  - 0.23191629372383424
  train_level9__tp_weighted_oob:
  - 0.2901569519708083
  - 0.2892053516214632
  - 0.287089375919419
  - 0.29285875294770425
  - 0.28996107382458247
start: 2023-12-31 13:44:04.006427
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
