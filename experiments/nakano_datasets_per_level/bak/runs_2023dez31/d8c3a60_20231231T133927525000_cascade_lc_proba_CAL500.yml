active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            0MzMzMzMBECAmZmZmZnZv4CZmZmZmdm/YGZmZmZm9r+AmZmZmZnZvw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJvwCZmZmZmcm/wJmZmZmZ6T8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D+YmZmZmZkBwMzMzMzMzBTANDMzMzMzG0AwMzMzMzPzvw==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+AmZmZmZnJv4CZmZmZmcm/gJmZmZmZyb+AmZmZmZnJvw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/gJmZmZmZ6b8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8CgmZmZmZn5P9DMzMzMzARAmJmZmZmZFcBoZmZmZmYSQA==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkBoZmZmZmYOQMzMzMzMzBDAmJmZmZmZCcCgmZmZmZnpPw==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcBoZmZmZmYGQICZmZmZmcm/MDMzMzMz87+gmZmZmZnpPw==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0BkZmZmZmYawJyZmZmZmR1AZGZmZmZmEsDAmZmZmZnZPw==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b9wZmZmZmb2P8jMzMzMzAzAnJmZmZmZEUAgMzMzMzPjvw==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAUwAAAAAAAABRAAAAAAAAAEMAAAAAAAADwPw==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8L8AAAAAAADwPw==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T9AMzMzMzPjP2hmZmZmZhJAgJmZmZmZ2b+YmZmZmZkZwA==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b+cmZmZmZkVQMjMzMzMzATAIDMzMzMz478gMzMzMzPjvw==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ2T/AmZmZmZnZP3BmZmZmZvY/kJmZmZmZ+b8gMzMzMzPjvw==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAAQAAAAAAAABDAAAAAAAAAEEAAAAAAAAAAQA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAJkAAAAAAAAAIwAAAAAAAAAhAAAAAAAAAIMAAAAAAAAAIwA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMFMBoZmZmZmYGQICZmZmZmcm/oJmZmZmZ6T/QzMzMzMz8Pw==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUCgmZmZmZkJQMDMzMzMzPy/MDMzMzMzG8CgmZmZmZkBQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b84MzMzMzMLQHBmZmZmZvY/yMzMzMzMDMDAmZmZmZnZPw==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC0BoZmZmZmYawMzMzMzMzCJAaGZmZmZmFsBAMzMzMzPjvw==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz8z84MzMzMzPzP8jMzMzMzPy/MjMzMzMzE8DOzMzMzMwQQA==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAADwPwAAAAAAABRAAAAAAAAA8L8AAAAAAAAAwA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMFMDgzMzMzMz8P+DMzMzMzPw/AJmZmZmZyb/gzMzMzMz8Pw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMA0MzMzMzMDQDQzMzMzMwtAzMzMzMzMDMBoZmZmZmb2Pw==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGMAAAAAAAAAIQAAAAAAAABjAAAAAAAAAEEAAAAAAAAAUQA==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzIUAwMzMzMzMLwNDMzMzMzAxAmJmZmZmZFcAwMzMzMzMLwA==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAUQAAAAAAAABTAAAAAAAAACMAAAAAAAADwvw==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAAAAAAAAAAPC/AAAAAAAAAEAAAAAAAAAAAA==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmGkCYmZmZmZkVwNDMzMzMzAxAgJmZmZmZ2b+YmZmZmZkRwA==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L8wMzMzMzMTwMDMzMzMzPy/aGZmZmZmIEAAmpmZmZnJPw==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb/QzMzMzMz8P5iZmZmZmQHAmJmZmZmZAcBoZmZmZmYGQA==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZAUBgZmZmZmYGwACamZmZmck/wMzMzMzM/L+gmZmZmZkBQA==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAAwAAAAAAAAAjAAAAAAAAACMAAAAAAAAAYQA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D/AmZmZmZnpP3BmZmZmZgZAyMzMzMzMFMAAmZmZmZnJvw==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAABRAAAAAAAAAFMAAAAAAAAAAAA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAIQAAAAAAAAABAAAAAAAAAEEAAAAAAAAAYwA==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZGUCYmZmZmZn5vzAzMzMzM+O/zMzMzMzMDMAwMzMzMzPjvw==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b9AMzMzMzPjP0AzMzMzM+M/gJmZmZmZ2b+AmZmZmZnZvw==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZ+T8yMzMzMzMDwDgzMzMzM+M/zszMzMzMBEAyMzMzMzMDwA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b+QmZmZmZnpv5yZmZmZmQFAwJmZmZmZyT+QmZmZmZnpvw==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAIwAAAAAAAAPA/AAAAAAAAAEAAAAAAAADwPw==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T+YmZmZmZn5vzQzMzMzMwNAmJmZmZmZ+b+gmZmZmZnZPw==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b/MzMzMzMwEwJiZmZmZmfm/mJmZmZmZ+b+amZmZmZkdQA==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZCUCgmZmZmZnJPzMzMzMzMxPAmJmZmZmZ6b+amZmZmZkBQA==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBsDQzMzMzMwYQKCZmZmZmQlAYGZmZmZmDsBgZmZmZmYGwA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z9gZmZmZmb2v0AzMzMzM+M/oJmZmZmZ+T9gZmZmZmb2vw==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0CYmZmZmZn5vzQzMzMzMwNAmJmZmZmZ+b+YmZmZmZn5vw==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z9gZmZmZmb2v0AzMzMzM+M/QDMzMzMz4z+AmZmZmZnZvw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZmBkAAmZmZmZnJv+DMzMzMzPw/IDMzMzMz87+QmZmZmZkJwA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/QzMzMzMz8P6CZmZmZmek/mJmZmZmZAcCYmZmZmZkBwA==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D8wMzMzMzPzv2hmZmZmZgZAzMzMzMzMGMBoZmZmZmYGQA==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAQQAAAAAAAABTAAAAAAAAAAAAAAAAAAADwPw==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAYQAAAAAAAAPC/AAAAAAAAIsAAAAAAAADwPw==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz87+AmZmZmZnpPwCamZmZmcm/wMzMzMzM/D9AMzMzMzPzvw==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzE0AwMzMzMzPzv4CZmZmZmcm/zMzMzMzMEMCgmZmZmZnpPw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j9oZmZmZmb2P6CZmZmZmdk/mJmZmZmZ+b+YmZmZmZn5vw==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb/MzMzMzMwQwGhmZmZmZgZA0MzMzMzM/D+AmZmZmZnJvw==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D+YmZmZmZkJwICZmZmZmcm/gJmZmZmZyb/QzMzMzMz8Pw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAADwPwAAAAAAABDAAAAAAAAAEEAAAAAAAAAIQA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEECYmZmZmZkJQICZmZmZmck/NDMzMzMzG8CgmZmZmZnpvw==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ6b+amZmZmZkBQJiZmZmZmem/mJmZmZmZ6b+gmZmZmZnJPw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFMAAAAAAAAAqQAAAAAAAABBAAAAAAAAAJsAAAAAAAADwvw==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAQwAAAAAAAABBAAAAAAAAACMAAAAAAAAAUQA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAwAAAAAAAAPA/AAAAAAAA8L8AAAAAAADwPw==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAAAAAAAAAAPA/AAAAAAAAEMAAAAAAAAAUQA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmFsA4MzMzMzMDQDgzMzMzMwtAyMzMzMzMDMA4MzMzMzMLQA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT/AzMzMzMz8v4CZmZmZmem/YGZmZmZmBsDQzMzMzMwUQA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMDECAmZmZmZnZv9DMzMzMzARAmJmZmZmZFcCAmZmZmZnZvw==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D8AmZmZmZnJvyAzMzMzM/O/4MzMzMzM/D+QmZmZmZkBwA==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAADwPwAAAAAAABBAAAAAAAAAEMAAAAAAAADwvw==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBMBgZmZmZmb2P9DMzMzMzAzAmJmZmZmZGUCgmZmZmZn5vw==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmFkCYmZmZmZkZwGhmZmZmZhJAMDMzMzMzA8BgZmZmZmb2vw==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMzA0BAMzMzMzMDQEAzMzMzMwNAYGZmZmZmHsAAmpmZmZnZPw==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcCgmZmZmZnpP8zMzMzMzBTANDMzMzMzG0CAmZmZmZnJvw==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcBoZmZmZmYOQGhmZmZmZg5AzMzMzMzMGMCgmZmZmZnpPw==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gGZmZmZmDkAAMzMzMzPzvwCamZmZmek/wMzMzMzMEMAAmpmZmZnpPw==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T9AMzMzMzPjP9DMzMzMzARAgJmZmZmZ2b+YmZmZmZkRwA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ6b+AmZmZmZnpv9DMzMzMzBBAMDMzMzMzE8CgmZmZmZkBQA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAIwAAAAAAAAABAAAAAAAAAAMAAAAAAAAAQQA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz47+cmZmZmZkRQGRmZmZmZhrAcGZmZmZm9j9wZmZmZmb2Pw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzF0CYmZmZmZkJwJiZmZmZmQHAaGZmZmZmBkCYmZmZmZkJwA==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmEkBgZmZmZmb2vzAzMzMzMwvAYGZmZmZm9r+gmZmZmZn5Pw==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L+gmZmZmZkJQNDMzMzMzBhAMDMzMzMzE8BgZmZmZmYGwA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b8wMzMzMzPjv5iZmZmZmfm/aGZmZmZm9j80MzMzMzMDQA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBEDMzMzMzMwEQJqZmZmZmRHANDMzMzMzC8DMzMzMzMwEQA==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzG8CgmZmZmZkBQGBmZmZmZgbA0MzMzMzMFECgmZmZmZkBQA==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b+cmZmZmZkBQM7MzMzMzBhAMjMzMzMzE8BkZmZmZmYGwA==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkDQzMzMzMz8P5iZmZmZmQHAgJmZmZmZyb+YmZmZmZkBwA==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MjMzMzMzA8BkZmZmZmb2v2RmZmZmZva/zszMzMzMDECcmZmZmZn5Pw==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b8wMzMzMzPjv6CZmZmZmdk/mJmZmZmZ+b80MzMzMzMLQA==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAUQAAAAAAAAPA/AAAAAAAACMAAAAAAAAAQwA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGEAAAAAAAAAQwAAAAAAAAAAAAAAAAAAAAMAAAAAAAAAAAA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwPwAAAAAAAPC/AAAAAAAA8L8AAAAAAAAAAA==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T9oZmZmZmb2PzAzMzMzM+O/aGZmZmZm9j/MzMzMzMwEwA==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T8wMzMzMzPjvzAzMzMzM+O/aGZmZmZm9j8wMzMzMzPjvw==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0AwMzMzMzPjv5iZmZmZmfm/oJmZmZmZ2T8wMzMzMzPjvw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+amZmZmZkVQJiZmZmZmfm/oJmZmZmZ2T/MzMzMzMwEwA==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwvwAAAAAAAPA/AAAAAAAAAEAAAAAAAAAAAA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMCgmZmZmZnZPzAzMzMzM+O/NDMzMzMzC0AwMzMzMzPjvw==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MzMzMzMzE8CamZmZmZkJQGZmZmZmZgbAmpmZmZmZAUCamZmZmZkBQA==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAwAAAAAAAAPA/AAAAAAAAAEAAAAAAAADwvw==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          QDMzMzMzA0DAzMzMzMwEwKCZmZmZmRFAYGZmZmZmGsBAMzMzMzMDQA==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 13:44:03.471213
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_proba
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - rf
                      - call: deep_forest.estimator_adapters.EstimatorAsTransformer
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: null
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                    - - xt
                      - call: deep_forest.estimator_adapters.EstimatorAsTransformer
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: false
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: null
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_proba
  params: {}
hash: d8c3a6021ef889b0bf36835226d9224ad66c29d0c5a2c13896b99dea4baad285
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/d8c3a60_20231231T133927525000_cascade_lc_proba_CAL500.yml
results:
  fit_time:
  - 249.4065854549408
  - 249.43472981452942
  - 264.6234083175659
  - 260.57747411727905
  - 269.0218017101288
  fitted_params:
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.06833048530416952
      - 0.4027896001926039
      - 0.14445381096261303
      - 0.08473774487132331
      - 0.38411174757435035
      - 0.15172312590790848
      - 0.20481270957724446
      - 0.0926977745841861
      - 0.15647747374824175
      - 0.10499731443800853
      - 0.210798473099005
      - 0.17863935515034413
      - 0.054701279727635145
      - 0.11731163812674078
      - 0.15247502404525598
      - 0.13537603207496396
      - 0.14543816131094878
      - 0.10441938112392657
      - 0.18741462258167624
      - 0.07199224912358373
      - 0.20940688794013598
      - 0.06649358974358972
      - 0.2515701925719398
      - 0.2071250583347357
      - 0.05620939981735435
      - 0.1198808832804741
      - 0.15004586946123585
      - 0.15944731475191684
      - 0.048412533591907274
      - 0.06320300354805253
      - 0.2548810406764952
      - 0.10588299894549895
      - 0.23662835621168946
      - 0.07311568073526703
      - 0.2826021734098032
      - 0.092262074870434
      - 0.06112330002680879
      - 0.033153482483599464
      - 0.036448914006385266
      - 0.02353638838013838
      - 0.04257646229295714
      - 0.019668219377521702
      - 0.01481333836470701
      - 0.051156361754187835
      - 0.024763851075664263
      - 0.1196218463744366
      - 0.04856366705856502
      - 0.031064256510685083
      - 0.11549802100073836
      - 0.16313573166251735
      - 0.041919360485020596
      - 0.3039615196404989
      - 0.10647614010385749
      - 0.05330837140139143
      - 0.08346328526434277
      - 0.4350419833273451
      - 0.08640708820145085
      - 0.03079988193624557
      - 0.0418254126952867
      - 0.0678185286935287
      - 0.17350888405575904
      - 0.0785320374070374
      - 0.02082755427157704
      - 0.1833221778221778
      - 0.14728480482957246
      - 0.1568735941580769
      - 0.1142649427490996
      - 0.11804036501072697
      - 0.2848189578793199
      - 0.11196518511449344
      - 0.1850320778779187
      - 0.04667322557265632
      - 0.2144370071216662
      - 0.09959652558662459
      - 0.29825821994270785
      - 0.07893501734382498
      - 0.07129451199053471
      - 0.5114479478057561
      - 0.32087591984163566
      - 0.39551366592235815
      - 0.15777272881439547
      - 0.06332236106285019
      - 0.049778389525580544
      - 0.06386607701741717
      - 0.2666149748596557
      - 0.04340904059310652
      - 0.02661214024013054
      - 0.11208963502919544
      - 0.06455236632189001
      - 0.02067246025579359
      - 0.0331773692288794
      - 0.023809957403707407
      - 0.01327351588979496
      - 0.06541425154706404
      - 0.022651271949024755
      - 0.07265647364331576
      - 0.054155128752507026
      - 0.02941375106061014
      - 0.01881858118971521
      - 0.031688681688681684
      - 0.027543950480625152
      - 0.028203268451762423
      - 0.027428398118519118
    - - 0.04925686021427019
      - 0.3620231388477575
      - 0.15942432672295598
      - 0.12362697059786114
      - 0.38386874794087555
      - 0.1670041479075899
      - 0.16938950806138306
      - 0.12636032679552237
      - 0.14432186562060983
      - 0.11150082046221753
      - 0.23287004123401234
      - 0.1613795992367421
      - 0.0513029153533935
      - 0.13419641224841913
      - 0.16105446414291694
      - 0.15374448650764433
      - 0.13508428251208965
      - 0.10998239812292608
      - 0.1738784286053003
      - 0.08998461496643916
      - 0.21592302556284843
      - 0.07184558166701024
      - 0.22888130315387312
      - 0.2479626005271629
      - 0.0699244387148799
      - 0.09760251136175087
      - 0.10235650061318899
      - 0.1915596031318735
      - 0.06991972719702605
      - 0.03722935839413112
      - 0.2971521568449631
      - 0.10636936037863236
      - 0.21563874344046752
      - 0.06950747976486718
      - 0.27496830426517926
      - 0.07198790096860197
      - 0.07473763602911201
      - 0.020093386081249307
      - 0.03933167762390023
      - 0.024597201967891624
      - 0.04168341222849008
      - 0.028675882940588822
      - 0.02072619782280577
      - 0.04020644212559495
      - 0.025098963007459736
      - 0.1282108035521901
      - 0.037180772177688295
      - 0.02544362253525069
      - 0.1385587456151972
      - 0.1778785791246305
      - 0.03525163605808767
      - 0.30042895327156643
      - 0.10689891185366021
      - 0.05481266020059123
      - 0.0854126146629609
      - 0.3939301058171129
      - 0.06453991037062881
      - 0.024453590741469532
      - 0.02540889708979771
      - 0.07047872258120419
      - 0.17827984204288552
      - 0.0664294385282237
      - 0.019597844223012688
      - 0.2084266373625795
      - 0.1359529947851441
      - 0.15876552174742478
      - 0.13017283958492676
      - 0.14230841795496968
      - 0.268215629093456
      - 0.1625341306869944
      - 0.1731261600801361
      - 0.031003364060267227
      - 0.21956132988436755
      - 0.05136641319207108
      - 0.3055102214597221
      - 0.057146020049245835
      - 0.07425197025197025
      - 0.49201160598439303
      - 0.36430458003122945
      - 0.35564975756455286
      - 0.135079701754176
      - 0.0671935173023516
      - 0.024838001329478603
      - 0.07543795961340405
      - 0.3068647603310432
      - 0.041958834815977675
      - 0.027229303970254703
      - 0.11738487020745084
      - 0.04409380302237445
      - 0.014979646300669027
      - 0.018549311036824678
      - 0.026082816648326165
      - 0.020059505763366653
      - 0.08119194892919003
      - 0.018424985508318843
      - 0.04842658618787381
      - 0.033057995020011485
      - 0.025287678290753235
      - 0.03345576456371911
      - 0.026863674271494657
      - 0.02604978354978355
      - 0.03425512683975995
      - 0.017237576186439823
    - - 0.04818289836381942
      - 0.35416074792249885
      - 0.12073279375802956
      - 0.09210850121972669
      - 0.35613080266504815
      - 0.1881066184096487
      - 0.15979375131404944
      - 0.1427693360931997
      - 0.17734080838013416
      - 0.13109784951890213
      - 0.20037778667040027
      - 0.16934621246418996
      - 0.06393023159011531
      - 0.1169427134936394
      - 0.16370024180539505
      - 0.16941204512617475
      - 0.1525711431862955
      - 0.0832083714896215
      - 0.1544001100452713
      - 0.10053095996973546
      - 0.21567822263578001
      - 0.0786756215230594
      - 0.24758374839019992
      - 0.23776640026640022
      - 0.07226919066537979
      - 0.1307256972610798
      - 0.10346225850775925
      - 0.14874818952673624
      - 0.05351942954064273
      - 0.057786021539363776
      - 0.23892093580150614
      - 0.1266574734396516
      - 0.2732637150229743
      - 0.08668403946780842
      - 0.3114149679683175
      - 0.09356592139866429
      - 0.07784019821056858
      - 0.019813130662228964
      - 0.027147862766485214
      - 0.02999580740544596
      - 0.07607284159008297
      - 0.01955878316934268
      - 0.015469619779964607
      - 0.06243082759936692
      - 0.017097056962135322
      - 0.13055295460158037
      - 0.04127781202249287
      - 0.0186350989385361
      - 0.11864984505290627
      - 0.1507682763977295
      - 0.053173388075344996
      - 0.3252033551239808
      - 0.09690105744322614
      - 0.039637133318452
      - 0.06619582914212131
      - 0.39495526852577234
      - 0.08433077954956779
      - 0.02547674348470229
      - 0.04460332987118701
      - 0.08015917855372555
      - 0.1953158490874754
      - 0.05996768167358085
      - 0.02346690665656183
      - 0.20593425285844696
      - 0.1339200128996928
      - 0.16508203977116642
      - 0.13659504505889097
      - 0.09627428656598018
      - 0.32934961672966734
      - 0.1016866669528782
      - 0.1550813075813076
      - 0.03843136030636031
      - 0.2230824912825483
      - 0.11163419913419911
      - 0.3336186650130264
      - 0.05557520210881555
      - 0.07665798566471416
      - 0.5048138689815557
      - 0.32137209192368127
      - 0.3728820048056018
      - 0.1822245226364544
      - 0.05677208673342693
      - 0.021761824848868763
      - 0.07533701245058343
      - 0.27357760782598944
      - 0.0429470498290723
      - 0.022021289368228142
      - 0.12173449971745427
      - 0.06814564364101225
      - 0.014936922485235022
      - 0.025278967365634095
      - 0.03130627667493418
      - 0.023052600177600174
      - 0.06638793098668214
      - 0.017647240400049388
      - 0.05603409295953815
      - 0.032823129890110686
      - 0.02854155853487491
      - 0.027901531093020453
      - 0.033286819412555374
      - 0.031119694481763445
      - 0.022093297795563377
      - 0.017620565635645576
    - - 0.055379010513814435
      - 0.3522877694201224
      - 0.1875633317698605
      - 0.10821886446886445
      - 0.3909508464540634
      - 0.17928522313598028
      - 0.13883588620641185
      - 0.10512975545237607
      - 0.18429597832522207
      - 0.1421215930741786
      - 0.2071800340989869
      - 0.15832042815461178
      - 0.04496868352372203
      - 0.11721401572000778
      - 0.1418969982733769
      - 0.13501174637354107
      - 0.14684200605457082
      - 0.11498708131772648
      - 0.15352715534167144
      - 0.06029267145427093
      - 0.2190703533444175
      - 0.075237228393169
      - 0.23271236678494733
      - 0.18135178740017446
      - 0.05743455401658525
      - 0.13045192756589813
      - 0.08847768435268433
      - 0.14881289102553472
      - 0.0577868368459605
      - 0.0418818710757606
      - 0.2706879800084868
      - 0.1083060869240682
      - 0.22133824030375754
      - 0.06336494766572698
      - 0.2802044049193172
      - 0.0913288709341341
      - 0.07302082435117607
      - 0.017787811147186146
      - 0.03122900509781197
      - 0.0213891833789793
      - 0.047365334159511746
      - 0.03409810067931665
      - 0.01692000034407077
      - 0.04625233014408271
      - 0.022125596923984015
      - 0.1251388891460301
      - 0.06159914478879996
      - 0.029155422124172124
      - 0.15640986104695775
      - 0.15671015292227408
      - 0.030345823557030454
      - 0.2856371292461619
      - 0.08079574502178466
      - 0.05711920793714
      - 0.06586483879682409
      - 0.41790815465304276
      - 0.06987263553440025
      - 0.022825864161091433
      - 0.03424671106699194
      - 0.07756435453784091
      - 0.21160413660413657
      - 0.07269271648956854
      - 0.019810109522188174
      - 0.1545917765137102
      - 0.14425521587049178
      - 0.13675076385602702
      - 0.11185848032438941
      - 0.10933904058904056
      - 0.25490031068335667
      - 0.0933258565334037
      - 0.16323721826706375
      - 0.0364848892975741
      - 0.2411160521878393
      - 0.048656017242744765
      - 0.3361847890865748
      - 0.08443879588329303
      - 0.08676899728209786
      - 0.475021868948425
      - 0.40234404484404485
      - 0.4255724661419405
      - 0.18886278901136974
      - 0.07431838994338993
      - 0.028061877922191794
      - 0.05437268227391823
      - 0.2385049174064698
      - 0.05629727534997395
      - 0.02202253373463033
      - 0.12333312782868883
      - 0.02707559893414074
      - 0.01698878772742409
      - 0.01950547837175744
      - 0.027753589003589006
      - 0.018089949161077108
      - 0.08846364258452172
      - 0.02239540762268035
      - 0.058649980537576814
      - 0.036653975062405295
      - 0.04462679935240911
      - 0.03190781712688208
      - 0.022206339580505743
      - 0.021791320823222913
      - 0.023894131466736766
      - 0.018368859401468096
    - - 0.05187898279032163
      - 0.37063023136327444
      - 0.16327516959784394
      - 0.12643526045824413
      - 0.3645532538828449
      - 0.1490260218708494
      - 0.2134792588672042
      - 0.08402981298237283
      - 0.1621061400473165
      - 0.10281621707540822
      - 0.23727390257145237
      - 0.1819851076953349
      - 0.045235827474967974
      - 0.125161877424295
      - 0.13961929950806024
      - 0.13469067780292268
      - 0.14655605733043917
      - 0.135200336062405
      - 0.16684225818900741
      - 0.07979961558908928
      - 0.1924029652388609
      - 0.06874181222734602
      - 0.2517338146773392
      - 0.20864555862304957
      - 0.07735629733457275
      - 0.15557775557775555
      - 0.10315348067336702
      - 0.17636162110247472
      - 0.05834611783536606
      - 0.04958809597363814
      - 0.2367246500099648
      - 0.14606982155293943
      - 0.29006063381063374
      - 0.08440225434395937
      - 0.2890664324337794
      - 0.07998690023405132
      - 0.055034323352448795
      - 0.03624448229243485
      - 0.03956066420352135
      - 0.0242838654366708
      - 0.04475116351854143
      - 0.04021663982209892
      - 0.021177414024267507
      - 0.05990227706918607
      - 0.04291186996855776
      - 0.15679750212826093
      - 0.034751519062254946
      - 0.016082161277756867
      - 0.12415782547597468
      - 0.15222625351701438
      - 0.01984851035583967
      - 0.2896314445427689
      - 0.10166739020783139
      - 0.06504436921103587
      - 0.07046863311808964
      - 0.34172087415508456
      - 0.06707585714938655
      - 0.02372273982018388
      - 0.03209513028478546
      - 0.10674225316215608
      - 0.13579288447415042
      - 0.07906909720482767
      - 0.021232023185148184
      - 0.17802853408537334
      - 0.15892262645569705
      - 0.1620150695143192
      - 0.12902663575740497
      - 0.10786174641026611
      - 0.2945562113325271
      - 0.09971138394433848
      - 0.13722454285641095
      - 0.042729705102154084
      - 0.18832010173921931
      - 0.06769383394383395
      - 0.3308254098147715
      - 0.07917027732368642
      - 0.0855256503076414
      - 0.49757129541793405
      - 0.3831642109265234
      - 0.41442257588090925
      - 0.1851939383493969
      - 0.05430341632964435
      - 0.014300739959291422
      - 0.05684027740479351
      - 0.2670474041978976
      - 0.057687971750471745
      - 0.028783587957046497
      - 0.1313567555503039
      - 0.03935045689077948
      - 0.01719656187764479
      - 0.03731427748281681
      - 0.039782019712497244
      - 0.019033110102873375
      - 0.058981139561496705
      - 0.024281401867608764
      - 0.06839633977133977
      - 0.035640846684880774
      - 0.023684012266718603
      - 0.028382951658813726
      - 0.041152748691303885
      - 0.020619245172816603
      - 0.03572771002094727
      - 0.022538626952030568
  score_time:
  - 6.403788328170776
  - 6.197838306427002
  - 6.58717679977417
  - 6.610912561416626
  - 6.481750011444092
  test_level0__average_precision_macro:
  - 0.3024620315956966
  - 0.31115208868678934
  - 0.3182250621814717
  - 0.29907903121727547
  - 0.2944512136540766
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.5095402607012998
  - 0.48975498766375075
  - 0.4998025338634635
  - 0.479228596250882
  - 0.49163531672810284
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.538187081982504
  - 0.5196410925234188
  - 0.5300011815784331
  - 0.5101980432409686
  - 0.5269742729935585
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.43045363115014434
  - 0.4270674204143245
  - 0.42505300293164855
  - 0.40835175341385993
  - 0.40560006299877316
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7641172974043985
  - 0.7745310585352059
  - 0.7587985436893202
  - 0.7693494238272388
  - 0.7622349910838124
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838122
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838123
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.6403029082275496
  - 0.6599019385005033
  - 0.6429725716282318
  - 0.6574483260660162
  - 0.6453231292517008
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.23588270259560135
  - -0.22546894146479407
  - -0.2412014563106796
  - -0.23065057617276108
  - -0.23776500891618782
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.23588270259560135
  - -0.22546894146479404
  - -0.2412014563106796
  - -0.23065057617276108
  - -0.23776500891618785
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.23588270259560126
  - -0.22546894146479393
  - -0.24120145631067955
  - -0.23065057617276102
  - -0.23776500891618776
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.35969709177245024
  - -0.34009806149949673
  - -0.35702742837176793
  - -0.34255167393398384
  - -0.3546768707482994
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6459960064492217
  - 0.6568400066381122
  - 0.6372341084309726
  - 0.6499543206831605
  - 0.6415560919423325
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.6182765531062124
  - 0.6320283055149604
  - 0.6113419701784405
  - 0.6251566762515668
  - 0.6158155914839123
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6205319547755707
  - 0.6348846688970402
  - 0.6144479979704326
  - 0.6275091299491908
  - 0.6186550183796592
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5007628353219475
  - 0.5219834320971022
  - 0.5039954447943575
  - 0.5176449377462192
  - 0.507555336639207
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5381870819825039
  - 0.5196410925234186
  - 0.5300011815784331
  - 0.5101980432409685
  - 0.5269742729935586
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8302814476359075
  - 0.8197401431086383
  - 0.8260423302545745
  - 0.8146528096531297
  - 0.8250341561592934
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -89.98979591836735
  - -91.3883495145631
  - -89.51041666666667
  - -88.78504672897196
  - -89.41836734693878
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.23588270259560135
  - -0.22546894146479407
  - -0.2412014563106796
  - -0.23065057617276108
  - -0.23776500891618782
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.23588270259560135
  - -0.22546894146479404
  - -0.2412014563106796
  - -0.23065057617276108
  - -0.23776500891618785
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.23588270259560126
  - -0.22546894146479393
  - -0.24120145631067955
  - -0.23065057617276102
  - -0.23776500891618776
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.35969709177245024
  - -0.34009806149949673
  - -0.35702742837176793
  - -0.34255167393398384
  - -0.3546768707482994
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.24695894824733722
  - -0.25578170296708
  - -0.2564152316188349
  - -0.26040887377905203
  - -0.2616631117480179
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7641172974043985
  - 0.7745310585352059
  - 0.7587985436893202
  - 0.7693494238272388
  - 0.7622349910838124
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838122
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838123
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.6403029082275496
  - 0.6599019385005033
  - 0.6429725716282318
  - 0.6574483260660162
  - 0.6453231292517008
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7641172974043985
  - 0.7745310585352059
  - 0.7587985436893202
  - 0.7693494238272388
  - 0.7622349910838124
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838122
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838123
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.6403029082275496
  - 0.6599019385005033
  - 0.6429725716282318
  - 0.6574483260660162
  - 0.6453231292517008
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5609874305542012
  - 0.5623443251760949
  - 0.5753796113730153
  - 0.565763596982129
  - 0.5410388248250604
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7482084197289217
  - 0.7412713079947233
  - 0.7407135259103905
  - 0.7368366183347964
  - 0.7344591564855733
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7530410517526628
  - 0.7442182970329201
  - 0.743584768381165
  - 0.7395911262209479
  - 0.7383368882519822
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5642594566154112
  - 0.5730169751501075
  - 0.5586483887492527
  - 0.5589034734559641
  - 0.5334989009416713
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7641172974043985
  - 0.7745310585352059
  - 0.7587985436893202
  - 0.7693494238272388
  - 0.7622349910838124
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838122
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7641172974043986
  - 0.774531058535206
  - 0.7587985436893204
  - 0.7693494238272389
  - 0.7622349910838123
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.6403029082275496
  - 0.6599019385005033
  - 0.6429725716282318
  - 0.6574483260660162
  - 0.6453231292517008
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.2958839244625474
  - 0.2963820803814711
  - 0.31575076395352775
  - 0.28822094945178084
  - 0.2734040960923944
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.222402170104982
  - 0.19374325485778668
  - 0.21522976903941518
  - 0.19691970306502588
  - 0.20621159534531558
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.2397537644747499
  - 0.20773970561253166
  - 0.23002524718554027
  - 0.21021294702877918
  - 0.22251086693080768
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.4333977091842639
  - 0.4285615611389774
  - 0.43924901259334354
  - 0.41113698671192406
  - 0.3952174034994374
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.3884485833168219
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801105
  - 0.378343570437884
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.38844858331682186
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801107
  - 0.3783435704378839
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.38844858331682186
  - 0.33546988406070305
  - 0.37408980582524265
  - 0.35495871518011063
  - 0.3783435704378839
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.4743290848468746
  - 0.4419342793129201
  - 0.46318134171907754
  - 0.44192518952623944
  - 0.4431037414965986
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.07182484644343172
  - -0.060043359411820145
  - -0.06442152103559871
  - -0.06796116504854369
  - -0.0725183277194373
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.07182484644343175
  - -0.06004335941182015
  - -0.0644215210355987
  - -0.06796116504854369
  - -0.0725183277194373
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.07182484644343173
  - -0.06004335941182016
  - -0.06442152103559869
  - -0.06796116504854369
  - -0.07251832771943728
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.13257591991017323
  - -0.11821362470370492
  - -0.11529961565338925
  - -0.12453583534930918
  - -0.12767431972789114
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.5397265702397464
  - -0.6044867565274766
  - -0.5614886731391586
  - -0.5770801197713458
  - -0.5491381018426789
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.5397265702397464
  - -0.6044867565274766
  - -0.5614886731391586
  - -0.5770801197713457
  - -0.5491381018426789
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.5397265702397464
  - -0.6044867565274766
  - -0.5614886731391585
  - -0.5770801197713455
  - -0.5491381018426787
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.39309499524295227
  - -0.43985209598337505
  - -0.42151904262753326
  - -0.4335389751244513
  - -0.42922193877551024
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.2569962395949318
  - 0.21984151810418165
  - 0.24806303464224644
  - 0.23066746267170007
  - 0.24604516746925295
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.2410401426200283
  - 0.2015402910697095
  - 0.2300802388505318
  - 0.2157749586321015
  - 0.2333068605290488
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.24497764550906415
  - 0.2048344018847096
  - 0.23468635362900714
  - 0.22061756690578732
  - 0.2376464875201118
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.3225718239374893
  - 0.2984091827046903
  - 0.3168930624225458
  - 0.29415420800886694
  - 0.2942229260017191
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.2397537644747499
  - 0.2077397056125316
  - 0.23002524718554032
  - 0.21021294702877913
  - 0.22251086693080754
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.08592038623864331
  - 0.08295789915637974
  - 0.08718001664511235
  - 0.06115555109526212
  - 0.04992753766889163
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - -0.010073661150561939
  - -0.046426436678904164
  - -0.006867767519820262
  - -0.042952813976686294
  - -0.02396810540362594
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - -0.011835956920545843
  - -0.05138695345774461
  - -0.014041211268591253
  - -0.051843288664986616
  - -0.02925220460744965
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.10864282300063596
  - 0.10937252533545092
  - 0.09460267755478248
  - 0.0718347109805633
  - 0.054345200774870775
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.5991774151043959
  - 0.5669452415474221
  - 0.587397810708488
  - 0.5712509784065134
  - 0.5838890807133573
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -96.1734693877551
  - -96.98058252427184
  - -96.44791666666667
  - -97.26168224299066
  - -95.5204081632653
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.611551416683178
  - -0.6645301159392967
  - -0.6259101941747572
  - -0.6450412848198892
  - -0.6216564295621161
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.6115514166831781
  - -0.6645301159392968
  - -0.6259101941747572
  - -0.6450412848198893
  - -0.6216564295621161
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.6115514166831781
  - -0.6645301159392967
  - -0.6259101941747572
  - -0.6450412848198893
  - -0.621656429562116
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5256709151531253
  - -0.5580657206870798
  - -0.5368186582809225
  - -0.5580748104737605
  - -0.5568962585034014
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.5313993425560124
  - -0.5861852734083063
  - -0.5598432539541013
  - -0.5926561883219756
  - -0.5776191829644037
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.3884485833168219
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801105
  - 0.378343570437884
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.38844858331682186
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801107
  - 0.3783435704378839
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.38844858331682186
  - 0.33546988406070305
  - 0.37408980582524265
  - 0.35495871518011063
  - 0.3783435704378839
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.4743290848468746
  - 0.4419342793129201
  - 0.46318134171907754
  - 0.44192518952623944
  - 0.4431037414965986
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.3884485833168219
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801105
  - 0.378343570437884
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.38844858331682186
  - 0.33546988406070316
  - 0.3740898058252427
  - 0.3549587151801107
  - 0.3783435704378839
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.38844858331682186
  - 0.33546988406070305
  - 0.37408980582524265
  - 0.35495871518011063
  - 0.3783435704378839
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.4743290848468746
  - 0.4419342793129201
  - 0.46318134171907754
  - 0.44192518952623944
  - 0.4431037414965986
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5690923595279004
  - 0.5780268184939538
  - 0.5891242581025171
  - 0.566110457132797
  - 0.5396487639846408
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.4891880614351929
  - 0.44417558243514244
  - 0.46892055197487736
  - 0.44402522119488247
  - 0.45150650398578973
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.4819931695330171
  - 0.42695217200560304
  - 0.45307978115313824
  - 0.429354082860287
  - 0.44105612252036824
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5811350799818629
  - 0.5921789052083601
  - 0.5851227965150761
  - 0.5714665824948064
  - 0.5451331321163905
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.22439072716465222
  - 0.1700443020077293
  - 0.19730987055016178
  - 0.19226930405589326
  - 0.21309688924113335
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.22439072716465228
  - 0.1700443020077293
  - 0.1973098705501618
  - 0.1922693040558933
  - 0.21309688924113335
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.2243907271646522
  - 0.17004430200772921
  - 0.19730987055016178
  - 0.19226930405589324
  - 0.21309688924113332
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.24720791298459743
  - 0.22004984251712828
  - 0.22145352900069878
  - 0.2239093509415649
  - 0.21610119047619047
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.1640578561521696
  - 0.16542558205297392
  - 0.17677993527508093
  - 0.16268941112421734
  - 0.16524668119675054
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.1640578561521696
  - 0.1654255820529739
  - 0.1767799352750809
  - 0.1626894111242174
  - 0.16524668119675054
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.16405785615216956
  - 0.16542558205297386
  - 0.17677993527508087
  - 0.16268941112421736
  - 0.16524668119675048
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.227121171862277
  - 0.22188443679579176
  - 0.24172781271837868
  - 0.2180158385846746
  - 0.22700255102040817
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.3235441802820521
  - 0.32669714791749166
  - 0.3480503510228122
  - 0.30613141559405954
  - 0.3043871453698937
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.18664630165874063
  - 0.1711004131765164
  - 0.1917844555577384
  - 0.18086294271152803
  - 0.1938559604163656
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.20928162195921932
  - 0.19276269784694247
  - 0.2131700659112182
  - 0.2033543023535994
  - 0.21717623574179815
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.45162114070695036
  - 0.44250586484490617
  - 0.4616855226313452
  - 0.41310946257507075
  - 0.41599633550992254
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.34588512839125296
  - 0.3777491579155935
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.36179908856746584
  - 0.3258554057875389
  - 0.3776294498381877
  - 0.34588512839125307
  - 0.37774915791559344
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.345885128391253
  - 0.37774915791559344
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.43073995662943887
  - 0.4086924051043932
  - 0.4321890286512929
  - 0.4190901269880953
  - 0.417155612244898
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.11095700416088763
  - -0.09953812800452447
  - -0.11529126213592233
  - -0.09735958624444242
  - -0.10907469784030119
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.11095700416088766
  - -0.09953812800452445
  - -0.11529126213592233
  - -0.09735958624444242
  - -0.10907469784030117
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.11095700416088762
  - -0.09953812800452444
  - -0.11529126213592229
  - -0.09735958624444241
  - -0.10907469784030117
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.22823543529129414
  - -0.2085308633957853
  - -0.22876484975541583
  - -0.19707787671786875
  - -0.21427721088435372
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.5272439072716465
  - -0.5746064662079367
  - -0.50707928802589
  - -0.5567552853643046
  - -0.5131761442441053
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.5272439072716465
  - -0.5746064662079367
  - -0.50707928802589
  - -0.5567552853643045
  - -0.5131761442441054
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.5272439072716465
  - -0.5746064662079367
  - -0.50707928802589
  - -0.5567552853643045
  - -0.5131761442441054
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.341024608079267
  - -0.38277673149982144
  - -0.3390461215932914
  - -0.3838319962940359
  - -0.3685671768707483
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.24178935600134818
  - 0.21627819180330407
  - 0.25710351141804433
  - 0.22789710573897876
  - 0.2503110632376011
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.2208514755684567
  - 0.19463994144473848
  - 0.2327639945143997
  - 0.20910586944596818
  - 0.23285496183206106
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.22336446963147258
  - 0.19678847845264313
  - 0.2353456609007174
  - 0.212152859736193
  - 0.23547457671828825
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.291447620209931
  - 0.2743109549931925
  - 0.2953093120316727
  - 0.28037542116834213
  - 0.27717619538332283
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.2092816219592193
  - 0.19276269784694242
  - 0.21317006591121834
  - 0.20335430235359941
  - 0.21717623574179826
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.07115189641671138
  - 0.05935114159407834
  - 0.07434021391608346
  - 0.06181172741487188
  - 0.046156748663948005
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - -0.14297280695512948
  - -0.16728320899941893
  - -0.12981408589330223
  - -0.1327840715431628
  - -0.11720704121320574
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - -0.14444992004314205
  - -0.17322556348193993
  - -0.133781592243454
  - -0.1389828108845337
  - -0.12085703281677868
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.08569955260892961
  - 0.06886843307814677
  - 0.08224539590881302
  - 0.07150410882745556
  - 0.046747771474115664
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.5665290281928144
  - 0.5479585214455158
  - 0.5666262103498995
  - 0.5552559059357177
  - 0.5747872807250818
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -100.54081632653062
  - -99.68932038834951
  - -99.91666666666667
  - -101.02803738317758
  - -99.14285714285714
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.6382009114325342
  - -0.6741445942124609
  - -0.6223705501618123
  - -0.6541148716087469
  - -0.6222508420844065
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.6382009114325342
  - -0.6741445942124611
  - -0.6223705501618123
  - -0.6541148716087469
  - -0.6222508420844066
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.6382009114325341
  - -0.674144594212461
  - -0.6223705501618122
  - -0.6541148716087467
  - -0.6222508420844065
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.5692600433705611
  - -0.5913075948956066
  - -0.5678109713487072
  - -0.5809098730119047
  - -0.5828443877551022
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.6162498247913889
  - -0.6458443831601778
  - -0.6133215677786558
  - -0.622248563583214
  - -0.6062359510095902
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.34588512839125296
  - 0.3777491579155935
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.36179908856746584
  - 0.3258554057875389
  - 0.3776294498381877
  - 0.34588512839125307
  - 0.37774915791559344
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.345885128391253
  - 0.37774915791559344
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.43073995662943887
  - 0.4086924051043932
  - 0.4321890286512929
  - 0.4190901269880953
  - 0.417155612244898
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.34588512839125296
  - 0.3777491579155935
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.36179908856746584
  - 0.3258554057875389
  - 0.3776294498381877
  - 0.34588512839125307
  - 0.37774915791559344
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.3617990885674658
  - 0.32585540578753885
  - 0.37762944983818764
  - 0.345885128391253
  - 0.37774915791559344
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.43073995662943887
  - 0.4086924051043932
  - 0.4321890286512929
  - 0.4190901269880953
  - 0.417155612244898
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5896559635247564
  - 0.576196314301108
  - 0.6025505393170532
  - 0.5832554953512472
  - 0.5444059944360359
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.38901633480360337
  - 0.36755367471711115
  - 0.3956067887310485
  - 0.3890282828618379
  - 0.40596119270427167
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.38375017520861104
  - 0.3541556168398222
  - 0.3866784322213442
  - 0.37775143641678616
  - 0.3937692513819255
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5936010095600212
  - 0.5862391183613009
  - 0.5934683579018944
  - 0.5735950293301557
  - 0.5390608598524166
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.2368733901327521
  - 0.19992459232726928
  - 0.25171925566343045
  - 0.2125941384629344
  - 0.24905884683970672
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.23687339013275213
  - 0.1999245923272693
  - 0.2517192556634304
  - 0.2125941384629344
  - 0.24905884683970675
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.2368733901327521
  - 0.1999245923272692
  - 0.25171925566343034
  - 0.21259413846293437
  - 0.24905884683970672
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.2992783001482827
  - 0.27712520700068183
  - 0.30392645003494057
  - 0.27361632977198025
  - 0.27675595238095235
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.12492569843471367
  - 0.12593081346026955
  - 0.1259101941747573
  - 0.13329098992831864
  - 0.12869031107588666
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.1249256984347137
  - 0.12593081346026958
  - 0.1259101941747573
  - 0.13329098992831867
  - 0.12869031107588666
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.12492569843471367
  - 0.1259308134602696
  - 0.12591019417475727
  - 0.13329098992831864
  - 0.12869031107588666
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.13146165648115607
  - 0.13156719810371137
  - 0.12826257861635224
  - 0.14547379721611506
  - 0.1403996598639456
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.30804635208422787
  - 0.3024468034080186
  - 0.32400505493562826
  - 0.2887396294794713
  - 0.28317538616757565
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.2133974604633174
  - 0.18668865423527642
  - 0.20864942332449635
  - 0.19048639413921303
  - 0.202747969915893
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.23086005127405712
  - 0.20100781389271463
  - 0.22443337138988614
  - 0.20327365046881019
  - 0.21742139395003077
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.44624061133423837
  - 0.4323523240624529
  - 0.4468907619856912
  - 0.4129172336880746
  - 0.4056443515034043
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.38220725183277204
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.35078486525723607
  - 0.37269665147612446
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.38220725183277193
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.3507848652572362
  - 0.3726966514761244
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.3822072518327718
  - 0.33339617306060887
  - 0.37773058252427183
  - 0.3507848652572361
  - 0.3726966514761244
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.4686677695017528
  - 0.44130921843036663
  - 0.4680337176799441
  - 0.43839202335345623
  - 0.44094387755102027
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.07004160887656033
  - -0.0613629936846074
  - -0.06654530744336569
  - -0.06532982487977497
  - -0.07103229641371113
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.07004160887656033
  - -0.06136299368460741
  - -0.06654530744336569
  - -0.06532982487977497
  - -0.07103229641371112
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.07004160887656033
  - -0.06136299368460741
  - -0.06654530744336569
  - -0.06532982487977497
  - -0.0710322964137111
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.1355672886542269
  - -0.1215378121245576
  - -0.11939640111809924
  - -0.12142547262071957
  - -0.12538265306122448
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.5477511392906677
  - -0.6052408332547836
  - -0.5557241100323623
  - -0.5838853098629889
  - -0.5562710521101644
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.5477511392906678
  - -0.6052408332547837
  - -0.5557241100323624
  - -0.5838853098629888
  - -0.5562710521101645
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.5477511392906677
  - -0.6052408332547836
  - -0.5557241100323624
  - -0.5838853098629888
  - -0.5562710521101644
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.3957649418440202
  - -0.43715296944507587
  - -0.41256988120195665
  - -0.4401825040258241
  - -0.43367346938775514
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.2533157404526917
  - 0.21819089711529793
  - 0.2511332770404769
  - 0.2272059497017411
  - 0.24179824274162362
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.23625229638701775
  - 0.20004524630959789
  - 0.23284084533383206
  - 0.2126980633802817
  - 0.2290271520759771
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.24000758457493607
  - 0.20346223221539803
  - 0.23788659634324097
  - 0.21758357572892
  - 0.2334624875038504
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.31909130287019255
  - 0.2978683244047562
  - 0.32105949359676716
  - 0.29110160439252203
  - 0.2928379748305717
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.23086005127405718
  - 0.20100781389271463
  - 0.2244333713898861
  - 0.2032736504688102
  - 0.2174213939500307
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.09460853568808675
  - 0.08581201132192916
  - 0.08985865547163761
  - 0.0659828509104309
  - 0.049947092789719386
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - -0.012936776895251988
  - -0.05315850659916161
  - -0.007967646833417255
  - -0.0409863193184775
  - -0.027149181577021723
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - -0.015153956405105726
  - -0.058921748838605646
  - -0.016251741006566667
  - -0.051837286372230555
  - -0.032381807562738014
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.1206016138362097
  - 0.1149852883834025
  - 0.10146493185457617
  - 0.07387799832905934
  - 0.055663666060258604
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.5837315610598751
  - 0.5556910471950095
  - 0.5764002056896743
  - 0.5594608484314872
  - 0.5779680486156438
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -96.88775510204081
  - -97.6116504854369
  - -97.28125
  - -97.90654205607477
  - -96.01020408163265
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.617792748167228
  - -0.6666038269393909
  - -0.6222694174757282
  - -0.6492151347427637
  - -0.6273033485238756
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.6177927481672281
  - -0.6666038269393911
  - -0.6222694174757282
  - -0.6492151347427638
  - -0.6273033485238756
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.6177927481672281
  - -0.666603826939391
  - -0.6222694174757281
  - -0.6492151347427637
  - -0.6273033485238755
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.5313322304982472
  - -0.5586907815696334
  - -0.5319662823200559
  - -0.5616079766465438
  - -0.5590561224489796
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.5388530000953303
  - -0.596139572832045
  - -0.563192239126387
  - -0.5979210149579738
  - -0.5818145366152402
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.38220725183277204
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.35078486525723607
  - 0.37269665147612446
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.38220725183277193
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.3507848652572362
  - 0.3726966514761244
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.3822072518327718
  - 0.33339617306060887
  - 0.37773058252427183
  - 0.3507848652572361
  - 0.3726966514761244
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.4686677695017528
  - 0.44130921843036663
  - 0.4680337176799441
  - 0.43839202335345623
  - 0.44094387755102027
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.38220725183277204
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.35078486525723607
  - 0.37269665147612446
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.38220725183277193
  - 0.3333961730606089
  - 0.37773058252427183
  - 0.3507848652572362
  - 0.3726966514761244
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.3822072518327718
  - 0.33339617306060887
  - 0.37773058252427183
  - 0.3507848652572361
  - 0.3726966514761244
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.4686677695017528
  - 0.44130921843036663
  - 0.4680337176799441
  - 0.43839202335345623
  - 0.44094387755102027
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5787232695163222
  - 0.5805947121559349
  - 0.5945649848048398
  - 0.5715844589608131
  - 0.5461546252955556
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.47479881596455975
  - 0.42877156238209146
  - 0.45779669962902325
  - 0.431215654838088
  - 0.4440250519885625
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.46632907362709
  - 0.41057764286743853
  - 0.4426693329109246
  - 0.41400911291736736
  - 0.43097618110292635
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5904573723524399
  - 0.5931659790054302
  - 0.5905107693992844
  - 0.5761890918976742
  - 0.5490171273807082
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.2163661581137309
  - 0.16929022528042226
  - 0.20307443365695793
  - 0.18546411396425005
  - 0.20596393897364768
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.21636615811373092
  - 0.16929022528042229
  - 0.20307443365695793
  - 0.18546411396425005
  - 0.2059639389736477
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.21636615811373092
  - 0.16929022528042226
  - 0.20307443365695788
  - 0.18546411396425003
  - 0.2059639389736477
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.2445379663835295
  - 0.22274896905542751
  - 0.23040269042627537
  - 0.217265822040192
  - 0.21164965986394557
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.16584109371904104
  - 0.16410594778018664
  - 0.17465614886731398
  - 0.1653207512929861
  - 0.1667327125024767
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.16584109371904102
  - 0.16410594778018664
  - 0.17465614886731393
  - 0.16532075129298612
  - 0.16673271250247673
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.16584109371904096
  - 0.1641059477801866
  - 0.17465614886731387
  - 0.1653207512929861
  - 0.1667327125024767
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.2241298031182234
  - 0.21856024937493906
  - 0.23763102725366866
  - 0.22112620131326427
  - 0.22929421768707484
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.30022221037828695
  - 0.29405626535451485
  - 0.31423099897541845
  - 0.28492558441884674
  - 0.27552679936840613
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.22027371786793482
  - 0.19117967651333292
  - 0.2139777302600806
  - 0.19586105493885203
  - 0.20578609279187024
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.23946640336481967
  - 0.20646477271619512
  - 0.22981057974132288
  - 0.20931865145270645
  - 0.2208690445838832
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.43920321581356236
  - 0.4236266485067157
  - 0.43669019360682876
  - 0.40786195692727256
  - 0.3973269601748983
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.388547652070537
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.35468650757644477
  - 0.3766594016247276
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.38854765207053693
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.354686507576445
  - 0.37665940162472755
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.38854765207053693
  - 0.33688377792440377
  - 0.37823624595469246
  - 0.35468650757644493
  - 0.3766594016247275
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.47399909144674274
  - 0.44414634542325554
  - 0.466356568832984
  - 0.4426274108987697
  - 0.44508503401360533
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.07093322765999603
  - -0.0606089169573004
  - -0.06583737864077668
  - -0.06641865529443788
  - -0.07152764018228651
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.07093322765999603
  - -0.060608916957300404
  - -0.0658373786407767
  - -0.0664186552944379
  - -0.07152764018228651
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.07093322765999602
  - -0.060608916957300425
  - -0.0658373786407767
  - -0.06641865529443788
  - -0.07152764018228651
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.13184736305273892
  - -0.11866821443647108
  - -0.1185316212438854
  - -0.12216078295844761
  - -0.12564200680272108
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.5405191202694669
  - -0.6025073051182956
  - -0.5559263754045307
  - -0.5788948371291172
  - -0.5518129581929859
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.540519120269467
  - -0.6025073051182958
  - -0.5559263754045307
  - -0.5788948371291172
  - -0.5518129581929859
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.540519120269467
  - -0.6025073051182956
  - -0.5559263754045308
  - -0.578894837129117
  - -0.5518129581929858
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.3941535455005186
  - -0.43718544014027344
  - -0.4151118099231307
  - -0.4352118061427825
  - -0.4292729591836734
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.2574398934328783
  - 0.22050237222624414
  - 0.2509587336918416
  - 0.23024834010634124
  - 0.24488025763439747
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.2411164391983278
  - 0.20256177737474496
  - 0.23322524320279373
  - 0.21557381569514145
  - 0.2320273404125473
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.24492210470159678
  - 0.20590582100579097
  - 0.2381290579672494
  - 0.2203260460033802
  - 0.23632271690850654
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.3224970685949463
  - 0.2998154638346708
  - 0.31891703489232653
  - 0.29462016306578537
  - 0.29623925222250713
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.23946640336481953
  - 0.20646477271619518
  - 0.229810579741323
  - 0.20931865145270648
  - 0.22086904458388332
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.08769404331891066
  - 0.08491445990101075
  - 0.09044766782046691
  - 0.06707275768025196
  - 0.05269902608003732
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - -0.0075358664720293865
  - -0.04620148822025176
  - -0.005400873118302565
  - -0.03896110089947993
  - -0.02343972263985055
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - -0.009093157964330356
  - -0.0522848151960023
  - -0.013386505296820233
  - -0.04755027640862039
  - -0.02749521806638908
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.11066479280585406
  - 0.11172887882627235
  - 0.10124534583436304
  - 0.07551161529784797
  - 0.06114460559396149
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.5955308233516278
  - 0.5639132329092602
  - 0.5850791191081409
  - 0.5694901411424417
  - 0.5833765333178296
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -96.28571428571429
  - -97.55339805825243
  - -96.54166666666667
  - -97.5607476635514
  - -95.5
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.611452347929463
  - -0.6631162220755961
  - -0.6217637540453074
  - -0.645313492423555
  - -0.6233405983752724
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.611452347929463
  - -0.6631162220755962
  - -0.6217637540453075
  - -0.6453134924235551
  - -0.6233405983752724
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.611452347929463
  - -0.6631162220755963
  - -0.6217637540453075
  - -0.645313492423555
  - -0.6233405983752723
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.5260009085532573
  - -0.5558536545767444
  - -0.533643431167016
  - -0.5573725891012302
  - -0.5549149659863946
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.5268062126550705
  - -0.5882516975327667
  - -0.5577041043684596
  - -0.5951225597549608
  - -0.5799309404005202
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.388547652070537
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.35468650757644477
  - 0.3766594016247276
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.38854765207053693
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.354686507576445
  - 0.37665940162472755
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.38854765207053693
  - 0.33688377792440377
  - 0.37823624595469246
  - 0.35468650757644493
  - 0.3766594016247275
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.47399909144674274
  - 0.44414634542325554
  - 0.466356568832984
  - 0.4426274108987697
  - 0.44508503401360533
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.388547652070537
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.35468650757644477
  - 0.3766594016247276
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.38854765207053693
  - 0.3368837779244038
  - 0.3782362459546926
  - 0.354686507576445
  - 0.37665940162472755
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.38854765207053693
  - 0.33688377792440377
  - 0.37823624595469246
  - 0.35468650757644493
  - 0.3766594016247275
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.47399909144674274
  - 0.44414634542325554
  - 0.466356568832984
  - 0.4426274108987697
  - 0.44508503401360533
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5723350879943693
  - 0.576826499520884
  - 0.593725398723067
  - 0.5686490782690867
  - 0.5406454876671519
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.48903477784197724
  - 0.4388810944599316
  - 0.46917766785668685
  - 0.4420629520296778
  - 0.4500189812407937
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.48360898866950036
  - 0.42278274746196814
  - 0.4543912991500573
  - 0.4263623596013922
  - 0.4398682224647092
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.586228202177215
  - 0.5891786789644989
  - 0.5895376878817553
  - 0.5728103912750943
  - 0.5449971195137228
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.22359817713493169
  - 0.17202375341691015
  - 0.2028721682847896
  - 0.19045458669812174
  - 0.2104220328908262
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.22359817713493163
  - 0.17202375341691017
  - 0.20287216828478966
  - 0.19045458669812176
  - 0.21042203289082623
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.22359817713493157
  - 0.17202375341691012
  - 0.2028721682847896
  - 0.1904545866981217
  - 0.21042203289082623
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.24614936272703117
  - 0.2227164983602299
  - 0.22786076170510136
  - 0.22223651992323357
  - 0.2160501700680272
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.16494947493560536
  - 0.16486002450749368
  - 0.17536407766990295
  - 0.16423192087832317
  - 0.16623736873390133
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.1649494749356053
  - 0.16486002450749362
  - 0.17536407766990292
  - 0.1642319208783232
  - 0.16623736873390133
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.16494947493560527
  - 0.16486002450749362
  - 0.1753640776699029
  - 0.1642319208783232
  - 0.1662373687339013
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.22784972871971132
  - 0.22142984706302563
  - 0.23849580712788254
  - 0.22039089097553619
  - 0.22903486394557826
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.29931218004180277
  - 0.2977305411811276
  - 0.3202496170395867
  - 0.28718315999952343
  - 0.2810021387399114
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.22085798166401793
  - 0.1939309220201589
  - 0.2152502239321487
  - 0.1981816353697586
  - 0.2066973895731764
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.24058854183755835
  - 0.2090162822070367
  - 0.23129741712080273
  - 0.2112543183398039
  - 0.22223256923199525
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.43937184881819846
  - 0.42803895382851603
  - 0.44439305325931805
  - 0.4108653815170349
  - 0.40334251591328546
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.38914206459282746
  - 0.3396173060608917
  - 0.3795509708737865
  - 0.354867979312222
  - 0.37873984545274425
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.3795509708737864
  - 0.35486797931222214
  - 0.3787398454527442
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.37955097087378636
  - 0.3548679793122221
  - 0.37873984545274414
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.47314625136068716
  - 0.4478885930447771
  - 0.4674659329140462
  - 0.44300977227438826
  - 0.446016156462585
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.07103229641371112
  - -0.060043359411820145
  - -0.06583737864077668
  - -0.06768895744487795
  - -0.07182484644343175
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.07103229641371112
  - -0.06004335941182015
  - -0.0658373786407767
  - -0.06768895744487796
  - -0.07182484644343175
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.0710322964137111
  - -0.060043359411820166
  - -0.0658373786407767
  - -0.06768895744487796
  - -0.07182484644343173
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.1330130540246338
  - -0.11751144592005715
  - -0.11716893780573026
  - -0.12373802363287424
  - -0.12627125850340135
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.5398256389934615
  - -0.6003393345272882
  - -0.5546116504854368
  - -0.5774430632429001
  - -0.549435308103824
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.5398256389934615
  - -0.6003393345272882
  - -0.5546116504854369
  - -0.5774430632429
  - -0.549435308103824
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.5398256389934614
  - -0.6003393345272882
  - -0.5546116504854369
  - -0.5774430632429
  - -0.549435308103824
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.3938406946146792
  - -0.43459996103516574
  - -0.41536512928022357
  - -0.43325220409273735
  - -0.42771258503401355
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.25796741246802746
  - 0.2230731559276686
  - 0.2522090206369714
  - 0.23067154814231233
  - 0.246448909410165
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.24157441574415744
  - 0.20454158387737723
  - 0.23422580041190788
  - 0.21570790359053554
  - 0.23360831041857624
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.24541126482257491
  - 0.20790073425203157
  - 0.2390635625580195
  - 0.2204073340889694
  - 0.23784620820452634
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.3218896587853384
  - 0.3034308502247131
  - 0.3204528868210294
  - 0.2952255033547165
  - 0.29685932203291115
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.24058854183755837
  - 0.20901628220703658
  - 0.23129741712080276
  - 0.21125431833980388
  - 0.2222325692319953
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.08941913294242133
  - 0.08737053527150183
  - 0.08852475015646293
  - 0.06180256761142626
  - 0.053630363266058745
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - -0.007076226962384626
  - -0.04085443775295225
  - -0.003722983211545477
  - -0.04230619276910934
  - -0.021609306625232933
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - -0.008898042980576564
  - -0.0465741698182541
  - -0.01139261593358277
  - -0.05096374155543324
  - -0.026017313990926327
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.11161129309511425
  - 0.1180329648146027
  - 0.09584959491297361
  - 0.0725861622773669
  - 0.05994672388697921
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.5975446048119549
  - 0.5681565630995228
  - 0.5861844275663416
  - 0.5731107328667036
  - 0.5845503174462926
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -96.27551020408163
  - -97.2621359223301
  - -96.26041666666667
  - -97.44859813084112
  - -95.40816326530613
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.6108579354071726
  - -0.6603826939391082
  - -0.6204490291262135
  - -0.6451320206877779
  - -0.6212601545472557
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.6108579354071726
  - -0.6603826939391083
  - -0.6204490291262136
  - -0.6451320206877779
  - -0.6212601545472558
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.6108579354071726
  - -0.6603826939391082
  - -0.6204490291262136
  - -0.6451320206877779
  - -0.6212601545472558
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.5268537486393128
  - -0.5521114069552228
  - -0.5325340670859539
  - -0.5569902277256117
  - -0.5539838435374149
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.5263319834002752
  - -0.5845924007375349
  - -0.5551006827331603
  - -0.5938005610797136
  - -0.5771093709158007
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.38914206459282746
  - 0.3396173060608917
  - 0.3795509708737865
  - 0.354867979312222
  - 0.37873984545274425
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.3795509708737864
  - 0.35486797931222214
  - 0.3787398454527442
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.37955097087378636
  - 0.3548679793122221
  - 0.37873984545274414
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.47314625136068716
  - 0.4478885930447771
  - 0.4674659329140462
  - 0.44300977227438826
  - 0.446016156462585
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.38914206459282746
  - 0.3396173060608917
  - 0.3795509708737865
  - 0.354867979312222
  - 0.37873984545274425
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.3795509708737864
  - 0.35486797931222214
  - 0.3787398454527442
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.3891420645928274
  - 0.3396173060608917
  - 0.37955097087378636
  - 0.3548679793122221
  - 0.37873984545274414
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.47314625136068716
  - 0.4478885930447771
  - 0.4674659329140462
  - 0.44300977227438826
  - 0.446016156462585
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5735377873425251
  - 0.5815647936139559
  - 0.5940290696119912
  - 0.5701546391377977
  - 0.5434804569317462
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.48952166425360716
  - 0.44416309201537074
  - 0.47172340008790337
  - 0.44626336051794185
  - 0.45216459253964125
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.4848176261283818
  - 0.4279520968605186
  - 0.4565925599257114
  - 0.4296684514921505
  - 0.4418030970956792
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5865187259366095
  - 0.5929597940647959
  - 0.590504002116036
  - 0.5739881202824021
  - 0.5472158579093874
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.2242916584109372
  - 0.1741917240079178
  - 0.2041868932038835
  - 0.191906360584339
  - 0.21279968297998808
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.22429165841093718
  - 0.1741917240079178
  - 0.2041868932038835
  - 0.191906360584339
  - 0.2127996829799881
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.22429165841093715
  - 0.17419172400791777
  - 0.20418689320388342
  - 0.19190636058433896
  - 0.21279968297998808
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.24646221361287057
  - 0.22530197746533753
  - 0.2276074423480084
  - 0.22419612197327884
  - 0.2176105442176871
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.16485040618189023
  - 0.16542558205297392
  - 0.17536407766990295
  - 0.1629616187278831
  - 0.1659401624727561
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.16485040618189023
  - 0.1654255820529739
  - 0.17536407766990292
  - 0.16296161872788315
  - 0.1659401624727561
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.1648504061818902
  - 0.16542558205297386
  - 0.1753640776699029
  - 0.16296161872788312
  - 0.1659401624727561
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.22668403774781645
  - 0.22258661557943957
  - 0.23985849056603764
  - 0.21881365030110955
  - 0.228405612244898
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.2984030309552225
  - 0.29333526271894117
  - 0.3144072932490066
  - 0.2880443873216084
  - 0.27501143114664384
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.22132799367470088
  - 0.1936747106142827
  - 0.21577785119548687
  - 0.19569886853818286
  - 0.20603838991791976
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.24035939618846341
  - 0.20840339292834803
  - 0.23197940021229124
  - 0.2084775772593174
  - 0.22121684169320138
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.43826247120627443
  - 0.4247807299533896
  - 0.43698548993921066
  - 0.4110808198497928
  - 0.3987401160059403
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.3888448583316823
  - 0.33876896974267134
  - 0.37894417475728165
  - 0.35432356410489046
  - 0.37913612046760453
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.3888448583316822
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048907
  - 0.37913612046760453
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.3888448583316821
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048906
  - 0.37913612046760453
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.47304768190350505
  - 0.446963178231646
  - 0.46712089447938504
  - 0.4426788826224107
  - 0.44577806122448965
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.07083415890628095
  - -0.059949099820906765
  - -0.0651294498381877
  - -0.06787042918065511
  - -0.07192391519714682
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.07083415890628096
  - -0.05994909982090678
  - -0.0651294498381877
  - -0.06787042918065511
  - -0.07192391519714682
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.07083415890628095
  - -0.05994909982090679
  - -0.06512944983818769
  - -0.06787042918065511
  - -0.07192391519714682
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.13177879299556866
  - -0.11687420852680457
  - -0.11633473095737248
  - -0.12366816915079008
  - -0.12642857142857142
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.5403209827620368
  - -0.6012819304364219
  - -0.5559263754045307
  - -0.5778060067144544
  - -0.5489399643352486
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.5403209827620369
  - -0.6012819304364219
  - -0.5559263754045307
  - -0.5778060067144543
  - -0.5489399643352486
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.5403209827620368
  - -0.6012819304364219
  - -0.5559263754045307
  - -0.5778060067144541
  - -0.5489399643352486
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.3951735251009266
  - -0.4361626132415495
  - -0.4165443745632424
  - -0.4336529482267992
  - -0.42779336734693874
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.25718631497119354
  - 0.22223800318168277
  - 0.2518289039767952
  - 0.23001261515298127
  - 0.24669525278381682
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.24134538523027732
  - 0.2039264639128461
  - 0.2337638031068688
  - 0.21530572862105088
  - 0.23390990770735284
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.24542526119339914
  - 0.20739836305153578
  - 0.23852090460065456
  - 0.2200648375439461
  - 0.23824784546780517
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.3212944116421245
  - 0.3025172885124665
  - 0.32006906404850766
  - 0.29474590320330124
  - 0.29659491416073974
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.2403593961884634
  - 0.20840339292834797
  - 0.23197940021229127
  - 0.20847757725931737
  - 0.2212168416932014
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.08933939609820653
  - 0.08672206443371679
  - 0.09074694897924857
  - 0.059969867431206865
  - 0.0539827223278951
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - -0.006902514630440722
  - -0.04170699595062329
  - -0.0025704771015779594
  - -0.043525342451859954
  - -0.02137588770453237
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - -0.00954977981433936
  - -0.047133825557877665
  - -0.009445493076286822
  - -0.05273520954675327
  - -0.026773901198764424
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.10912832397467327
  - 0.11618110514817384
  - 0.1011021011254281
  - 0.07212930472824175
  - 0.060292914010913294
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.5982660644352946
  - 0.5669246030481288
  - 0.5877029187112907
  - 0.5675266685232911
  - 0.5840940297776875
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -96.16326530612245
  - -97.10679611650485
  - -96.39583333333333
  - -97.44859813084112
  - -95.41836734693878
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.6111551416683177
  - -0.6612310302573285
  - -0.6210558252427184
  - -0.6456764358951093
  - -0.6208638795323954
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.6111551416683179
  - -0.6612310302573287
  - -0.6210558252427184
  - -0.6456764358951094
  - -0.6208638795323955
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.6111551416683179
  - -0.6612310302573288
  - -0.6210558252427184
  - -0.6456764358951093
  - -0.6208638795323955
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.526952318096495
  - -0.553036821768354
  - -0.5328791055206149
  - -0.5573211173775893
  - -0.5542219387755103
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.5269033945399763
  - -0.5860980057659203
  - -0.5557419709181605
  - -0.5913154624501559
  - -0.5779348339236453
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.3888448583316823
  - 0.33876896974267134
  - 0.37894417475728165
  - 0.35432356410489046
  - 0.37913612046760453
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.3888448583316822
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048907
  - 0.37913612046760453
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.3888448583316821
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048906
  - 0.37913612046760453
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.47304768190350505
  - 0.446963178231646
  - 0.46712089447938504
  - 0.4426788826224107
  - 0.44577806122448965
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.3888448583316823
  - 0.33876896974267134
  - 0.37894417475728165
  - 0.35432356410489046
  - 0.37913612046760453
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.3888448583316822
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048907
  - 0.37913612046760453
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.3888448583316821
  - 0.33876896974267134
  - 0.37894417475728154
  - 0.3543235641048906
  - 0.37913612046760453
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.47304768190350505
  - 0.446963178231646
  - 0.46712089447938504
  - 0.4426788826224107
  - 0.44577806122448965
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5712012139563222
  - 0.5778090940465817
  - 0.5916515019020906
  - 0.5686385734254709
  - 0.5379916063016505
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.4892898330286992
  - 0.443877796582092
  - 0.47207459434115945
  - 0.44327669257198493
  - 0.45147812689541633
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.4843346922783966
  - 0.4274047354601047
  - 0.4572812773919764
  - 0.42807848025976786
  - 0.4420034768654546
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5843333054020623
  - 0.5902172528252759
  - 0.5898133654653984
  - 0.572754200210719
  - 0.5437955487054357
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.22379631464236183
  - 0.17324912809878404
  - 0.20287216828478966
  - 0.19154341711278466
  - 0.21329502674856352
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.2237963146423618
  - 0.17324912809878404
  - 0.20287216828478966
  - 0.1915434171127847
  - 0.21329502674856352
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.22379631464236177
  - 0.17324912809878398
  - 0.2028721682847896
  - 0.19154341711278464
  - 0.2132950267485635
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.2451293831266231
  - 0.22373932525895376
  - 0.22642819706498948
  - 0.223795377839217
  - 0.2175297619047619
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.1650485436893204
  - 0.16551984164388728
  - 0.1760720064724919
  - 0.1627801469921059
  - 0.16584109371904102
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.1650485436893204
  - 0.16551984164388728
  - 0.1760720064724919
  - 0.16278014699210597
  - 0.16584109371904102
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.16504854368932034
  - 0.16551984164388725
  - 0.17607200647249188
  - 0.162780146992106
  - 0.16584109371904102
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.22791829877688158
  - 0.22322385297269212
  - 0.24069269741439545
  - 0.2188835047831937
  - 0.2282482993197279
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.3018727430225701
  - 0.29453239232760714
  - 0.31454621995200777
  - 0.2859633814872476
  - 0.2782021363045471
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.22232417848638208
  - 0.19410214917488228
  - 0.21556443621793855
  - 0.1985745817414968
  - 0.2061940039583809
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.24168684545107755
  - 0.20884717824004173
  - 0.23145425331406896
  - 0.21216566385664082
  - 0.22211318064302685
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.44049740880421007
  - 0.4262758448697878
  - 0.43809866935575376
  - 0.4078549464208745
  - 0.4012116369088072
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.38844858331682186
  - 0.33782637383353753
  - 0.37702265372168287
  - 0.35523092278377627
  - 0.3788389142064593
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.38844858331682186
  - 0.3378263738335376
  - 0.37702265372168287
  - 0.35523092278377644
  - 0.37883891420645927
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.3884485833168218
  - 0.3378263738335374
  - 0.3770226537216828
  - 0.35523092278377644
  - 0.3788389142064592
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.4723405531889364
  - 0.44606211643991306
  - 0.4654219077568135
  - 0.442359022625499
  - 0.44486819727891147
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.07182484644343175
  - -0.0598548402299934
  - -0.06603964401294499
  - -0.06796116504854369
  - -0.0720229839508619
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.07182484644343175
  - -0.0598548402299934
  - -0.06603964401294499
  - -0.06796116504854369
  - -0.0720229839508619
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.07182484644343173
  - -0.05985484022999341
  - -0.06603964401294497
  - -0.06796116504854369
  - -0.07202298395086187
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.13295734085318292
  - -0.11633844205604442
  - -0.11750960866526905
  - -0.12446965741891367
  - -0.12652210884353743
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.5397265702397464
  - -0.602318785936469
  - -0.5569377022653721
  - -0.57680791216768
  - -0.5491381018426789
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.5397265702397464
  - -0.602318785936469
  - -0.5569377022653722
  - -0.5768079121676799
  - -0.5491381018426789
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.5397265702397464
  - -0.602318785936469
  - -0.5569377022653721
  - -0.5768079121676798
  - -0.5491381018426787
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.39470210595788086
  - -0.4375994415040427
  - -0.4170684835779176
  - -0.4331713199555873
  - -0.428609693877551
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.2569801701544554
  - 0.22154159184036856
  - 0.2501020351639952
  - 0.23078813467281964
  - 0.24634234501231006
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.2410401426200283
  - 0.20324373369626858
  - 0.23230309072781655
  - 0.2159761681469631
  - 0.2336836959178685
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.24497141990930507
  - 0.2066653924265101
  - 0.23699872413614984
  - 0.22072481985337158
  - 0.23784289483656335
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.3208712501415429
  - 0.30187366415318756
  - 0.31829942933327077
  - 0.29446708218890283
  - 0.2958160830353482
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.24168684545107752
  - 0.20884717824004168
  - 0.2314542533140689
  - 0.21216566385664082
  - 0.22211318064302693
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.08505743785548894
  - 0.0851042710878976
  - 0.08620972314033017
  - 0.06177865935742555
  - 0.0526192482583151
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - -0.010073661150561939
  - -0.04268904807892623
  - -0.007503601187284791
  - -0.042598687913250305
  - -0.022016127610927697
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - -0.012400785499100503
  - -0.048684799118671504
  - -0.014030537635491114
  - -0.0518427989081476
  - -0.02758103774442095
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.10572421401432451
  - 0.11386601352073138
  - 0.09686619508381124
  - 0.07204620986306373
  - 0.0581827082619871
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.5992646981515994
  - 0.5680900117157606
  - 0.5873126101953127
  - 0.5741286859178157
  - 0.5835199589584037
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -96.13265306122449
  - -97.09708737864078
  - -96.36458333333333
  - -97.34579439252336
  - -95.55102040816327
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.6115514166831781
  - -0.6621736261664624
  - -0.622977346278317
  - -0.6447690772162236
  - -0.6211610857935407
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.6115514166831781
  - -0.6621736261664625
  - -0.6229773462783171
  - -0.6447690772162236
  - -0.6211610857935407
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.6115514166831781
  - -0.6621736261664625
  - -0.6229773462783171
  - -0.6447690772162233
  - -0.6211610857935407
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5276594468110636
  - -0.553937883560087
  - -0.5345780922431865
  - -0.5576409773745009
  - -0.5551318027210885
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.5255286733659476
  - -0.5847703917237969
  - -0.5566942432078638
  - -0.5929833441170531
  - -0.5762738770374473
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.38844858331682186
  - 0.33782637383353753
  - 0.37702265372168287
  - 0.35523092278377627
  - 0.3788389142064593
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.38844858331682186
  - 0.3378263738335376
  - 0.37702265372168287
  - 0.35523092278377644
  - 0.37883891420645927
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.3884485833168218
  - 0.3378263738335374
  - 0.3770226537216828
  - 0.35523092278377644
  - 0.3788389142064592
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.4723405531889364
  - 0.44606211643991306
  - 0.4654219077568135
  - 0.442359022625499
  - 0.44486819727891147
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.38844858331682186
  - 0.33782637383353753
  - 0.37702265372168287
  - 0.35523092278377627
  - 0.3788389142064593
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.38844858331682186
  - 0.3378263738335376
  - 0.37702265372168287
  - 0.35523092278377644
  - 0.37883891420645927
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.3884485833168218
  - 0.3378263738335374
  - 0.3770226537216828
  - 0.35523092278377644
  - 0.3788389142064592
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.4723405531889364
  - 0.44606211643991306
  - 0.4654219077568135
  - 0.442359022625499
  - 0.44486819727891147
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5722193172214262
  - 0.5784701150281248
  - 0.5906235537201585
  - 0.567571197790931
  - 0.5401990877458831
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.49069680216664047
  - 0.44530119566133186
  - 0.47134535424125246
  - 0.4466386339407148
  - 0.4520637563902608
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.485978992971095
  - 0.42897358302398997
  - 0.45625136468407906
  - 0.4311291099906965
  - 0.4420996987357301
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5854599427935923
  - 0.5912969974450294
  - 0.5884923866990474
  - 0.5726575304203136
  - 0.5456105040304251
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.2243907271646523
  - 0.1722122725987369
  - 0.20186084142394822
  - 0.19254151165955902
  - 0.21309688924113335
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.22439072716465228
  - 0.17221227259873692
  - 0.20186084142394822
  - 0.19254151165955902
  - 0.21309688924113335
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.2243907271646522
  - 0.17221227259873687
  - 0.20186084142394814
  - 0.192541511659559
  - 0.21309688924113332
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.24560080226966888
  - 0.2223024969964607
  - 0.22590408805031448
  - 0.22427700611042892
  - 0.21671343537414964
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.1640578561521696
  - 0.16561410123480064
  - 0.17516181229773467
  - 0.1626894111242174
  - 0.16574202496532595
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.1640578561521696
  - 0.16561410123480064
  - 0.17516181229773461
  - 0.1626894111242174
  - 0.16574202496532595
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.16405785615216956
  - 0.16561410123480064
  - 0.17516181229773461
  - 0.1626894111242174
  - 0.1657420249653259
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.2267397509192673
  - 0.22375961944345224
  - 0.23951781970649885
  - 0.21808201651507017
  - 0.2281547619047619
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.29955762989108725
  - 0.2922834691530054
  - 0.3141798074060026
  - 0.28319089629934086
  - 0.2734927747155847
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.22076240918914397
  - 0.19340624859862515
  - 0.2155627576908611
  - 0.1969773822621143
  - 0.2049093722555411
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.23932542334739015
  - 0.20842481698292484
  - 0.23149321444499493
  - 0.21058061150426638
  - 0.22088556468387247
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.439079763662546
  - 0.42391177119574985
  - 0.43749462801205974
  - 0.40523290464039396
  - 0.3966438003937611
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.3889439270853973
  - 0.3365067395607503
  - 0.37560679611650477
  - 0.35668269666999347
  - 0.37784822666930845
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.38894392708539727
  - 0.3365067395607503
  - 0.3756067961165049
  - 0.35668269666999364
  - 0.3778482266693085
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.3889439270853972
  - 0.33650673956075033
  - 0.3756067961165048
  - 0.3566826966699937
  - 0.37784822666930845
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.4730476819035048
  - 0.44486881839140174
  - 0.4637360237596087
  - 0.4439472929549915
  - 0.44387329931972774
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.07172577768971665
  - -0.060137619002733525
  - -0.065331715210356
  - -0.06823337265220941
  - -0.07241925896572221
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.07172577768971666
  - -0.060137619002733525
  - -0.06533171521035598
  - -0.06823337265220941
  - -0.07241925896572221
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.07172577768971665
  - -0.06013761900273354
  - -0.06533171521035598
  - -0.06823337265220941
  - -0.0724192589657222
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.13318876479613267
  - -0.11682144364710847
  - -0.11674965059399023
  - -0.1252049677566417
  - -0.12676445578231293
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.539330295224886
  - -0.6033556414365161
  - -0.5590614886731392
  - -0.5750839306777971
  - -0.5497325143649693
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.5393302952248861
  - -0.6033556414365162
  - -0.5590614886731392
  - -0.575083930677797
  - -0.5497325143649693
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.5393302952248861
  - -0.6033556414365161
  - -0.5590614886731392
  - -0.575083930677797
  - -0.5497325143649693
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.39376355330036267
  - -0.43830973796148975
  - -0.4195143256464012
  - -0.4308477392883667
  - -0.4293622448979592
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.2573862239947839
  - 0.22049220548627244
  - 0.24905652799964495
  - 0.23206076753522334
  - 0.24561401459197074
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.24142171934571394
  - 0.20228921124206709
  - 0.23122898767276803
  - 0.2170504113522169
  - 0.23293025528276537
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.2454533362630356
  - 0.20560474977646362
  - 0.23590153030800662
  - 0.22185870500477634
  - 0.23716085392625585
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.3214876789873483
  - 0.30096276050085724
  - 0.3168506716739544
  - 0.29582836950433555
  - 0.2949519222229823
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.23932542334739013
  - 0.20842481698292484
  - 0.2314932144449949
  - 0.21058061150426632
  - 0.22088556468387258
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.08768377123475664
  - 0.08050413719862141
  - 0.08581739445628413
  - 0.06222784625393895
  - 0.04934730100404507
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - -0.009198254459644967
  - -0.04530721374457885
  - -0.007397079618517869
  - -0.041478324349683696
  - -0.024328131526224036
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - -0.011714361240675876
  - -0.05150253910448003
  - -0.014327473387887162
  - -0.04991231931654708
  - -0.02988340247970885
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.10634133966637213
  - 0.11155586346642583
  - 0.09370329355617778
  - 0.07434539158431819
  - 0.05520631368737135
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.5960372190957418
  - 0.5670291737617985
  - 0.5876219115106923
  - 0.5718696876040954
  - 0.5821793997707309
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -96.22448979591837
  - -97.04854368932038
  - -96.28125
  - -97.29906542056075
  - -95.57142857142857
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.6110560729146026
  - -0.6634932604392496
  - -0.6243932038834952
  - -0.6433173033300064
  - -0.6221517733306915
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.6110560729146027
  - -0.6634932604392497
  - -0.6243932038834952
  - -0.6433173033300064
  - -0.6221517733306915
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.6110560729146027
  - -0.6634932604392497
  - -0.6243932038834951
  - -0.6433173033300061
  - -0.6221517733306914
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.526952318096495
  - -0.5551311816085982
  - -0.5362639762403912
  - -0.5560527070450084
  - -0.5561267006802721
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.5273379225530973
  - -0.5847482646169194
  - -0.5575875838349789
  - -0.5929400130462121
  - -0.5755423108631568
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.3889439270853973
  - 0.3365067395607503
  - 0.37560679611650477
  - 0.35668269666999347
  - 0.37784822666930845
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.38894392708539727
  - 0.3365067395607503
  - 0.3756067961165049
  - 0.35668269666999364
  - 0.3778482266693085
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.3889439270853972
  - 0.33650673956075033
  - 0.3756067961165048
  - 0.3566826966699937
  - 0.37784822666930845
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.4730476819035048
  - 0.44486881839140174
  - 0.4637360237596087
  - 0.4439472929549915
  - 0.44387329931972774
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.3889439270853973
  - 0.3365067395607503
  - 0.37560679611650477
  - 0.35668269666999347
  - 0.37784822666930845
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.38894392708539727
  - 0.3365067395607503
  - 0.3756067961165049
  - 0.35668269666999364
  - 0.3778482266693085
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.3889439270853972
  - 0.33650673956075033
  - 0.3756067961165048
  - 0.3566826966699937
  - 0.37784822666930845
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.4730476819035048
  - 0.44486881839140174
  - 0.4637360237596087
  - 0.4439472929549915
  - 0.44387329931972774
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5707548419537274
  - 0.5759110837762722
  - 0.589672872346831
  - 0.5658690203747918
  - 0.5366980847432394
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.4886673872901383
  - 0.4438908975315471
  - 0.47070351454107384
  - 0.4443932336557138
  - 0.4505017167056581
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.4831466461896528
  - 0.42784980784771304
  - 0.4560956771246913
  - 0.4299359005095704
  - 0.4416692168309438
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5834064843824903
  - 0.5891084208095924
  - 0.587312978166679
  - 0.5702392022517611
  - 0.5446929530496355
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.2247870021795126
  - 0.17117541709868977
  - 0.19973705501618125
  - 0.19426549314944197
  - 0.21250247671884287
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.22478700217951258
  - 0.1711754170986898
  - 0.19973705501618122
  - 0.19426549314944197
  - 0.21250247671884287
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.22478700217951253
  - 0.17117541709868975
  - 0.19973705501618122
  - 0.19426549314944194
  - 0.21250247671884284
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.24653935492718718
  - 0.22159220053901352
  - 0.22345824598183087
  - 0.2266005867776495
  - 0.21596088435374153
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.1641569249058847
  - 0.1653313224620605
  - 0.1758697411003237
  - 0.16241720352055164
  - 0.16534574995046564
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.16415692490588468
  - 0.1653313224620605
  - 0.17586974110032363
  - 0.16241720352055167
  - 0.16534574995046564
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.16415692490588465
  - 0.1653313224620605
  - 0.17586974110032358
  - 0.16241720352055167
  - 0.1653457499504656
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.2265083269763176
  - 0.22327661785238817
  - 0.24027777777777773
  - 0.2173467061773421
  - 0.22791241496598638
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.2974532124834258
  - 0.2952172788471988
  - 0.3135652476037449
  - 0.2880226493344672
  - 0.27576327955099733
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.22152763739648573
  - 0.193374478377036
  - 0.21518440626302165
  - 0.19848324541042123
  - 0.205235155869548
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.2402265633838488
  - 0.20785060412417602
  - 0.23089840662491487
  - 0.21200316144919068
  - 0.22110958688582075
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.43705237076306136
  - 0.42602061648338435
  - 0.4382547406903998
  - 0.4112131486357816
  - 0.3984796739319728
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.38934020210025755
  - 0.33650673956075033
  - 0.37489886731391586
  - 0.3553216586516649
  - 0.3791361204676046
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.37489886731391586
  - 0.355321658651665
  - 0.37913612046760453
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.3748988673139158
  - 0.355321658651665
  - 0.3791361204676044
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.47423908664683867
  - 0.4457658213462351
  - 0.4641334730957373
  - 0.4424325536592718
  - 0.44468537414965975
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.07093322765999605
  - -0.05947780186633989
  - -0.06462378640776698
  - -0.06796116504854369
  - -0.07232019021200713
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.07093322765999603
  - -0.0594778018663399
  - -0.06462378640776699
  - -0.06796116504854369
  - -0.07232019021200713
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.07093322765999602
  - -0.05947780186633991
  - -0.06462378640776699
  - -0.06796116504854369
  - -0.07232019021200713
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.1313202307382424
  - -0.1155916160665
  - -0.11519479385045424
  - -0.12456524776281827
  - -0.1271045918367347
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.5397265702397464
  - -0.6040154585729097
  - -0.5604773462783172
  - -0.5767171762997915
  - -0.5485436893203883
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.5397265702397464
  - -0.6040154585729098
  - -0.5604773462783171
  - -0.5767171762997914
  - -0.5485436893203883
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.5397265702397464
  - -0.6040154585729097
  - -0.5604773462783171
  - -0.5767171762997912
  - -0.5485436893203883
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.39444068261491916
  - -0.43864256258726503
  - -0.42067173305380856
  - -0.43300219857790984
  - -0.4282100340136055
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.2578381500228729
  - 0.22074294430683505
  - 0.248772158977826
  - 0.2308905450653538
  - 0.24672192248625247
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.24172714971091155
  - 0.20228921124206709
  - 0.2306926379986309
  - 0.21604325278605319
  - 0.23390990770735284
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.24571772990139337
  - 0.20562380316671833
  - 0.23515142082155002
  - 0.22086574351666116
  - 0.23818540437267696
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.32262818005616933
  - 0.3019694221090672
  - 0.3176690643924258
  - 0.2945151980532354
  - 0.295671731000953
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.2402265633838488
  - 0.20785060412417594
  - 0.23089840662491487
  - 0.21200316144919062
  - 0.22110958688582083
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.08790659637788656
  - 0.08411751444654933
  - 0.08537344485184738
  - 0.0632866265069891
  - 0.0519979612561953
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - -0.006564704694229979
  - -0.04333800778616164
  - -0.006377257255774922
  - -0.042480703901327056
  - -0.022438437388788833
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - -0.008510003514146228
  - -0.04926695886720563
  - -0.013381700928706363
  - -0.051420473019972185
  - -0.027837516530513667
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.10700931712375035
  - 0.11448033797723119
  - 0.09465061554110185
  - 0.07326689323724925
  - 0.05701762403220211
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.5970552479065191
  - 0.5659111889483918
  - 0.588034948936862
  - 0.5739426655548705
  - 0.5816955852929988
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -96.10204081632654
  - -97.01941747572816
  - -96.34375
  - -97.26168224299066
  - -95.59183673469387
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.6106597978997425
  - -0.6634932604392496
  - -0.625101132686084
  - -0.6446783413483349
  - -0.6208638795323954
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.6106597978997425
  - -0.6634932604392497
  - -0.6251011326860841
  - -0.644678341348335
  - -0.6208638795323955
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.6106597978997423
  - -0.6634932604392496
  - -0.6251011326860841
  - -0.6446783413483349
  - -0.6208638795323954
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.5257609133531613
  - -0.5542341786537648
  - -0.5358665269042627
  - -0.5575674463407282
  - -0.5553146258503402
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.5280175977496419
  - -0.5842989115924674
  - -0.5594510863231551
  - -0.5927728956802056
  - -0.5757849950775473
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.38934020210025755
  - 0.33650673956075033
  - 0.37489886731391586
  - 0.3553216586516649
  - 0.3791361204676046
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.37489886731391586
  - 0.355321658651665
  - 0.37913612046760453
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.3748988673139158
  - 0.355321658651665
  - 0.3791361204676044
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.47423908664683867
  - 0.4457658213462351
  - 0.4641334730957373
  - 0.4424325536592718
  - 0.44468537414965975
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.38934020210025755
  - 0.33650673956075033
  - 0.37489886731391586
  - 0.3553216586516649
  - 0.3791361204676046
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.37489886731391586
  - 0.355321658651665
  - 0.37913612046760453
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.3893402021002576
  - 0.3365067395607503
  - 0.3748988673139158
  - 0.355321658651665
  - 0.3791361204676044
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.47423908664683867
  - 0.4457658213462351
  - 0.4641334730957373
  - 0.4424325536592718
  - 0.44468537414965975
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5693571044572074
  - 0.5767991817222095
  - 0.5880339714576831
  - 0.5675160154525954
  - 0.5393450558718128
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.4896622332041885
  - 0.4449402708635291
  - 0.46934478479747166
  - 0.4466181269427713
  - 0.4506567346850359
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.48360350296065285
  - 0.4285538594892545
  - 0.45453611177185677
  - 0.43117591802360644
  - 0.4406406968725461
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5825692301158352
  - 0.5917442446573035
  - 0.5867777980120752
  - 0.5727503774442443
  - 0.5457192677562095
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.22439072716465222
  - 0.17051559996229615
  - 0.19832119741100324
  - 0.19263224752744762
  - 0.21369130176342382
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.22439072716465228
  - 0.17051559996229618
  - 0.19832119741100324
  - 0.1926322475274476
  - 0.21369130176342382
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.2243907271646522
  - 0.17051559996229615
  - 0.19832119741100318
  - 0.19263224752744756
  - 0.2136913017634238
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.2458622256126306
  - 0.22125937591323835
  - 0.22230083857442343
  - 0.22444612748810636
  - 0.21711309523809524
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.16494947493560533
  - 0.16599113959845413
  - 0.17657766990291265
  - 0.1626894111242174
  - 0.1654448187041807
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.1649494749356053
  - 0.16599113959845413
  - 0.17657766990291263
  - 0.1626894111242174
  - 0.1654448187041807
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.16494947493560527
  - 0.16599113959845413
  - 0.1765776699029126
  - 0.1626894111242174
  - 0.16544481870418068
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.2283768610342079
  - 0.2245064454329967
  - 0.24183263452131368
  - 0.2179864261711655
  - 0.22757227891156465
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.29892831876427456
  - 0.29441425350657735
  - 0.3199788941947872
  - 0.28717384306416777
  - 0.27627796015402395
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.22297611403119194
  - 0.19248243176950172
  - 0.21554435256467366
  - 0.19747854219093441
  - 0.20540270267998412
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.24045394333004047
  - 0.20728846962766337
  - 0.2313300966823333
  - 0.2109757416510609
  - 0.22134336392796555
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.4376656034692522
  - 0.4268579245554614
  - 0.4443035102680715
  - 0.4090611172316466
  - 0.39950003082910535
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.38834951456310685
  - 0.3338674710151758
  - 0.3752022653721682
  - 0.3549587151801106
  - 0.37913612046760453
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.3883495145631068
  - 0.3338674710151758
  - 0.3752022653721683
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.3883495145631068
  - 0.3338674710151759
  - 0.3752022653721682
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.47395194953243813
  - 0.4400509789914603
  - 0.46441736547868634
  - 0.4415979764259504
  - 0.44420068027210874
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.07093322765999603
  - -0.060985955320953904
  - -0.06411812297734629
  - -0.06823337265220941
  - -0.07212205270457697
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.07093322765999603
  - -0.060985955320953904
  - -0.06411812297734627
  - -0.06823337265220941
  - -0.07212205270457697
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.07093322765999603
  - -0.06098595532095392
  - -0.06411812297734627
  - -0.06823337265220941
  - -0.07212205270457696
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.1319202187384824
  - -0.11919586323343183
  - -0.11502445842068486
  - -0.12555056361537387
  - -0.126875
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.540717257776897
  - -0.6051465736638703
  - -0.5606796116504855
  - -0.57680791216768
  - -0.5487418268278186
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.5407172577768972
  - -0.6051465736638703
  - -0.5606796116504854
  - -0.5768079121676799
  - -0.5487418268278185
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.5407172577768972
  - -0.6051465736638703
  - -0.5606796116504854
  - -0.5768079121676798
  - -0.5487418268278185
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.3941278317290798
  - -0.44075315777510793
  - -0.42055817610062896
  - -0.4328514599586755
  - -0.4289243197278912
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.2569809251832222
  - 0.2181923011900911
  - 0.2491136530425944
  - 0.2307008596713633
  - 0.24675482112738062
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.24096385542168675
  - 0.2003847024213623
  - 0.23092244491472674
  - 0.2157749586321015
  - 0.23390990770735284
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.24489171163636997
  - 0.20371081853717907
  - 0.23549478619584163
  - 0.22056984316215358
  - 0.23812504373858692
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.3222631410305326
  - 0.2965616183087984
  - 0.3180368984244498
  - 0.2939281665435198
  - 0.2953142671710873
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.24045394333004041
  - 0.2072884696276634
  - 0.23133009668233337
  - 0.21097574165106084
  - 0.22134336392796558
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.08816078644292767
  - 0.07876041156602646
  - 0.08931220519577912
  - 0.06140607194022295
  - 0.05191226599293855
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - -0.007778898681274262
  - -0.05140095476419694
  - -0.004603002142443188
  - -0.043716592642566096
  - -0.021907373423385397
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - -0.009903929175732061
  - -0.05742017945457324
  - -0.011407685226486336
  - -0.05279685177066798
  - -0.02767323692261084
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.10996024627510327
  - 0.10408616079105029
  - 0.09728728155661007
  - 0.07218387003618101
  - 0.05669813926631236
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.6000054504453229
  - 0.5646990000376461
  - 0.5877467136459291
  - 0.5719524172381911
  - 0.5826849437292093
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -96.05102040816327
  - -97.07766990291262
  - -96.20833333333333
  - -97.25233644859813
  - -95.51020408163265
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.6116504854368932
  - -0.6661325289848241
  - -0.6247977346278317
  - -0.6450412848198893
  - -0.6208638795323954
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.6116504854368932
  - -0.6661325289848242
  - -0.6247977346278317
  - -0.6450412848198893
  - -0.6208638795323955
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.6116504854368932
  - -0.6661325289848242
  - -0.6247977346278316
  - -0.6450412848198892
  - -0.6208638795323955
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5260480504675619
  - -0.5599490210085397
  - -0.5355826345213135
  - -0.5584020235740496
  - -0.5557993197278912
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.5296859992172468
  - -0.5851923763690497
  - -0.5592061793370458
  - -0.590792686867353
  - -0.5766553407543309
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.38834951456310685
  - 0.3338674710151758
  - 0.3752022653721682
  - 0.3549587151801106
  - 0.37913612046760453
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.3883495145631068
  - 0.3338674710151758
  - 0.3752022653721683
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.3883495145631068
  - 0.3338674710151759
  - 0.3752022653721682
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.47395194953243813
  - 0.4400509789914603
  - 0.46441736547868634
  - 0.4415979764259504
  - 0.44420068027210874
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.38834951456310685
  - 0.3338674710151758
  - 0.3752022653721682
  - 0.3549587151801106
  - 0.37913612046760453
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.3883495145631068
  - 0.3338674710151758
  - 0.3752022653721683
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.3883495145631068
  - 0.3338674710151759
  - 0.3752022653721682
  - 0.3549587151801107
  - 0.37913612046760453
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.47395194953243813
  - 0.4400509789914603
  - 0.46441736547868634
  - 0.4415979764259504
  - 0.44420068027210874
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5700852548691819
  - 0.5769162679512959
  - 0.5896803387563394
  - 0.5672302616676193
  - 0.5384251766488083
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.4901769992604815
  - 0.4427831168598586
  - 0.46954920337944483
  - 0.44538749828451074
  - 0.4505967312191318
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.48350429767584846
  - 0.42644577034315456
  - 0.453807735998414
  - 0.43108524492086975
  - 0.4409127582897513
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5828079585630727
  - 0.5910672372933217
  - 0.5867488950750189
  - 0.5716194316639424
  - 0.5448250357658213
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.22340003962750155
  - 0.16938448487133564
  - 0.1981189320388349
  - 0.192541511659559
  - 0.21349316425599368
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.2234000396275015
  - 0.16938448487133567
  - 0.19811893203883496
  - 0.19254151165955902
  - 0.21349316425599366
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.22340003962750143
  - 0.1693844848713356
  - 0.1981189320388349
  - 0.192541511659559
  - 0.21349316425599363
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.24617507649847
  - 0.2191487807253954
  - 0.22241439552760303
  - 0.2245968661073406
  - 0.2163988095238095
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.16494947493560533
  - 0.16448298614384013
  - 0.17708333333333334
  - 0.16241720352055164
  - 0.16564295621161085
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.1649494749356053
  - 0.16448298614384013
  - 0.17708333333333334
  - 0.16241720352055167
  - 0.16564295621161085
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.16494947493560527
  - 0.16448298614384013
  - 0.1770833333333333
  - 0.16241720352055167
  - 0.16564295621161082
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.22777687303396785
  - 0.2209021982660649
  - 0.24200296995108309
  - 0.21700111031860997
  - 0.22780187074829936
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.5710375376038712
  - 0.56801379399168
  - 0.5699412304197482
  - 0.5679531338386719
  - 0.5756425263573467
  train_level0__average_precision_macro_masked:
  - 0.24322571561409687
  - 0.2407077987967829
  - 0.2427171053369457
  - 0.24438899453084748
  - 0.25406708871820777
  train_level0__average_precision_macro_oob:
  - 0.2641620939091725
  - 0.26464787631203457
  - 0.26482805952285926
  - 0.26958097167285056
  - 0.2775209495725344
  train_level0__average_precision_micro:
  - 0.6226712594498586
  - 0.624284894295323
  - 0.6209032589026889
  - 0.6292798537681628
  - 0.6255813024716453
  train_level0__average_precision_micro_masked:
  - 0.4221634932298668
  - 0.4265667842136671
  - 0.422731714829505
  - 0.4336026263436129
  - 0.42772905151688995
  train_level0__average_precision_micro_oob:
  - 0.4830442517612652
  - 0.490034580333135
  - 0.48639126908236374
  - 0.4940104479209181
  - 0.4918404669647942
  train_level0__average_precision_samples:
  - 0.6375543669668979
  - 0.640694576331341
  - 0.6369961945750022
  - 0.6459839371764518
  - 0.6405328523263882
  train_level0__average_precision_samples_masked:
  - 0.4656067367257416
  - 0.4725134606128005
  - 0.47027498795375083
  - 0.47814162397541327
  - 0.47467484163411494
  train_level0__average_precision_samples_oob:
  - 0.5189434500593819
  - 0.5247605190717226
  - 0.5210725846905847
  - 0.5283103237552504
  - 0.5253363140348404
  train_level0__average_precision_weighted:
  - 0.6461261960966264
  - 0.6439944050748229
  - 0.647139173646167
  - 0.6482510493443334
  - 0.6510948807555791
  train_level0__average_precision_weighted_masked:
  - 0.34443043670691653
  - 0.3457085042752119
  - 0.34615272283266446
  - 0.3532066462692926
  - 0.3575627267077572
  train_level0__average_precision_weighted_oob:
  - 0.37517823393058125
  - 0.3807658401683058
  - 0.3799065551093537
  - 0.38731366462426364
  - 0.39262319961652453
  train_level0__f1_macro:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__f1_macro_masked:
  - 0.8178257394865144
  - 0.8154327274346631
  - 0.8188165067393876
  - 0.8163535116738292
  - 0.8181130472849235
  train_level0__f1_macro_oob:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__f1_micro:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__f1_micro_masked:
  - 0.8252173463051128
  - 0.8230589716023808
  - 0.8262682418346073
  - 0.8240105890138981
  - 0.8255380794701986
  train_level0__f1_micro_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__f1_samples:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__f1_samples_masked:
  - 0.8249902663872429
  - 0.8227870755582549
  - 0.8260304424263278
  - 0.8237667982031116
  - 0.8253064330360244
  train_level0__f1_samples_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__f1_weighted:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__f1_weighted_masked:
  - 0.7189862411409595
  - 0.7145519540024156
  - 0.7185595426403939
  - 0.7144609755759529
  - 0.718459311685885
  train_level0__f1_weighted_oob:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__fn_macro:
  - -0.23356243391329423
  - -0.23622162201620553
  - -0.2323162274618586
  - -0.2349268772274794
  - -0.2331058348553302
  train_level0__fn_macro_masked:
  - -0.18217426051348556
  - -0.18456727256533695
  - -0.18118349326061273
  - -0.18364648832617092
  - -0.1818869527150766
  train_level0__fn_macro_oob:
  - -0.23356243391329423
  - -0.23622162201620553
  - -0.2323162274618586
  - -0.2349268772274794
  - -0.2331058348553302
  train_level0__fn_micro:
  - -0.23356243391329423
  - -0.23622162201620556
  - -0.23231622746185854
  - -0.2349268772274794
  - -0.23310583485533018
  train_level0__fn_micro_masked:
  - -0.17478265369488719
  - -0.1769410283976191
  - -0.17373175816539263
  - -0.1759894109861019
  - -0.17446192052980133
  train_level0__fn_micro_oob:
  - -0.23356243391329423
  - -0.23622162201620556
  - -0.23231622746185854
  - -0.2349268772274794
  - -0.23310583485533018
  train_level0__fn_samples:
  - -0.2335624339132942
  - -0.23622162201620553
  - -0.23231622746185848
  - -0.23492687722747935
  - -0.23310583485533012
  train_level0__fn_samples_masked:
  - -0.17500973361275715
  - -0.17721292444174516
  - -0.17396955757367216
  - -0.17623320179688837
  - -0.17469356696397564
  train_level0__fn_samples_oob:
  - -0.2335624339132942
  - -0.23622162201620553
  - -0.23231622746185848
  - -0.23492687722747935
  - -0.23310583485533012
  train_level0__fn_weighted:
  - -0.3447281990263024
  - -0.3495011736180169
  - -0.345318168795905
  - -0.34928550806402486
  - -0.34542002653873627
  train_level0__fn_weighted_masked:
  - -0.2810137588590407
  - -0.2854480459975843
  - -0.28144045735960604
  - -0.285539024424047
  - -0.2815406883141151
  train_level0__fn_weighted_oob:
  - -0.3447281990263024
  - -0.3495011736180169
  - -0.345318168795905
  - -0.34928550806402486
  - -0.34542002653873627
  train_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__jaccard_macro:
  - 0.6457160781674675
  - 0.6428840502646415
  - 0.6477546575329296
  - 0.6446600181578346
  - 0.6466563139586152
  train_level0__jaccard_macro_masked:
  - 0.7128871922857951
  - 0.7100951445856981
  - 0.7145577451726018
  - 0.7115148007616263
  - 0.7134904660777899
  train_level0__jaccard_macro_oob:
  - 0.6457160781674675
  - 0.6428840502646415
  - 0.6477546575329296
  - 0.6446600181578346
  - 0.6466563139586152
  train_level0__jaccard_micro:
  - 0.6213204496308273
  - 0.6178328904635371
  - 0.6229600450196962
  - 0.6195290886292618
  - 0.6219207982538197
  train_level0__jaccard_micro_masked:
  - 0.7024425698742374
  - 0.6993204856856411
  - 0.7039668442865601
  - 0.7006955856200617
  - 0.7029074889867841
  train_level0__jaccard_micro_oob:
  - 0.6213204496308273
  - 0.6178328904635371
  - 0.6229600450196962
  - 0.6195290886292618
  - 0.6219207982538197
  train_level0__jaccard_samples:
  - 0.624138112394373
  - 0.6204782157366855
  - 0.6255589191383524
  - 0.6223302584070106
  - 0.6245934088468467
  train_level0__jaccard_samples_masked:
  - 0.7047900031356709
  - 0.7012050222912724
  - 0.7059319022139773
  - 0.7029598188935364
  - 0.7050497128929816
  train_level0__jaccard_samples_oob:
  - 0.624138112394373
  - 0.6204782157366855
  - 0.6255589191383524
  - 0.6223302584070106
  - 0.6245934088468467
  train_level0__jaccard_weighted:
  - 0.5168703112764017
  - 0.5117834967319771
  - 0.5162321905597476
  - 0.5125556770504812
  - 0.5158079859334127
  train_level0__jaccard_weighted_masked:
  - 0.5901708557780619
  - 0.5850078110909195
  - 0.5894939023461805
  - 0.5854011370078692
  - 0.5891357587916153
  train_level0__jaccard_weighted_oob:
  - 0.5168703112764017
  - 0.5117834967319771
  - 0.5162321905597476
  - 0.5125556770504812
  - 0.5158079859334127
  train_level0__label_ranking_average_precision_score:
  - 0.6375543669668984
  - 0.6406945763313409
  - 0.6369961945750026
  - 0.6459839371764518
  - 0.6405328523263887
  train_level0__label_ranking_average_precision_score_oob:
  - 0.518943450059382
  - 0.5247605190717227
  - 0.5210725846905849
  - 0.5283103237552507
  - 0.5253363140348399
  train_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__ndcg:
  - 0.8780347104606919
  - 0.8798740468431391
  - 0.8778003636811061
  - 0.8834602664280554
  - 0.8810378188896574
  train_level0__ndcg_oob:
  - 0.8190107178785295
  - 0.822921793906783
  - 0.8191960112573675
  - 0.8252944626106032
  - 0.8225121092686383
  train_level0__neg_coverage_error:
  - -84.87623762376238
  - -84.80952380952381
  - -84.33497536945812
  - -84.95949367088608
  - -83.88861386138613
  train_level0__neg_coverage_error_oob:
  - -90.30445544554455
  - -90.93984962406014
  - -90.5960591133005
  - -90.03037974683544
  - -89.74752475247524
  train_level0__neg_hamming_loss_macro:
  - -0.23356243391329423
  - -0.23622162201620553
  - -0.2323162274618586
  - -0.2349268772274794
  - -0.2331058348553302
  train_level0__neg_hamming_loss_macro_masked:
  - -0.18217426051348556
  - -0.18456727256533695
  - -0.18118349326061273
  - -0.18364648832617092
  - -0.1818869527150766
  train_level0__neg_hamming_loss_macro_oob:
  - -0.23356243391329423
  - -0.23622162201620553
  - -0.2323162274618586
  - -0.2349268772274794
  - -0.2331058348553302
  train_level0__neg_hamming_loss_micro:
  - -0.23356243391329423
  - -0.23622162201620556
  - -0.23231622746185854
  - -0.2349268772274794
  - -0.23310583485533018
  train_level0__neg_hamming_loss_micro_masked:
  - -0.17478265369488719
  - -0.1769410283976191
  - -0.17373175816539263
  - -0.1759894109861019
  - -0.17446192052980133
  train_level0__neg_hamming_loss_micro_oob:
  - -0.23356243391329423
  - -0.23622162201620556
  - -0.23231622746185854
  - -0.2349268772274794
  - -0.23310583485533018
  train_level0__neg_hamming_loss_samples:
  - -0.2335624339132942
  - -0.23622162201620553
  - -0.23231622746185848
  - -0.23492687722747935
  - -0.23310583485533012
  train_level0__neg_hamming_loss_samples_masked:
  - -0.17500973361275715
  - -0.17721292444174516
  - -0.17396955757367216
  - -0.17623320179688837
  - -0.17469356696397564
  train_level0__neg_hamming_loss_samples_oob:
  - -0.2335624339132942
  - -0.23622162201620553
  - -0.23231622746185848
  - -0.23492687722747935
  - -0.23310583485533012
  train_level0__neg_hamming_loss_weighted:
  - -0.3447281990263024
  - -0.3495011736180169
  - -0.345318168795905
  - -0.34928550806402486
  - -0.34542002653873627
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.2810137588590407
  - -0.2854480459975843
  - -0.28144045735960604
  - -0.285539024424047
  - -0.2815406883141151
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.3447281990263024
  - -0.3495011736180169
  - -0.345318168795905
  - -0.34928550806402486
  - -0.34542002653873627
  train_level0__neg_label_ranking_loss:
  - -0.18558061086352362
  - -0.1868238551639913
  - -0.18385726207297834
  - -0.1835776440787784
  - -0.18389053502597455
  train_level0__neg_label_ranking_loss_oob:
  - -0.26017702894206346
  - -0.2579876978095079
  - -0.2565227062662044
  - -0.2562359812298369
  - -0.2547120848553272
  train_level0__precision_macro:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__precision_macro_masked:
  - 0.8178257394865144
  - 0.8154327274346631
  - 0.8188165067393876
  - 0.8163535116738292
  - 0.8181130472849235
  train_level0__precision_macro_oob:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__precision_micro:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__precision_micro_masked:
  - 0.8252173463051128
  - 0.8230589716023808
  - 0.8262682418346073
  - 0.8240105890138981
  - 0.8255380794701986
  train_level0__precision_micro_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__precision_samples:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__precision_samples_masked:
  - 0.8249902663872429
  - 0.8227870755582549
  - 0.8260304424263278
  - 0.8237667982031116
  - 0.8253064330360244
  train_level0__precision_samples_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__precision_weighted:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__precision_weighted_masked:
  - 0.7189862411409595
  - 0.7145519540024156
  - 0.7185595426403939
  - 0.7144609755759529
  - 0.718459311685885
  train_level0__precision_weighted_oob:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__recall_macro:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__recall_macro_masked:
  - 0.8178257394865144
  - 0.8154327274346631
  - 0.8188165067393876
  - 0.8163535116738292
  - 0.8181130472849235
  train_level0__recall_macro_oob:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__recall_micro:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__recall_micro_masked:
  - 0.8252173463051128
  - 0.8230589716023808
  - 0.8262682418346073
  - 0.8240105890138981
  - 0.8255380794701986
  train_level0__recall_micro_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__recall_samples:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__recall_samples_masked:
  - 0.8249902663872429
  - 0.8227870755582549
  - 0.8260304424263278
  - 0.8237667982031116
  - 0.8253064330360244
  train_level0__recall_samples_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__recall_weighted:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__recall_weighted_masked:
  - 0.7189862411409595
  - 0.7145519540024156
  - 0.7185595426403939
  - 0.7144609755759529
  - 0.718459311685885
  train_level0__recall_weighted_oob:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__roc_auc_macro:
  - 0.712216453983237
  - 0.7079081261662005
  - 0.7143853926082228
  - 0.7104384549927373
  - 0.7152451292543579
  train_level0__roc_auc_macro_masked:
  - 0.5860899088530318
  - 0.5803532160745729
  - 0.5899393191042076
  - 0.5837741480625558
  - 0.5911643459110856
  train_level0__roc_auc_macro_oob:
  - 0.5364322698454218
  - 0.5329185463360626
  - 0.5390621522351248
  - 0.5364543727314973
  - 0.5499150752269272
  train_level0__roc_auc_micro:
  - 0.8128804184206497
  - 0.8119132411354033
  - 0.8143987838681044
  - 0.8148709134176181
  - 0.8146393949340066
  train_level0__roc_auc_micro_masked:
  - 0.7521751615662131
  - 0.7522636101815332
  - 0.7553841512446627
  - 0.7557042014360098
  - 0.7552658805636021
  train_level0__roc_auc_micro_oob:
  - 0.7364098605679921
  - 0.7377981584225685
  - 0.7398218732040907
  - 0.7401192361181319
  - 0.7423115129105038
  train_level0__roc_auc_samples:
  - 0.8144193891364765
  - 0.8131761448360086
  - 0.8161427379270217
  - 0.8164223559212216
  - 0.8161094649740255
  train_level0__roc_auc_samples_masked:
  - 0.754308102605172
  - 0.7545801699372507
  - 0.7588254409450769
  - 0.758338771584815
  - 0.759121070877535
  train_level0__roc_auc_samples_oob:
  - 0.7398229710579365
  - 0.742012302190492
  - 0.7434772937337958
  - 0.7437640187701632
  - 0.7452879151446729
  train_level0__roc_auc_weighted:
  - 0.7036110077224952
  - 0.7014509928615523
  - 0.7065051218507717
  - 0.7086549045743824
  - 0.7107511148209549
  train_level0__roc_auc_weighted_masked:
  - 0.5767551886436171
  - 0.5749665023356461
  - 0.5824001458299157
  - 0.5847982556916262
  - 0.5886046044586333
  train_level0__roc_auc_weighted_oob:
  - 0.5325118583070433
  - 0.5359315328699393
  - 0.5403285302467191
  - 0.5380845526686775
  - 0.5526663943273356
  train_level0__tn_macro:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__tn_macro_masked:
  - 0.8178257394865144
  - 0.8154327274346631
  - 0.8188165067393876
  - 0.8163535116738292
  - 0.8181130472849235
  train_level0__tn_macro_oob:
  - 0.7664375660867059
  - 0.7637783779837946
  - 0.7676837725381416
  - 0.7650731227725205
  - 0.7668941651446699
  train_level0__tn_micro:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__tn_micro_masked:
  - 0.8252173463051128
  - 0.8230589716023808
  - 0.8262682418346073
  - 0.8240105890138981
  - 0.8255380794701986
  train_level0__tn_micro_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725206
  - 0.7668941651446698
  train_level0__tn_samples:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__tn_samples_masked:
  - 0.8249902663872429
  - 0.8227870755582549
  - 0.8260304424263278
  - 0.8237667982031116
  - 0.8253064330360244
  train_level0__tn_samples_oob:
  - 0.7664375660867058
  - 0.7637783779837944
  - 0.7676837725381415
  - 0.7650731227725205
  - 0.7668941651446698
  train_level0__tn_weighted:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__tn_weighted_masked:
  - 0.7189862411409595
  - 0.7145519540024156
  - 0.7185595426403939
  - 0.7144609755759529
  - 0.718459311685885
  train_level0__tn_weighted_oob:
  - 0.6552718009736976
  - 0.650498826381983
  - 0.6546818312040951
  - 0.6507144919359752
  - 0.6545799734612636
  train_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__average_precision_macro:
  - 0.3676025190279359
  - 0.36319400347665615
  - 0.36207747127990125
  - 0.35081367401243935
  - 0.35192532965812867
  train_level10__average_precision_macro_masked:
  - 0.28861166594515136
  - 0.2859475819257739
  - 0.2851038494561215
  - 0.2767048905197299
  - 0.2741257045465624
  train_level10__average_precision_macro_oob:
  - 0.36159610630135935
  - 0.35811755078484087
  - 0.35710351203003227
  - 0.3479149649430286
  - 0.34677933937741634
  train_level10__average_precision_micro:
  - 0.2615207010749098
  - 0.2360358907533095
  - 0.24056224571577933
  - 0.23306121055321094
  - 0.23792698392431355
  train_level10__average_precision_micro_masked:
  - 0.18834532715711386
  - 0.17037590369322914
  - 0.17283917519771663
  - 0.16870821751620735
  - 0.1715731491874765
  train_level10__average_precision_micro_oob:
  - 0.26227204144729
  - 0.23619732900058077
  - 0.24221943670161344
  - 0.23390347414528384
  - 0.23846241314518057
  train_level10__average_precision_samples:
  - 0.2752419409374847
  - 0.24919056004606063
  - 0.25444169150858825
  - 0.24431083849347746
  - 0.24910745871225598
  train_level10__average_precision_samples_masked:
  - 0.20707750790890697
  - 0.186737159715971
  - 0.19015701424230982
  - 0.18218178010279792
  - 0.18654800079057918
  train_level10__average_precision_samples_oob:
  - 0.2757672299626289
  - 0.24937206847332355
  - 0.25591269121729215
  - 0.24524508615238746
  - 0.2496593138452777
  train_level10__average_precision_weighted:
  - 0.501877850977784
  - 0.5002498088590802
  - 0.5028159033380208
  - 0.49192023970998267
  - 0.4891344021542288
  train_level10__average_precision_weighted_masked:
  - 0.40740279967558235
  - 0.4076064965745634
  - 0.4107260673621642
  - 0.4023642743758648
  - 0.3971906949347462
  train_level10__average_precision_weighted_oob:
  - 0.49503448359504637
  - 0.4945243524869976
  - 0.49701809815421116
  - 0.4884846655796084
  - 0.48301744097523136
  train_level10__f1_macro:
  - 0.4288186100163415
  - 0.39937221695014224
  - 0.42653881103830876
  - 0.41206832985129654
  - 0.43523502835720457
  train_level10__f1_macro_masked:
  - 0.40130107160417633
  - 0.36961365388309414
  - 0.3994051547935638
  - 0.38414786933842004
  - 0.4085477493764526
  train_level10__f1_macro_oob:
  - 0.4267278669614535
  - 0.39652529381706697
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__f1_micro:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383089
  - 0.41206832985129654
  - 0.4352350283572047
  train_level10__f1_micro_masked:
  - 0.39494928586214034
  - 0.36156488449537194
  - 0.3922734409183332
  - 0.37646591661151557
  - 0.40234375
  train_level10__f1_micro_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.42560619828781865
  - 0.41071648027528573
  - 0.43412957800634433
  train_level10__f1_samples:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383088
  - 0.4120683298512965
  - 0.43523502835720457
  train_level10__f1_samples_masked:
  - 0.3956579999186307
  - 0.3623828607018229
  - 0.39296094674152227
  - 0.3770931470301611
  - 0.40293660181675484
  train_level10__f1_samples_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__f1_weighted:
  - 0.5169065085333516
  - 0.5087616032252036
  - 0.5242837113903897
  - 0.5164933080115801
  - 0.5211952638562825
  train_level10__f1_weighted_masked:
  - 0.48592155527951486
  - 0.4760626355442609
  - 0.4948474616913068
  - 0.4864913633738922
  - 0.4915887326526409
  train_level10__f1_weighted_oob:
  - 0.5144445044360388
  - 0.5062323608774718
  - 0.5231671606296697
  - 0.5142387184438246
  - 0.5203988465856895
  train_level10__fn_macro:
  - -0.05243679707776603
  - -0.04749738423729226
  - -0.050695872590750396
  - -0.049576010814796616
  - -0.05226857637220033
  train_level10__fn_macro_masked:
  - -0.05063665725030275
  - -0.04618164736334877
  - -0.04887959246244212
  - -0.04758507232180114
  - -0.04981984830329125
  train_level10__fn_macro_oob:
  - -0.0534941843698933
  - -0.04735138817918583
  - -0.051030656655028934
  - -0.0503871205604031
  - -0.05217245025473421
  train_level10__fn_micro:
  - -0.05243679707776603
  - -0.04749738423729226
  - -0.050695872590750396
  - -0.04957601081479661
  - -0.05226857637220033
  train_level10__fn_micro_masked:
  - -0.04652245911819499
  - -0.04237354799800718
  - -0.04506730497001519
  - -0.04370615486432826
  - -0.045969577814569534
  train_level10__fn_micro_oob:
  - -0.0534941843698933
  - -0.04735138817918583
  - -0.051030656655028934
  - -0.0503871205604031
  - -0.05217245025473421
  train_level10__fn_samples:
  - -0.05243679707776602
  - -0.04749738423729226
  - -0.050695872590750396
  - -0.0495760108147966
  - -0.052268576372200316
  train_level10__fn_samples_masked:
  - -0.04643833785903273
  - -0.04217453591664313
  - -0.044924121309873485
  - -0.04360467335102826
  - -0.04581288920416384
  train_level10__fn_samples_oob:
  - -0.05349418436989329
  - -0.04735138817918582
  - -0.051030656655028934
  - -0.05038712056040309
  - -0.05217245025473421
  train_level10__fn_weighted:
  - -0.1051306565989452
  - -0.09565890416192933
  - -0.10071445050947064
  - -0.09953064700257722
  - -0.10261508625089313
  train_level10__fn_weighted_masked:
  - -0.10563631992097612
  - -0.09652676011206175
  - -0.1001770605775367
  - -0.0991151740215764
  - -0.10151157360948229
  train_level10__fn_weighted_oob:
  - -0.10674380793362802
  - -0.09494740146617059
  - -0.10099079935805937
  - -0.10079302645275612
  - -0.10218281106461162
  train_level10__fp_macro:
  - -0.5187445929058925
  - -0.5531303988125654
  - -0.5227653163709407
  - -0.5383556593339069
  - -0.512496395270595
  train_level10__fp_macro_masked:
  - -0.548062271145521
  - -0.5842046987535572
  - -0.551715252743994
  - -0.5682670583397788
  - -0.5416324023202561
  train_level10__fp_macro_oob:
  - -0.5197779486686532
  - -0.5561233180037471
  - -0.5233631450571524
  - -0.5388963991643112
  - -0.5136979717389214
  train_level10__fp_micro:
  - -0.5187445929058925
  - -0.5531303988125654
  - -0.5227653163709407
  - -0.5383556593339068
  - -0.512496395270595
  train_level10__fp_micro_masked:
  - -0.5585282550196646
  - -0.5960615675066209
  - -0.5626592541116516
  - -0.5798279285241562
  - -0.5516866721854304
  train_level10__fp_micro_oob:
  - -0.5197779486686532
  - -0.5561233180037473
  - -0.5233631450571524
  - -0.5388963991643112
  - -0.5136979717389215
  train_level10__fp_samples:
  - -0.5187445929058926
  - -0.5531303988125654
  - -0.5227653163709407
  - -0.5383556593339068
  - -0.5124963952705951
  train_level10__fp_samples_masked:
  - -0.5579036622223366
  - -0.5954426033815339
  - -0.5621149319486042
  - -0.5793021796188106
  - -0.5512505089790813
  train_level10__fp_samples_oob:
  - -0.5197779486686532
  - -0.5561233180037473
  - -0.5233631450571523
  - -0.5388963991643112
  - -0.5136979717389214
  train_level10__fp_weighted:
  - -0.37796283486770327
  - -0.3955794926128671
  - -0.37500183810013976
  - -0.3839760449858426
  - -0.3761896498928244
  train_level10__fp_weighted_masked:
  - -0.40844212479950903
  - -0.4274106043436773
  - -0.40497547773115655
  - -0.4143934626045315
  - -0.4068996937378769
  train_level10__fp_weighted_oob:
  - -0.3788116876303332
  - -0.39882023765635766
  - -0.37584204001227095
  - -0.3849682551034192
  - -0.37741834234969895
  train_level10__jaccard_macro:
  - 0.29260532012006646
  - 0.27435287567931776
  - 0.29528962379106133
  - 0.2821277416519734
  - 0.29851267091170974
  train_level10__jaccard_macro_masked:
  - 0.2700349517399539
  - 0.250618830409979
  - 0.2731850549297917
  - 0.2594986606762418
  - 0.27678144872627347
  train_level10__jaccard_macro_oob:
  - 0.29092149062560924
  - 0.2719670353123326
  - 0.294648293375782
  - 0.2808670394878654
  - 0.2977424831394499
  train_level10__jaccard_micro:
  - 0.27292750076475986
  - 0.24950973685410682
  - 0.2710831471602912
  - 0.2595000386966953
  - 0.27814722098505673
  train_level10__jaccard_micro_masked:
  - 0.24606654629868455
  - 0.22067696247099303
  - 0.2439926358760906
  - 0.23188051329713513
  - 0.25183374083129584
  train_level10__jaccard_micro_oob:
  - 0.27123588983762814
  - 0.2472912683237731
  - 0.27033020444120415
  - 0.2584287039901021
  - 0.27724489326109975
  train_level10__jaccard_samples:
  - 0.27811544073770955
  - 0.25333714197022794
  - 0.27588461872551484
  - 0.26393786072008507
  - 0.2826679420568924
  train_level10__jaccard_samples_masked:
  - 0.2512972549819682
  - 0.224502144109776
  - 0.2488988695156798
  - 0.23635904876054736
  - 0.2564127303324152
  train_level10__jaccard_samples_oob:
  - 0.27638244675901213
  - 0.2511175787312866
  - 0.27509417583315576
  - 0.2628043370539494
  - 0.28170417184679863
  train_level10__jaccard_weighted:
  - 0.3634256095038868
  - 0.3606610668086796
  - 0.3732226703246886
  - 0.36523184122057517
  - 0.36818174240389634
  train_level10__jaccard_weighted_masked:
  - 0.3357092241876977
  - 0.33140412272798003
  - 0.34676216444276753
  - 0.3380624951990966
  - 0.34193870907582474
  train_level10__jaccard_weighted_oob:
  - 0.3612195175620768
  - 0.3582473484033124
  - 0.3723335013062189
  - 0.3630684996302659
  - 0.36759609972174706
  train_level10__label_ranking_average_precision_score:
  - 0.2752419409374848
  - 0.2491905600460605
  - 0.25444169150858814
  - 0.24431083849347748
  - 0.24910745871225606
  train_level10__label_ranking_average_precision_score_oob:
  - 0.275767229962629
  - 0.24937206847332347
  - 0.2559126912172922
  - 0.2452450861523877
  - 0.24965931384527768
  train_level10__matthews_corrcoef_macro:
  - 0.1853223250305955
  - 0.1725247726288208
  - 0.18746301207537192
  - 0.17873044138863378
  - 0.1821646779527024
  train_level10__matthews_corrcoef_macro_masked:
  - 0.1459705097980476
  - 0.13716079483242954
  - 0.1480261297931085
  - 0.14324942979506625
  - 0.14318942916078653
  train_level10__matthews_corrcoef_macro_oob:
  - 0.1797288619311443
  - 0.1677791719285943
  - 0.18375780685357096
  - 0.17496147175808943
  - 0.18030555603542336
  train_level10__matthews_corrcoef_micro:
  - 0.09108411832685336
  - 0.07253097348008769
  - 0.09330264393676034
  - 0.08087899307129172
  - 0.09856897185592071
  train_level10__matthews_corrcoef_micro_masked:
  - 0.04667524978887678
  - 0.031241974051237475
  - 0.048905696743368525
  - 0.04036129678002584
  - 0.05551843626812571
  train_level10__matthews_corrcoef_micro_oob:
  - 0.08565816297776818
  - 0.06960567439481151
  - 0.09127185378109752
  - 0.07691225712534736
  - 0.09762607569706275
  train_level10__matthews_corrcoef_samples:
  - 0.08530990299128934
  - 0.06562240670071263
  - 0.08717369583667244
  - 0.075969717530692
  - 0.0940213753534723
  train_level10__matthews_corrcoef_samples_masked:
  - 0.040841333916955394
  - 0.025625951867512847
  - 0.04457940533410448
  - 0.03616020811427485
  - 0.05199719358361591
  train_level10__matthews_corrcoef_samples_oob:
  - 0.08021817039306725
  - 0.0631007988348403
  - 0.08515704598010174
  - 0.07214168724335152
  - 0.0932266955766274
  train_level10__matthews_corrcoef_weighted:
  - 0.21908087267968482
  - 0.21979063651608025
  - 0.2324596917320054
  - 0.23007801998383443
  - 0.22090055872396056
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.1674790501661107
  - 0.17239517022906414
  - 0.18299512483520217
  - 0.18432930728855132
  - 0.17386726399884359
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.21426476067766811
  - 0.214856251708978
  - 0.22757435063349785
  - 0.2243132396026845
  - 0.21956259672279327
  train_level10__ndcg:
  - 0.6266998750267988
  - 0.6067691117718484
  - 0.6077580537769691
  - 0.6065498958912353
  - 0.6059519369921584
  train_level10__ndcg_oob:
  - 0.6290498030738223
  - 0.6082973358942163
  - 0.6117669706142129
  - 0.6088715274509023
  - 0.6077114857489367
  train_level10__neg_coverage_error:
  - -92.67079207920793
  - -93.4937343358396
  - -92.12068965517241
  - -93.45822784810126
  - -91.52970297029702
  train_level10__neg_coverage_error_oob:
  - -93.17821782178218
  - -94.09022556390977
  - -92.69458128078817
  - -93.95696202531646
  - -92.22524752475248
  train_level10__neg_hamming_loss_macro:
  - -0.5711813899836586
  - -0.6006277830498578
  - -0.5734611889616912
  - -0.5879316701487035
  - -0.5647649716427954
  train_level10__neg_hamming_loss_macro_masked:
  - -0.5986989283958237
  - -0.6303863461169057
  - -0.6005948452064362
  - -0.61585213066158
  - -0.5914522506235473
  train_level10__neg_hamming_loss_macro_oob:
  - -0.5732721330385466
  - -0.6034747061829331
  - -0.5743938017121814
  - -0.5892835197247143
  - -0.5658704219936557
  train_level10__neg_hamming_loss_micro:
  - -0.5711813899836585
  - -0.6006277830498576
  - -0.5734611889616912
  - -0.5879316701487034
  - -0.5647649716427954
  train_level10__neg_hamming_loss_micro_masked:
  - -0.6050507141378596
  - -0.6384351155046281
  - -0.6077265590816668
  - -0.6235340833884845
  - -0.59765625
  train_level10__neg_hamming_loss_micro_oob:
  - -0.5732721330385466
  - -0.6034747061829331
  - -0.5743938017121814
  - -0.5892835197247143
  - -0.5658704219936557
  train_level10__neg_hamming_loss_samples:
  - -0.5711813899836585
  - -0.6006277830498578
  - -0.5734611889616911
  - -0.5879316701487035
  - -0.5647649716427954
  train_level10__neg_hamming_loss_samples_masked:
  - -0.6043420000813694
  - -0.6376171392981771
  - -0.6070390532584777
  - -0.6229068529698388
  - -0.5970633981832453
  train_level10__neg_hamming_loss_samples_oob:
  - -0.5732721330385466
  - -0.6034747061829331
  - -0.5743938017121814
  - -0.5892835197247143
  - -0.5658704219936557
  train_level10__neg_hamming_loss_weighted:
  - -0.48309349146664843
  - -0.4912383967747964
  - -0.4757162886096103
  - -0.4835066919884199
  - -0.4788047361437175
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.5140784447204851
  - -0.5239373644557389
  - -0.5051525383086932
  - -0.5135086366261078
  - -0.5084112673473591
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.48555549556396127
  - -0.4937676391225282
  - -0.47683283937033033
  - -0.48576128155617543
  - -0.4796011534143104
  train_level10__neg_label_ranking_loss:
  - -0.4586614437118517
  - -0.5064592579162785
  - -0.48592293023267125
  - -0.5182674442908544
  - -0.4968055122426238
  train_level10__neg_label_ranking_loss_oob:
  - -0.46294186550332184
  - -0.5101788370164725
  - -0.4897582241827606
  - -0.5214841048357242
  - -0.5010789481331264
  train_level10__precision_macro:
  - 0.4288186100163415
  - 0.39937221695014224
  - 0.42653881103830876
  - 0.41206832985129654
  - 0.43523502835720457
  train_level10__precision_macro_masked:
  - 0.40130107160417633
  - 0.36961365388309414
  - 0.3994051547935638
  - 0.38414786933842004
  - 0.4085477493764526
  train_level10__precision_macro_oob:
  - 0.4267278669614535
  - 0.39652529381706697
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__precision_micro:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383089
  - 0.41206832985129654
  - 0.4352350283572047
  train_level10__precision_micro_masked:
  - 0.39494928586214034
  - 0.36156488449537194
  - 0.3922734409183332
  - 0.37646591661151557
  - 0.40234375
  train_level10__precision_micro_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.42560619828781865
  - 0.41071648027528573
  - 0.43412957800634433
  train_level10__precision_samples:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383088
  - 0.4120683298512965
  - 0.43523502835720457
  train_level10__precision_samples_masked:
  - 0.3956579999186307
  - 0.3623828607018229
  - 0.39296094674152227
  - 0.3770931470301611
  - 0.40293660181675484
  train_level10__precision_samples_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__precision_weighted:
  - 0.5169065085333516
  - 0.5087616032252036
  - 0.5242837113903897
  - 0.5164933080115801
  - 0.5211952638562825
  train_level10__precision_weighted_masked:
  - 0.48592155527951486
  - 0.4760626355442609
  - 0.4948474616913068
  - 0.4864913633738922
  - 0.4915887326526409
  train_level10__precision_weighted_oob:
  - 0.5144445044360388
  - 0.5062323608774718
  - 0.5231671606296697
  - 0.5142387184438246
  - 0.5203988465856895
  train_level10__recall_macro:
  - 0.4288186100163415
  - 0.39937221695014224
  - 0.42653881103830876
  - 0.41206832985129654
  - 0.43523502835720457
  train_level10__recall_macro_masked:
  - 0.40130107160417633
  - 0.36961365388309414
  - 0.3994051547935638
  - 0.38414786933842004
  - 0.4085477493764526
  train_level10__recall_macro_oob:
  - 0.4267278669614535
  - 0.39652529381706697
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__recall_micro:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383089
  - 0.41206832985129654
  - 0.4352350283572047
  train_level10__recall_micro_masked:
  - 0.39494928586214034
  - 0.36156488449537194
  - 0.3922734409183332
  - 0.37646591661151557
  - 0.40234375
  train_level10__recall_micro_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.42560619828781865
  - 0.41071648027528573
  - 0.43412957800634433
  train_level10__recall_samples:
  - 0.4288186100163414
  - 0.39937221695014236
  - 0.4265388110383088
  - 0.4120683298512965
  - 0.43523502835720457
  train_level10__recall_samples_masked:
  - 0.3956579999186307
  - 0.3623828607018229
  - 0.39296094674152227
  - 0.3770931470301611
  - 0.40293660181675484
  train_level10__recall_samples_oob:
  - 0.42672786696145343
  - 0.3965252938170669
  - 0.4256061982878186
  - 0.4107164802752857
  - 0.4341295780063443
  train_level10__recall_weighted:
  - 0.5169065085333516
  - 0.5087616032252036
  - 0.5242837113903897
  - 0.5164933080115801
  - 0.5211952638562825
  train_level10__recall_weighted_masked:
  - 0.48592155527951486
  - 0.4760626355442609
  - 0.4948474616913068
  - 0.4864913633738922
  - 0.4915887326526409
  train_level10__recall_weighted_oob:
  - 0.5144445044360388
  - 0.5062323608774718
  - 0.5231671606296697
  - 0.5142387184438246
  - 0.5203988465856895
  train_level10__roc_auc_macro:
  - 0.6807902041170794
  - 0.6676130025401186
  - 0.6775980063560549
  - 0.6584510520221051
  - 0.6677761612451201
  train_level10__roc_auc_macro_masked:
  - 0.6583404211311614
  - 0.6459754664007581
  - 0.6544984875832093
  - 0.6381809387043228
  - 0.6410564808831363
  train_level10__roc_auc_macro_oob:
  - 0.674314337303209
  - 0.6607211920909886
  - 0.6714648991366425
  - 0.6531279380947224
  - 0.6622750288324571
  train_level10__roc_auc_micro:
  - 0.5748505458144499
  - 0.5304263332207201
  - 0.5521833793180722
  - 0.528181116312181
  - 0.5445109101575725
  train_level10__roc_auc_micro_masked:
  - 0.5500617523300233
  - 0.5087466786500687
  - 0.5288700859848104
  - 0.5079701599599513
  - 0.5225849530009424
  train_level10__roc_auc_micro_oob:
  - 0.5727979569585792
  - 0.5286621883776086
  - 0.5514749785130142
  - 0.5274432650696359
  - 0.543311708680831
  train_level10__roc_auc_samples:
  - 0.5584841537208951
  - 0.5149821159748368
  - 0.5360123247746487
  - 0.5171346284145265
  - 0.5286223115556189
  train_level10__roc_auc_samples_masked:
  - 0.5353083510016473
  - 0.49701225825576806
  - 0.5153631780635193
  - 0.4992813005220759
  - 0.5088255285451462
  train_level10__roc_auc_samples_oob:
  - 0.5563674060259106
  - 0.5132293632631082
  - 0.5357065012997537
  - 0.5167423765365113
  - 0.5275807950382201
  train_level10__roc_auc_weighted:
  - 0.6859466472331679
  - 0.6847699736380852
  - 0.693279864465142
  - 0.6803397802931995
  - 0.6777692276092993
  train_level10__roc_auc_weighted_masked:
  - 0.6549102266404649
  - 0.6562007346190641
  - 0.6633799314610462
  - 0.6520576097499747
  - 0.6457787279689045
  train_level10__roc_auc_weighted_oob:
  - 0.6788196444155267
  - 0.6770020569147406
  - 0.6852751257146698
  - 0.6730684586940225
  - 0.6700985889651057
  train_level10__tn_macro:
  - 0.24769297318081326
  - 0.21064797917122904
  - 0.24491845616720068
  - 0.2267174634386137
  - 0.25439776987407475
  train_level10__tn_macro_masked:
  - 0.2697634683409935
  - 0.231228028681106
  - 0.26710125399539325
  - 0.24808645333405024
  - 0.2764806449646671
  train_level10__tn_macro_oob:
  - 0.24665961741805256
  - 0.2076550599800472
  - 0.24432062748098904
  - 0.22617672360820942
  - 0.2531961934057483
  train_level10__tn_micro:
  - 0.24769297318081324
  - 0.21064797917122904
  - 0.24491845616720073
  - 0.22671746343861374
  - 0.2543977698740748
  train_level10__tn_micro_masked:
  - 0.26668909128544815
  - 0.22699740409576002
  - 0.26360898772295577
  - 0.24418266048974188
  - 0.2738514072847682
  train_level10__tn_micro_oob:
  - 0.24665961741805248
  - 0.2076550599800472
  - 0.24432062748098904
  - 0.22617672360820942
  - 0.25319619340574834
  train_level10__tn_samples:
  - 0.24769297318081318
  - 0.210647979171229
  - 0.24491845616720068
  - 0.2267174634386137
  - 0.25439776987407475
  train_level10__tn_samples_masked:
  - 0.26708660416490626
  - 0.2273444721767209
  - 0.2639155104777236
  - 0.244464618584301
  - 0.274055924056943
  train_level10__tn_samples_oob:
  - 0.24665961741805242
  - 0.20765505998004719
  - 0.24432062748098898
  - 0.22617672360820934
  - 0.2531961934057483
  train_level10__tn_weighted:
  - 0.27730896610599426
  - 0.2549193337691158
  - 0.27967999310395536
  - 0.2667384469501326
  - 0.2783903235684393
  train_level10__tn_weighted_masked:
  - 0.31054411634145024
  - 0.28714134965873855
  - 0.31358406490923746
  - 0.30006751297142165
  - 0.3115596179480081
  train_level10__tn_weighted_oob:
  - 0.27646011334336446
  - 0.2516785887256254
  - 0.2788397911918241
  - 0.26574623683255594
  - 0.27716163111156483
  train_level10__tp_macro:
  - 0.1811256368355282
  - 0.18872423777891328
  - 0.18162035487110822
  - 0.1853508664126828
  - 0.1808372584831299
  train_level10__tp_macro_masked:
  - 0.13153760326318276
  - 0.13838562520198816
  - 0.1323039007981706
  - 0.13606141600436983
  - 0.13206710441178535
  train_level10__tp_macro_oob:
  - 0.18006824954340092
  - 0.18887023383701973
  - 0.18128557080682967
  - 0.1845397566670763
  - 0.180933384600596
  train_level10__tp_micro:
  - 0.1811256368355282
  - 0.1887242377789133
  - 0.18162035487110814
  - 0.1853508664126828
  - 0.18083725848312987
  train_level10__tp_micro_masked:
  - 0.1282601945766922
  - 0.13456748039961192
  - 0.12866445319537745
  - 0.13228325612177366
  - 0.1284923427152318
  train_level10__tp_micro_oob:
  - 0.18006824954340095
  - 0.18887023383701973
  - 0.18128557080682958
  - 0.1845397566670763
  - 0.180933384600596
  train_level10__tp_samples:
  - 0.18112563683552818
  - 0.18872423777891323
  - 0.1816203548711081
  - 0.18535086641268275
  - 0.18083725848312984
  train_level10__tp_samples_masked:
  - 0.12857139575372442
  - 0.135038388525102
  - 0.1290454362637987
  - 0.13262852844586012
  - 0.1288806777598118
  train_level10__tp_samples_oob:
  - 0.18006824954340092
  - 0.18887023383701967
  - 0.18128557080682955
  - 0.18453975666707628
  - 0.18093338460059596
  train_level10__tp_weighted:
  - 0.23959754242735726
  - 0.2538422694560876
  - 0.24460371828643435
  - 0.24975486106144765
  - 0.24280494028784322
  train_level10__tp_weighted_masked:
  - 0.1753774389380646
  - 0.18892128588552257
  - 0.1812633967820694
  - 0.1864238504024706
  - 0.18002911470463287
  train_level10__tp_weighted_oob:
  - 0.23798439109267447
  - 0.2545537721518464
  - 0.24432736943784558
  - 0.24849248161126872
  - 0.2432372154741247
  train_level1__average_precision_macro:
  - 0.4224875529704094
  - 0.3986580060729206
  - 0.41519935218423715
  - 0.40079591944600895
  - 0.3912664781938663
  train_level1__average_precision_macro_masked:
  - 0.31605549751143175
  - 0.29963275503743303
  - 0.3119383583590753
  - 0.30504184240836174
  - 0.296458712136205
  train_level1__average_precision_macro_oob:
  - 0.40168256649798184
  - 0.3790055147745134
  - 0.3931906318312327
  - 0.3834621620423658
  - 0.3744644685698208
  train_level1__average_precision_micro:
  - 0.21166556229979602
  - 0.1993707138618063
  - 0.20303036377612746
  - 0.2054623274268973
  - 0.21551203753373166
  train_level1__average_precision_micro_masked:
  - 0.14972000215844772
  - 0.142187718329654
  - 0.14424647537330898
  - 0.1464854889319736
  - 0.15304848974995264
  train_level1__average_precision_micro_oob:
  - 0.20209776989344025
  - 0.19269958316617317
  - 0.19490527406075742
  - 0.19813547496450712
  - 0.20815540133305616
  train_level1__average_precision_samples:
  - 0.23459777247402738
  - 0.2206167224551674
  - 0.22392695147066483
  - 0.22663453312575538
  - 0.23652787003600062
  train_level1__average_precision_samples_masked:
  - 0.17565397775193653
  - 0.1663901677448871
  - 0.1677559421471317
  - 0.1704442710342464
  - 0.17841700406251768
  train_level1__average_precision_samples_oob:
  - 0.22479572965146505
  - 0.21454429919498583
  - 0.21547521370531217
  - 0.21942619867284044
  - 0.2294643959361298
  train_level1__average_precision_weighted:
  - 0.5462257417856765
  - 0.5316681445384498
  - 0.5462528160808112
  - 0.5365614083464934
  - 0.5216014223471005
  train_level1__average_precision_weighted_masked:
  - 0.4208091352461454
  - 0.41315561771329773
  - 0.4268465412430778
  - 0.42134286512774266
  - 0.41174633348692585
  train_level1__average_precision_weighted_oob:
  - 0.5204067433709337
  - 0.5056611395354347
  - 0.5195355277562292
  - 0.5137409657934819
  - 0.5001531735892719
  train_level1__f1_macro:
  - 0.39791406325098533
  - 0.37282526705112295
  - 0.41068439427997505
  - 0.3881774609807054
  - 0.423892146496203
  train_level1__f1_macro_masked:
  - 0.3832555025903218
  - 0.35378040568299185
  - 0.39743747638180615
  - 0.3692287144218108
  - 0.40672502066452587
  train_level1__f1_macro_oob:
  - 0.3778717677593003
  - 0.3572280215100858
  - 0.39659955043282785
  - 0.3724960058989799
  - 0.40959338652311833
  train_level1__f1_micro:
  - 0.3979140632509853
  - 0.37282526705112295
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__f1_micro_masked:
  - 0.37670772096874355
  - 0.3464089991346986
  - 0.3912439193884642
  - 0.36259430840502976
  - 0.40159354304635764
  train_level1__f1_micro_oob:
  - 0.3778717677593002
  - 0.35722802151008587
  - 0.39659955043282796
  - 0.37249600589897996
  - 0.40959338652311833
  train_level1__f1_samples:
  - 0.3979140632509853
  - 0.3728252670511229
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__f1_samples_masked:
  - 0.3771150408699874
  - 0.34684710257424173
  - 0.39170994694364825
  - 0.3630510758257169
  - 0.4020564968929903
  train_level1__f1_samples_oob:
  - 0.37787176775930015
  - 0.3572280215100858
  - 0.39659955043282796
  - 0.3724960058989799
  - 0.4095933865231184
  train_level1__f1_weighted:
  - 0.4702272470276145
  - 0.4600853699968917
  - 0.4800645997124958
  - 0.46538283259301627
  - 0.48296315198530165
  train_level1__f1_weighted_masked:
  - 0.47052177501262243
  - 0.45146708935140156
  - 0.4800333227023371
  - 0.4575443698062464
  - 0.47546183695113076
  train_level1__f1_weighted_oob:
  - 0.44990979188463137
  - 0.4401764609298276
  - 0.46397044842037477
  - 0.4473866414508622
  - 0.4650990099009901
  train_level1__fn_macro:
  - -0.09345861770643082
  - -0.0874029734530501
  - -0.09634607106987424
  - -0.08472409979107781
  - -0.08838796501009326
  train_level1__fn_macro_masked:
  - -0.08285537734132482
  - -0.0789389914620144
  - -0.0853096479492171
  - -0.07664852044630327
  - -0.08002797384754408
  train_level1__fn_macro_oob:
  - -0.09999519369412668
  - -0.09278049492663698
  - -0.10392653881103832
  - -0.09005776084552046
  - -0.09492454099778912
  train_level1__fn_micro:
  - -0.09345861770643084
  - -0.0874029734530501
  - -0.09634607106987422
  - -0.0847240997910778
  - -0.08838796501009324
  train_level1__fn_micro_masked:
  - -0.07565721382736494
  - -0.07192490232582531
  - -0.07816642215530333
  - -0.06970218398411648
  - -0.07339093543046357
  train_level1__fn_micro_oob:
  - -0.0999951936941267
  - -0.09278049492663698
  - -0.1039265388110383
  - -0.09005776084552046
  - -0.0949245409977891
  train_level1__fn_samples:
  - -0.09345861770643084
  - -0.08740297345305009
  - -0.09634607106987421
  - -0.08472409979107777
  - -0.08838796501009322
  train_level1__fn_samples_masked:
  - -0.07556473398778332
  - -0.07173241111577755
  - -0.07801694968567424
  - -0.06952242661426057
  - -0.07323572112799058
  train_level1__fn_samples_oob:
  - -0.09999519369412667
  - -0.09278049492663697
  - -0.10392653881103829
  - -0.09005776084552045
  - -0.09492454099778909
  train_level1__fn_weighted:
  - -0.199864203932483
  - -0.18625777463849155
  - -0.2013604476344285
  - -0.18429495074707117
  - -0.18432275186281516
  train_level1__fn_weighted_masked:
  - -0.17911832011294657
  - -0.1717936630774033
  - -0.1812884302174428
  - -0.16884376446720623
  - -0.1690465555364832
  train_level1__fn_weighted_oob:
  - -0.21018541817140868
  - -0.19652138174030048
  - -0.2128565597357192
  - -0.19366664812563403
  - -0.1961845462896805
  train_level1__fp_macro:
  - -0.5086273190425838
  - -0.539771759495827
  - -0.4929695346501507
  - -0.5270984392282169
  - -0.4877198884937037
  train_level1__fp_macro_masked:
  - -0.5338891200683533
  - -0.5672806028549938
  - -0.5172528756689767
  - -0.554122765131886
  - -0.51324700548793
  train_level1__fp_macro_oob:
  - -0.522133038546573
  - -0.5499914835632771
  - -0.4994739107561338
  - -0.5374462332554997
  - -0.49548207247909254
  train_level1__fp_micro:
  - -0.5086273190425838
  - -0.5397717594958269
  - -0.49296953465015064
  - -0.5270984392282168
  - -0.48771988849370373
  train_level1__fp_micro_masked:
  - -0.5476350652038915
  - -0.5816660985394762
  - -0.5305896584562325
  - -0.5677035076108538
  - -0.5250155215231788
  train_level1__fp_micro_oob:
  - -0.5221330385465731
  - -0.5499914835632771
  - -0.49947391075613373
  - -0.5374462332554996
  - -0.4954820724790926
  train_level1__fp_samples:
  - -0.5086273190425838
  - -0.5397717594958269
  - -0.4929695346501506
  - -0.5270984392282169
  - -0.4877198884937037
  train_level1__fp_samples_masked:
  - -0.5473202251422293
  - -0.5814204863099808
  - -0.5302731033706775
  - -0.5674264975600226
  - -0.5247077819790192
  train_level1__fp_samples_oob:
  - -0.5221330385465731
  - -0.5499914835632772
  - -0.49947391075613373
  - -0.5374462332554996
  - -0.4954820724790926
  train_level1__fp_weighted:
  - -0.32990854903990247
  - -0.3536568553646168
  - -0.3185749526530757
  - -0.35032221665991237
  - -0.33271409615188324
  train_level1__fp_weighted_masked:
  - -0.35035990487443097
  - -0.376739247571195
  - -0.3386782470802201
  - -0.37361186572654737
  - -0.35549160751238607
  train_level1__fp_weighted_oob:
  - -0.33990478994395995
  - -0.3633021573298719
  - -0.323172991843906
  - -0.3589467104235037
  - -0.33871644380932936
  train_level1__jaccard_macro:
  - 0.2760592251469812
  - 0.25795485977305965
  - 0.2889654748411032
  - 0.2667424377165828
  - 0.2937442678795155
  train_level1__jaccard_macro_masked:
  - 0.2676728946152916
  - 0.2465876361410291
  - 0.28230665087143725
  - 0.2542417576045412
  - 0.2823247671851749
  train_level1__jaccard_macro_oob:
  - 0.2592420353378237
  - 0.24437742515349756
  - 0.27686254470227073
  - 0.2535398605818944
  - 0.28125144939680446
  train_level1__jaccard_micro:
  - 0.24837248372483725
  - 0.22912429716473262
  - 0.2584032981252445
  - 0.24083138905408907
  - 0.26894869253640313
  train_level1__jaccard_micro_masked:
  - 0.23206401326171158
  - 0.20948892377463807
  - 0.24319654427645787
  - 0.2214443923496031
  - 0.25124619667249304
  train_level1__jaccard_micro_oob:
  - 0.23294814814814815
  - 0.21745441618651223
  - 0.24734903282575949
  - 0.22887563240957487
  - 0.25754004230885463
  train_level1__jaccard_samples:
  - 0.25125548560804717
  - 0.23129234728102746
  - 0.2612053803338488
  - 0.2439433983142129
  - 0.2720772560789913
  train_level1__jaccard_samples_masked:
  - 0.23483432778590152
  - 0.21155019804497271
  - 0.24600713133628532
  - 0.22452724210634764
  - 0.2543625040628364
  train_level1__jaccard_samples_oob:
  - 0.2356849348160638
  - 0.21944265357781303
  - 0.24980871813889055
  - 0.23189217759296274
  - 0.26064476464903275
  train_level1__jaccard_weighted:
  - 0.33195951503858323
  - 0.3225741137131571
  - 0.3407270993774854
  - 0.3258720662468022
  - 0.3386894549835183
  train_level1__jaccard_weighted_masked:
  - 0.33480298755973187
  - 0.3187201025468646
  - 0.3441806855757479
  - 0.3210358586358542
  - 0.33459673920224225
  train_level1__jaccard_weighted_oob:
  - 0.3132494895957715
  - 0.30485985948915456
  - 0.32582913025607574
  - 0.3097366113312522
  - 0.3226810468133116
  train_level1__label_ranking_average_precision_score:
  - 0.2345977724740274
  - 0.22061672245516747
  - 0.22392695147066485
  - 0.22663453312575543
  - 0.23652787003600043
  train_level1__label_ranking_average_precision_score_oob:
  - 0.22479572965146524
  - 0.2145442991949859
  - 0.21547521370531225
  - 0.2194261986728403
  - 0.22946439593612986
  train_level1__matthews_corrcoef_macro:
  - 0.15905038063404647
  - 0.14782932816990937
  - 0.16326732683785555
  - 0.15747388895720704
  - 0.16196613508951818
  train_level1__matthews_corrcoef_macro_masked:
  - 0.12394537583850844
  - 0.11282448688538659
  - 0.12334750501221167
  - 0.12050270782642963
  - 0.11923679492946275
  train_level1__matthews_corrcoef_macro_oob:
  - 0.12829174663279316
  - 0.11620107405659
  - 0.1305320327085678
  - 0.1321515274823028
  - 0.13578196312667207
  train_level1__matthews_corrcoef_micro:
  - -0.05651962887601002
  - -0.07036986691393267
  - -0.04971616079525171
  - -0.04497177102212351
  - -0.013279433286064412
  train_level1__matthews_corrcoef_micro_masked:
  - -0.07666697610548409
  - -0.09313622419144815
  - -0.07210545453538852
  - -0.06906232831429023
  - -0.04442456433687982
  train_level1__matthews_corrcoef_micro_oob:
  - -0.09739696185590893
  - -0.10397421788526964
  - -0.0855969157468291
  - -0.07814827924068951
  - -0.046778769387932885
  train_level1__matthews_corrcoef_samples:
  - -0.06190047429767696
  - -0.07612510592237832
  - -0.0550951378281485
  - -0.05154495069814832
  - -0.01820723653499044
  train_level1__matthews_corrcoef_samples_masked:
  - -0.08055519755353155
  - -0.09531480483159406
  - -0.07499997297131696
  - -0.07329673057190969
  - -0.047657356553054094
  train_level1__matthews_corrcoef_samples_oob:
  - -0.10250819128685637
  - -0.10947966663528994
  - -0.09038411769649048
  - -0.08439460305441186
  - -0.051344127964170476
  train_level1__matthews_corrcoef_weighted:
  - 0.18304296311067256
  - 0.18379256341925532
  - 0.19078561292830862
  - 0.19054552930604163
  - 0.1882473913149127
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.14224483472740174
  - 0.1345717103502123
  - 0.13941724971577038
  - 0.14309143390885465
  - 0.13794033365640132
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.14594477267747016
  - 0.14089286263191567
  - 0.14954177027348128
  - 0.15731045379054298
  - 0.1514529658439481
  train_level1__ndcg:
  - 0.5870202610290339
  - 0.5749585727528024
  - 0.5742897305486147
  - 0.5775814693842292
  - 0.5862602745049867
  train_level1__ndcg_oob:
  - 0.5793860102054381
  - 0.5710535940152595
  - 0.5676913997377047
  - 0.5723905772293819
  - 0.5815480316043655
  train_level1__neg_coverage_error:
  - -99.23514851485149
  - -98.26065162907268
  - -97.77832512315271
  - -99.76455696202531
  - -96.8069306930693
  train_level1__neg_coverage_error_oob:
  - -99.71534653465346
  - -98.65664160401002
  - -98.41379310344827
  - -100.24303797468355
  - -97.43564356435644
  train_level1__neg_hamming_loss_macro:
  - -0.6020859367490147
  - -0.6271747329488772
  - -0.589315605720025
  - -0.6118225390192946
  - -0.576107853503797
  train_level1__neg_hamming_loss_macro_masked:
  - -0.6167444974096783
  - -0.6462195943170082
  - -0.602562523618194
  - -0.6307712855781893
  - -0.5932749793354741
  train_level1__neg_hamming_loss_macro_oob:
  - -0.6221282322406997
  - -0.6427719784899141
  - -0.603400449567172
  - -0.62750399410102
  - -0.5904066134768816
  train_level1__neg_hamming_loss_micro:
  - -0.6020859367490147
  - -0.627174732948877
  - -0.5893156057200248
  - -0.6118225390192946
  - -0.576107853503797
  train_level1__neg_hamming_loss_micro_masked:
  - -0.6232922790312565
  - -0.6535910008653014
  - -0.6087560806115357
  - -0.6374056915949702
  - -0.5984064569536424
  train_level1__neg_hamming_loss_micro_oob:
  - -0.6221282322406998
  - -0.6427719784899141
  - -0.603400449567172
  - -0.62750399410102
  - -0.5904066134768816
  train_level1__neg_hamming_loss_samples:
  - -0.6020859367490147
  - -0.627174732948877
  - -0.5893156057200248
  - -0.6118225390192946
  - -0.576107853503797
  train_level1__neg_hamming_loss_samples_masked:
  - -0.6228849591300126
  - -0.6531528974257582
  - -0.6082900530563518
  - -0.6369489241742832
  - -0.5979435031070097
  train_level1__neg_hamming_loss_samples_oob:
  - -0.6221282322406998
  - -0.6427719784899141
  - -0.603400449567172
  - -0.62750399410102
  - -0.5904066134768816
  train_level1__neg_hamming_loss_weighted:
  - -0.5297727529723855
  - -0.5399146300031082
  - -0.5199354002875042
  - -0.5346171674069836
  - -0.5170368480146984
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.5294782249873776
  - -0.5485329106485983
  - -0.5199666772976629
  - -0.5424556301937535
  - -0.5245381630488692
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.5500902081153686
  - -0.5598235390701725
  - -0.5360295515796252
  - -0.5526133585491378
  - -0.5349009900990099
  train_level1__neg_label_ranking_loss:
  - -0.5544271288481838
  - -0.5801733139263808
  - -0.558955214306464
  - -0.5621512553534197
  - -0.533761514607924
  train_level1__neg_label_ranking_loss_oob:
  - -0.5810644428049612
  - -0.6009006213292412
  - -0.5828351242173838
  - -0.5843005683230927
  - -0.5542087314164312
  train_level1__precision_macro:
  - 0.39791406325098533
  - 0.37282526705112295
  - 0.41068439427997505
  - 0.3881774609807054
  - 0.423892146496203
  train_level1__precision_macro_masked:
  - 0.3832555025903218
  - 0.35378040568299185
  - 0.39743747638180615
  - 0.3692287144218108
  - 0.40672502066452587
  train_level1__precision_macro_oob:
  - 0.3778717677593003
  - 0.3572280215100858
  - 0.39659955043282785
  - 0.3724960058989799
  - 0.40959338652311833
  train_level1__precision_micro:
  - 0.3979140632509853
  - 0.37282526705112295
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__precision_micro_masked:
  - 0.37670772096874355
  - 0.3464089991346986
  - 0.3912439193884642
  - 0.36259430840502976
  - 0.40159354304635764
  train_level1__precision_micro_oob:
  - 0.3778717677593002
  - 0.35722802151008587
  - 0.39659955043282796
  - 0.37249600589897996
  - 0.40959338652311833
  train_level1__precision_samples:
  - 0.3979140632509853
  - 0.3728252670511229
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__precision_samples_masked:
  - 0.3771150408699874
  - 0.34684710257424173
  - 0.39170994694364825
  - 0.3630510758257169
  - 0.4020564968929903
  train_level1__precision_samples_oob:
  - 0.37787176775930015
  - 0.3572280215100858
  - 0.39659955043282796
  - 0.3724960058989799
  - 0.4095933865231184
  train_level1__precision_weighted:
  - 0.4702272470276145
  - 0.4600853699968917
  - 0.4800645997124958
  - 0.46538283259301627
  - 0.48296315198530165
  train_level1__precision_weighted_masked:
  - 0.47052177501262243
  - 0.45146708935140156
  - 0.4800333227023371
  - 0.4575443698062464
  - 0.47546183695113076
  train_level1__precision_weighted_oob:
  - 0.44990979188463137
  - 0.4401764609298276
  - 0.46397044842037477
  - 0.4473866414508622
  - 0.4650990099009901
  train_level1__recall_macro:
  - 0.39791406325098533
  - 0.37282526705112295
  - 0.41068439427997505
  - 0.3881774609807054
  - 0.423892146496203
  train_level1__recall_macro_masked:
  - 0.3832555025903218
  - 0.35378040568299185
  - 0.39743747638180615
  - 0.3692287144218108
  - 0.40672502066452587
  train_level1__recall_macro_oob:
  - 0.3778717677593003
  - 0.3572280215100858
  - 0.39659955043282785
  - 0.3724960058989799
  - 0.40959338652311833
  train_level1__recall_micro:
  - 0.3979140632509853
  - 0.37282526705112295
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__recall_micro_masked:
  - 0.37670772096874355
  - 0.3464089991346986
  - 0.3912439193884642
  - 0.36259430840502976
  - 0.40159354304635764
  train_level1__recall_micro_oob:
  - 0.3778717677593002
  - 0.35722802151008587
  - 0.39659955043282796
  - 0.37249600589897996
  - 0.40959338652311833
  train_level1__recall_samples:
  - 0.3979140632509853
  - 0.3728252670511229
  - 0.4106843942799751
  - 0.38817746098070544
  - 0.423892146496203
  train_level1__recall_samples_masked:
  - 0.3771150408699874
  - 0.34684710257424173
  - 0.39170994694364825
  - 0.3630510758257169
  - 0.4020564968929903
  train_level1__recall_samples_oob:
  - 0.37787176775930015
  - 0.3572280215100858
  - 0.39659955043282796
  - 0.3724960058989799
  - 0.4095933865231184
  train_level1__recall_weighted:
  - 0.4702272470276145
  - 0.4600853699968917
  - 0.4800645997124958
  - 0.46538283259301627
  - 0.48296315198530165
  train_level1__recall_weighted_masked:
  - 0.47052177501262243
  - 0.45146708935140156
  - 0.4800333227023371
  - 0.4575443698062464
  - 0.47546183695113076
  train_level1__recall_weighted_oob:
  - 0.44990979188463137
  - 0.4401764609298276
  - 0.46397044842037477
  - 0.4473866414508622
  - 0.4650990099009901
  train_level1__roc_auc_macro:
  - 0.7141850290756424
  - 0.6937589803234605
  - 0.7084800699694189
  - 0.6954743166859794
  - 0.6908188208838919
  train_level1__roc_auc_macro_masked:
  - 0.6696046091349966
  - 0.6531394861088243
  - 0.6683780407214447
  - 0.6558496546901649
  - 0.6493693667452333
  train_level1__roc_auc_macro_oob:
  - 0.689716407429436
  - 0.6717171904834998
  - 0.6835813358270378
  - 0.6756888408832136
  - 0.6694030189543924
  train_level1__roc_auc_micro:
  - 0.46063019291596896
  - 0.4344820739206152
  - 0.456170558451936
  - 0.4533480758713671
  - 0.4833515524651555
  train_level1__roc_auc_micro_masked:
  - 0.43263015862881443
  - 0.4113195909455442
  - 0.4308539919541384
  - 0.42911207296515963
  - 0.4566425366971508
  train_level1__roc_auc_micro_oob:
  - 0.4331101951866545
  - 0.4123436129560896
  - 0.43096471889110016
  - 0.4304333696727243
  - 0.46238769050455764
  train_level1__roc_auc_samples:
  - 0.44557287115181626
  - 0.4198266860736191
  - 0.441044785693536
  - 0.43784874464658036
  - 0.4662439655932355
  train_level1__roc_auc_samples_masked:
  - 0.41838369627732763
  - 0.40001239391407734
  - 0.4177878502396978
  - 0.4160224286519842
  - 0.4410559532601623
  train_level1__roc_auc_samples_oob:
  - 0.41893555719503883
  - 0.39909937867075873
  - 0.41716487578261624
  - 0.41569943167690726
  - 0.4457992992389271
  train_level1__roc_auc_weighted:
  - 0.7127486193858223
  - 0.703071458727986
  - 0.7125806434418724
  - 0.7046164912679524
  - 0.6961417143033906
  train_level1__roc_auc_weighted_masked:
  - 0.6569374173619272
  - 0.6524626135932442
  - 0.6617060355220352
  - 0.6557162696965713
  - 0.6475563809213507
  train_level1__roc_auc_weighted_oob:
  - 0.6854680055535364
  - 0.6762679857762534
  - 0.6833716168040741
  - 0.6803550201887827
  - 0.6703926864275934
  train_level1__tn_macro:
  - 0.2578102470441219
  - 0.2240066184879675
  - 0.2747142378879908
  - 0.2379746835443038
  - 0.27917427665096606
  train_level1__tn_macro_masked:
  - 0.2839366194181611
  - 0.24815212457966931
  - 0.3015636310704105
  - 0.2622307465419431
  - 0.30486604179699334
  train_level1__tn_macro_oob:
  - 0.24430452754013263
  - 0.21378689442051732
  - 0.2682098617820078
  - 0.22762688951702104
  - 0.2714120926655772
  train_level1__tn_micro:
  - 0.25781024704412187
  - 0.2240066184879675
  - 0.2747142378879908
  - 0.2379746835443038
  - 0.27917427665096606
  train_level1__tn_micro_masked:
  - 0.2775822811012213
  - 0.2413928730629048
  - 0.2956785833783749
  - 0.25630708140304437
  - 0.3005225579470199
  train_level1__tn_micro_oob:
  - 0.24430452754013265
  - 0.21378689442051732
  - 0.26820986178200773
  - 0.227626889517021
  - 0.27141209266557725
  train_level1__tn_samples:
  - 0.2578102470441218
  - 0.22400661848796746
  - 0.2747142378879907
  - 0.23797468354430373
  - 0.279174276650966
  train_level1__tn_samples_masked:
  - 0.27767004124501354
  - 0.2413665892482742
  - 0.2957573390556503
  - 0.25634030064308905
  - 0.3005986510570052
  train_level1__tn_samples_oob:
  - 0.24430452754013257
  - 0.21378689442051726
  - 0.2682098617820077
  - 0.22762688951702095
  - 0.2714120926655772
  train_level1__tn_weighted:
  - 0.3253632519337952
  - 0.2968419710173662
  - 0.33610687855101934
  - 0.3003922752760627
  - 0.3218658773093804
  train_level1__tn_weighted_masked:
  - 0.3686263362665282
  - 0.33781270643122063
  - 0.3798812955601739
  - 0.3408491098494057
  - 0.3629677041734988
  train_level1__tn_weighted_oob:
  - 0.3153670110297376
  - 0.28719666905211116
  - 0.3315088393601891
  - 0.2917677815124715
  - 0.3158635296519342
  train_level1__tp_macro:
  - 0.14010381620686338
  - 0.14881864856315546
  - 0.1359701563919843
  - 0.15020277743640167
  - 0.14471786984523693
  train_level1__tp_macro_masked:
  - 0.09931888317216071
  - 0.10562828110332254
  - 0.09587384531139558
  - 0.1069979678798677
  - 0.10185897886753251
  train_level1__tp_macro_oob:
  - 0.13356724021916752
  - 0.14344112708956858
  - 0.1283896886508202
  - 0.144869116381959
  - 0.13818129385754108
  train_level1__tp_micro:
  - 0.1401038162068634
  - 0.14881864856315546
  - 0.13597015639198431
  - 0.15020277743640162
  - 0.14471786984523696
  train_level1__tp_micro_masked:
  - 0.09912543986752226
  - 0.1050161260717938
  - 0.0955653360100893
  - 0.10628722700198544
  - 0.10107098509933775
  train_level1__tp_micro_oob:
  - 0.13356724021916755
  - 0.14344112708956858
  - 0.12838968865082023
  - 0.14486911638195896
  - 0.1381812938575411
  train_level1__tp_samples:
  - 0.14010381620686338
  - 0.14881864856315544
  - 0.1359701563919843
  - 0.1502027774364016
  - 0.14471786984523693
  train_level1__tp_samples_masked:
  - 0.09944499962497379
  - 0.10548051332596761
  - 0.09595260788799793
  - 0.10671077518262784
  - 0.10145784583598505
  train_level1__tp_samples_oob:
  - 0.13356724021916752
  - 0.14344112708956855
  - 0.1283896886508202
  - 0.14486911638195893
  - 0.13818129385754108
  train_level1__tp_weighted:
  - 0.14486399509381953
  - 0.16324339897952542
  - 0.14395772116147648
  - 0.1649905573169536
  - 0.16109727467592125
  train_level1__tp_weighted_masked:
  - 0.10189543874609411
  - 0.11365438292018103
  - 0.10015202714216326
  - 0.11669525995684074
  - 0.11249413277763193
  train_level1__tp_weighted_oob:
  - 0.13454278085489385
  - 0.15297979187771651
  - 0.13246160906018575
  - 0.15561885993839078
  - 0.14923548024905586
  train_level2__average_precision_macro:
  - 0.39280379633965207
  - 0.37959628442591564
  - 0.3818573782985856
  - 0.36748636542410945
  - 0.3634372644422965
  train_level2__average_precision_macro_masked:
  - 0.3125612218748711
  - 0.297590732580096
  - 0.30109963062163825
  - 0.290098245941219
  - 0.2848937890227858
  train_level2__average_precision_macro_oob:
  - 0.389204667501636
  - 0.3733687563605678
  - 0.3775946082213311
  - 0.364565120559931
  - 0.35988835572263855
  train_level2__average_precision_micro:
  - 0.24739326760948346
  - 0.22596380512377967
  - 0.23077917349102026
  - 0.2200689837893669
  - 0.23245170358940176
  train_level2__average_precision_micro_masked:
  - 0.17770447684166615
  - 0.16223457052989335
  - 0.16577178878257762
  - 0.15886580455286317
  - 0.16734856336894488
  train_level2__average_precision_micro_oob:
  - 0.24612775637370288
  - 0.2245224557880829
  - 0.23006198867154054
  - 0.21962480873244952
  - 0.23220350901785175
  train_level2__average_precision_samples:
  - 0.2597151823615222
  - 0.2386447523311271
  - 0.24319393068815234
  - 0.2307024026486146
  - 0.24264329440344143
  train_level2__average_precision_samples_masked:
  - 0.19557493687943733
  - 0.17844222987836147
  - 0.18216606834076302
  - 0.17220027791664072
  - 0.18189258616459883
  train_level2__average_precision_samples_oob:
  - 0.25855506548341717
  - 0.23721240807356256
  - 0.2424261217674297
  - 0.23028296573764853
  - 0.2422707206376481
  train_level2__average_precision_weighted:
  - 0.5241038485037179
  - 0.5155800446193308
  - 0.5228806006031427
  - 0.5091748089478068
  - 0.49899954578416517
  train_level2__average_precision_weighted_masked:
  - 0.42782359881959
  - 0.4184288512486792
  - 0.4271281710309884
  - 0.4157122654243588
  - 0.4064583168178498
  train_level2__average_precision_weighted_oob:
  - 0.5200641744358692
  - 0.5086829400959713
  - 0.5177569523874422
  - 0.5057010090598537
  - 0.49481385079320556
  train_level2__f1_macro:
  - 0.4187253676823993
  - 0.392461736866438
  - 0.42323879669042036
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__f1_macro_masked:
  - 0.3899317799181966
  - 0.3619191651262731
  - 0.3960968228478565
  - 0.37611257510024565
  - 0.401726111088252
  train_level2__f1_macro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690276
  - 0.4002703699152022
  - 0.42516581755262906
  train_level2__f1_micro:
  - 0.4187253676823993
  - 0.3924617368664379
  - 0.4232387966904204
  - 0.40494039572323953
  - 0.4293473036624051
  train_level2__f1_micro_masked:
  - 0.3836162285241151
  - 0.3536722867556441
  - 0.38879880575502535
  - 0.3684447385837194
  - 0.3954108029801324
  train_level2__f1_micro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.42516581755262906
  train_level2__f1_samples:
  - 0.4187253676823993
  - 0.39246173686643787
  - 0.4232387966904203
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__f1_samples_masked:
  - 0.3842874160339631
  - 0.3544673430787009
  - 0.3895160275817756
  - 0.3690819393473766
  - 0.3960778558462279
  train_level2__f1_samples_oob:
  - 0.41310198981063156
  - 0.38652456383677636
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.425165817552629
  train_level2__f1_weighted:
  - 0.5073098625841593
  - 0.5043410442050739
  - 0.5231788230581422
  - 0.5090260395559688
  - 0.5170031642339491
  train_level2__f1_weighted_masked:
  - 0.47407891562829246
  - 0.4709876981636198
  - 0.4937434485934918
  - 0.4782442999467486
  - 0.48628028000236595
  train_level2__f1_weighted_oob:
  - 0.501956971085523
  - 0.4981902634625294
  - 0.5222866472799922
  - 0.503795879123062
  - 0.5130420026538736
  train_level2__fn_macro:
  - -0.05260501778333173
  - -0.04730272282648368
  - -0.049882825577502524
  - -0.04937937814919503
  - -0.05135537825627224
  train_level2__fn_macro_masked:
  - -0.051565702969871736
  - -0.046500534914958584
  - -0.04786061800184804
  - -0.04781191915587978
  - -0.04947346801663042
  train_level2__fn_macro_oob:
  - -0.052917427665096606
  - -0.048105701146069046
  - -0.05012195705198718
  - -0.049748064397197984
  - -0.05154763049120447
  train_level2__fn_micro:
  - -0.05260501778333173
  - -0.047302722826483685
  - -0.04988282557750251
  - -0.04937937814919503
  - -0.051355378256272226
  train_level2__fn_micro_masked:
  - -0.047169323121506936
  - -0.04260953929255054
  - -0.04411499755488637
  - -0.04383851753805427
  - -0.04558153973509934
  train_level2__fn_micro_oob:
  - -0.052917427665096606
  - -0.04810570114606905
  - -0.05012195705198718
  - -0.049748064397197984
  - -0.05154763049120446
  train_level2__fn_samples:
  - -0.05260501778333172
  - -0.04730272282648367
  - -0.04988282557750251
  - -0.04937937814919503
  - -0.051355378256272226
  train_level2__fn_samples_masked:
  - -0.04707721711489072
  - -0.04240986764482971
  - -0.04396554610181404
  - -0.043714870229172524
  - -0.045422571501604
  train_level2__fn_samples_oob:
  - -0.052917427665096606
  - -0.04810570114606905
  - -0.05012195705198719
  - -0.04974806439719798
  - -0.051547630491204456
  train_level2__fn_weighted:
  - -0.1078651696839609
  - -0.0963895110665002
  - -0.09904520205157329
  - -0.10067648281908455
  - -0.1019286516280494
  train_level2__fn_weighted_masked:
  - -0.11037555278388664
  - -0.09794651087392857
  - -0.09824152079596143
  - -0.10060139224205929
  - -0.10169615832854687
  train_level2__fn_weighted_oob:
  - -0.10851970061704184
  - -0.09762560500963988
  - -0.09821666256791463
  - -0.1010364437239929
  - -0.10189241604572828
  train_level2__fp_macro:
  - -0.528669614534269
  - -0.5602355403070783
  - -0.5268783777320771
  - -0.5456802261275656
  - -0.5192973180813227
  train_level2__fp_macro_masked:
  - -0.5585025171119317
  - -0.5915802999587683
  - -0.5560425591502955
  - -0.5760755057438744
  - -0.5488004208951175
  train_level2__fp_macro_oob:
  - -0.5339805825242719
  - -0.5653697350171546
  - -0.5283131665789851
  - -0.5499815656875999
  - -0.5232865519561665
  train_level2__fp_micro:
  - -0.528669614534269
  - -0.5602355403070783
  - -0.5268783777320771
  - -0.5456802261275654
  - -0.5192973180813227
  train_level2__fp_micro_masked:
  - -0.569214448354378
  - -0.6037181739518054
  - -0.5670861966900883
  - -0.5877167438782264
  - -0.5590076572847682
  train_level2__fp_micro_oob:
  - -0.5339805825242718
  - -0.5653697350171545
  - -0.5283131665789851
  - -0.5499815656875998
  - -0.5232865519561665
  train_level2__fp_samples:
  - -0.528669614534269
  - -0.5602355403070783
  - -0.5268783777320771
  - -0.5456802261275655
  - -0.5192973180813226
  train_level2__fp_samples_masked:
  - -0.5686353668511461
  - -0.6031227892764692
  - -0.5665184263164104
  - -0.5872031904234509
  - -0.5584995726521681
  train_level2__fp_samples_oob:
  - -0.5339805825242718
  - -0.5653697350171545
  - -0.5283131665789851
  - -0.5499815656875998
  - -0.5232865519561665
  train_level2__fp_weighted:
  - -0.38482496773187974
  - -0.399269444728426
  - -0.3777759748902844
  - -0.39029747762494676
  - -0.3810681841380015
  train_level2__fp_weighted_masked:
  - -0.415545531587821
  - -0.43106579096245157
  - -0.40801503061054684
  - -0.4211543078111922
  - -0.41202356166908727
  train_level2__fp_weighted_oob:
  - -0.38952332829743513
  - -0.4041841315278307
  - -0.3794966901520933
  - -0.395167677152945
  - -0.3850655813003981
  train_level2__jaccard_macro:
  - 0.28496253984059305
  - 0.26942655241080044
  - 0.29351471908780746
  - 0.276011017990793
  - 0.2940641143438292
  train_level2__jaccard_macro_masked:
  - 0.26168623017226106
  - 0.24529571425798538
  - 0.2715782832298665
  - 0.25290035609559985
  - 0.2717280022209806
  train_level2__jaccard_macro_oob:
  - 0.2805306390269142
  - 0.264628693063727
  - 0.2923273546247271
  - 0.27196852713511543
  - 0.2905814433176807
  train_level2__jaccard_micro:
  - 0.26480243161094225
  - 0.2441383485960796
  - 0.2684228885147944
  - 0.25387163880114033
  - 0.2733559778450993
  train_level2__jaccard_micro_masked:
  - 0.23732991836081319
  - 0.2148249609785621
  - 0.24130990415335463
  - 0.2258242471443406
  - 0.24642494397601045
  train_level2__jaccard_micro_oob:
  - 0.26032044098494717
  - 0.23956024069130888
  - 0.2670777341797082
  - 0.25021126219559037
  - 0.26997497405847526
  train_level2__jaccard_samples:
  - 0.2698216953074619
  - 0.24794030709385365
  - 0.27323406086890123
  - 0.25849547735406136
  - 0.27822792656766276
  train_level2__jaccard_samples_masked:
  - 0.24245992490879967
  - 0.21860457744971315
  - 0.24624253263617568
  - 0.2305031019619454
  - 0.2513889587623094
  train_level2__jaccard_samples_oob:
  - 0.2653506013468721
  - 0.24330246811817247
  - 0.271816151125285
  - 0.2548898893098293
  - 0.27488728599364026
  train_level2__jaccard_weighted:
  - 0.3555873823038065
  - 0.3574137497214135
  - 0.3732238376892172
  - 0.35832291351185686
  - 0.36469900645318426
  train_level2__jaccard_weighted_masked:
  - 0.3264145118718035
  - 0.327806371423486
  - 0.3468240586096692
  - 0.3308600834637477
  - 0.3376975142840122
  train_level2__jaccard_weighted_oob:
  - 0.35079498691554306
  - 0.35188821547555904
  - 0.3725600161839952
  - 0.3534616793957072
  - 0.36114368189045243
  train_level2__label_ranking_average_precision_score:
  - 0.25971518236152225
  - 0.23864475233112728
  - 0.24319393068815218
  - 0.23070240264861472
  - 0.2426432944034415
  train_level2__label_ranking_average_precision_score_oob:
  - 0.2585550654834173
  - 0.23721240807356267
  - 0.24242612176742964
  - 0.23028296573764845
  - 0.24227072063764826
  train_level2__matthews_corrcoef_macro:
  - 0.17934533739354375
  - 0.17197328607152404
  - 0.1857599368590692
  - 0.17493956031075708
  - 0.18039079769776803
  train_level2__matthews_corrcoef_macro_masked:
  - 0.13966991396673306
  - 0.1362740581029569
  - 0.14823991514843401
  - 0.13853728724688283
  - 0.14063411318655566
  train_level2__matthews_corrcoef_macro_oob:
  - 0.17306170581951857
  - 0.1634204123512021
  - 0.17987501066142303
  - 0.16772665454014923
  - 0.17562810130854262
  train_level2__matthews_corrcoef_micro:
  - 0.07922178082823234
  - 0.06491178309664684
  - 0.09203458699315037
  - 0.07322501452971848
  - 0.09470958465198498
  train_level2__matthews_corrcoef_micro_masked:
  - 0.033340830245684745
  - 0.022290275664464326
  - 0.049248625400436806
  - 0.03193883807002917
  - 0.05044244924537589
  train_level2__matthews_corrcoef_micro_oob:
  - 0.07188725844894285
  - 0.05531582910385965
  - 0.0894479972564324
  - 0.06665948474412804
  - 0.08947323170251456
  train_level2__matthews_corrcoef_samples:
  - 0.072793391699772
  - 0.057461239816394324
  - 0.08593665574127679
  - 0.06609672672824682
  - 0.08876450752221232
  train_level2__matthews_corrcoef_samples_masked:
  - 0.02637926998592546
  - 0.01643856958702619
  - 0.04451035754205675
  - 0.025962465609835093
  - 0.045278176380331686
  train_level2__matthews_corrcoef_samples_oob:
  - 0.06556907463854013
  - 0.04820968010673757
  - 0.08356564945499582
  - 0.05887365908810829
  - 0.08317726424964421
  train_level2__matthews_corrcoef_weighted:
  - 0.21445580374657083
  - 0.22082383654477755
  - 0.2318029534507998
  - 0.2246330090313865
  - 0.22057991899088172
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.1601466473900769
  - 0.17161952339993125
  - 0.18382889017589296
  - 0.1775119818547587
  - 0.1717876021071684
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.20669285622224148
  - 0.21070131760100003
  - 0.22625744754651167
  - 0.21521848857274725
  - 0.21508882460614126
  train_level2__ndcg:
  - 0.6001217750207285
  - 0.5892613949110698
  - 0.5861184992099471
  - 0.5841577671618604
  - 0.5954658522013678
  train_level2__ndcg_oob:
  - 0.6006402786676132
  - 0.5890045742186091
  - 0.587398450599717
  - 0.5851528226225517
  - 0.5963663586184457
  train_level2__neg_coverage_error:
  - -93.66336633663366
  - -94.55388471177945
  - -92.92118226600985
  - -94.80506329113923
  - -92.43069306930693
  train_level2__neg_coverage_error_oob:
  - -94.19059405940594
  - -94.95488721804512
  - -93.53694581280789
  - -95.36455696202532
  - -93.10396039603961
  train_level2__neg_hamming_loss_macro:
  - -0.5812746323176007
  - -0.6075382631335621
  - -0.5767612033095797
  - -0.5950596042767605
  - -0.5706526963375949
  train_level2__neg_hamming_loss_macro_masked:
  - -0.6100682200818035
  - -0.6380808348737269
  - -0.6039031771521435
  - -0.6238874248997544
  - -0.598273888911748
  train_level2__neg_hamming_loss_macro_oob:
  - -0.5868980101893685
  - -0.6134754361632236
  - -0.5784351236309724
  - -0.599729630084798
  - -0.574834182447371
  train_level2__neg_hamming_loss_micro:
  - -0.5812746323176007
  - -0.6075382631335621
  - -0.5767612033095796
  - -0.5950596042767605
  - -0.570652696337595
  train_level2__neg_hamming_loss_micro_masked:
  - -0.6163837714758849
  - -0.6463277132443559
  - -0.6112011942449747
  - -0.6315552614162806
  - -0.6045891970198676
  train_level2__neg_hamming_loss_micro_oob:
  - -0.5868980101893685
  - -0.6134754361632236
  - -0.5784351236309723
  - -0.5997296300847978
  - -0.574834182447371
  train_level2__neg_hamming_loss_samples:
  - -0.5812746323176007
  - -0.607538263133562
  - -0.5767612033095796
  - -0.5950596042767604
  - -0.570652696337595
  train_level2__neg_hamming_loss_samples_masked:
  - -0.6157125839660369
  - -0.645532656921299
  - -0.6104839724182244
  - -0.6309180606526233
  - -0.6039221441537722
  train_level2__neg_hamming_loss_samples_oob:
  - -0.5868980101893685
  - -0.6134754361632235
  - -0.5784351236309724
  - -0.599729630084798
  - -0.574834182447371
  train_level2__neg_hamming_loss_weighted:
  - -0.4926901374158406
  - -0.49565895579492614
  - -0.4768211769418578
  - -0.49097396044403124
  - -0.4829968357660509
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.5259210843717075
  - -0.5290123018363801
  - -0.5062565514065083
  - -0.5217557000532513
  - -0.5137197199976341
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.49804302891447705
  - -0.5018097365374705
  - -0.4777133527200078
  - -0.4962041208769378
  - -0.4869579973461264
  train_level2__neg_label_ranking_loss:
  - -0.4687500798967902
  - -0.5137999236299039
  - -0.48784915689063696
  - -0.5259459081295109
  - -0.4999714457842805
  train_level2__neg_label_ranking_loss_oob:
  - -0.4748079098990632
  - -0.5199332689072044
  - -0.49276108314975825
  - -0.5304839768709425
  - -0.5050608056198443
  train_level2__precision_macro:
  - 0.4187253676823993
  - 0.392461736866438
  - 0.42323879669042036
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__precision_macro_masked:
  - 0.3899317799181966
  - 0.3619191651262731
  - 0.3960968228478565
  - 0.37611257510024565
  - 0.401726111088252
  train_level2__precision_macro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690276
  - 0.4002703699152022
  - 0.42516581755262906
  train_level2__precision_micro:
  - 0.4187253676823993
  - 0.3924617368664379
  - 0.4232387966904204
  - 0.40494039572323953
  - 0.4293473036624051
  train_level2__precision_micro_masked:
  - 0.3836162285241151
  - 0.3536722867556441
  - 0.38879880575502535
  - 0.3684447385837194
  - 0.3954108029801324
  train_level2__precision_micro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.42516581755262906
  train_level2__precision_samples:
  - 0.4187253676823993
  - 0.39246173686643787
  - 0.4232387966904203
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__precision_samples_masked:
  - 0.3842874160339631
  - 0.3544673430787009
  - 0.3895160275817756
  - 0.3690819393473766
  - 0.3960778558462279
  train_level2__precision_samples_oob:
  - 0.41310198981063156
  - 0.38652456383677636
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.425165817552629
  train_level2__precision_weighted:
  - 0.5073098625841593
  - 0.5043410442050739
  - 0.5231788230581422
  - 0.5090260395559688
  - 0.5170031642339491
  train_level2__precision_weighted_masked:
  - 0.47407891562829246
  - 0.4709876981636198
  - 0.4937434485934918
  - 0.4782442999467486
  - 0.48628028000236595
  train_level2__precision_weighted_oob:
  - 0.501956971085523
  - 0.4981902634625294
  - 0.5222866472799922
  - 0.503795879123062
  - 0.5130420026538736
  train_level2__recall_macro:
  - 0.4187253676823993
  - 0.392461736866438
  - 0.42323879669042036
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__recall_macro_masked:
  - 0.3899317799181966
  - 0.3619191651262731
  - 0.3960968228478565
  - 0.37611257510024565
  - 0.401726111088252
  train_level2__recall_macro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690276
  - 0.4002703699152022
  - 0.42516581755262906
  train_level2__recall_micro:
  - 0.4187253676823993
  - 0.3924617368664379
  - 0.4232387966904204
  - 0.40494039572323953
  - 0.4293473036624051
  train_level2__recall_micro_masked:
  - 0.3836162285241151
  - 0.3536722867556441
  - 0.38879880575502535
  - 0.3684447385837194
  - 0.3954108029801324
  train_level2__recall_micro_oob:
  - 0.41310198981063156
  - 0.3865245638367764
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.42516581755262906
  train_level2__recall_samples:
  - 0.4187253676823993
  - 0.39246173686643787
  - 0.4232387966904203
  - 0.4049403957232395
  - 0.4293473036624051
  train_level2__recall_samples_masked:
  - 0.3842874160339631
  - 0.3544673430787009
  - 0.3895160275817756
  - 0.3690819393473766
  - 0.3960778558462279
  train_level2__recall_samples_oob:
  - 0.41310198981063156
  - 0.38652456383677636
  - 0.4215648763690277
  - 0.40027036991520215
  - 0.425165817552629
  train_level2__recall_weighted:
  - 0.5073098625841593
  - 0.5043410442050739
  - 0.5231788230581422
  - 0.5090260395559688
  - 0.5170031642339491
  train_level2__recall_weighted_masked:
  - 0.47407891562829246
  - 0.4709876981636198
  - 0.4937434485934918
  - 0.4782442999467486
  - 0.48628028000236595
  train_level2__recall_weighted_oob:
  - 0.501956971085523
  - 0.4981902634625294
  - 0.5222866472799922
  - 0.503795879123062
  - 0.5130420026538736
  train_level2__roc_auc_macro:
  - 0.694194453998641
  - 0.6765089732874054
  - 0.6875393390497161
  - 0.664660350345539
  - 0.6744021976610499
  train_level2__roc_auc_macro_masked:
  - 0.6699013424460113
  - 0.6537560822222832
  - 0.6624650868430485
  - 0.6422497590272318
  - 0.6482418820257317
  train_level2__roc_auc_macro_oob:
  - 0.6889956830342839
  - 0.6704474976692784
  - 0.6816450457092775
  - 0.6601105444789072
  - 0.6692010335274513
  train_level2__roc_auc_micro:
  - 0.558668280497423
  - 0.515625119985464
  - 0.5408770861686527
  - 0.5087791338715881
  - 0.5366331913406197
  train_level2__roc_auc_micro_masked:
  - 0.5331927540931125
  - 0.4927189043926923
  - 0.5172499443342667
  - 0.4877331327730495
  - 0.5142934751133529
  train_level2__roc_auc_micro_oob:
  - 0.5536357604862567
  - 0.5104930270568542
  - 0.5372127645176571
  - 0.5058097531477954
  - 0.5337123659005565
  train_level2__roc_auc_samples:
  - 0.5357122929740965
  - 0.49605184336313674
  - 0.5195823898998131
  - 0.49066232130466897
  - 0.5160946091183503
  train_level2__roc_auc_samples_masked:
  - 0.5114553689287785
  - 0.4765513071699126
  - 0.49893647513601463
  - 0.47256358331921194
  - 0.49593666525590613
  train_level2__roc_auc_samples_oob:
  - 0.530358464431892
  - 0.49070895091007266
  - 0.5159115591377428
  - 0.48737360601475915
  - 0.5126090548169125
  train_level2__roc_auc_weighted:
  - 0.6960945127174492
  - 0.6906077362085684
  - 0.7018090635651477
  - 0.6862078415013594
  - 0.6839832427811717
  train_level2__roc_auc_weighted_masked:
  - 0.6623863243959714
  - 0.6601256935905904
  - 0.6705846537862773
  - 0.655725446955488
  - 0.6522232137992076
  train_level2__roc_auc_weighted_oob:
  - 0.6898493618189914
  - 0.6828749492415485
  - 0.6942024614141667
  - 0.6801642065640237
  - 0.6771520852526273
  train_level2__tn_macro:
  - 0.2377679515524368
  - 0.20354283767671602
  - 0.24080539480606433
  - 0.2193928966449551
  - 0.24759684706334711
  train_level2__tn_macro_masked:
  - 0.2593232223745828
  - 0.22385242747589482
  - 0.2627739475890919
  - 0.2402780059299545
  - 0.26931262638980574
  train_level2__tn_macro_oob:
  - 0.23245698356243394
  - 0.19840864296663985
  - 0.2393706059591563
  - 0.21509155708492075
  - 0.24360761318850332
  train_level2__tn_micro:
  - 0.2377679515524368
  - 0.20354283767671605
  - 0.2408053948060644
  - 0.21939289664495515
  - 0.24759684706334711
  train_level2__tn_micro_masked:
  - 0.25600289795073483
  - 0.21934079765057557
  - 0.2591820451445191
  - 0.23629384513567175
  - 0.26653042218543044
  train_level2__tn_micro_oob:
  - 0.2324569835624339
  - 0.1984086429666399
  - 0.23937060595915635
  - 0.21509155708492073
  - 0.24360761318850332
  train_level2__tn_samples:
  - 0.23776795155243674
  - 0.20354283767671602
  - 0.2408053948060643
  - 0.2193928966449551
  - 0.2475968470633471
  train_level2__tn_samples_masked:
  - 0.25635489953609664
  - 0.21966428628178547
  - 0.2595120161099175
  - 0.23656360777966068
  - 0.26680686038385626
  train_level2__tn_samples_oob:
  - 0.23245698356243386
  - 0.19840864296663988
  - 0.23937060595915627
  - 0.2150915570849207
  - 0.24360761318850327
  train_level2__tn_weighted:
  - 0.27044683324181784
  - 0.251229381653557
  - 0.2769058563138106
  - 0.26041701431102854
  - 0.27351178932326226
  train_level2__tn_weighted_masked:
  - 0.3034407095531384
  - 0.28348616303996416
  - 0.3105445120298471
  - 0.29330666776476094
  - 0.3064357500167976
  train_level2__tn_weighted_oob:
  - 0.2657484726762624
  - 0.24631469485415228
  - 0.2751851410520018
  - 0.2555468147830302
  - 0.2695143921608656
  train_level2__tp_macro:
  - 0.18095741612996252
  - 0.18891889918972185
  - 0.18243340188435608
  - 0.18554749907828436
  - 0.181750456599058
  train_level2__tp_macro_masked:
  - 0.1306085575436138
  - 0.13806673765037836
  - 0.13332287525876466
  - 0.13583456917029116
  - 0.1324134846984462
  train_level2__tp_macro_oob:
  - 0.18064500624819763
  - 0.1881159208701365
  - 0.1821942704098714
  - 0.18517881283028143
  - 0.18155820436412573
  train_level2__tp_micro:
  - 0.18095741612996252
  - 0.18891889918972188
  - 0.18243340188435603
  - 0.18554749907828438
  - 0.18175045659905797
  train_level2__tp_micro_masked:
  - 0.12761333057338026
  - 0.13433148910506856
  - 0.12961676061050625
  - 0.13215089344804765
  - 0.128880380794702
  train_level2__tp_micro_oob:
  - 0.18064500624819763
  - 0.1881159208701365
  - 0.18219427040987135
  - 0.18517881283028143
  - 0.18155820436412573
  train_level2__tp_samples:
  - 0.18095741612996247
  - 0.18891889918972185
  - 0.18243340188435597
  - 0.18554749907828436
  - 0.18175045659905795
  train_level2__tp_samples_masked:
  - 0.1279325164978664
  - 0.13480305679691545
  - 0.13000401147185814
  - 0.13251833156771586
  - 0.12927099546237164
  train_level2__tp_samples_oob:
  - 0.1806450062481976
  - 0.18811592087013648
  - 0.1821942704098713
  - 0.1851788128302814
  - 0.18155820436412573
  train_level2__tp_weighted:
  - 0.23686302934234163
  - 0.25311166255151674
  - 0.24627296674433172
  - 0.24860902524494027
  - 0.24349137491068693
  train_level2__tp_weighted_masked:
  - 0.17063820607515406
  - 0.18750153512365575
  - 0.1831989365636446
  - 0.1849376321819877
  - 0.1798445299855683
  train_level2__tp_weighted_oob:
  - 0.23620849840926067
  - 0.251875568608377
  - 0.24710150622799035
  - 0.2482490643400319
  - 0.24352761049300808
  train_level3__average_precision_macro:
  - 0.3754101535148856
  - 0.36960462207796324
  - 0.3707878530300844
  - 0.3571241168368254
  - 0.3559388570935438
  train_level3__average_precision_macro_masked:
  - 0.2965251392870017
  - 0.2903402577956279
  - 0.29282932546248513
  - 0.282062609613693
  - 0.27836168023490426
  train_level3__average_precision_macro_oob:
  - 0.3701921324950309
  - 0.363893918268712
  - 0.3655049839287718
  - 0.35288050495073664
  - 0.35120311770887475
  train_level3__average_precision_micro:
  - 0.2588412350481557
  - 0.23172822693141668
  - 0.24003258824692758
  - 0.2297299962216558
  - 0.23812382639608576
  train_level3__average_precision_micro_masked:
  - 0.18590170732512118
  - 0.1668425054420562
  - 0.17238039881755418
  - 0.16585482212242533
  - 0.17148782752989186
  train_level3__average_precision_micro_oob:
  - 0.25887563699837435
  - 0.23236583894153887
  - 0.2407363901046034
  - 0.23032218605290755
  - 0.2384571944204659
  train_level3__average_precision_samples:
  - 0.2729133239086641
  - 0.2453868632300133
  - 0.2532309683080136
  - 0.24066720015979293
  - 0.24925343068455236
  train_level3__average_precision_samples_masked:
  - 0.2048082685265907
  - 0.18358268083326862
  - 0.18943600271724326
  - 0.1794423142521087
  - 0.18658036461715197
  train_level3__average_precision_samples_oob:
  - 0.2726903768311887
  - 0.2459664297120686
  - 0.25376820029898844
  - 0.2411932707563613
  - 0.24966290998311455
  train_level3__average_precision_weighted:
  - 0.5087442135650369
  - 0.5068528397753737
  - 0.5118834616232322
  - 0.4984559606575804
  - 0.4941305911918807
  train_level3__average_precision_weighted_masked:
  - 0.41437611668918745
  - 0.41194892920159737
  - 0.41822866327906916
  - 0.40757797648962285
  - 0.4026139391180086
  train_level3__average_precision_weighted_oob:
  - 0.503020689819068
  - 0.5002430731731304
  - 0.5055134010310939
  - 0.4939247013069619
  - 0.4889447826911263
  train_level3__f1_macro:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199579
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__f1_macro_masked:
  - 0.39714399475653295
  - 0.36687153538888
  - 0.3990295347361726
  - 0.381855521470992
  - 0.406355252377997
  train_level3__f1_macro_oob:
  - 0.422522349322311
  - 0.39353237462588503
  - 0.4254866325505763
  - 0.40779156937446226
  - 0.4310775737767951
  train_level3__f1_micro:
  - 0.42466115543593197
  - 0.39667128987517336
  - 0.42577359031995793
  - 0.40992994961287943
  - 0.43292800153801786
  train_level3__f1_micro_masked:
  - 0.3907317325605465
  - 0.3587592102158009
  - 0.39183589426813886
  - 0.37416280608868296
  - 0.40006725993377484
  train_level3__f1_micro_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767952
  train_level3__f1_samples:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199578
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__f1_samples_masked:
  - 0.3914248167769572
  - 0.35958543903172613
  - 0.3925526818943808
  - 0.37479520264502886
  - 0.40067750609066066
  train_level3__f1_samples_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767951
  train_level3__f1_weighted:
  - 0.5133277269490505
  - 0.5065444823430642
  - 0.524017503783951
  - 0.5142058743288808
  - 0.5191614780034705
  train_level3__f1_weighted_masked:
  - 0.4826015425252757
  - 0.47414976775823525
  - 0.49530378212759885
  - 0.48433376999645833
  - 0.49053248571832037
  train_level3__f1_weighted_oob:
  - 0.5099705180930687
  - 0.5034547638151827
  - 0.5238970765334191
  - 0.5118090485536668
  - 0.5179225783403084
  train_level3__fn_macro:
  - -0.0522445448428338
  - -0.0475460495899944
  - -0.050337175379023394
  - -0.049674327147597404
  - -0.05161972507930405
  train_level3__fn_macro_masked:
  - -0.0501551383186916
  - -0.04615556640815935
  - -0.048047227823392075
  - -0.047682053862308185
  - -0.04886649729476489
  train_level3__fn_macro_oob:
  - -0.053061616841295775
  - -0.04757038226634547
  - -0.050193696494332585
  - -0.04992011797959937
  - -0.05149956743247141
  train_level3__fn_micro:
  - -0.0522445448428338
  - -0.0475460495899944
  - -0.05033717537902339
  - -0.0496743271475974
  - -0.05161972507930405
  train_level3__fn_micro_masked:
  - -0.04605671703581039
  - -0.04232110548810866
  - -0.04429516382261344
  - -0.04381204500330907
  - -0.045064155629139076
  train_level3__fn_micro_oob:
  - -0.05306161684129578
  - -0.047570382266345475
  - -0.050193696494332585
  - -0.04992011797959936
  - -0.0514995674324714
  train_level3__fn_samples:
  - -0.05224454484283379
  - -0.0475460495899944
  - -0.05033717537902338
  - -0.0496743271475974
  - -0.051619725079304034
  train_level3__fn_samples_masked:
  - -0.04597726349458535
  - -0.04212306501547146
  - -0.04415041723123977
  - -0.0437077048838016
  - -0.04491507653804686
  train_level3__fn_samples_oob:
  - -0.053061616841295775
  - -0.047570382266345475
  - -0.050193696494332585
  - -0.049920117979599346
  - -0.051499567432471395
  train_level3__fn_weighted:
  - -0.1050787016143738
  - -0.09633994338958231
  - -0.0999434625750135
  - -0.09982942249980797
  - -0.102160610390936
  train_level3__fn_weighted_masked:
  - -0.10495314833024713
  - -0.09686581083910238
  - -0.09852857483073296
  - -0.09909712219004442
  - -0.09990947689461077
  train_level3__fn_weighted_oob:
  - -0.10646900681425278
  - -0.09560649667018804
  - -0.09900717239351062
  - -0.10009773772914729
  - -0.10129452893742982
  train_level3__fp_macro:
  - -0.5230942997212342
  - -0.5557826605348323
  - -0.5238892343010187
  - -0.5403957232395232
  - -0.5154522733826781
  train_level3__fp_macro_masked:
  - -0.5527008669247754
  - -0.5869728982029607
  - -0.5529232374404354
  - -0.5704624246666997
  - -0.5447782503272381
  train_level3__fp_macro_oob:
  - -0.5244160338363932
  - -0.5588972431077694
  - -0.5243196709550911
  - -0.5422883126459384
  - -0.5174228587907335
  train_level3__fp_micro:
  - -0.5230942997212342
  - -0.5557826605348323
  - -0.5238892343010187
  - -0.5403957232395231
  - -0.5154522733826781
  train_level3__fp_micro_masked:
  - -0.5632115504036431
  - -0.5989196842960904
  - -0.5638689419092476
  - -0.5820251489080079
  - -0.5548685844370861
  train_level3__fp_micro_oob:
  - -0.5244160338363933
  - -0.5588972431077694
  - -0.5243196709550911
  - -0.5422883126459384
  - -0.5174228587907335
  train_level3__fp_samples:
  - -0.5230942997212342
  - -0.5557826605348323
  - -0.5238892343010186
  - -0.5403957232395231
  - -0.5154522733826781
  train_level3__fp_samples_masked:
  - -0.5625979197284575
  - -0.5982914959528024
  - -0.5632969008743794
  - -0.5814970924711695
  - -0.5544074173712925
  train_level3__fp_samples_oob:
  - -0.5244160338363933
  - -0.5588972431077694
  - -0.524319670955091
  - -0.5422883126459384
  - -0.5174228587907334
  train_level3__fp_weighted:
  - -0.3815935714365757
  - -0.3971155742673536
  - -0.3760390336410355
  - -0.3859647031713112
  - -0.37867791160559366
  train_level3__fp_weighted_masked:
  - -0.41244530914447713
  - -0.4289844214026623
  - -0.40616764304166814
  - -0.4165691078134973
  - -0.4095580373870688
  train_level3__fp_weighted_oob:
  - -0.3835604750926786
  - -0.40093873951462927
  - -0.37709575107307025
  - -0.3880932137171857
  - -0.3807828927222619
  train_level3__jaccard_macro:
  - 0.28948293215001564
  - 0.27230532429314414
  - 0.29500546347385564
  - 0.2801761893432717
  - 0.296651634452491
  train_level3__jaccard_macro_masked:
  - 0.2670825355425109
  - 0.2486318742463048
  - 0.27327463522885803
  - 0.25752285194522917
  - 0.2751374541091259
  train_level3__jaccard_macro_oob:
  - 0.28766795655915817
  - 0.2698177258501256
  - 0.2950088922357745
  - 0.27836314225533676
  - 0.2952028437386179
  train_level3__jaccard_micro:
  - 0.2695681357069852
  - 0.24740484429065743
  - 0.2704652823138035
  - 0.2578062202436159
  - 0.27626554616694016
  train_level3__jaccard_micro_masked:
  - 0.24280086823699654
  - 0.21859023517382414
  - 0.2436541724016517
  - 0.2301354695844731
  - 0.25005254903228935
  train_level3__jaccard_micro_oob:
  - 0.26784680539898237
  - 0.24496751033761985
  - 0.27023373783090077
  - 0.2561169514811899
  - 0.2747602855129737
  train_level3__jaccard_samples:
  - 0.27472293554670996
  - 0.25125101451782306
  - 0.27528984665223716
  - 0.2623150307902841
  - 0.2808633184148364
  train_level3__jaccard_samples_masked:
  - 0.24800836799085446
  - 0.222402178003034
  - 0.2485971937728638
  - 0.2346866798229021
  - 0.2547173697924002
  train_level3__jaccard_samples_oob:
  - 0.27295326527052804
  - 0.248766510005077
  - 0.27498466735349975
  - 0.2606431621693513
  - 0.27937079137993287
  train_level3__jaccard_weighted:
  - 0.36045896794779275
  - 0.3588208619026446
  - 0.3733572204941445
  - 0.363008520782253
  - 0.3662487674758975
  train_level3__jaccard_weighted_masked:
  - 0.3331561971942528
  - 0.3299166188311774
  - 0.3475253917148385
  - 0.33610376533414965
  - 0.34103310702174616
  train_level3__jaccard_weighted_oob:
  - 0.3573219422464967
  - 0.3560887516957617
  - 0.37347807975383945
  - 0.3607459852244849
  - 0.36524950905165987
  train_level3__label_ranking_average_precision_score:
  - 0.27291332390866413
  - 0.2453868632300134
  - 0.25323096830801317
  - 0.2406672001597931
  - 0.24925343068455236
  train_level3__label_ranking_average_precision_score_oob:
  - 0.2726903768311889
  - 0.24596642971206864
  - 0.25376820029898867
  - 0.2411932707563612
  - 0.24966290998311452
  train_level3__matthews_corrcoef_macro:
  - 0.1817143034245908
  - 0.1722488293647021
  - 0.18608176714506822
  - 0.1761000170254566
  - 0.18265913510889117
  train_level3__matthews_corrcoef_macro_masked:
  - 0.14400720929324876
  - 0.13751417823493695
  - 0.14867070187239353
  - 0.14017608883804603
  - 0.14468943074322158
  train_level3__matthews_corrcoef_macro_oob:
  - 0.17646438041292187
  - 0.16682284008875142
  - 0.18388758727760207
  - 0.1729698354069173
  - 0.17897809534255527
  train_level3__matthews_corrcoef_micro:
  - 0.08698590264273696
  - 0.06918956398462944
  - 0.09351333102973561
  - 0.07812477126907029
  - 0.097911529683301
  train_level3__matthews_corrcoef_micro_masked:
  - 0.044411847609899545
  - 0.028608150408178348
  - 0.05144211934698999
  - 0.037694638537257213
  - 0.05679987195164963
  train_level3__matthews_corrcoef_micro_oob:
  - 0.08218397411363937
  - 0.06537980720852733
  - 0.09361943959432549
  - 0.07492067940911551
  - 0.0962105179726568
  train_level3__matthews_corrcoef_samples:
  - 0.08106629379839862
  - 0.061853752902608874
  - 0.08725518807118612
  - 0.07235625417458891
  - 0.09296179326396063
  train_level3__matthews_corrcoef_samples_masked:
  - 0.03818550154160861
  - 0.02265451601458024
  - 0.046593697442105175
  - 0.03279710048461174
  - 0.0526943148332033
  train_level3__matthews_corrcoef_samples_oob:
  - 0.07640082105626636
  - 0.05866248150267274
  - 0.08764566200032663
  - 0.06896033708257193
  - 0.09135768445081945
  train_level3__matthews_corrcoef_weighted:
  - 0.21492436973596638
  - 0.21902286945759622
  - 0.23194965957309507
  - 0.22629759429811397
  - 0.22138876425171358
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.1648799684337674
  - 0.172297147232123
  - 0.1848206458519301
  - 0.18044334673873907
  - 0.17644013024940572
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.20720917805813593
  - 0.2126887894071071
  - 0.22949608069557892
  - 0.221445888071153
  - 0.21836777342210872
  train_level3__ndcg:
  - 0.6219355323654826
  - 0.5978755599057398
  - 0.6062177182794873
  - 0.6013889090704089
  - 0.6061652872420347
  train_level3__ndcg_oob:
  - 0.6234500005473903
  - 0.6007787641886623
  - 0.6085616218683249
  - 0.6030609726049267
  - 0.6073004550068328
  train_level3__neg_coverage_error:
  - -92.9059405940594
  - -93.90977443609023
  - -92.03940886699507
  - -94.01012658227847
  - -91.72524752475248
  train_level3__neg_coverage_error_oob:
  - -93.44554455445545
  - -94.3358395989975
  - -92.60591133004927
  - -94.5746835443038
  - -92.3069306930693
  train_level3__neg_hamming_loss_macro:
  - -0.575338844564068
  - -0.6033287101248267
  - -0.5742264096800421
  - -0.5900700503871206
  - -0.5670719984619822
  train_level3__neg_hamming_loss_macro_masked:
  - -0.602856005243467
  - -0.6331284646111199
  - -0.6009704652638275
  - -0.618144478529008
  - -0.5936447476220029
  train_level3__neg_hamming_loss_macro_oob:
  - -0.5774776506776891
  - -0.6064676253741149
  - -0.5745133674494237
  - -0.5922084306255377
  - -0.5689224262232049
  train_level3__neg_hamming_loss_micro:
  - -0.575338844564068
  - -0.6033287101248266
  - -0.5742264096800421
  - -0.5900700503871206
  - -0.5670719984619821
  train_level3__neg_hamming_loss_micro_masked:
  - -0.6092682674394535
  - -0.6412407897841991
  - -0.6081641057318611
  - -0.625837193911317
  - -0.5999327400662252
  train_level3__neg_hamming_loss_micro_oob:
  - -0.5774776506776891
  - -0.6064676253741149
  - -0.5745133674494237
  - -0.5922084306255376
  - -0.5689224262232049
  train_level3__neg_hamming_loss_samples:
  - -0.575338844564068
  - -0.6033287101248266
  - -0.574226409680042
  - -0.5900700503871206
  - -0.567071998461982
  train_level3__neg_hamming_loss_samples_masked:
  - -0.6085751832230428
  - -0.6404145609682739
  - -0.6074473181056192
  - -0.6252047973549711
  - -0.5993224939093393
  train_level3__neg_hamming_loss_samples_oob:
  - -0.5774776506776892
  - -0.6064676253741148
  - -0.5745133674494237
  - -0.5922084306255376
  - -0.5689224262232049
  train_level3__neg_hamming_loss_weighted:
  - -0.4866722730509495
  - -0.49345551765693585
  - -0.47598249621604904
  - -0.4857941256711193
  - -0.48083852199652954
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.5173984574747242
  - -0.5258502322417646
  - -0.5046962178724012
  - -0.5156662300035416
  - -0.5094675142816796
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.49002948190693124
  - -0.4965452361848173
  - -0.4761029234665809
  - -0.4881909514463331
  - -0.4820774216596917
  train_level3__neg_label_ranking_loss:
  - -0.45930223767803957
  - -0.5068397210650751
  - -0.4867289506480854
  - -0.5208856056043749
  - -0.49842573617042274
  train_level3__neg_label_ranking_loss_oob:
  - -0.4639719800698634
  - -0.5110978487147423
  - -0.49045536658188643
  - -0.5246653786256835
  - -0.5025257194222749
  train_level3__precision_macro:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199579
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__precision_macro_masked:
  - 0.39714399475653295
  - 0.36687153538888
  - 0.3990295347361726
  - 0.381855521470992
  - 0.406355252377997
  train_level3__precision_macro_oob:
  - 0.422522349322311
  - 0.39353237462588503
  - 0.4254866325505763
  - 0.40779156937446226
  - 0.4310775737767951
  train_level3__precision_micro:
  - 0.42466115543593197
  - 0.39667128987517336
  - 0.42577359031995793
  - 0.40992994961287943
  - 0.43292800153801786
  train_level3__precision_micro_masked:
  - 0.3907317325605465
  - 0.3587592102158009
  - 0.39183589426813886
  - 0.37416280608868296
  - 0.40006725993377484
  train_level3__precision_micro_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767952
  train_level3__precision_samples:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199578
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__precision_samples_masked:
  - 0.3914248167769572
  - 0.35958543903172613
  - 0.3925526818943808
  - 0.37479520264502886
  - 0.40067750609066066
  train_level3__precision_samples_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767951
  train_level3__precision_weighted:
  - 0.5133277269490505
  - 0.5065444823430642
  - 0.524017503783951
  - 0.5142058743288808
  - 0.5191614780034705
  train_level3__precision_weighted_masked:
  - 0.4826015425252757
  - 0.47414976775823525
  - 0.49530378212759885
  - 0.48433376999645833
  - 0.49053248571832037
  train_level3__precision_weighted_oob:
  - 0.5099705180930687
  - 0.5034547638151827
  - 0.5238970765334191
  - 0.5118090485536668
  - 0.5179225783403084
  train_level3__recall_macro:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199579
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__recall_macro_masked:
  - 0.39714399475653295
  - 0.36687153538888
  - 0.3990295347361726
  - 0.381855521470992
  - 0.406355252377997
  train_level3__recall_macro_oob:
  - 0.422522349322311
  - 0.39353237462588503
  - 0.4254866325505763
  - 0.40779156937446226
  - 0.4310775737767951
  train_level3__recall_micro:
  - 0.42466115543593197
  - 0.39667128987517336
  - 0.42577359031995793
  - 0.40992994961287943
  - 0.43292800153801786
  train_level3__recall_micro_masked:
  - 0.3907317325605465
  - 0.3587592102158009
  - 0.39183589426813886
  - 0.37416280608868296
  - 0.40006725993377484
  train_level3__recall_micro_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767952
  train_level3__recall_samples:
  - 0.4246611554359319
  - 0.39667128987517336
  - 0.4257735903199578
  - 0.4099299496128794
  - 0.43292800153801786
  train_level3__recall_samples_masked:
  - 0.3914248167769572
  - 0.35958543903172613
  - 0.3925526818943808
  - 0.37479520264502886
  - 0.40067750609066066
  train_level3__recall_samples_oob:
  - 0.42252234932231086
  - 0.3935323746258851
  - 0.4254866325505763
  - 0.4077915693744623
  - 0.4310775737767951
  train_level3__recall_weighted:
  - 0.5133277269490505
  - 0.5065444823430642
  - 0.524017503783951
  - 0.5142058743288808
  - 0.5191614780034705
  train_level3__recall_weighted_masked:
  - 0.4826015425252757
  - 0.47414976775823525
  - 0.49530378212759885
  - 0.48433376999645833
  - 0.49053248571832037
  train_level3__recall_weighted_oob:
  - 0.5099705180930687
  - 0.5034547638151827
  - 0.5238970765334191
  - 0.5118090485536668
  - 0.5179225783403084
  train_level3__roc_auc_macro:
  - 0.6842104690138618
  - 0.670389273133655
  - 0.6806625694720305
  - 0.6618451422192573
  - 0.6697299216342198
  train_level3__roc_auc_macro_masked:
  - 0.6615244902637937
  - 0.6488910582105838
  - 0.657054114942615
  - 0.6405712402392769
  - 0.6441110405860603
  train_level3__roc_auc_macro_oob:
  - 0.6775891279724673
  - 0.6643069115062387
  - 0.6748320581670151
  - 0.6567991480297549
  - 0.6636757739298361
  train_level3__roc_auc_micro:
  - 0.5719025356892651
  - 0.5260993825463514
  - 0.5514642548594191
  - 0.523596583203172
  - 0.5445582293963037
  train_level3__roc_auc_micro_masked:
  - 0.5468823828789284
  - 0.5040292503898203
  - 0.5281558225203368
  - 0.5027963373102476
  - 0.5225722215184283
  train_level3__roc_auc_micro_oob:
  - 0.5690530599076193
  - 0.5243573921474989
  - 0.5500106811693941
  - 0.5225507308000952
  - 0.5430424711771805
  train_level3__roc_auc_samples:
  - 0.5538624262278768
  - 0.5081974730549305
  - 0.5337465418166887
  - 0.5092129778151676
  - 0.5273675500900066
  train_level3__roc_auc_samples_masked:
  - 0.5300677703198718
  - 0.489651403366879
  - 0.5129976646001313
  - 0.4914276490455156
  - 0.5072857073200656
  train_level3__roc_auc_samples_oob:
  - 0.5506014251701987
  - 0.5065022248499351
  - 0.5324070472036876
  - 0.508190815108193
  - 0.5259407778889207
  train_level3__roc_auc_weighted:
  - 0.6878950172213747
  - 0.6865447890211236
  - 0.6957402304683751
  - 0.6832897947207781
  - 0.6805527695538711
  train_level3__roc_auc_weighted_masked:
  - 0.6570753514758285
  - 0.6578726271779
  - 0.6656533062682295
  - 0.6544427487397932
  - 0.6495354589532402
  train_level3__roc_auc_weighted_oob:
  - 0.680765198669177
  - 0.6791410157664697
  - 0.6875650866480095
  - 0.6768011580509072
  - 0.6730536745297443
  train_level3__tn_macro:
  - 0.24334326636547157
  - 0.20799571744896223
  - 0.24379453823712272
  - 0.22467739953299742
  - 0.2514418917619917
  train_level3__tn_macro_masked:
  - 0.26512487256173917
  - 0.22845982923170252
  - 0.26589326929895196
  - 0.24589108700712928
  - 0.2733347969576852
  train_level3__tn_macro_oob:
  - 0.24202153225031242
  - 0.20488113487602502
  - 0.24336410158305039
  - 0.22278481012658227
  - 0.24947130635393636
  train_level3__tn_micro:
  - 0.2433432663654715
  - 0.20799571744896223
  - 0.24379453823712277
  - 0.22467739953299742
  - 0.2514418917619917
  train_level3__tn_micro_masked:
  - 0.26200579590146966
  - 0.22413928730629049
  - 0.2623992999253597
  - 0.24198544010589013
  - 0.2706694950331126
  train_level3__tn_micro_oob:
  - 0.24202153225031242
  - 0.20488113487602502
  - 0.24336410158305036
  - 0.22278481012658227
  - 0.24947130635393636
  train_level3__tn_samples:
  - 0.24334326636547143
  - 0.2079957174489622
  - 0.24379453823712272
  - 0.22467739953299737
  - 0.2514418917619917
  train_level3__tn_samples_masked:
  - 0.26239234665878536
  - 0.22449557960545244
  - 0.26273354155194845
  - 0.24226970573194204
  - 0.2708990156647319
  train_level3__tn_samples_oob:
  - 0.2420215322503123
  - 0.204881134876025
  - 0.24336410158305027
  - 0.22278481012658222
  - 0.2494713063539363
  train_level3__tn_weighted:
  - 0.2736782295371219
  - 0.2533832521146293
  - 0.27864279756305954
  - 0.26474978876466393
  - 0.2759020618556701
  train_level3__tn_weighted_masked:
  - 0.30654093199648214
  - 0.2855675325997534
  - 0.3123918995987258
  - 0.2978918677624558
  - 0.3089012742988161
  train_level3__tn_weighted_oob:
  - 0.27171132588101904
  - 0.24956008686735373
  - 0.2775860801310248
  - 0.26262127821878956
  - 0.2737970807390017
  train_level3__tp_macro:
  - 0.18131788907046045
  - 0.18867557242621114
  - 0.18197905208283519
  - 0.18525255007988198
  - 0.18148610977602617
  train_level3__tp_macro_masked:
  - 0.13201912219479392
  - 0.1384117061571776
  - 0.13313626543722062
  - 0.13596443446386278
  - 0.1330204554203117
  train_level3__tp_macro_oob:
  - 0.18050081707199847
  - 0.1886512397498601
  - 0.182122530967526
  - 0.18500675924788001
  - 0.18160626742285882
  train_level3__tp_micro:
  - 0.18131788907046045
  - 0.18867557242621116
  - 0.18197905208283513
  - 0.18525255007988203
  - 0.18148610977602614
  train_level3__tp_micro_masked:
  - 0.1287259366590768
  - 0.13461992290951044
  - 0.12943659434277918
  - 0.13217736598279287
  - 0.12939776490066227
  train_level3__tp_micro_oob:
  - 0.18050081707199847
  - 0.1886512397498601
  - 0.18212253096752595
  - 0.18500675924788004
  - 0.1816062674228588
  train_level3__tp_samples:
  - 0.1813178890704604
  - 0.1886755724262111
  - 0.18197905208283513
  - 0.18525255007988198
  - 0.18148610977602614
  train_level3__tp_samples_masked:
  - 0.12903247011817176
  - 0.1350898594262737
  - 0.1298191403424324
  - 0.1325254969130868
  - 0.1297784904259288
  train_level3__tp_samples_oob:
  - 0.1805008170719984
  - 0.18865123974986006
  - 0.1821225309675259
  - 0.18500675924788001
  - 0.18160626742285876
  train_level3__tp_weighted:
  - 0.23964949741192865
  - 0.2531612302284347
  - 0.24537470622089147
  - 0.24945608556421683
  - 0.24325941614780033
  train_level3__tp_weighted_masked:
  - 0.1760606105287936
  - 0.18858223515848194
  - 0.1829118825288731
  - 0.18644190223400256
  - 0.1816312114195044
  train_level3__tp_weighted_oob:
  - 0.23825919221204966
  - 0.25389467694782897
  - 0.24631099640239437
  - 0.24918777033487757
  - 0.24412549760130656
  train_level4__average_precision_macro:
  - 0.3753269578772162
  - 0.363818874605738
  - 0.3675421426164058
  - 0.3494522788575375
  - 0.35483712456173555
  train_level4__average_precision_macro_masked:
  - 0.29610273771731377
  - 0.28623804147388066
  - 0.28883835260126656
  - 0.27451401906714373
  - 0.2770258278386173
  train_level4__average_precision_macro_oob:
  - 0.3697315180968064
  - 0.3599124320199264
  - 0.36396359879826823
  - 0.34641491811644415
  - 0.3497281159719127
  train_level4__average_precision_micro:
  - 0.2607367141217048
  - 0.23427687313072565
  - 0.23909601286761736
  - 0.23110409113206262
  - 0.23903572542436718
  train_level4__average_precision_micro_masked:
  - 0.1874913742670527
  - 0.16887181301130877
  - 0.17156524166838022
  - 0.16681436206418038
  - 0.17234033826779724
  train_level4__average_precision_micro_oob:
  - 0.2607634296118208
  - 0.23470431253210322
  - 0.24072709782377477
  - 0.2316389165164034
  - 0.2395425129784392
  train_level4__average_precision_samples:
  - 0.2737989555537842
  - 0.24713080690892075
  - 0.25322906512789145
  - 0.242841379872893
  - 0.24984383615001884
  train_level4__average_precision_samples_masked:
  - 0.2058002295973496
  - 0.18501650085304724
  - 0.1892008942871769
  - 0.18093458569533616
  - 0.18730007299594237
  train_level4__average_precision_samples_oob:
  - 0.2737205468002514
  - 0.24731883164043553
  - 0.25471534808930724
  - 0.2432733421161202
  - 0.25068621451674905
  train_level4__average_precision_weighted:
  - 0.509553897280535
  - 0.5011822436167529
  - 0.509248056351077
  - 0.4915873802531369
  - 0.4929344677829778
  train_level4__average_precision_weighted_masked:
  - 0.4148838801927463
  - 0.40808952864156384
  - 0.41505360629838867
  - 0.4013245677600722
  - 0.40085963598633223
  train_level4__average_precision_weighted_oob:
  - 0.50388225749951
  - 0.49664304746447396
  - 0.504403025062565
  - 0.4876674006124407
  - 0.4869391435747048
  train_level4__f1_macro:
  - 0.4260069210804576
  - 0.3976689296055672
  - 0.42682576880769035
  - 0.41007742411208054
  - 0.4335768528309142
  train_level4__f1_macro_masked:
  - 0.3986686211532513
  - 0.367653732119621
  - 0.4001583701661331
  - 0.38226773722234814
  - 0.4068556855999696
  train_level4__f1_macro_oob:
  - 0.42509372296452946
  - 0.3948706718251941
  - 0.42539097996078234
  - 0.40811109745606483
  - 0.4320148034220898
  train_level4__f1_micro:
  - 0.42600692108045757
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309142
  train_level4__f1_micro_masked:
  - 0.39228420616849513
  - 0.35957206911922807
  - 0.39296836795099477
  - 0.3746128391793514
  - 0.4005846440397351
  train_level4__f1_micro_oob:
  - 0.42509372296452946
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560649
  - 0.43201480342208975
  train_level4__f1_samples:
  - 0.4260069210804575
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309141
  train_level4__f1_samples_masked:
  - 0.3929600210194791
  - 0.36036718021405467
  - 0.3936718077896752
  - 0.3752520189793379
  - 0.4011919417779234
  train_level4__f1_samples_oob:
  - 0.4250937229645294
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560648
  - 0.4320148034220898
  train_level4__f1_weighted:
  - 0.5142142725436243
  - 0.5073509897529155
  - 0.5248774811182747
  - 0.5138459134239725
  - 0.5200385322037359
  train_level4__f1_weighted_masked:
  - 0.4837251764861419
  - 0.474532960177471
  - 0.4963789316750775
  - 0.4842386996134319
  - 0.4908104935766818
  train_level4__f1_weighted_oob:
  - 0.513106663583325
  - 0.5051075360424134
  - 0.5229917171404739
  - 0.5116816451723123
  - 0.5181797999387568
  train_level4__fn_macro:
  - -0.052725175430164375
  - -0.04713239409202618
  - -0.050624133148405005
  - -0.04974806439719799
  - -0.05149956743247141
  train_level4__fn_macro_masked:
  - -0.0505746894566446
  - -0.045940318391884526
  - -0.04836720483260085
  - -0.047466750997087886
  - -0.048926343010530726
  train_level4__fn_macro_oob:
  - -0.052725175430164375
  - -0.047278390150132604
  - -0.05081543832799273
  - -0.05026422514440211
  - -0.05154763049120447
  train_level4__fn_micro:
  - -0.052725175430164375
  - -0.04713239409202618
  - -0.05062413314840499
  - -0.049748064397197984
  - -0.0514995674324714
  train_level4__fn_micro_masked:
  - -0.046470709997930036
  - -0.04213755670346383
  - -0.04460402028157414
  - -0.043600264725347455
  - -0.0451158940397351
  train_level4__fn_micro_oob:
  - -0.052725175430164375
  - -0.04727839015013261
  - -0.05081543832799273
  - -0.05026422514440211
  - -0.05154763049120446
  train_level4__fn_samples:
  - -0.05272517543016437
  - -0.04713239409202618
  - -0.05062413314840499
  - -0.04974806439719797
  - -0.051499567432471395
  train_level4__fn_samples_masked:
  - -0.04639850174196897
  - -0.04194669254539687
  - -0.04445308800744475
  - -0.043482554940378705
  - -0.04495880403952357
  train_level4__fn_samples_oob:
  - -0.05272517543016437
  - -0.04727839015013261
  - -0.05081543832799273
  - -0.050264225144402104
  - -0.051547630491204456
  train_level4__fn_weighted:
  - -0.10563900046759485
  - -0.09538189313415388
  - -0.10045610236569825
  - -0.09993192792306001
  - -0.10171991425946719
  train_level4__fn_weighted_masked:
  - -0.10544589418614381
  - -0.09622841450922173
  - -0.09900347306218622
  - -0.09883693610198835
  - -0.10007767447568411
  train_level4__fn_weighted_oob:
  - -0.1054772778440515
  - -0.0949486922910903
  - -0.10050249854853471
  - -0.10029109421228423
  - -0.10170077574767787
  train_level4__fp_macro:
  - -0.5212679034893781
  - -0.5551986763024065
  - -0.5225500980439046
  - -0.5401745114907214
  - -0.5149235797366144
  train_level4__fp_macro_masked:
  - -0.550756689390104
  - -0.5864059494884946
  - -0.551474425001266
  - -0.5702655117805641
  - -0.5442179713894997
  train_level4__fp_macro_oob:
  - -0.5221811016053063
  - -0.5578509380246733
  - -0.5237935817112248
  - -0.541624677399533
  - -0.5164375660867057
  train_level4__fp_micro:
  - -0.521267903489378
  - -0.5551986763024065
  - -0.5225500980439045
  - -0.5401745114907214
  - -0.5149235797366144
  train_level4__fp_micro_masked:
  - -0.5612450838335749
  - -0.5982903741773081
  - -0.5624276117674311
  - -0.5817868960953011
  - -0.5542994619205298
  train_level4__fp_micro_oob:
  - -0.5221811016053062
  - -0.5578509380246733
  - -0.5237935817112248
  - -0.541624677399533
  - -0.5164375660867058
  train_level4__fp_samples:
  - -0.521267903489378
  - -0.5551986763024065
  - -0.5225500980439045
  - -0.5401745114907214
  - -0.5149235797366144
  train_level4__fp_samples_masked:
  - -0.560641477238552
  - -0.5976861272405485
  - -0.5618751042028801
  - -0.5812654260802833
  - -0.553849254182553
  train_level4__fp_samples_oob:
  - -0.5221811016053062
  - -0.5578509380246733
  - -0.5237935817112248
  - -0.541624677399533
  - -0.5164375660867058
  train_level4__fp_weighted:
  - -0.3801467269887808
  - -0.3972671171129307
  - -0.37466641651602695
  - -0.3862221586529675
  - -0.378241553536797
  train_level4__fp_weighted_masked:
  - -0.4108289293277143
  - -0.42923862531330736
  - -0.4046175952627365
  - -0.4169243642845798
  - -0.40911183194763406
  train_level4__fp_weighted_oob:
  - -0.3814160585726234
  - -0.3999437716664963
  - -0.37650578431099135
  - -0.38802726061540344
  - -0.3801194243135654
  train_level4__jaccard_macro:
  - 0.29060681858214743
  - 0.27312592835477933
  - 0.29580118653578585
  - 0.28029070503107895
  - 0.2973001872928065
  train_level4__jaccard_macro_masked:
  - 0.2683365443923752
  - 0.24919857854244287
  - 0.27410213857611304
  - 0.25787400185171827
  - 0.2755951980410968
  train_level4__jaccard_macro_oob:
  - 0.28984020703698693
  - 0.2708260254625604
  - 0.29464361226053226
  - 0.278627367754245
  - 0.2959590075711679
  train_level4__jaccard_micro:
  - 0.27065361772294916
  - 0.24818150066058223
  - 0.2713150014440543
  - 0.2579228890331757
  - 0.27679420698965973
  train_level4__jaccard_micro_masked:
  - 0.2440009656393337
  - 0.21919406659100718
  - 0.2445305743297351
  - 0.23047606638544602
  - 0.250456920115807
  train_level4__jaccard_micro_oob:
  - 0.269916838330663
  - 0.24600551799411818
  - 0.27015657509074065
  - 0.25636908254330976
  - 0.2755222462335433
  train_level4__jaccard_samples:
  - 0.2757378664580131
  - 0.25200614852649966
  - 0.27606790842886386
  - 0.2624301178531712
  - 0.28130585480361564
  train_level4__jaccard_samples_masked:
  - 0.24912267491454873
  - 0.22299232467029428
  - 0.2493957679196711
  - 0.23501982748306993
  - 0.25504279305411737
  train_level4__jaccard_samples_oob:
  - 0.2750046327967974
  - 0.24981278059604264
  - 0.27489819652366415
  - 0.2608355894852561
  - 0.2800432443166288
  train_level4__jaccard_weighted:
  - 0.36141293576138306
  - 0.35949552882442853
  - 0.37399279222807624
  - 0.3626641249454369
  - 0.3671587354844323
  train_level4__jaccard_weighted_masked:
  - 0.33430730452298774
  - 0.33013567030510765
  - 0.3483233911808999
  - 0.33600045496489306
  - 0.34131224792468295
  train_level4__jaccard_weighted_oob:
  - 0.3603008401849063
  - 0.3575010077947589
  - 0.37232713313760707
  - 0.3606914445637808
  - 0.3654369042854267
  train_level4__label_ranking_average_precision_score:
  - 0.27379895555378414
  - 0.24713080690892072
  - 0.25322906512789145
  - 0.24284137987289303
  - 0.24984383615001887
  train_level4__label_ranking_average_precision_score_oob:
  - 0.2737205468002516
  - 0.24731883164043547
  - 0.2547153480893073
  - 0.24327334211612023
  - 0.2506862145167493
  train_level4__matthews_corrcoef_macro:
  - 0.1809269015256187
  - 0.17270345950006433
  - 0.18724082471534284
  - 0.17608238658097536
  - 0.1830858553721449
  train_level4__matthews_corrcoef_macro_masked:
  - 0.14288117178675666
  - 0.1372724214856286
  - 0.1493714348800115
  - 0.14130159575266985
  - 0.14491367028789554
  train_level4__matthews_corrcoef_macro_oob:
  - 0.17903548621104004
  - 0.16900275798113412
  - 0.18365996637524393
  - 0.17091223365869876
  - 0.180448251816978
  train_level4__matthews_corrcoef_micro:
  - 0.08709146354885601
  - 0.07162384225716635
  - 0.09383467453452272
  - 0.0780751890521405
  - 0.09898232662359836
  train_level4__matthews_corrcoef_micro_masked:
  - 0.04432932506596149
  - 0.030147515731961203
  - 0.05133343980945339
  - 0.03895157289628467
  - 0.05709044239880054
  train_level4__matthews_corrcoef_micro_oob:
  - 0.08606532575115829
  - 0.06786085574898797
  - 0.09166870261428973
  - 0.07426652175352853
  - 0.09711012485031212
  train_level4__matthews_corrcoef_samples:
  - 0.08170328823540819
  - 0.06454238850865131
  - 0.08781708969095356
  - 0.07239848210382956
  - 0.09422241315102863
  train_level4__matthews_corrcoef_samples_masked:
  - 0.03851340933429477
  - 0.024395472987956607
  - 0.04699881010823923
  - 0.034353255362237434
  - 0.05324865679922956
  train_level4__matthews_corrcoef_samples_oob:
  - 0.08097534114311973
  - 0.06090806968854782
  - 0.08563359426634319
  - 0.06884382756294376
  - 0.09229042684955534
  train_level4__matthews_corrcoef_weighted:
  - 0.21536119914024676
  - 0.21973660608580692
  - 0.23302277822788856
  - 0.2254337622853861
  - 0.22199566696542564
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.16521972977157715
  - 0.17221188092444886
  - 0.18554037679836474
  - 0.1807863976053653
  - 0.17640739879384593
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.21233644263382273
  - 0.21492351315456334
  - 0.22800908350919016
  - 0.21935991572978897
  - 0.21912436751982972
  train_level4__ndcg:
  - 0.6230589418006542
  - 0.6033984643581285
  - 0.6042728260070541
  - 0.6031346263779749
  - 0.6073219760352683
  train_level4__ndcg_oob:
  - 0.6247971273303772
  - 0.6056250576016337
  - 0.6080851603550137
  - 0.6049897587447276
  - 0.609115441471101
  train_level4__neg_coverage_error:
  - -92.60891089108911
  - -93.83458646616542
  - -92.02709359605912
  - -93.81012658227849
  - -91.52722772277228
  train_level4__neg_coverage_error_oob:
  - -93.14356435643565
  - -94.39348370927318
  - -92.58866995073892
  - -94.36962025316456
  - -92.1980198019802
  train_level4__neg_hamming_loss_macro:
  - -0.5739930789195424
  - -0.6023310703944328
  - -0.5731742311923096
  - -0.5899225758879195
  - -0.5664231471690859
  train_level4__neg_hamming_loss_macro_masked:
  - -0.6013313788467487
  - -0.6323462678803791
  - -0.5998416298338669
  - -0.6177322627776518
  - -0.5931443144000303
  train_level4__neg_hamming_loss_macro_oob:
  - -0.5749062770354705
  - -0.6051293281748059
  - -0.5746090200392175
  - -0.5918889025439351
  - -0.5679851965779102
  train_level4__neg_hamming_loss_micro:
  - -0.5739930789195424
  - -0.6023310703944327
  - -0.5731742311923095
  - -0.5899225758879194
  - -0.5664231471690858
  train_level4__neg_hamming_loss_micro_masked:
  - -0.6077157938315049
  - -0.640427930880772
  - -0.6070316320490052
  - -0.6253871608206486
  - -0.5994153559602649
  train_level4__neg_hamming_loss_micro_oob:
  - -0.5749062770354706
  - -0.6051293281748059
  - -0.5746090200392175
  - -0.5918889025439351
  - -0.5679851965779102
  train_level4__neg_hamming_loss_samples:
  - -0.5739930789195423
  - -0.6023310703944327
  - -0.5731742311923095
  - -0.5899225758879194
  - -0.5664231471690858
  train_level4__neg_hamming_loss_samples_masked:
  - -0.607039978980521
  - -0.6396328197859453
  - -0.6063281922103249
  - -0.6247479810206621
  - -0.5988080582220766
  train_level4__neg_hamming_loss_samples_oob:
  - -0.5749062770354706
  - -0.6051293281748059
  - -0.5746090200392175
  - -0.5918889025439351
  - -0.5679851965779101
  train_level4__neg_hamming_loss_weighted:
  - -0.48578572745637566
  - -0.4926490102470845
  - -0.4751225188817253
  - -0.48615408657602754
  - -0.4799614677962641
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.5162748235138581
  - -0.525467039822529
  - -0.5036210683249226
  - -0.5157613003865681
  - -0.5091895064233182
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.48689333641667487
  - -0.4948924639575865
  - -0.4770082828595261
  - -0.48831835482768765
  - -0.48182020006124315
  train_level4__neg_label_ranking_loss:
  - -0.45797552525723384
  - -0.5075993910032833
  - -0.4850388511515586
  - -0.5204533840277856
  - -0.49917335018649756
  train_level4__neg_label_ranking_loss_oob:
  - -0.4625918999854735
  - -0.5115469286602048
  - -0.4888392254883441
  - -0.5236772578524759
  - -0.5027400103935125
  train_level4__precision_macro:
  - 0.4260069210804576
  - 0.3976689296055672
  - 0.42682576880769035
  - 0.41007742411208054
  - 0.4335768528309142
  train_level4__precision_macro_masked:
  - 0.3986686211532513
  - 0.367653732119621
  - 0.4001583701661331
  - 0.38226773722234814
  - 0.4068556855999696
  train_level4__precision_macro_oob:
  - 0.42509372296452946
  - 0.3948706718251941
  - 0.42539097996078234
  - 0.40811109745606483
  - 0.4320148034220898
  train_level4__precision_micro:
  - 0.42600692108045757
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309142
  train_level4__precision_micro_masked:
  - 0.39228420616849513
  - 0.35957206911922807
  - 0.39296836795099477
  - 0.3746128391793514
  - 0.4005846440397351
  train_level4__precision_micro_oob:
  - 0.42509372296452946
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560649
  - 0.43201480342208975
  train_level4__precision_samples:
  - 0.4260069210804575
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309141
  train_level4__precision_samples_masked:
  - 0.3929600210194791
  - 0.36036718021405467
  - 0.3936718077896752
  - 0.3752520189793379
  - 0.4011919417779234
  train_level4__precision_samples_oob:
  - 0.4250937229645294
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560648
  - 0.4320148034220898
  train_level4__precision_weighted:
  - 0.5142142725436243
  - 0.5073509897529155
  - 0.5248774811182747
  - 0.5138459134239725
  - 0.5200385322037359
  train_level4__precision_weighted_masked:
  - 0.4837251764861419
  - 0.474532960177471
  - 0.4963789316750775
  - 0.4842386996134319
  - 0.4908104935766818
  train_level4__precision_weighted_oob:
  - 0.513106663583325
  - 0.5051075360424134
  - 0.5229917171404739
  - 0.5116816451723123
  - 0.5181797999387568
  train_level4__recall_macro:
  - 0.4260069210804576
  - 0.3976689296055672
  - 0.42682576880769035
  - 0.41007742411208054
  - 0.4335768528309142
  train_level4__recall_macro_masked:
  - 0.3986686211532513
  - 0.367653732119621
  - 0.4001583701661331
  - 0.38226773722234814
  - 0.4068556855999696
  train_level4__recall_macro_oob:
  - 0.42509372296452946
  - 0.3948706718251941
  - 0.42539097996078234
  - 0.40811109745606483
  - 0.4320148034220898
  train_level4__recall_micro:
  - 0.42600692108045757
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309142
  train_level4__recall_micro_masked:
  - 0.39228420616849513
  - 0.35957206911922807
  - 0.39296836795099477
  - 0.3746128391793514
  - 0.4005846440397351
  train_level4__recall_micro_oob:
  - 0.42509372296452946
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560649
  - 0.43201480342208975
  train_level4__recall_samples:
  - 0.4260069210804575
  - 0.3976689296055673
  - 0.42682576880769046
  - 0.41007742411208065
  - 0.4335768528309141
  train_level4__recall_samples_masked:
  - 0.3929600210194791
  - 0.36036718021405467
  - 0.3936718077896752
  - 0.3752520189793379
  - 0.4011919417779234
  train_level4__recall_samples_oob:
  - 0.4250937229645294
  - 0.39487067182519403
  - 0.42539097996078246
  - 0.4081110974560648
  - 0.4320148034220898
  train_level4__recall_weighted:
  - 0.5142142725436243
  - 0.5073509897529155
  - 0.5248774811182747
  - 0.5138459134239725
  - 0.5200385322037359
  train_level4__recall_weighted_masked:
  - 0.4837251764861419
  - 0.474532960177471
  - 0.4963789316750775
  - 0.4842386996134319
  - 0.4908104935766818
  train_level4__recall_weighted_oob:
  - 0.513106663583325
  - 0.5051075360424134
  - 0.5229917171404739
  - 0.5116816451723123
  - 0.5181797999387568
  train_level4__roc_auc_macro:
  - 0.6847406651687259
  - 0.6678920855746218
  - 0.6800345228368855
  - 0.657613869744175
  - 0.6687137817300779
  train_level4__roc_auc_macro_masked:
  - 0.6623457808944347
  - 0.6470330593295626
  - 0.6567428499947753
  - 0.6365345003393638
  - 0.6433812213321688
  train_level4__roc_auc_macro_oob:
  - 0.6778500281950064
  - 0.6622096368839389
  - 0.67422187808535
  - 0.6525077336150986
  - 0.6626113330497394
  train_level4__roc_auc_micro:
  - 0.5740252640282458
  - 0.5282901571404132
  - 0.5510248447767574
  - 0.5255602830308623
  - 0.5451553272788829
  train_level4__roc_auc_micro_masked:
  - 0.5492463012947879
  - 0.5065460934092365
  - 0.5275874736525143
  - 0.5047722323633812
  - 0.5234657322948013
  train_level4__roc_auc_micro_oob:
  - 0.5713634608044963
  - 0.5264720143261774
  - 0.5503423384929834
  - 0.5244942566425232
  - 0.543836596064435
  train_level4__roc_auc_samples:
  - 0.5560255894927433
  - 0.5110768321867596
  - 0.5340437728629314
  - 0.5126312620164383
  - 0.5281472404242489
  train_level4__roc_auc_samples_masked:
  - 0.5325416563641285
  - 0.4929296115596855
  - 0.5132459558571203
  - 0.4948328582361211
  - 0.5086519323076463
  train_level4__roc_auc_samples_oob:
  - 0.5531699303316634
  - 0.5092510332251211
  - 0.5332887368464997
  - 0.5116444176438956
  - 0.5272704843887467
  train_level4__roc_auc_weighted:
  - 0.6888416182828756
  - 0.6844643750157355
  - 0.6948302411397
  - 0.6799791768810152
  - 0.6795192971738208
  train_level4__roc_auc_weighted_masked:
  - 0.6581861278225772
  - 0.6561877646866419
  - 0.6647304824860528
  - 0.6514520250937668
  - 0.6484275070447475
  train_level4__roc_auc_weighted_oob:
  - 0.6815483340384986
  - 0.6773166564306651
  - 0.6867409029765138
  - 0.6729627911382081
  - 0.6715473351823521
  train_level4__tn_macro:
  - 0.24516966259732773
  - 0.20857970168138792
  - 0.24513367449423693
  - 0.22489861128179922
  - 0.2519705854080554
  train_level4__tn_macro_masked:
  - 0.2670690500964104
  - 0.22902677794616852
  - 0.2673420817381213
  - 0.24608799989326505
  - 0.27389507589542367
  train_level4__tn_macro_oob:
  - 0.2442564644813996
  - 0.2059274399591211
  - 0.24389019082691663
  - 0.22344844537298758
  - 0.2504565990579641
  train_level4__tn_micro:
  - 0.2451696625973277
  - 0.20857970168138792
  - 0.24513367449423693
  - 0.2248986112817992
  - 0.2519705854080554
  train_level4__tn_micro_masked:
  - 0.263972262471538
  - 0.22476859742507277
  - 0.2638406300671763
  - 0.24222369291859697
  - 0.2712386175496689
  train_level4__tn_micro_oob:
  - 0.2442564644813996
  - 0.2059274399591211
  - 0.24389019082691663
  - 0.22344844537298758
  - 0.250456599057964
  train_level4__tn_samples:
  - 0.24516966259732764
  - 0.2085797016813879
  - 0.24513367449423684
  - 0.2248986112817991
  - 0.2519705854080553
  train_level4__tn_samples_masked:
  - 0.264348789148691
  - 0.2251009483177063
  - 0.2641553382234477
  - 0.24250137212282824
  - 0.27145717885347137
  train_level4__tn_samples_oob:
  - 0.24425646448139954
  - 0.20592743995912105
  - 0.2438901908269166
  - 0.22344844537298753
  - 0.25045659905796397
  train_level4__tn_weighted:
  - 0.27512507398491676
  - 0.25323170926905225
  - 0.2800154146880681
  - 0.2644923332830077
  - 0.2763384199244667
  train_level4__tn_weighted_masked:
  - 0.30815731181324485
  - 0.2853133286891084
  - 0.31394194737765757
  - 0.2975366112913733
  - 0.30934747973825083
  train_level4__tn_weighted_oob:
  - 0.2738557424010742
  - 0.25055505471548667
  - 0.27817604689310366
  - 0.26268723132057176
  - 0.27446054914769824
  train_level4__tp_macro:
  - 0.18083725848312984
  - 0.18908922792417937
  - 0.18169209431345362
  - 0.18517881283028143
  - 0.18160626742285882
  train_level4__tp_macro_masked:
  - 0.13159957105684095
  - 0.1386269541734524
  - 0.13281628842801185
  - 0.1361797373290831
  - 0.13296060970454585
  train_level4__tp_macro_oob:
  - 0.18083725848312984
  - 0.18894323186607292
  - 0.18150078913386583
  - 0.1846626520830773
  - 0.18155820436412573
  train_level4__tp_micro:
  - 0.18083725848312987
  - 0.18908922792417937
  - 0.18169209431345354
  - 0.18517881283028143
  - 0.1816062674228588
  train_level4__tp_micro_masked:
  - 0.12831194369695714
  - 0.13480347169415527
  - 0.12912773788381848
  - 0.13238914626075446
  - 0.1293460264900662
  train_level4__tp_micro_oob:
  - 0.18083725848312987
  - 0.18894323186607295
  - 0.1815007891338658
  - 0.1846626520830773
  - 0.18155820436412573
  train_level4__tp_samples:
  - 0.18083725848312981
  - 0.18908922792417934
  - 0.18169209431345348
  - 0.1851788128302814
  - 0.18160626742285876
  train_level4__tp_samples_masked:
  - 0.12861123187078816
  - 0.1352662318963483
  - 0.12951646956622742
  - 0.1327506468565097
  - 0.12973476292445207
  train_level4__tp_samples_oob:
  - 0.18083725848312981
  - 0.1889432318660729
  - 0.18150078913386578
  - 0.18466265208307728
  - 0.18155820436412573
  train_level4__tp_weighted:
  - 0.23908919855870767
  - 0.2541192804838631
  - 0.24486206643020672
  - 0.24935358014096481
  - 0.24370011227926916
  train_level4__tp_weighted_masked:
  - 0.17556786467289692
  - 0.18921963148836257
  - 0.18243698429741986
  - 0.18670208832205867
  - 0.18146301383843105
  train_level4__tp_weighted_oob:
  - 0.239250921182251
  - 0.2545524813269267
  - 0.2448156702473703
  - 0.24899441385174062
  - 0.24371925079105852
  train_level5__average_precision_macro:
  - 0.37339615092929446
  - 0.3621775535151346
  - 0.36671661011677176
  - 0.35230356004289065
  - 0.3524665345934232
  train_level5__average_precision_macro_masked:
  - 0.29594941616926557
  - 0.285119054801095
  - 0.2891634863040707
  - 0.27823963770157895
  - 0.2741210422535406
  train_level5__average_precision_macro_oob:
  - 0.36618270623588095
  - 0.35822309699657023
  - 0.3616687783932671
  - 0.3490326498462556
  - 0.3468133705805153
  train_level5__average_precision_micro:
  - 0.2608848432259153
  - 0.23368108471645674
  - 0.23944847563006913
  - 0.22960416038924097
  - 0.23819074066059226
  train_level5__average_precision_micro_masked:
  - 0.18774943751048262
  - 0.16845053927818007
  - 0.17204359461389904
  - 0.16603412742959778
  - 0.17137923773461589
  train_level5__average_precision_micro_oob:
  - 0.26097279197797124
  - 0.2346696022941001
  - 0.24103444988782427
  - 0.23037697511216157
  - 0.23831743605695205
  train_level5__average_precision_samples:
  - 0.2737212476668129
  - 0.24684596724876604
  - 0.25390700724197546
  - 0.2408042008176703
  - 0.24932561153000884
  train_level5__average_precision_samples_masked:
  - 0.2057819369034422
  - 0.1845999719436259
  - 0.1897878343697453
  - 0.17968712242244084
  - 0.18626410056253204
  train_level5__average_precision_samples_oob:
  - 0.27389974740222633
  - 0.24749521165361574
  - 0.25541693528479686
  - 0.24155888058374006
  - 0.2496020656160568
  train_level5__average_precision_weighted:
  - 0.5067711691601668
  - 0.500465180614616
  - 0.5087898501032
  - 0.4942037509068602
  - 0.48952109134988175
  train_level5__average_precision_weighted_masked:
  - 0.4133553232849782
  - 0.4077416779857156
  - 0.4150689747571533
  - 0.40497673678410484
  - 0.3964791539622927
  train_level5__average_precision_weighted_oob:
  - 0.500131579175293
  - 0.4956680392252586
  - 0.5030055408280211
  - 0.4896275170336059
  - 0.48327668311795596
  train_level5__f1_macro:
  - 0.42778525425358066
  - 0.39810691777988655
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.4342497356531769
  train_level5__f1_macro_masked:
  - 0.4002508248060397
  - 0.36826118911633227
  - 0.3996185722914809
  - 0.3823805128303752
  - 0.4076103839026909
  train_level5__f1_macro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046486
  - 0.4085535209536684
  - 0.43271171777371903
  train_level5__f1_micro:
  - 0.4277852542535807
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__f1_micro_masked:
  - 0.3938366797764438
  - 0.3602013792380103
  - 0.39250508326255373
  - 0.3747452018530774
  - 0.40133485099337746
  train_level5__f1_micro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046487
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__f1_samples:
  - 0.42778525425358066
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__f1_samples_masked:
  - 0.3945289942842722
  - 0.36101675986495146
  - 0.3931877026017636
  - 0.37537611654510905
  - 0.4019394830396011
  train_level5__f1_samples_oob:
  - 0.4260309526098241
  - 0.396233301700854
  - 0.42591706920464867
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__f1_weighted:
  - 0.5166159171735674
  - 0.5075823055785321
  - 0.5239657834489857
  - 0.5137847280162948
  - 0.5207890170460345
  train_level5__f1_weighted_masked:
  - 0.4857002345451382
  - 0.47484453095983375
  - 0.494802407618339
  - 0.4840932165662755
  - 0.49162286691711554
  train_level5__f1_weighted_oob:
  - 0.5137978686231623
  - 0.506462127713185
  - 0.523469369645741
  - 0.5120680932666914
  - 0.5195100540981933
  train_level5__fn_macro:
  - -0.05226857637220033
  - -0.0473757208555369
  - -0.05062413314840499
  - -0.0496989062307976
  - -0.05183600884360281
  train_level5__fn_macro_masked:
  - -0.050436138314672925
  - -0.046056493665789046
  - -0.048572601907193196
  - -0.04754270439732847
  - -0.049248932172149484
  train_level5__fn_macro_oob:
  - -0.05296549072382967
  - -0.047278390150132604
  - -0.05052848055861113
  - -0.05006759247880054
  - -0.051787945784869754
  train_level5__fn_micro:
  - -0.05226857637220033
  - -0.0473757208555369
  - -0.05062413314840499
  - -0.04969890623079759
  - -0.05183600884360281
  train_level5__fn_micro_masked:
  - -0.04634133719726764
  - -0.04224244172326087
  - -0.04478418654930121
  - -0.04367968232958306
  - -0.04545219370860927
  train_level5__fn_micro_oob:
  - -0.05296549072382967
  - -0.04727839015013261
  - -0.05052848055861112
  - -0.05006759247880054
  - -0.05178794578486975
  train_level5__fn_samples:
  - -0.052268576372200316
  - -0.047375720855536894
  - -0.05062413314840499
  - -0.04969890623079758
  - -0.051836008843602795
  train_level5__fn_samples_masked:
  - -0.04626636100648983
  - -0.042039686679124014
  - -0.04463102994432456
  - -0.04356951794506405
  - -0.04530043643471952
  train_level5__fn_samples_oob:
  - -0.05296549072382966
  - -0.04727839015013261
  - -0.050528480558611116
  - -0.05006759247880054
  - -0.05178794578486974
  train_level5__fn_weighted:
  - -0.10476595298175768
  - -0.0956958217546338
  - -0.10053545758552238
  - -0.09993166305116528
  - -0.10184367663570483
  train_level5__fn_weighted_masked:
  - -0.10517978606534702
  - -0.09649252322116468
  - -0.09954967489080425
  - -0.09886629280415346
  - -0.10021772897204724
  train_level5__fn_weighted_oob:
  - -0.10586541214055556
  - -0.09511572503570422
  - -0.10010572244941422
  - -0.10031599217038678
  - -0.10167423701133001
  train_level5__fp_macro:
  - -0.519946169374219
  - -0.5545173613645764
  - -0.5228131426658376
  - -0.5399778788251198
  - -0.5139142555032203
  train_level5__fp_macro_masked:
  - -0.5493130368792873
  - -0.5856823172178788
  - -0.5518088258013257
  - -0.5700767827722963
  - -0.5431406839251596
  train_level5__fp_macro_oob:
  - -0.5210035566663462
  - -0.5564883081490133
  - -0.5235544502367402
  - -0.5413788865675311
  - -0.5155003364414111
  train_level5__fp_micro:
  - -0.519946169374219
  - -0.5545173613645765
  - -0.5228131426658377
  - -0.5399778788251198
  - -0.5139142555032202
  train_level5__fp_micro_masked:
  - -0.5598219830262886
  - -0.5975561790387288
  - -0.5627107301881451
  - -0.5815751158173396
  - -0.5532129552980133
  train_level5__fp_micro_oob:
  - -0.5210035566663462
  - -0.5564883081490133
  - -0.5235544502367402
  - -0.5413788865675311
  - -0.5155003364414111
  train_level5__fp_samples:
  - -0.519946169374219
  - -0.5545173613645765
  - -0.5228131426658377
  - -0.5399778788251198
  - -0.5139142555032202
  train_level5__fp_samples_masked:
  - -0.559204644709238
  - -0.5969435534559244
  - -0.562181267453912
  - -0.5810543655098268
  - -0.5527600805256794
  train_level5__fp_samples_oob:
  - -0.5210035566663462
  - -0.5564883081490133
  - -0.5235544502367401
  - -0.541378886567531
  - -0.5155003364414111
  train_level5__fp_weighted:
  - -0.37861812984467497
  - -0.396721872666834
  - -0.37549875896549195
  - -0.3862836089325398
  - -0.3773673063182607
  train_level5__fp_weighted_masked:
  - -0.40911997938951483
  - -0.42866294581900155
  - -0.4056479174908568
  - -0.4170404906295711
  - -0.40815940411083723
  train_level5__fp_weighted_oob:
  - -0.38033671923628215
  - -0.39842214725111097
  - -0.3764249079048448
  - -0.38761591456292166
  - -0.3788157088904767
  train_level5__jaccard_macro:
  - 0.2921044751042934
  - 0.27330612736645415
  - 0.29539381077170157
  - 0.280446469061953
  - 0.29784440445966476
  train_level5__jaccard_macro_masked:
  - 0.26957196409533496
  - 0.2495139185128804
  - 0.2734561246364237
  - 0.2579045534272034
  - 0.276186684885141
  train_level5__jaccard_macro_oob:
  - 0.290497892440148
  - 0.27188556027522703
  - 0.2950195659570074
  - 0.27904088238703967
  - 0.29671091967635593
  train_level5__jaccard_micro:
  - 0.2720908548981245
  - 0.24852277733051814
  - 0.2711024651205204
  - 0.25811738511967347
  - 0.27734291064247785
  train_level5__jaccard_micro_masked:
  - 0.24520338300443012
  - 0.2196619601196092
  - 0.2441718970154989
  - 0.23057627781216405
  - 0.2510437230978349
  train_level5__jaccard_micro_oob:
  - 0.2706730181995847
  - 0.24706417842512518
  - 0.27058108621344473
  - 0.2567183542348798
  - 0.27608942316538376
  train_level5__jaccard_samples:
  - 0.2771539649008952
  - 0.2524087547532338
  - 0.2759007466270189
  - 0.2626305322420609
  - 0.281856843021122
  train_level5__jaccard_samples_masked:
  - 0.2503250517438353
  - 0.2235329971724557
  - 0.24907548256602863
  - 0.23513750278693654
  - 0.25562475100223364
  train_level5__jaccard_samples_oob:
  - 0.2756689969020482
  - 0.25091212892843856
  - 0.27523124954873307
  - 0.2611682016533301
  - 0.2806293330032219
  train_level5__jaccard_weighted:
  - 0.3635331303446775
  - 0.359555796066044
  - 0.37296969653834755
  - 0.36254546096492757
  - 0.367905927044083
  train_level5__jaccard_weighted_masked:
  - 0.33592277471911525
  - 0.33026699148845245
  - 0.3467617665090071
  - 0.3358164962238284
  - 0.342067769219652
  train_level5__jaccard_weighted_oob:
  - 0.36080678332237265
  - 0.3586235410328998
  - 0.3726946291844636
  - 0.3611113299825554
  - 0.3668376078581036
  train_level5__label_ranking_average_precision_score:
  - 0.2737212476668128
  - 0.24684596724876617
  - 0.2539070072419756
  - 0.2408042008176701
  - 0.2493256115300089
  train_level5__label_ranking_average_precision_score_oob:
  - 0.27389974740222645
  - 0.2474952116536161
  - 0.25541693528479714
  - 0.2415588805837401
  - 0.24960206561605677
  train_level5__matthews_corrcoef_macro:
  - 0.18393525466199614
  - 0.17304176731219345
  - 0.18647934347738465
  - 0.17637745909937697
  - 0.1820715041523678
  train_level5__matthews_corrcoef_macro_masked:
  - 0.1449743306721312
  - 0.138155033610079
  - 0.1479212401270126
  - 0.1408606981494385
  - 0.14347993813064144
  train_level5__matthews_corrcoef_macro_oob:
  - 0.1799109062857765
  - 0.17051789985049448
  - 0.1850302847893096
  - 0.17303917403508065
  - 0.18068944642996426
  train_level5__matthews_corrcoef_micro:
  - 0.09042007258549654
  - 0.07140490139769258
  - 0.09354175580615046
  - 0.07850497623674327
  - 0.09874231641251809
  train_level5__matthews_corrcoef_micro_masked:
  - 0.04629962168089668
  - 0.030375404468124045
  - 0.05020626212078926
  - 0.03877600744141997
  - 0.05652342850464678
  train_level5__matthews_corrcoef_micro_oob:
  - 0.0864165808678573
  - 0.06948041585828917
  - 0.09310580967385694
  - 0.07536364691829903
  - 0.09717908029821139
  train_level5__matthews_corrcoef_samples:
  - 0.08532621794944173
  - 0.0642377380353783
  - 0.08739550229369951
  - 0.07300762031681857
  - 0.09406623964929776
  train_level5__matthews_corrcoef_samples_masked:
  - 0.04088096406457034
  - 0.02451062443367291
  - 0.04579421737445505
  - 0.03413256156256007
  - 0.05275949916120622
  train_level5__matthews_corrcoef_samples_oob:
  - 0.08148056781628908
  - 0.06262851109427668
  - 0.08707371673994069
  - 0.07023700175441143
  - 0.09247542226116763
  train_level5__matthews_corrcoef_weighted:
  - 0.21928003216989692
  - 0.2193652097201882
  - 0.23075228446337406
  - 0.2253252714309463
  - 0.2216970108420344
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.16795348663689497
  - 0.17216464823791702
  - 0.18211097715158192
  - 0.17992365480147546
  - 0.17581186485738248
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.2133073018201297
  - 0.21746705118738727
  - 0.22921069730323637
  - 0.2218094505638182
  - 0.21974668699727298
  train_level5__ndcg:
  - 0.6254750223576881
  - 0.6022925658221545
  - 0.6053917234590032
  - 0.6001456252625581
  - 0.6074410464625695
  train_level5__ndcg_oob:
  - 0.6270788022436611
  - 0.6057867267784236
  - 0.609277197512658
  - 0.6024388381676282
  - 0.608470105175329
  train_level5__neg_coverage_error:
  - -92.63366336633663
  - -93.82456140350877
  - -92.07389162561576
  - -93.75696202531645
  - -91.5990099009901
  train_level5__neg_coverage_error_oob:
  - -93.12128712871286
  - -94.3358395989975
  - -92.66502463054188
  - -94.25569620253165
  - -92.22772277227723
  train_level5__neg_hamming_loss_macro:
  - -0.5722147457464193
  - -0.6018930822201133
  - -0.5734372758142428
  - -0.5896767850559175
  - -0.5657502643468231
  train_level5__neg_hamming_loss_macro_masked:
  - -0.5997491751939603
  - -0.6317388108836678
  - -0.6003814277085191
  - -0.6176194871696248
  - -0.5923896160973091
  train_level5__neg_hamming_loss_macro_oob:
  - -0.573969047390176
  - -0.603766698299146
  - -0.5740829307953514
  - -0.5914464790463316
  - -0.567288282226281
  train_level5__neg_hamming_loss_micro:
  - -0.5722147457464193
  - -0.6018930822201134
  - -0.5734372758142426
  - -0.5896767850559174
  - -0.5657502643468231
  train_level5__neg_hamming_loss_micro_masked:
  - -0.6061633202235562
  - -0.6397986207619897
  - -0.6074949167374463
  - -0.6252547981469225
  - -0.5986651490066225
  train_level5__neg_hamming_loss_micro_oob:
  - -0.573969047390176
  - -0.603766698299146
  - -0.5740829307953513
  - -0.5914464790463315
  - -0.5672882822262809
  train_level5__neg_hamming_loss_samples:
  - -0.5722147457464193
  - -0.6018930822201134
  - -0.5734372758142426
  - -0.5896767850559175
  - -0.565750264346823
  train_level5__neg_hamming_loss_samples_masked:
  - -0.6054710057157279
  - -0.6389832401350486
  - -0.6068122973982364
  - -0.624623883454891
  - -0.5980605169603989
  train_level5__neg_hamming_loss_samples_oob:
  - -0.5739690473901758
  - -0.6037666982991459
  - -0.5740829307953512
  - -0.5914464790463315
  - -0.5672882822262809
  train_level5__neg_hamming_loss_weighted:
  - -0.48338408282643264
  - -0.49241769442146793
  - -0.47603421655101424
  - -0.4862152719837052
  - -0.47921098295396547
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.5142997654548619
  - -0.5251554690401662
  - -0.505197592381661
  - -0.5159067834337244
  - -0.5083771330828845
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.4862021313768377
  - -0.493537872286815
  - -0.47653063035425897
  - -0.48793190673330855
  - -0.48048994590180666
  train_level5__neg_label_ranking_loss:
  - -0.4579149533378155
  - -0.5078899213677146
  - -0.48508529963513813
  - -0.5181140237181883
  - -0.4984167831754712
  train_level5__neg_label_ranking_loss_oob:
  - -0.4623950358408941
  - -0.5118115580256627
  - -0.4886838826392929
  - -0.5215069490810457
  - -0.5026944059997532
  train_level5__precision_macro:
  - 0.42778525425358066
  - 0.39810691777988655
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.4342497356531769
  train_level5__precision_macro_masked:
  - 0.4002508248060397
  - 0.36826118911633227
  - 0.3996185722914809
  - 0.3823805128303752
  - 0.4076103839026909
  train_level5__precision_macro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046486
  - 0.4085535209536684
  - 0.43271171777371903
  train_level5__precision_micro:
  - 0.4277852542535807
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__precision_micro_masked:
  - 0.3938366797764438
  - 0.3602013792380103
  - 0.39250508326255373
  - 0.3747452018530774
  - 0.40133485099337746
  train_level5__precision_micro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046487
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__precision_samples:
  - 0.42778525425358066
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__precision_samples_masked:
  - 0.3945289942842722
  - 0.36101675986495146
  - 0.3931877026017636
  - 0.37537611654510905
  - 0.4019394830396011
  train_level5__precision_samples_oob:
  - 0.4260309526098241
  - 0.396233301700854
  - 0.42591706920464867
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__precision_weighted:
  - 0.5166159171735674
  - 0.5075823055785321
  - 0.5239657834489857
  - 0.5137847280162948
  - 0.5207890170460345
  train_level5__precision_weighted_masked:
  - 0.4857002345451382
  - 0.47484453095983375
  - 0.494802407618339
  - 0.4840932165662755
  - 0.49162286691711554
  train_level5__precision_weighted_oob:
  - 0.5137978686231623
  - 0.506462127713185
  - 0.523469369645741
  - 0.5120680932666914
  - 0.5195100540981933
  train_level5__recall_macro:
  - 0.42778525425358066
  - 0.39810691777988655
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.4342497356531769
  train_level5__recall_macro_masked:
  - 0.4002508248060397
  - 0.36826118911633227
  - 0.3996185722914809
  - 0.3823805128303752
  - 0.4076103839026909
  train_level5__recall_macro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046486
  - 0.4085535209536684
  - 0.43271171777371903
  train_level5__recall_micro:
  - 0.4277852542535807
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__recall_micro_masked:
  - 0.3938366797764438
  - 0.3602013792380103
  - 0.39250508326255373
  - 0.3747452018530774
  - 0.40133485099337746
  train_level5__recall_micro_oob:
  - 0.4260309526098241
  - 0.3962333017008541
  - 0.4259170692046487
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__recall_samples:
  - 0.42778525425358066
  - 0.3981069177798866
  - 0.4265627241857573
  - 0.4103232149440826
  - 0.434249735653177
  train_level5__recall_samples_masked:
  - 0.3945289942842722
  - 0.36101675986495146
  - 0.3931877026017636
  - 0.37537611654510905
  - 0.4019394830396011
  train_level5__recall_samples_oob:
  - 0.4260309526098241
  - 0.396233301700854
  - 0.42591706920464867
  - 0.4085535209536684
  - 0.43271171777371914
  train_level5__recall_weighted:
  - 0.5166159171735674
  - 0.5075823055785321
  - 0.5239657834489857
  - 0.5137847280162948
  - 0.5207890170460345
  train_level5__recall_weighted_masked:
  - 0.4857002345451382
  - 0.47484453095983375
  - 0.494802407618339
  - 0.4840932165662755
  - 0.49162286691711554
  train_level5__recall_weighted_oob:
  - 0.5137978686231623
  - 0.506462127713185
  - 0.523469369645741
  - 0.5120680932666914
  - 0.5195100540981933
  train_level5__roc_auc_macro:
  - 0.6824751900086671
  - 0.6668303819428426
  - 0.678685644899113
  - 0.6587805945863061
  - 0.6687344385786701
  train_level5__roc_auc_macro_masked:
  - 0.6601600571432732
  - 0.6459127727850786
  - 0.6556602780589831
  - 0.6382928447739016
  - 0.6428344968292561
  train_level5__roc_auc_macro_oob:
  - 0.6757351102532972
  - 0.6614363519466883
  - 0.6724889266231511
  - 0.6538788707623526
  - 0.6622091248178793
  train_level5__roc_auc_micro:
  - 0.5742216826483613
  - 0.527891667570106
  - 0.5512718350957624
  - 0.5242411406878138
  - 0.5443861243419403
  train_level5__roc_auc_micro_masked:
  - 0.5495459268724765
  - 0.5061984305663771
  - 0.5281769835748592
  - 0.5040377892487116
  - 0.5222646168199203
  train_level5__roc_auc_micro_oob:
  - 0.5715926715121915
  - 0.5266814494665429
  - 0.5507578339784439
  - 0.523411037662612
  - 0.5427265621567559
  train_level5__roc_auc_samples:
  - 0.5569394144647826
  - 0.5109954693733048
  - 0.535042759300924
  - 0.5113703451497629
  - 0.5282787393277051
  train_level5__roc_auc_samples_masked:
  - 0.533596901307178
  - 0.49276729303346284
  - 0.5145671348041797
  - 0.49394621388503873
  - 0.5080999477756923
  train_level5__roc_auc_samples_oob:
  - 0.5542164922695432
  - 0.509832655326813
  - 0.5347574811095444
  - 0.5106981284351853
  - 0.5267220910461785
  train_level5__roc_auc_weighted:
  - 0.6874289886711815
  - 0.684134044174721
  - 0.6943198603841814
  - 0.6803895635770083
  - 0.6788089116181297
  train_level5__roc_auc_weighted_masked:
  - 0.6566224031883345
  - 0.6560235416091534
  - 0.6644553102743679
  - 0.6523036748419648
  - 0.6474321232645157
  train_level5__roc_auc_weighted_oob:
  - 0.6800960659012055
  - 0.6772039788627701
  - 0.6862118373498327
  - 0.6735837778560111
  - 0.6705367562768294
  train_level5__tn_macro:
  - 0.24649139671248677
  - 0.20926101661921795
  - 0.24487062987230376
  - 0.2250952439474007
  - 0.25297990964144956
  train_level5__tn_macro_masked:
  - 0.2685127026072272
  - 0.22975041021678433
  - 0.26700768093806143
  - 0.24627672890153274
  - 0.27497236335976377
  train_level5__tn_macro_oob:
  - 0.24543400942035953
  - 0.20729006983478113
  - 0.24412932230140127
  - 0.22369423620498954
  - 0.25139382870325866
  train_level5__tn_micro:
  - 0.2464913967124868
  - 0.20926101661921795
  - 0.2448706298723038
  - 0.22509524394740077
  - 0.25297990964144956
  train_level5__tn_micro_masked:
  - 0.26539536327882424
  - 0.2255027925636521
  - 0.2635575116464623
  - 0.24243547319655856
  - 0.2723251241721854
  train_level5__tn_micro_oob:
  - 0.2454340094203595
  - 0.20729006983478113
  - 0.2441293223014013
  - 0.22369423620498954
  - 0.25139382870325866
  train_level5__tn_samples:
  - 0.2464913967124867
  - 0.2092610166192179
  - 0.2448706298723037
  - 0.2250952439474007
  - 0.25297990964144956
  train_level5__tn_samples_masked:
  - 0.26578562167800485
  - 0.22584352210233033
  - 0.2638491749724159
  - 0.24271243269328469
  - 0.272546352510345
  train_level5__tn_samples_oob:
  - 0.24543400942035942
  - 0.20729006983478107
  - 0.24412932230140127
  - 0.22369423620498952
  - 0.2513938287032586
  train_level5__tn_weighted:
  - 0.27665367112902256
  - 0.253776953715149
  - 0.27918307223860317
  - 0.2644308830034354
  - 0.27721266714300297
  train_level5__tn_weighted_masked:
  - 0.3098662617514445
  - 0.2858890081834141
  - 0.3129116251495372
  - 0.297420484946382
  - 0.3102999075750476
  train_level5__tn_weighted_oob:
  - 0.27493508173741543
  - 0.2520766791308721
  - 0.27825692329925034
  - 0.2630985773730535
  - 0.275764264570787
  train_level5__tp_macro:
  - 0.18129385754109392
  - 0.18884590116066863
  - 0.18169209431345362
  - 0.18522797099668178
  - 0.1812698260117274
  train_level5__tp_macro_masked:
  - 0.1317381221988126
  - 0.13851077889954788
  - 0.1326108913534195
  - 0.13610378392884248
  - 0.13263802054292712
  train_level5__tp_macro_oob:
  - 0.18059694318946456
  - 0.18894323186607292
  - 0.18178774690324745
  - 0.18485928474867888
  - 0.18131788907046045
  train_level5__tp_micro:
  - 0.18129385754109392
  - 0.18884590116066866
  - 0.18169209431345354
  - 0.1852279709966818
  - 0.1812698260117274
  train_level5__tp_micro_masked:
  - 0.12844131649761953
  - 0.13469858667435824
  - 0.1289475716160914
  - 0.13230972865651885
  - 0.12900972682119205
  train_level5__tp_micro_oob:
  - 0.18059694318946456
  - 0.18894323186607295
  - 0.1817877469032474
  - 0.18485928474867888
  - 0.18131788907046045
  train_level5__tp_samples:
  - 0.18129385754109387
  - 0.18884590116066863
  - 0.18169209431345348
  - 0.18522797099668178
  - 0.18126982601172736
  train_level5__tp_samples_masked:
  - 0.1287433726062673
  - 0.13517323776262116
  - 0.1293385276293476
  - 0.13266368385182434
  - 0.1293931305292561
  train_level5__tp_samples_oob:
  - 0.18059694318946454
  - 0.1889432318660729
  - 0.18178774690324737
  - 0.18485928474867885
  - 0.1813178890704604
  train_level5__tp_weighted:
  - 0.23996224604454477
  - 0.2538053518633832
  - 0.24478271121038264
  - 0.2493538450128595
  - 0.24357634990303156
  train_level5__tp_weighted_masked:
  - 0.17583397279369373
  - 0.18895552277641964
  - 0.1818907824688018
  - 0.18667273161989353
  - 0.18132295934206794
  train_level5__tp_weighted_oob:
  - 0.23886278688574694
  - 0.25438544858231277
  - 0.24521244634649078
  - 0.24896951589363808
  - 0.2437457895274064
  train_level6__average_precision_macro:
  - 0.3712868011058223
  - 0.3609006040282685
  - 0.36586289291918905
  - 0.3532170037762683
  - 0.35135800263516875
  train_level6__average_precision_macro_masked:
  - 0.2932019942721474
  - 0.2833864137277796
  - 0.28862070275078355
  - 0.2783307383901234
  - 0.27439891112846654
  train_level6__average_precision_macro_oob:
  - 0.3660186208307996
  - 0.35630448480328536
  - 0.36074684047490196
  - 0.34776093339431413
  - 0.34691886652224835
  train_level6__average_precision_micro:
  - 0.26228377701235617
  - 0.23494104512981814
  - 0.24005147338798988
  - 0.23240553423908322
  - 0.23775263311683786
  train_level6__average_precision_micro_masked:
  - 0.18904721088423315
  - 0.1691633842195363
  - 0.17245311194604773
  - 0.16801728542995142
  - 0.17170620094407663
  train_level6__average_precision_micro_oob:
  - 0.26256094515084616
  - 0.23491539221857147
  - 0.2411625830080146
  - 0.23287529556080105
  - 0.2385983662023207
  train_level6__average_precision_samples:
  - 0.27540004337525464
  - 0.24772658178295287
  - 0.25397219054908576
  - 0.24344432070879313
  - 0.24895565379659912
  train_level6__average_precision_samples_masked:
  - 0.20716005868179402
  - 0.18536664894578112
  - 0.18998120323687773
  - 0.18148743521661456
  - 0.18669177214498198
  train_level6__average_precision_samples_oob:
  - 0.2754987672286099
  - 0.24762942863384788
  - 0.25502094740018755
  - 0.24400812426788518
  - 0.2499390557142853
  train_level6__average_precision_weighted:
  - 0.5044428266096261
  - 0.49820848058791156
  - 0.5077737323544658
  - 0.49622784997974
  - 0.4882719034786282
  train_level6__average_precision_weighted_masked:
  - 0.4107721101994718
  - 0.4052330868718269
  - 0.41541783062999244
  - 0.40555591268498437
  - 0.39716362048365894
  train_level6__average_precision_weighted_oob:
  - 0.4989917254187782
  - 0.49285306100803306
  - 0.5017103884452245
  - 0.4895750950673968
  - 0.48309867679809404
  train_level6__f1_macro:
  - 0.42797750648851296
  - 0.39822858116164195
  - 0.42680185566024187
  - 0.411134324689689
  - 0.4348264923579737
  train_level6__f1_macro_masked:
  - 0.4005273664891749
  - 0.36828899254443487
  - 0.39986082260333483
  - 0.3832957907700862
  - 0.4082386292240671
  train_level6__f1_macro_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.4092417352832739
  - 0.4335047582428146
  train_level6__f1_micro:
  - 0.4279775064885129
  - 0.39822858116164195
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__f1_micro_masked:
  - 0.39412129993790107
  - 0.3602276004929596
  - 0.39273672560677425
  - 0.3756452680344143
  - 0.4019815811258278
  train_level6__f1_micro_oob:
  - 0.4265596462558877
  - 0.3958926442319391
  - 0.42555837199292174
  - 0.40924173528327396
  - 0.4335047582428146
  train_level6__f1_samples:
  - 0.4279775064885129
  - 0.3982285811616419
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__f1_samples_masked:
  - 0.394811077935289
  - 0.3610400992189177
  - 0.39343213764118423
  - 0.37629101529984427
  - 0.4025859909800196
  train_level6__f1_samples_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.40924173528327384
  - 0.4335047582428146
  train_level6__f1_weighted:
  - 0.5166849358050324
  - 0.5077723150067174
  - 0.5242662177476808
  - 0.5147721704397668
  - 0.5213368888435235
  train_level6__f1_weighted_masked:
  - 0.4858699516724289
  - 0.4749043873000788
  - 0.49519633954245595
  - 0.4852159310449664
  - 0.4920016726381461
  train_level6__f1_weighted_oob:
  - 0.51410552362984
  - 0.5062504324263482
  - 0.5228738252004798
  - 0.5127008722231492
  - 0.5199275288353578
  train_level6__fn_macro:
  - -0.052388734019032976
  - -0.04744871888459012
  - -0.05076761203309581
  - -0.0496989062307976
  - -0.05176391425550323
  train_level6__fn_macro_masked:
  - -0.05048212368964252
  - -0.046255306744787845
  - -0.048778257763872374
  - -0.04751021012165331
  - -0.0491615690314843
  train_level6__fn_macro_oob:
  - -0.0529895222531962
  - -0.047205392121079395
  - -0.05110239609737434
  - -0.05060833230920487
  - -0.051787945784869754
  train_level6__fn_micro:
  - -0.05238873401903297
  - -0.04744871888459012
  - -0.050767612033095794
  - -0.04969890623079759
  - -0.05176391425550322
  train_level6__fn_micro_masked:
  - -0.046393086317532604
  - -0.04242599050790571
  - -0.044964352817028284
  - -0.043653209794837854
  - -0.04534871688741722
  train_level6__fn_micro_oob:
  - -0.05298952225319619
  - -0.047205392121079395
  - -0.05110239609737434
  - -0.05060833230920487
  - -0.05178794578486975
  train_level6__fn_samples:
  - -0.05238873401903297
  - -0.04744871888459012
  - -0.05076761203309579
  - -0.04969890623079759
  - -0.051763914255503224
  train_level6__fn_samples_masked:
  - -0.04631876924954864
  - -0.04222360206025296
  - -0.04480863136448351
  - -0.04353899978900647
  - -0.04519606731747834
  train_level6__fn_samples_oob:
  - -0.052989522253196183
  - -0.0472053921210794
  - -0.05110239609737433
  - -0.05060833230920486
  - -0.05178794578486974
  train_level6__fn_weighted:
  - -0.10483649970100414
  - -0.0959108731862619
  - -0.10103542082351957
  - -0.09987153713106657
  - -0.10178319893845054
  train_level6__fn_weighted_masked:
  - -0.10515396962773767
  - -0.09688589909763536
  - -0.10009912927702404
  - -0.09875420220508371
  - -0.10034614476280924
  train_level6__fn_weighted_oob:
  - -0.1057991950033567
  - -0.0950354357256966
  - -0.1013401651501284
  - -0.10088758571916692
  - -0.10165816066142697
  train_level6__fp_macro:
  - -0.5196337594924542
  - -0.5543226999537679
  - -0.5224305323066621
  - -0.5391667690795133
  - -0.5134095933865231
  train_level6__fp_macro_masked:
  - -0.5489905098211825
  - -0.5854557007107772
  - -0.5513609196327927
  - -0.5691939991082605
  - -0.5425998017444487
  train_level6__fp_macro_oob:
  - -0.5204508314909162
  - -0.5569019636469816
  - -0.523339231909704
  - -0.5401499324075213
  - -0.5147072959723157
  train_level6__fp_micro:
  - -0.519633759492454
  - -0.5543226999537679
  - -0.5224305323066623
  - -0.5391667690795133
  - -0.5134095933865231
  train_level6__fp_micro_masked:
  - -0.5594856137445663
  - -0.5973464089991347
  - -0.5622989215761974
  - -0.5807015221707479
  - -0.5526697019867549
  train_level6__fp_micro_oob:
  - -0.5204508314909161
  - -0.5569019636469815
  - -0.523339231909704
  - -0.5401499324075212
  - -0.5147072959723157
  train_level6__fp_samples:
  - -0.519633759492454
  - -0.5543226999537679
  - -0.5224305323066623
  - -0.5391667690795133
  - -0.5134095933865231
  train_level6__fp_samples_masked:
  - -0.5588701528151623
  - -0.5967362987208292
  - -0.5617592309943322
  - -0.5801699849111491
  - -0.552217941702502
  train_level6__fp_samples_oob:
  - -0.5204508314909161
  - -0.5569019636469815
  - -0.5233392319097039
  - -0.5401499324075212
  - -0.5147072959723157
  train_level6__fp_weighted:
  - -0.37847856449396355
  - -0.3963168118070207
  - -0.37469836142879964
  - -0.3853562924291667
  - -0.37687991221802597
  train_level6__fp_weighted_masked:
  - -0.4089760786998335
  - -0.4282097136022859
  - -0.40470453118052013
  - -0.41602986674995
  - -0.40765218259904457
  train_level6__fp_weighted_oob:
  - -0.3800952813668032
  - -0.3987141318479553
  - -0.3757860096493919
  - -0.3864115420576838
  - -0.37841431050321533
  train_level6__jaccard_macro:
  - 0.2922027465828005
  - 0.2734537860348196
  - 0.2956116928331735
  - 0.281163506336206
  - 0.2983831290154246
  train_level6__jaccard_macro_masked:
  - 0.2697315527778516
  - 0.24957934188290523
  - 0.273662882053282
  - 0.2586642355371175
  - 0.27675518226276585
  train_level6__jaccard_macro_oob:
  - 0.29091182634745955
  - 0.27167766431539503
  - 0.2947052060857713
  - 0.27957381698082945
  - 0.29733385173838406
  train_level6__jaccard_micro:
  - 0.2722464266605519
  - 0.2486176095278605
  - 0.2712956770231653
  - 0.25875964914994665
  - 0.27781360356210655
  train_level6__jaccard_micro_masked:
  - 0.2454240783707141
  - 0.21968146347703724
  - 0.2443512098259324
  - 0.23125814863102997
  - 0.2515500299483593
  train_level6__jaccard_micro_oob:
  - 0.2710999786174665
  - 0.24679934469995754
  - 0.27029161603888213
  - 0.2572620519159456
  - 0.27673544527115135
  train_level6__jaccard_samples:
  - 0.2773189652042798
  - 0.2524387127351502
  - 0.2761014219452205
  - 0.26328038234151485
  - 0.2823570379576987
  train_level6__jaccard_samples_masked:
  - 0.250549941938347
  - 0.2234941993562153
  - 0.2492685812235466
  - 0.23583754065593138
  - 0.2561519890225912
  train_level6__jaccard_samples_oob:
  - 0.2761396469292767
  - 0.2506098597205847
  - 0.27505716389989665
  - 0.26165610500773273
  - 0.28113766858206457
  train_level6__jaccard_weighted:
  - 0.3635511978122175
  - 0.35974492464881114
  - 0.37322311646769607
  - 0.3634214166672908
  - 0.3684251034137841
  train_level6__jaccard_weighted_masked:
  - 0.33601711435661213
  - 0.33034804493881353
  - 0.3470820458700216
  - 0.3367622058892061
  - 0.3424176554908002
  train_level6__jaccard_weighted_oob:
  - 0.3610923577342015
  - 0.35851989683986235
  - 0.3720818508721261
  - 0.3615986275177662
  - 0.36725941213950336
  train_level6__label_ranking_average_precision_score:
  - 0.2754000433752545
  - 0.2477265817829528
  - 0.2539721905490859
  - 0.24344432070879304
  - 0.248955653796599
  train_level6__label_ranking_average_precision_score_oob:
  - 0.27549876722861005
  - 0.2476294286338479
  - 0.2550209474001877
  - 0.24400812426788498
  - 0.24993905571428515
  train_level6__matthews_corrcoef_macro:
  - 0.183338060335731
  - 0.1732756997536909
  - 0.18724121971752983
  - 0.177102535797965
  - 0.18277497434365575
  train_level6__matthews_corrcoef_macro_masked:
  - 0.14450635786824018
  - 0.13775348958933956
  - 0.1483280593253092
  - 0.14169896666634585
  - 0.14469507103956974
  train_level6__matthews_corrcoef_macro_oob:
  - 0.17975800853908394
  - 0.1690320854884973
  - 0.18405690221397875
  - 0.17249214494513138
  - 0.18114416004823003
  train_level6__matthews_corrcoef_micro:
  - 0.09028384444414127
  - 0.07132789748740835
  - 0.09338323448915113
  - 0.0794391640463977
  - 0.09959117994354796
  train_level6__matthews_corrcoef_micro_masked:
  - 0.04637529589579038
  - 0.02968719893584975
  - 0.04973793563508038
  - 0.03976087749478995
  - 0.05752199289142493
  train_level6__matthews_corrcoef_micro_oob:
  - 0.08694008571198354
  - 0.0692973193085112
  - 0.0910062718196614
  - 0.07455304637754294
  - 0.09805805187979867
  train_level6__matthews_corrcoef_samples:
  - 0.08510402951710998
  - 0.0642246197826242
  - 0.08719622913068556
  - 0.07419832457465915
  - 0.09479284794948399
  train_level6__matthews_corrcoef_samples_masked:
  - 0.04079528078478988
  - 0.02388858979032738
  - 0.045459082059676505
  - 0.03537697622863251
  - 0.05358175002275926
  train_level6__matthews_corrcoef_samples_oob:
  - 0.08217182847154778
  - 0.06252555928052432
  - 0.08479034548189779
  - 0.06967475751142214
  - 0.09370111363529125
  train_level6__matthews_corrcoef_weighted:
  - 0.21895420940663807
  - 0.21958522997160104
  - 0.2320116825998309
  - 0.226327791636044
  - 0.22202789459374317
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.1678520047905562
  - 0.17174925948865252
  - 0.18306281079347753
  - 0.18095537140934706
  - 0.17621496683526378
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.2135815740339574
  - 0.21660871383428615
  - 0.2276906516233055
  - 0.2211918366111313
  - 0.21946285116162195
  train_level6__ndcg:
  - 0.6270480673371703
  - 0.6045215127442818
  - 0.6069290034966063
  - 0.6046173300455407
  - 0.6057756458785417
  train_level6__ndcg_oob:
  - 0.6285642484600219
  - 0.6059590669862397
  - 0.6101502375219583
  - 0.6064904697336919
  - 0.6078864777482328
  train_level6__neg_coverage_error:
  - -92.62376237623762
  - -93.69423558897243
  - -92.10098522167488
  - -93.63291139240506
  - -91.61138613861387
  train_level6__neg_coverage_error_oob:
  - -93.11138613861387
  - -94.26315789473684
  - -92.66256157635468
  - -94.20506329113924
  - -92.22277227722772
  train_level6__neg_hamming_loss_macro:
  - -0.572022493511487
  - -0.6017714188383579
  - -0.5731981443397581
  - -0.588865675310311
  - -0.5651735076420262
  train_level6__neg_hamming_loss_macro_masked:
  - -0.599472633510825
  - -0.6317110074555651
  - -0.6001391773966652
  - -0.6167042092299138
  - -0.5917613707759328
  train_level6__neg_hamming_loss_macro_oob:
  - -0.5734403537441123
  - -0.6041073557680608
  - -0.5744416280070783
  - -0.5907582647167261
  - -0.5664952417571855
  train_level6__neg_hamming_loss_micro:
  - -0.572022493511487
  - -0.601771418838358
  - -0.573198144339758
  - -0.588865675310311
  - -0.5651735076420263
  train_level6__neg_hamming_loss_micro_masked:
  - -0.605878700062099
  - -0.6397723995070405
  - -0.6072632743932257
  - -0.6243547319655857
  - -0.5980184188741722
  train_level6__neg_hamming_loss_micro_oob:
  - -0.5734403537441123
  - -0.604107355768061
  - -0.5744416280070783
  - -0.5907582647167261
  - -0.5664952417571855
  train_level6__neg_hamming_loss_samples:
  - -0.572022493511487
  - -0.601771418838358
  - -0.573198144339758
  - -0.588865675310311
  - -0.5651735076420263
  train_level6__neg_hamming_loss_samples_masked:
  - -0.605188922064711
  - -0.6389599007810822
  - -0.6065678623588157
  - -0.6237089847001557
  - -0.5974140090199804
  train_level6__neg_hamming_loss_samples_oob:
  - -0.5734403537441123
  - -0.6041073557680608
  - -0.5744416280070782
  - -0.5907582647167261
  - -0.5664952417571854
  train_level6__neg_hamming_loss_weighted:
  - -0.48331506419496767
  - -0.49222768499328257
  - -0.47573378225231927
  - -0.48522782956023325
  - -0.4786631111564765
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.5141300483275711
  - -0.5250956126999212
  - -0.5048036604575441
  - -0.5147840689550336
  - -0.5079983273618539
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.48589447637016003
  - -0.4937495675736518
  - -0.4771261747995203
  - -0.4872991277768508
  - -0.4800724711646422
  train_level6__neg_label_ranking_loss:
  - -0.4578110201073404
  - -0.5079841683404923
  - -0.485451319688792
  - -0.5182528862049348
  - -0.4982036768564035
  train_level6__neg_label_ranking_loss_oob:
  - -0.46212913174283127
  - -0.5118908770798449
  - -0.4894543090449974
  - -0.5220123407668699
  - -0.5025754312557628
  train_level6__precision_macro:
  - 0.42797750648851296
  - 0.39822858116164195
  - 0.42680185566024187
  - 0.411134324689689
  - 0.4348264923579737
  train_level6__precision_macro_masked:
  - 0.4005273664891749
  - 0.36828899254443487
  - 0.39986082260333483
  - 0.3832957907700862
  - 0.4082386292240671
  train_level6__precision_macro_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.4092417352832739
  - 0.4335047582428146
  train_level6__precision_micro:
  - 0.4279775064885129
  - 0.39822858116164195
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__precision_micro_masked:
  - 0.39412129993790107
  - 0.3602276004929596
  - 0.39273672560677425
  - 0.3756452680344143
  - 0.4019815811258278
  train_level6__precision_micro_oob:
  - 0.4265596462558877
  - 0.3958926442319391
  - 0.42555837199292174
  - 0.40924173528327396
  - 0.4335047582428146
  train_level6__precision_samples:
  - 0.4279775064885129
  - 0.3982285811616419
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__precision_samples_masked:
  - 0.394811077935289
  - 0.3610400992189177
  - 0.39343213764118423
  - 0.37629101529984427
  - 0.4025859909800196
  train_level6__precision_samples_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.40924173528327384
  - 0.4335047582428146
  train_level6__precision_weighted:
  - 0.5166849358050324
  - 0.5077723150067174
  - 0.5242662177476808
  - 0.5147721704397668
  - 0.5213368888435235
  train_level6__precision_weighted_masked:
  - 0.4858699516724289
  - 0.4749043873000788
  - 0.49519633954245595
  - 0.4852159310449664
  - 0.4920016726381461
  train_level6__precision_weighted_oob:
  - 0.51410552362984
  - 0.5062504324263482
  - 0.5228738252004798
  - 0.5127008722231492
  - 0.5199275288353578
  train_level6__recall_macro:
  - 0.42797750648851296
  - 0.39822858116164195
  - 0.42680185566024187
  - 0.411134324689689
  - 0.4348264923579737
  train_level6__recall_macro_masked:
  - 0.4005273664891749
  - 0.36828899254443487
  - 0.39986082260333483
  - 0.3832957907700862
  - 0.4082386292240671
  train_level6__recall_macro_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.4092417352832739
  - 0.4335047582428146
  train_level6__recall_micro:
  - 0.4279775064885129
  - 0.39822858116164195
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__recall_micro_masked:
  - 0.39412129993790107
  - 0.3602276004929596
  - 0.39273672560677425
  - 0.3756452680344143
  - 0.4019815811258278
  train_level6__recall_micro_oob:
  - 0.4265596462558877
  - 0.3958926442319391
  - 0.42555837199292174
  - 0.40924173528327396
  - 0.4335047582428146
  train_level6__recall_samples:
  - 0.4279775064885129
  - 0.3982285811616419
  - 0.426801855660242
  - 0.4111343246896891
  - 0.43482649235797366
  train_level6__recall_samples_masked:
  - 0.394811077935289
  - 0.3610400992189177
  - 0.39343213764118423
  - 0.37629101529984427
  - 0.4025859909800196
  train_level6__recall_samples_oob:
  - 0.4265596462558877
  - 0.39589264423193904
  - 0.4255583719929217
  - 0.40924173528327384
  - 0.4335047582428146
  train_level6__recall_weighted:
  - 0.5166849358050324
  - 0.5077723150067174
  - 0.5242662177476808
  - 0.5147721704397668
  - 0.5213368888435235
  train_level6__recall_weighted_masked:
  - 0.4858699516724289
  - 0.4749043873000788
  - 0.49519633954245595
  - 0.4852159310449664
  - 0.4920016726381461
  train_level6__recall_weighted_oob:
  - 0.51410552362984
  - 0.5062504324263482
  - 0.5228738252004798
  - 0.5127008722231492
  - 0.5199275288353578
  train_level6__roc_auc_macro:
  - 0.6822536643276772
  - 0.6671099025152764
  - 0.6783541396030623
  - 0.6586984324753239
  - 0.6682481900127937
  train_level6__roc_auc_macro_masked:
  - 0.6603502950512403
  - 0.6459536927423262
  - 0.6546126527383443
  - 0.6384134370731994
  - 0.6429343652030292
  train_level6__roc_auc_macro_oob:
  - 0.675459900348206
  - 0.6613281393441229
  - 0.6717386507826063
  - 0.6530327097179908
  - 0.6623905650296665
  train_level6__roc_auc_micro:
  - 0.57520843429333
  - 0.5290688968496557
  - 0.5516347704103279
  - 0.5277573970780715
  - 0.5443524298780409
  train_level6__roc_auc_micro_masked:
  - 0.5505588043365675
  - 0.5071476476898686
  - 0.5283806797795522
  - 0.5072790957676322
  - 0.5231192454628342
  train_level6__roc_auc_micro_oob:
  - 0.572856787212213
  - 0.5269527322937291
  - 0.5504786021588484
  - 0.5265809801347554
  - 0.5434342088940463
  train_level6__roc_auc_samples:
  - 0.5585146807309234
  - 0.5125066478468223
  - 0.5355853085371479
  - 0.5154909259945775
  - 0.5277023208112573
  train_level6__roc_auc_samples_masked:
  - 0.5350430284198509
  - 0.49445809527248613
  - 0.514847142582931
  - 0.4978245094159452
  - 0.5083501807351538
  train_level6__roc_auc_samples_oob:
  - 0.5560532528566051
  - 0.5104518047162235
  - 0.534618414055414
  - 0.5146792639634182
  - 0.5267873326434837
  train_level6__roc_auc_weighted:
  - 0.6867379607098074
  - 0.6842338429603564
  - 0.6941577107908375
  - 0.6809608537736436
  - 0.6784668953688014
  train_level6__roc_auc_weighted_masked:
  - 0.656071443217663
  - 0.6557699920015425
  - 0.6638733185630772
  - 0.6527050594583793
  - 0.6474584796487549
  train_level6__roc_auc_weighted_oob:
  - 0.6793737642494417
  - 0.6768275608705862
  - 0.6857496468879724
  - 0.6733965439904086
  - 0.670315839280534
  train_level6__tn_macro:
  - 0.2468038065942517
  - 0.2094556780300265
  - 0.24525324023147926
  - 0.22590635369300724
  - 0.25348457175814676
  train_level6__tn_macro_masked:
  - 0.26883522966533197
  - 0.22997702672388579
  - 0.26745558710659456
  - 0.24715951256556853
  - 0.27551324554047474
  train_level6__tn_macro_oob:
  - 0.24598673459578965
  - 0.2068764143368129
  - 0.24434454062843752
  - 0.22492319036499936
  - 0.2521868691723541
  train_level6__tn_micro:
  - 0.24680380659425166
  - 0.20945567803002652
  - 0.24525324023147926
  - 0.22590635369300724
  - 0.2534845717581467
  train_level6__tn_micro_masked:
  - 0.2657317325605465
  - 0.22571256260324618
  - 0.2639693202584099
  - 0.24330906684315023
  - 0.2728683774834437
  train_level6__tn_micro_oob:
  - 0.24598673459578968
  - 0.20687641433681292
  - 0.24434454062843752
  - 0.2249231903649994
  - 0.2521868691723541
  train_level6__tn_samples:
  - 0.24680380659425158
  - 0.20945567803002646
  - 0.2452532402314792
  - 0.2259063536930072
  - 0.25348457175814665
  train_level6__tn_samples_masked:
  - 0.2661201135720806
  - 0.2260507768374256
  - 0.26427121143199556
  - 0.24359681329196242
  - 0.2730884913335223
  train_level6__tn_samples_oob:
  - 0.2459867345957896
  - 0.20687641433681284
  - 0.24434454062843744
  - 0.22492319036499933
  - 0.25218686917235406
  train_level6__tn_weighted:
  - 0.27679323647973403
  - 0.25418201457496226
  - 0.2799834697752955
  - 0.26535819950680856
  - 0.27770006124323776
  train_level6__tn_weighted_masked:
  - 0.3100101624411257
  - 0.2863422404001299
  - 0.31385501145987393
  - 0.29843110882600316
  - 0.3108071290868402
  train_level6__tn_weighted_oob:
  - 0.27517651960689427
  - 0.2517846945340277
  - 0.27889582155470316
  - 0.2643029498782914
  - 0.2761656629580484
  train_level6__tp_macro:
  - 0.18117369989426127
  - 0.1887729031316154
  - 0.18154861542876277
  - 0.1852279709966818
  - 0.18134192059982698
  train_level6__tp_macro_masked:
  - 0.13169213682384298
  - 0.1383119658205491
  - 0.13240523549674033
  - 0.13613627820451765
  - 0.13272538368359227
  train_level6__tp_macro_oob:
  - 0.18057291166009806
  - 0.18901622989512615
  - 0.18121383136448424
  - 0.1843185449182745
  - 0.18131788907046043
  train_level6__tp_micro:
  - 0.18117369989426127
  - 0.18877290313161543
  - 0.18154861542876274
  - 0.1852279709966818
  - 0.18134192059982698
  train_level6__tp_micro_masked:
  - 0.12838956737735457
  - 0.1345150378897134
  - 0.12876740534836434
  - 0.13233620119126407
  - 0.1291132036423841
  train_level6__tp_micro_oob:
  - 0.18057291166009806
  - 0.18901622989512618
  - 0.18121383136448418
  - 0.18431854491827454
  - 0.18131788907046045
  train_level6__tp_samples:
  - 0.18117369989426121
  - 0.18877290313161538
  - 0.18154861542876272
  - 0.18522797099668178
  - 0.18134192059982696
  train_level6__tp_samples_masked:
  - 0.12869096436320848
  - 0.13498932238149217
  - 0.12916092620918868
  - 0.13269420200788193
  - 0.1294974996464973
  train_level6__tp_samples_oob:
  - 0.18057291166009798
  - 0.18901622989512612
  - 0.18121383136448418
  - 0.1843185449182745
  - 0.1813178890704604
  train_level6__tp_weighted:
  - 0.23989169932529833
  - 0.2535903004317551
  - 0.24428274797238544
  - 0.2494139709329583
  - 0.2436368276002858
  train_level6__tp_weighted_masked:
  - 0.17585978923130305
  - 0.18856214689994896
  - 0.18134132808258202
  - 0.18678482221896325
  - 0.18119454355130588
  train_level6__tp_weighted_oob:
  - 0.23892900402294578
  - 0.2544657378923203
  - 0.2439780036457766
  - 0.24839792234485794
  - 0.24376186587730936
  train_level7__average_precision_macro:
  - 0.3717116202498002
  - 0.36222241462976174
  - 0.36128885338579947
  - 0.34909709045147785
  - 0.3532354566901117
  train_level7__average_precision_macro_masked:
  - 0.29386822295399445
  - 0.2834985109595533
  - 0.2840742568361074
  - 0.2753974179732617
  - 0.27578564897502594
  train_level7__average_precision_macro_oob:
  - 0.3678632518327454
  - 0.3573285302530957
  - 0.35681258842877644
  - 0.34578266942060165
  - 0.34844646545389474
  train_level7__average_precision_micro:
  - 0.26002931833872245
  - 0.2346826958045836
  - 0.2410627750148735
  - 0.23247066779107556
  - 0.2374657108964538
  train_level7__average_precision_micro_masked:
  - 0.18764402232037192
  - 0.16888082820700118
  - 0.17328170872596121
  - 0.16826572596974299
  - 0.17136791847774718
  train_level7__average_precision_micro_oob:
  - 0.2610838256177707
  - 0.23464659459490086
  - 0.24199012050421087
  - 0.23330662800370364
  - 0.2383407725000206
  train_level7__average_precision_samples:
  - 0.2739258422134063
  - 0.24712720726388962
  - 0.2559154668078192
  - 0.24388297954070218
  - 0.24887693525790328
  train_level7__average_precision_samples_masked:
  - 0.20624387047315995
  - 0.18463584467284297
  - 0.19120068710136287
  - 0.1819468448899814
  - 0.18641085797865742
  train_level7__average_precision_samples_oob:
  - 0.27466119965734276
  - 0.247201486589695
  - 0.2569009396439742
  - 0.2448962692076226
  - 0.24956580308758392
  train_level7__average_precision_weighted:
  - 0.5062278609186585
  - 0.49911950816126255
  - 0.5024846244444834
  - 0.49009641239379387
  - 0.48980408721878044
  train_level7__average_precision_weighted_masked:
  - 0.4128912552130278
  - 0.40483370894322274
  - 0.4097873718527981
  - 0.4005996269696873
  - 0.3985139216618481
  train_level7__average_precision_weighted_oob:
  - 0.501972510627048
  - 0.4940750379179733
  - 0.49685720124747906
  - 0.4865091199150079
  - 0.48459085086785103
  train_level7__f1_macro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.42651489789086033
  - 0.41096227110728767
  - 0.43470633471114095
  train_level7__f1_macro_masked:
  - 0.4010400519089506
  - 0.3685340138864618
  - 0.39942840759605075
  - 0.38302872840646834
  - 0.40812952379550776
  train_level7__f1_macro_oob:
  - 0.42720849754878404
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.43340863212534836
  train_level7__f1_micro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__f1_micro_masked:
  - 0.3946387911405506
  - 0.3604898130424522
  - 0.39232491699482663
  - 0.3753805426869623
  - 0.4019039735099338
  train_level7__f1_micro_oob:
  - 0.427208497548784
  - 0.3962819670535562
  - 0.4258453297623033
  - 0.40961042153127686
  - 0.43340863212534847
  train_level7__f1_samples:
  - 0.42845813707584346
  - 0.3983502445433973
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__f1_samples_masked:
  - 0.39530835938530673
  - 0.3613207522008656
  - 0.39299943538771465
  - 0.37601372273834566
  - 0.4024994874164408
  train_level7__f1_samples_oob:
  - 0.427208497548784
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.4334086321253484
  train_level7__f1_weighted:
  - 0.5171545681165503
  - 0.5074470271269438
  - 0.5238255807762612
  - 0.5148458048264956
  - 0.5207675819128305
  train_level7__f1_weighted_masked:
  - 0.48631369968737687
  - 0.4749155694953437
  - 0.4944919084118797
  - 0.48492421801722724
  - 0.4914686569610203
  train_level7__f1_weighted_oob:
  - 0.514963799600456
  - 0.5060472565839816
  - 0.5230383668543641
  - 0.5130134210589048
  - 0.5198065734408492
  train_level7__fn_macro:
  - -0.05229260790156686
  - -0.04759471494269654
  - -0.05095891721268353
  - -0.04972348531399779
  - -0.05195616649043545
  train_level7__fn_macro_masked:
  - -0.05036788544179284
  - -0.04627205786270246
  - -0.049091934463965814
  - -0.047641787561001854
  - -0.04933596480251751
  train_level7__fn_macro_oob:
  - -0.05294145919446314
  - -0.04759471494269654
  - -0.05115022239227127
  - -0.05051001597640408
  - -0.05181197731423628
  train_level7__fn_micro:
  - -0.052292607901566854
  - -0.04759471494269655
  - -0.05095891721268354
  - -0.04972348531399779
  - -0.051956166490435454
  train_level7__fn_micro_masked:
  - -0.04628958807700269
  - -0.04245221176285497
  - -0.04527320927598898
  - -0.043759099933818664
  - -0.045503932119205295
  train_level7__fn_micro_oob:
  - -0.052941459194463136
  - -0.04759471494269655
  - -0.05115022239227127
  - -0.05051001597640408
  - -0.05181197731423628
  train_level7__fn_samples:
  - -0.05229260790156685
  - -0.04759471494269654
  - -0.05095891721268354
  - -0.049723485313997784
  - -0.05195616649043544
  train_level7__fn_samples_masked:
  - -0.046213819511602916
  - -0.04224717229239508
  - -0.045126968314546836
  - -0.04364796321806371
  - -0.045350180123004916
  train_level7__fn_samples_oob:
  - -0.05294145919446313
  - -0.04759471494269655
  - -0.05115022239227126
  - -0.050510015976404074
  - -0.05181197731423628
  train_level7__fn_weighted:
  - -0.1045448896160323
  - -0.09615458093110817
  - -0.10119413126316777
  - -0.09991709509695637
  - -0.10226370317444115
  train_level7__fn_weighted_masked:
  - -0.10489097772010102
  - -0.09677880707769414
  - -0.10047711932418384
  - -0.0992244581321971
  - -0.10077980656144947
  train_level7__fn_weighted_oob:
  - -0.10569426630902623
  - -0.09572602705775565
  - -0.10115432688772885
  - -0.10092122444979486
  - -0.10178830254159435
  train_level7__fp_macro:
  - -0.5192492550225895
  - -0.5540550405139062
  - -0.5225261848964562
  - -0.5393142435787146
  - -0.5133374987984236
  train_level7__fp_macro_masked:
  - -0.5485920626492565
  - -0.5851939282508358
  - -0.5514796579399833
  - -0.5693294840325298
  - -0.5425345114019747
  train_level7__fp_macro_oob:
  - -0.5198500432567528
  - -0.5561233180037471
  - -0.5230044478454254
  - -0.5398795624923192
  - -0.5147793905604153
  train_level7__fp_micro:
  - -0.5192492550225897
  - -0.5540550405139061
  - -0.5225261848964561
  - -0.5393142435787145
  - -0.5133374987984235
  train_level7__fp_micro_masked:
  - -0.5590716207824467
  - -0.5970579751946928
  - -0.5624018737291844
  - -0.580860357379219
  - -0.5525920943708609
  train_level7__fp_micro_oob:
  - -0.5198500432567529
  - -0.5561233180037473
  - -0.5230044478454254
  - -0.539879562492319
  - -0.5147793905604152
  train_level7__fp_samples:
  - -0.5192492550225897
  - -0.5540550405139061
  - -0.5225261848964561
  - -0.5393142435787145
  - -0.5133374987984235
  train_level7__fp_samples_masked:
  - -0.5584778211030903
  - -0.5964320755067393
  - -0.5618735962977385
  - -0.5803383140435906
  - -0.5521503324605543
  train_level7__fp_samples_oob:
  - -0.5198500432567529
  - -0.5561233180037471
  - -0.5230044478454254
  - -0.5398795624923189
  - -0.5147793905604152
  train_level7__fp_weighted:
  - -0.37830054226741744
  - -0.39639839194194804
  - -0.3749802879605708
  - -0.385237100076548
  - -0.37696871491272843
  train_level7__fp_weighted_masked:
  - -0.40879532259252205
  - -0.42830562342696205
  - -0.4050309722639364
  - -0.4158513238505757
  - -0.4077515364775302
  train_level7__fp_weighted_oob:
  - -0.37934193409051786
  - -0.3982267163582628
  - -0.37580730625790704
  - -0.3860653544913003
  - -0.37840512401755644
  train_level7__jaccard_macro:
  - 0.2925458795780367
  - 0.2734125774430102
  - 0.29517770164334706
  - 0.2811099445920218
  - 0.2981744157759184
  train_level7__jaccard_macro_masked:
  - 0.2700840584038425
  - 0.24967809308301642
  - 0.27309849192184044
  - 0.25850912546202753
  - 0.27656795992290745
  train_level7__jaccard_macro_oob:
  - 0.2913490361607178
  - 0.2718960314293077
  - 0.2947718841352481
  - 0.2799200569674499
  - 0.2972314663084234
  train_level7__jaccard_micro:
  - 0.27263552259347046
  - 0.24871245613235496
  - 0.27106382978723403
  - 0.2586233565351895
  - 0.2777155139326015
  train_level7__jaccard_micro_masked:
  - 0.24582554316291663
  - 0.21987653136295301
  - 0.2440324672205946
  - 0.23105751996089294
  - 0.2514892514892515
  train_level7__jaccard_micro_oob:
  - 0.2716243678090669
  - 0.24710202099896825
  - 0.2705231816248405
  - 0.2575535120933467
  - 0.2766571047262575
  train_level7__jaccard_samples:
  - 0.2777215204477603
  - 0.2525832911996517
  - 0.2758407815236016
  - 0.26309545054477484
  - 0.2822362941049496
  train_level7__jaccard_samples_masked:
  - 0.2509479833088249
  - 0.22374347987715235
  - 0.24889825565854362
  - 0.23558308847397863
  - 0.25605817609380543
  train_level7__jaccard_samples_oob:
  - 0.2767968554352659
  - 0.25091417101696256
  - 0.27527824124412825
  - 0.2619212015638295
  - 0.28115637726353243
  train_level7__jaccard_weighted:
  - 0.363875592316417
  - 0.35938560289911714
  - 0.3726388860306224
  - 0.3635887340505624
  - 0.36782415218479547
  train_level7__jaccard_weighted_masked:
  - 0.3362948930875982
  - 0.330357884501118
  - 0.346257554461989
  - 0.33656679048750743
  - 0.3418857260693336
  train_level7__jaccard_weighted_oob:
  - 0.3617115989131427
  - 0.35822191325768227
  - 0.3720611743504258
  - 0.3619161537230331
  - 0.36709132913427645
  train_level7__label_ranking_average_precision_score:
  - 0.2739258422134063
  - 0.24712720726388956
  - 0.25591546680781935
  - 0.24388297954070232
  - 0.24887693525790314
  train_level7__label_ranking_average_precision_score_oob:
  - 0.27466119965734287
  - 0.2472014865896951
  - 0.256900939643974
  - 0.24489626920762264
  - 0.24956580308758367
  train_level7__matthews_corrcoef_macro:
  - 0.1837046311965659
  - 0.17200160432155062
  - 0.18632817490234416
  - 0.17715314589786457
  - 0.1826531953712151
  train_level7__matthews_corrcoef_macro_masked:
  - 0.14498062530427075
  - 0.13624663836718318
  - 0.14686892591555764
  - 0.14184900916865448
  - 0.14445933523540727
  train_level7__matthews_corrcoef_macro_oob:
  - 0.18085010709736946
  - 0.16888097745324698
  - 0.1836402187177927
  - 0.17340040652678695
  - 0.18091554597503817
  train_level7__matthews_corrcoef_micro:
  - 0.09110252801439228
  - 0.07103037014672817
  - 0.09249751667396386
  - 0.07916793848342295
  - 0.098896284961437
  train_level7__matthews_corrcoef_micro_masked:
  - 0.04725899797837031
  - 0.029850340850634344
  - 0.04816913827585256
  - 0.039094220994391055
  - 0.056862620821790985
  train_level7__matthews_corrcoef_micro_oob:
  - 0.0878082268104626
  - 0.06858033455118435
  - 0.0911851316077114
  - 0.07527093859173473
  - 0.09788123447250632
  train_level7__matthews_corrcoef_samples:
  - 0.08580796680483314
  - 0.06379772222525927
  - 0.08630148015479022
  - 0.07402778297952028
  - 0.09418999958298181
  train_level7__matthews_corrcoef_samples_masked:
  - 0.04166816622176
  - 0.02405958776723131
  - 0.043904867312765126
  - 0.03476375971771132
  - 0.053113199115109505
  train_level7__matthews_corrcoef_samples_oob:
  - 0.08266017004388071
  - 0.06196696452153356
  - 0.08528729109688424
  - 0.07044328848205489
  - 0.09342255769508505
  train_level7__matthews_corrcoef_weighted:
  - 0.21940901372819657
  - 0.21851344695599773
  - 0.2304169846638545
  - 0.22710440396587048
  - 0.22143469800970847
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.16854416523956084
  - 0.1709932277714353
  - 0.18063942395299437
  - 0.18146189224958678
  - 0.17550362294529478
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.21510840989954322
  - 0.21571072252574355
  - 0.22685405720011445
  - 0.22230225241644827
  - 0.21956829048481197
  train_level7__ndcg:
  - 0.6230465594499576
  - 0.6052125901885863
  - 0.6096360578326191
  - 0.6050045059962403
  - 0.6060953521370773
  train_level7__ndcg_oob:
  - 0.6256438076790612
  - 0.6062886944385624
  - 0.6125290107351982
  - 0.6071198485311362
  - 0.6080036178904099
  train_level7__neg_coverage_error:
  - -92.6509900990099
  - -93.50877192982456
  - -92.0295566502463
  - -93.54430379746836
  - -91.61138613861387
  train_level7__neg_coverage_error_oob:
  - -93.2128712871287
  - -94.10526315789474
  - -92.61330049261083
  - -94.0632911392405
  - -92.25990099009901
  train_level7__neg_hamming_loss_macro:
  - -0.5715418629241564
  - -0.6016497554566026
  - -0.5734851021091396
  - -0.5890377288927123
  - -0.565293665288859
  train_level7__neg_hamming_loss_macro_masked:
  - -0.5989599480910495
  - -0.6314659861135381
  - -0.6005715924039493
  - -0.6169712715935317
  - -0.5918704762044923
  train_level7__neg_hamming_loss_macro_oob:
  - -0.5727915024512161
  - -0.6037180329464438
  - -0.5741546702376967
  - -0.5903895784687232
  - -0.5665913678746516
  train_level7__neg_hamming_loss_micro:
  - -0.5715418629241565
  - -0.6016497554566027
  - -0.5734851021091396
  - -0.5890377288927123
  - -0.5652936652888589
  train_level7__neg_hamming_loss_micro_masked:
  - -0.6053612088594494
  - -0.6395101869575478
  - -0.6076750830051734
  - -0.6246194573130377
  - -0.5980960264900662
  train_level7__neg_hamming_loss_micro_oob:
  - -0.572791502451216
  - -0.6037180329464438
  - -0.5741546702376967
  - -0.5903895784687231
  - -0.5665913678746516
  train_level7__neg_hamming_loss_samples:
  - -0.5715418629241564
  - -0.6016497554566027
  - -0.5734851021091396
  - -0.5890377288927123
  - -0.5652936652888589
  train_level7__neg_hamming_loss_samples_masked:
  - -0.6046916406146933
  - -0.6386792477991344
  - -0.6070005646122854
  - -0.6239862772616542
  - -0.5975005125835591
  train_level7__neg_hamming_loss_samples_oob:
  - -0.572791502451216
  - -0.6037180329464438
  - -0.5741546702376966
  - -0.5903895784687231
  - -0.5665913678746515
  train_level7__neg_hamming_loss_weighted:
  - -0.4828454318834497
  - -0.4925529728730561
  - -0.47617441922373877
  - -0.4851541951735044
  - -0.47923241808716954
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.5136863003126231
  - -0.5250844305046563
  - -0.5055080915881204
  - -0.5150757819827728
  - -0.5085313430389796
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.4850362003995441
  - -0.49395274341601836
  - -0.47696163314563583
  - -0.4869865789410952
  - -0.4801934265591508
  train_level7__neg_label_ranking_loss:
  - -0.4569003388235239
  - -0.5061753980988282
  - -0.48523350949851524
  - -0.5187416099389603
  - -0.4984638454589543
  train_level7__neg_label_ranking_loss_oob:
  - -0.46120343348968834
  - -0.510191334989117
  - -0.48876188770474205
  - -0.5221609013023703
  - -0.502501527082247
  train_level7__precision_macro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.42651489789086033
  - 0.41096227110728767
  - 0.43470633471114095
  train_level7__precision_macro_masked:
  - 0.4010400519089506
  - 0.3685340138864618
  - 0.39942840759605075
  - 0.38302872840646834
  - 0.40812952379550776
  train_level7__precision_macro_oob:
  - 0.42720849754878404
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.43340863212534836
  train_level7__precision_micro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__precision_micro_masked:
  - 0.3946387911405506
  - 0.3604898130424522
  - 0.39232491699482663
  - 0.3753805426869623
  - 0.4019039735099338
  train_level7__precision_micro_oob:
  - 0.427208497548784
  - 0.3962819670535562
  - 0.4258453297623033
  - 0.40961042153127686
  - 0.43340863212534847
  train_level7__precision_samples:
  - 0.42845813707584346
  - 0.3983502445433973
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__precision_samples_masked:
  - 0.39530835938530673
  - 0.3613207522008656
  - 0.39299943538771465
  - 0.37601372273834566
  - 0.4024994874164408
  train_level7__precision_samples_oob:
  - 0.427208497548784
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.4334086321253484
  train_level7__precision_weighted:
  - 0.5171545681165503
  - 0.5074470271269438
  - 0.5238255807762612
  - 0.5148458048264956
  - 0.5207675819128305
  train_level7__precision_weighted_masked:
  - 0.48631369968737687
  - 0.4749155694953437
  - 0.4944919084118797
  - 0.48492421801722724
  - 0.4914686569610203
  train_level7__precision_weighted_oob:
  - 0.514963799600456
  - 0.5060472565839816
  - 0.5230383668543641
  - 0.5130134210589048
  - 0.5198065734408492
  train_level7__recall_macro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.42651489789086033
  - 0.41096227110728767
  - 0.43470633471114095
  train_level7__recall_macro_masked:
  - 0.4010400519089506
  - 0.3685340138864618
  - 0.39942840759605075
  - 0.38302872840646834
  - 0.40812952379550776
  train_level7__recall_macro_oob:
  - 0.42720849754878404
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.43340863212534836
  train_level7__recall_micro:
  - 0.4284581370758435
  - 0.39835024454339735
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__recall_micro_masked:
  - 0.3946387911405506
  - 0.3604898130424522
  - 0.39232491699482663
  - 0.3753805426869623
  - 0.4019039735099338
  train_level7__recall_micro_oob:
  - 0.427208497548784
  - 0.3962819670535562
  - 0.4258453297623033
  - 0.40961042153127686
  - 0.43340863212534847
  train_level7__recall_samples:
  - 0.42845813707584346
  - 0.3983502445433973
  - 0.4265148978908604
  - 0.4109622711072877
  - 0.434706334711141
  train_level7__recall_samples_masked:
  - 0.39530835938530673
  - 0.3613207522008656
  - 0.39299943538771465
  - 0.37601372273834566
  - 0.4024994874164408
  train_level7__recall_samples_oob:
  - 0.427208497548784
  - 0.39628196705355617
  - 0.42584532976230327
  - 0.40961042153127686
  - 0.4334086321253484
  train_level7__recall_weighted:
  - 0.5171545681165503
  - 0.5074470271269438
  - 0.5238255807762612
  - 0.5148458048264956
  - 0.5207675819128305
  train_level7__recall_weighted_masked:
  - 0.48631369968737687
  - 0.4749155694953437
  - 0.4944919084118797
  - 0.48492421801722724
  - 0.4914686569610203
  train_level7__recall_weighted_oob:
  - 0.514963799600456
  - 0.5060472565839816
  - 0.5230383668543641
  - 0.5130134210589048
  - 0.5198065734408492
  train_level7__roc_auc_macro:
  - 0.6828993136795297
  - 0.6676255334629435
  - 0.6772195314995529
  - 0.6581537185493626
  - 0.6673146424056933
  train_level7__roc_auc_macro_masked:
  - 0.6608344231907392
  - 0.6467281526924987
  - 0.6539482864858938
  - 0.6380720271491759
  - 0.6415097203243652
  train_level7__roc_auc_macro_oob:
  - 0.6767443919259718
  - 0.6615493882512015
  - 0.6711223293456158
  - 0.6531291292326212
  - 0.6614346439594619
  train_level7__roc_auc_micro:
  - 0.5738967136895428
  - 0.5290390288783295
  - 0.5524469993961952
  - 0.527586918163459
  - 0.5439644767311136
  train_level7__roc_auc_micro_masked:
  - 0.5494927095116784
  - 0.5070026801757921
  - 0.5292692248676425
  - 0.507432629075937
  - 0.5225278053719495
  train_level7__roc_auc_micro_oob:
  - 0.5720401724478283
  - 0.5269998191021203
  - 0.5512053769800304
  - 0.5269507821916588
  - 0.5431069025516044
  train_level7__roc_auc_samples:
  - 0.5570779489635346
  - 0.5133592308809043
  - 0.5371541369705324
  - 0.5158432902890285
  - 0.5278261207125801
  train_level7__roc_auc_samples_masked:
  - 0.533936113072472
  - 0.4950265827231331
  - 0.5166068915743739
  - 0.4982927175248484
  - 0.5083773038203852
  train_level7__roc_auc_samples_oob:
  - 0.5548200932777773
  - 0.5113200373456004
  - 0.5362945988833266
  - 0.5155534829583239
  - 0.5269526357595876
  train_level7__roc_auc_weighted:
  - 0.6874836221518792
  - 0.6845488752047872
  - 0.6926659546899563
  - 0.6800198136186768
  - 0.6777830301766837
  train_level7__roc_auc_weighted_masked:
  - 0.6568616183675999
  - 0.6562257772814095
  - 0.6625884932297271
  - 0.6520287464012914
  - 0.6465502415647314
  train_level7__roc_auc_weighted_oob:
  - 0.6804615159342339
  - 0.6772544770662895
  - 0.6845865266327386
  - 0.6729494004475727
  - 0.6699976001278789
  train_level7__tn_macro:
  - 0.24718831106411612
  - 0.20972333746988833
  - 0.24515758764168538
  - 0.22575887919380605
  - 0.2535566663462463
  train_level7__tn_macro_masked:
  - 0.26923367683725796
  - 0.23023879918382734
  - 0.2673368487994039
  - 0.24702402764129924
  - 0.27557853588294856
  train_level7__tn_macro_oob:
  - 0.24658752282995294
  - 0.20765505998004724
  - 0.24467932469271603
  - 0.22519356028020157
  - 0.2521147745842545
  train_level7__tn_micro:
  - 0.24718831106411612
  - 0.2097233374698883
  - 0.2451575876416854
  - 0.22575887919380608
  - 0.2535566663462463
  train_level7__tn_micro_masked:
  - 0.26614572552266613
  - 0.22600099640768806
  - 0.263866368105423
  - 0.24315023163467903
  - 0.27294598509933776
  train_level7__tn_micro_oob:
  - 0.2465875228299529
  - 0.2076550599800472
  - 0.24467932469271605
  - 0.22519356028020154
  - 0.2521147745842545
  train_level7__tn_samples:
  - 0.24718831106411604
  - 0.20972333746988825
  - 0.2451575876416853
  - 0.22575887919380602
  - 0.25355666634624624
  train_level7__tn_samples_masked:
  - 0.2665124452841526
  - 0.22635500005151554
  - 0.2641568461285893
  - 0.24342848415952104
  - 0.27315610057547013
  train_level7__tn_samples_oob:
  - 0.24658752282995283
  - 0.20765505998004719
  - 0.244679324692716
  - 0.2251935602802015
  - 0.25211477458425446
  train_level7__tn_weighted:
  - 0.2769712587062801
  - 0.25410043444003494
  - 0.27970154324352425
  - 0.2654773918594272
  - 0.2776112585485353
  train_level7__tn_weighted_masked:
  - 0.3101909185484371
  - 0.2862463305754537
  - 0.3135285703764575
  - 0.29860965172537746
  - 0.3107077752083547
  train_level7__tn_weighted_oob:
  - 0.27592986688317966
  - 0.2522721100237202
  - 0.2788745249461881
  - 0.26464913744467483
  - 0.27617484944370724
  train_level7__tp_macro:
  - 0.18126982601172742
  - 0.18862690707350904
  - 0.18135731024917504
  - 0.1852033919134816
  - 0.18114966836489474
  train_level7__tp_macro_masked:
  - 0.13180637507169268
  - 0.13829521470263448
  - 0.13209155879664689
  - 0.1360047007651691
  - 0.1325509879125591
  train_level7__tp_macro_oob:
  - 0.18062097471883107
  - 0.188626907073509
  - 0.1811660050695873
  - 0.1844168612510753
  - 0.18129385754109392
  train_level7__tp_micro:
  - 0.1812698260117274
  - 0.18862690707350901
  - 0.181357310249175
  - 0.18520339191348162
  - 0.18114966836489474
  train_level7__tp_micro_masked:
  - 0.12849306561788448
  - 0.13448881663476414
  - 0.12845854888940364
  - 0.13223031105228325
  - 0.12895798841059603
  train_level7__tp_micro_oob:
  - 0.1806209747188311
  - 0.18862690707350901
  - 0.18116600506958727
  - 0.18441686125107534
  - 0.18129385754109392
  train_level7__tp_samples:
  - 0.18126982601172736
  - 0.188626907073509
  - 0.18135731024917495
  - 0.18520339191348156
  - 0.18114966836489474
  train_level7__tp_samples_masked:
  - 0.1287959141011542
  - 0.13496575214935005
  - 0.1288425892591253
  - 0.13258523857882468
  - 0.12934338684097071
  train_level7__tp_samples_oob:
  - 0.18062097471883107
  - 0.18862690707350896
  - 0.18116600506958722
  - 0.1844168612510753
  - 0.18129385754109387
  train_level7__tp_weighted:
  - 0.2401833094102702
  - 0.25334659268690884
  - 0.24412403753273723
  - 0.24936841296706846
  - 0.24315632336429518
  train_level7__tp_weighted_masked:
  - 0.1761227811389397
  - 0.18866923891989018
  - 0.18096333803542222
  - 0.1863145662918499
  - 0.18076088175266566
  train_level7__tp_weighted_oob:
  - 0.2390339327172763
  - 0.2537751465602613
  - 0.24416384190817614
  - 0.24836428361423002
  - 0.24363172399714197
  train_level8__average_precision_macro:
  - 0.370241794769332
  - 0.36198491884952555
  - 0.3612449410190323
  - 0.348190648722115
  - 0.3567036562433018
  train_level8__average_precision_macro_masked:
  - 0.2911736843146101
  - 0.28368672826384017
  - 0.28370049811196796
  - 0.27413458932534746
  - 0.27971812485784486
  train_level8__average_precision_macro_oob:
  - 0.36422406133963503
  - 0.3583731423138701
  - 0.35614209355413895
  - 0.3447366253921925
  - 0.35091923611487913
  train_level8__average_precision_micro:
  - 0.26119095851806057
  - 0.23393937888171917
  - 0.24273705936922127
  - 0.23046582752703365
  - 0.23729184624249625
  train_level8__average_precision_micro_masked:
  - 0.18800184892106087
  - 0.16846289851811086
  - 0.17420656356323433
  - 0.1667572335303217
  - 0.1712072501227917
  train_level8__average_precision_micro_oob:
  - 0.26157062571417267
  - 0.2344177115812941
  - 0.24348877630116328
  - 0.23144742896176168
  - 0.23831438360950413
  train_level8__average_precision_samples:
  - 0.27384261380907876
  - 0.24675779551225038
  - 0.2566612714492928
  - 0.2421448228453269
  - 0.24827002038722165
  train_level8__average_precision_samples_masked:
  - 0.20578211909401375
  - 0.18441456257823366
  - 0.19158369328014888
  - 0.1806408396745787
  - 0.18608207126750537
  train_level8__average_precision_samples_oob:
  - 0.2742233035363048
  - 0.2471379763115987
  - 0.25719364566673303
  - 0.24318908958185906
  - 0.24933835222826622
  train_level8__average_precision_weighted:
  - 0.5029909647801144
  - 0.49947217046932113
  - 0.5032969216356888
  - 0.489740800115465
  - 0.4937723692765907
  train_level8__average_precision_weighted_masked:
  - 0.4086635169214334
  - 0.40595398515309083
  - 0.4108152618218866
  - 0.3999875008192174
  - 0.4028835922740262
  train_level8__average_precision_weighted_oob:
  - 0.4969467127184831
  - 0.49500840588457445
  - 0.4969693156981635
  - 0.48513299085363126
  - 0.48756043261975823
  train_level8__f1_macro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.41133095735529057
  - 0.43441795635874264
  train_level8__f1_macro_masked:
  - 0.40091332234491983
  - 0.3685367415216484
  - 0.3988802048843402
  - 0.3833556323724908
  - 0.4078259001908449
  train_level8__f1_macro_oob:
  - 0.427160434490051
  - 0.39555198676302405
  - 0.42534315366588543
  - 0.41000368686248007
  - 0.4339373257714121
  train_level8__f1_micro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.426084461236788
  - 0.4113309573552906
  - 0.4344179563587427
  train_level8__f1_micro_masked:
  - 0.3945352929000207
  - 0.3604898130424522
  - 0.39178441819164544
  - 0.3756717405691595
  - 0.40159354304635764
  train_level8__f1_micro_oob:
  - 0.4271604344900509
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686248
  - 0.4339373257714121
  train_level8__f1_samples:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.4113309573552906
  - 0.43441795635874264
  train_level8__f1_samples_masked:
  - 0.3952216523286365
  - 0.3613066227841874
  - 0.3924822642335657
  - 0.3762986535792949
  - 0.4022037941610488
  train_level8__f1_samples_oob:
  - 0.42716043449005087
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686247995
  - 0.43393732577141214
  train_level8__f1_weighted:
  - 0.5168301041442761
  - 0.5081179979202229
  - 0.5233915356122394
  - 0.5157172333600852
  - 0.5205006634684087
  train_level8__f1_weighted_masked:
  - 0.4858822433053762
  - 0.4749578014815738
  - 0.4938359194981866
  - 0.48571354924880095
  - 0.4912511252629635
  train_level8__f1_weighted_oob:
  - 0.5147200695993049
  - 0.5055471910100756
  - 0.5227224671613903
  - 0.5133079586058202
  - 0.5203592936613248
  train_level8__fn_macro:
  - -0.05274920695953091
  - -0.047327055502834746
  - -0.050743698885647344
  - -0.049674327147597404
  - -0.05210035566663463
  train_level8__fn_macro_masked:
  - -0.05095572520647163
  - -0.04622961444316668
  - -0.048939968837575044
  - -0.047699397105345646
  - -0.04947955859744598
  train_level8__fn_macro_oob:
  - -0.05337402672306066
  - -0.04727839015013262
  - -0.051030656655028934
  - -0.050583753226004675
  - -0.05178794578486976
  train_level8__fn_micro:
  - -0.052749206959530906
  - -0.04732705550283476
  - -0.05074369888564733
  - -0.0496743271475974
  - -0.052100355666634623
  train_level8__fn_micro_masked:
  - -0.046832953839784724
  - -0.042399769252956444
  - -0.045118781046508634
  - -0.04381204500330907
  - -0.04565914735099338
  train_level8__fn_micro_oob:
  - -0.05337402672306066
  - -0.04727839015013261
  - -0.051030656655028934
  - -0.05058375322600467
  - -0.05178794578486975
  train_level8__fn_samples:
  - -0.05274920695953089
  - -0.04732705550283475
  - -0.05074369888564733
  - -0.0496743271475974
  - -0.05210035566663461
  train_level8__fn_samples_masked:
  - -0.0467524050818384
  - -0.04219369423025688
  - -0.044970384445291986
  - -0.0437027525904821
  - -0.0455051189562455
  train_level8__fn_samples_oob:
  - -0.05337402672306065
  - -0.04727839015013261
  - -0.051030656655028934
  - -0.05058375322600466
  - -0.05178794578486975
  train_level8__fn_weighted:
  - -0.1055261766530599
  - -0.09556906274751567
  - -0.10090510586189148
  - -0.09982650890896617
  - -0.10231269776462182
  train_level8__fn_weighted_masked:
  - -0.10607458471412827
  - -0.0968651906227842
  - -0.1003574317156454
  - -0.09934348071280324
  - -0.10076538339612225
  train_level8__fn_weighted_oob:
  - -0.10649320153746006
  - -0.09509016670229344
  - -0.10100829300076819
  - -0.10109498041272338
  - -0.10161962845769112
  train_level8__fp_macro:
  - -0.5188407190233586
  - -0.5541037058666083
  - -0.5231718398775648
  - -0.538994715497112
  - -0.5134816879746227
  train_level8__fp_macro_masked:
  - -0.5481309524486085
  - -0.585233644035185
  - -0.5521798262780847
  - -0.5689449705221635
  - -0.5426945412117091
  train_level8__fp_macro_oob:
  - -0.5194655387868884
  - -0.5571696230868434
  - -0.5236261896790857
  - -0.5394125599115153
  - -0.5142747284437181
  train_level8__fp_micro:
  - -0.5188407190233586
  - -0.5541037058666083
  - -0.5231718398775647
  - -0.538994715497112
  - -0.5134816879746227
  train_level8__fp_micro_masked:
  - -0.5586317532601945
  - -0.5971104177045914
  - -0.563096800761846
  - -0.5805162144275314
  - -0.5527473096026491
  train_level8__fp_micro_oob:
  - -0.5194655387868884
  - -0.5571696230868434
  - -0.5236261896790856
  - -0.5394125599115153
  - -0.5142747284437181
  train_level8__fp_samples:
  - -0.5188407190233587
  - -0.5541037058666082
  - -0.5231718398775647
  - -0.538994715497112
  - -0.5134816879746227
  train_level8__fp_samples_masked:
  - -0.5580259425895251
  - -0.5964996829855557
  - -0.5625473513211423
  - -0.5799985938302229
  - -0.5522910868827057
  train_level8__fp_samples_oob:
  - -0.5194655387868883
  - -0.5571696230868433
  - -0.5236261896790855
  - -0.5394125599115153
  - -0.5142747284437181
  train_level8__fp_weighted:
  - -0.3776437192026642
  - -0.39631293933226147
  - -0.37570335852586906
  - -0.38445625773094844
  - -0.3771866387669695
  train_level8__fp_weighted_masked:
  - -0.40804317198049544
  - -0.42817700789564206
  - -0.405806648786168
  - -0.4149429700383957
  - -0.4079834913409143
  train_level8__fp_weighted_oob:
  - -0.3787867288632351
  - -0.3993626422876309
  - -0.37626923983784155
  - -0.3855970609814563
  - -0.37802107788098405
  train_level8__jaccard_macro:
  - 0.2924711486586218
  - 0.2736229123542841
  - 0.29481913652225356
  - 0.2814601241276109
  - 0.2978954175567167
  train_level8__jaccard_macro_masked:
  - 0.2699281457473007
  - 0.24966116483806655
  - 0.27264815443248197
  - 0.2587981458246779
  - 0.2762966898971175
  train_level8__jaccard_macro_oob:
  - 0.29132707597004254
  - 0.2713708704072567
  - 0.294359799432275
  - 0.2802024779425961
  - 0.2976374550119565
  train_level8__jaccard_micro:
  - 0.27259660229062493
  - 0.2488832163369496
  - 0.27071621744811447
  - 0.25891544828653207
  - 0.27748016025296635
  train_level8__jaccard_micro_masked:
  - 0.24574522949974215
  - 0.21987653136295301
  - 0.24361436527751104
  - 0.23127821509477012
  - 0.25124619667249304
  train_level8__jaccard_micro_oob:
  - 0.2715855093278736
  - 0.2465346234341351
  - 0.27011799723610075
  - 0.25786455193309527
  - 0.2770880967360781
  train_level8__jaccard_samples:
  - 0.27772346554286237
  - 0.2527406142473282
  - 0.27549793676104734
  - 0.2634017689927578
  - 0.28204414935502875
  train_level8__jaccard_samples_masked:
  - 0.25091190607808683
  - 0.22372222616117843
  - 0.24849700107858796
  - 0.23581025043777826
  - 0.2558719997930173
  train_level8__jaccard_samples_oob:
  - 0.27672413578713667
  - 0.2503118907669359
  - 0.27485181285388727
  - 0.262248563704532
  - 0.2815711974280387
  train_level8__jaccard_weighted:
  - 0.3635362810578282
  - 0.3599771819545089
  - 0.37229297569869335
  - 0.36443270124796107
  - 0.3675318348061538
  train_level8__jaccard_weighted_masked:
  - 0.33585798499097946
  - 0.3303099426987482
  - 0.34573798525967736
  - 0.33728209785340085
  - 0.3416531513849986
  train_level8__jaccard_weighted_oob:
  - 0.3615416107875754
  - 0.35787814996255973
  - 0.3718610885408624
  - 0.36215537350683696
  - 0.36753738862158414
  train_level8__label_ranking_average_precision_score:
  - 0.2738426138090785
  - 0.2467577955122503
  - 0.25666127144929246
  - 0.24214482284532693
  - 0.2482700203872217
  train_level8__label_ranking_average_precision_score_oob:
  - 0.2742233035363048
  - 0.24713797631159853
  - 0.25719364566673303
  - 0.24318908958185886
  - 0.2493383522282661
  train_level8__matthews_corrcoef_macro:
  - 0.18333378564941138
  - 0.1729191352194711
  - 0.18624198124677985
  - 0.17832603175810477
  - 0.18146767675047168
  train_level8__matthews_corrcoef_macro_masked:
  - 0.1439253807346301
  - 0.13711831714571782
  - 0.1468605814470111
  - 0.14273433747409864
  - 0.14310971217703614
  train_level8__matthews_corrcoef_macro_oob:
  - 0.17979287594676696
  - 0.16812599616473667
  - 0.18304576462390795
  - 0.17373392601132456
  - 0.18156252827488165
  train_level8__matthews_corrcoef_micro:
  - 0.08971507986075321
  - 0.07209840242343685
  - 0.09265469687796121
  - 0.079738599526751
  - 0.09815592737591855
  train_level8__matthews_corrcoef_micro_masked:
  - 0.045109796359058575
  - 0.030054418161585154
  - 0.04824507923984849
  - 0.039176372963413676
  - 0.055984718898804194
  train_level8__matthews_corrcoef_micro_oob:
  - 0.08649354925777229
  - 0.06867124157282758
  - 0.09097821222750442
  - 0.07550647111920585
  - 0.09853709128932928
  train_level8__matthews_corrcoef_samples:
  - 0.08420809218649722
  - 0.06497562355742487
  - 0.08661931018965538
  - 0.07444571848352945
  - 0.09339386182339009
  train_level8__matthews_corrcoef_samples_masked:
  - 0.039314042539896024
  - 0.024264753905137576
  - 0.0440487186724187
  - 0.034737869198884344
  - 0.052185874156347525
  train_level8__matthews_corrcoef_samples_oob:
  - 0.0813655143297733
  - 0.06191199564430378
  - 0.08511742928003506
  - 0.07051314901875859
  - 0.09411335507633636
  train_level8__matthews_corrcoef_weighted:
  - 0.21873493209143843
  - 0.22057984196952893
  - 0.23057154704486427
  - 0.22879583650587157
  - 0.22021185399788587
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.16690881299543225
  - 0.17224777625481494
  - 0.1808277682047104
  - 0.18266049535220197
  - 0.17417373206454456
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.21403962108537297
  - 0.21487359965066666
  - 0.2266975218439234
  - 0.2229698017800935
  - 0.22009194815791427
  train_level8__ndcg:
  - 0.6252028649391865
  - 0.6039182107635411
  - 0.6116517804601372
  - 0.6033943596208077
  - 0.6043058330136202
  train_level8__ndcg_oob:
  - 0.6269635324221995
  - 0.6059906385756955
  - 0.6140697523908522
  - 0.605812517159389
  - 0.6069808907267257
  train_level8__neg_coverage_error:
  - -92.60148514851485
  - -93.65664160401002
  - -92.06650246305419
  - -93.53417721518987
  - -91.69059405940594
  train_level8__neg_coverage_error_oob:
  - -93.13613861386139
  - -94.19298245614036
  - -92.61576354679804
  - -94.04303797468354
  - -92.31930693069307
  train_level8__neg_hamming_loss_macro:
  - -0.5715899259828896
  - -0.601430761369443
  - -0.573915538763212
  - -0.5886690426447094
  - -0.5655820436412573
  train_level8__neg_hamming_loss_macro_masked:
  - -0.5990866776550802
  - -0.6314632584783516
  - -0.6011197951156598
  - -0.6166443676275093
  - -0.5921740998091551
  train_level8__neg_hamming_loss_macro_oob:
  - -0.5728395655099491
  - -0.604448013236976
  - -0.5746568463341145
  - -0.58999631313752
  - -0.5660626742285879
  train_level8__neg_hamming_loss_micro:
  - -0.5715899259828896
  - -0.6014307613694431
  - -0.573915538763212
  - -0.5886690426447093
  - -0.5655820436412573
  train_level8__neg_hamming_loss_micro_masked:
  - -0.6054647070999793
  - -0.6395101869575478
  - -0.6082155818083546
  - -0.6243282594308405
  - -0.5984064569536424
  train_level8__neg_hamming_loss_micro_oob:
  - -0.5728395655099491
  - -0.604448013236976
  - -0.5746568463341145
  - -0.58999631313752
  - -0.5660626742285879
  train_level8__neg_hamming_loss_samples:
  - -0.5715899259828896
  - -0.6014307613694431
  - -0.573915538763212
  - -0.5886690426447094
  - -0.5655820436412573
  train_level8__neg_hamming_loss_samples_masked:
  - -0.6047783476713635
  - -0.6386933772158127
  - -0.6075177357664343
  - -0.6237013464207051
  - -0.5977962058389511
  train_level8__neg_hamming_loss_samples_oob:
  - -0.5728395655099491
  - -0.604448013236976
  - -0.5746568463341145
  - -0.58999631313752
  - -0.5660626742285879
  train_level8__neg_hamming_loss_weighted:
  - -0.48316989585572395
  - -0.4918820020797771
  - -0.4766084643877606
  - -0.4842827666399147
  - -0.47949933653159127
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.5141177566946238
  - -0.5250421985184264
  - -0.5061640805018134
  - -0.514286450751199
  - -0.5087488747370364
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.4852799304006951
  - -0.4944528089899243
  - -0.4772775328386097
  - -0.4866920413941798
  - -0.47964070633867517
  train_level8__neg_label_ranking_loss:
  - -0.45825024911193923
  - -0.5064003800893178
  - -0.48589393213059506
  - -0.5173962297380323
  - -0.4973111862571379
  train_level8__neg_label_ranking_loss_oob:
  - -0.4625992223529238
  - -0.5101795735520409
  - -0.4896253399530549
  - -0.5210349916473151
  - -0.5015350644329382
  train_level8__precision_macro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.41133095735529057
  - 0.43441795635874264
  train_level8__precision_macro_masked:
  - 0.40091332234491983
  - 0.3685367415216484
  - 0.3988802048843402
  - 0.3833556323724908
  - 0.4078259001908449
  train_level8__precision_macro_oob:
  - 0.427160434490051
  - 0.39555198676302405
  - 0.42534315366588543
  - 0.41000368686248007
  - 0.4339373257714121
  train_level8__precision_micro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.426084461236788
  - 0.4113309573552906
  - 0.4344179563587427
  train_level8__precision_micro_masked:
  - 0.3945352929000207
  - 0.3604898130424522
  - 0.39178441819164544
  - 0.3756717405691595
  - 0.40159354304635764
  train_level8__precision_micro_oob:
  - 0.4271604344900509
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686248
  - 0.4339373257714121
  train_level8__precision_samples:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.4113309573552906
  - 0.43441795635874264
  train_level8__precision_samples_masked:
  - 0.3952216523286365
  - 0.3613066227841874
  - 0.3924822642335657
  - 0.3762986535792949
  - 0.4022037941610488
  train_level8__precision_samples_oob:
  - 0.42716043449005087
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686247995
  - 0.43393732577141214
  train_level8__precision_weighted:
  - 0.5168301041442761
  - 0.5081179979202229
  - 0.5233915356122394
  - 0.5157172333600852
  - 0.5205006634684087
  train_level8__precision_weighted_masked:
  - 0.4858822433053762
  - 0.4749578014815738
  - 0.4938359194981866
  - 0.48571354924880095
  - 0.4912511252629635
  train_level8__precision_weighted_oob:
  - 0.5147200695993049
  - 0.5055471910100756
  - 0.5227224671613903
  - 0.5133079586058202
  - 0.5203592936613248
  train_level8__recall_macro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.41133095735529057
  - 0.43441795635874264
  train_level8__recall_macro_masked:
  - 0.40091332234491983
  - 0.3685367415216484
  - 0.3988802048843402
  - 0.3833556323724908
  - 0.4078259001908449
  train_level8__recall_macro_oob:
  - 0.427160434490051
  - 0.39555198676302405
  - 0.42534315366588543
  - 0.41000368686248007
  - 0.4339373257714121
  train_level8__recall_micro:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.426084461236788
  - 0.4113309573552906
  - 0.4344179563587427
  train_level8__recall_micro_masked:
  - 0.3945352929000207
  - 0.3604898130424522
  - 0.39178441819164544
  - 0.3756717405691595
  - 0.40159354304635764
  train_level8__recall_micro_oob:
  - 0.4271604344900509
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686248
  - 0.4339373257714121
  train_level8__recall_samples:
  - 0.42841007401711045
  - 0.398569238630557
  - 0.42608446123678795
  - 0.4113309573552906
  - 0.43441795635874264
  train_level8__recall_samples_masked:
  - 0.3952216523286365
  - 0.3613066227841874
  - 0.3924822642335657
  - 0.3762986535792949
  - 0.4022037941610488
  train_level8__recall_samples_oob:
  - 0.42716043449005087
  - 0.39555198676302405
  - 0.4253431536658855
  - 0.41000368686247995
  - 0.43393732577141214
  train_level8__recall_weighted:
  - 0.5168301041442761
  - 0.5081179979202229
  - 0.5233915356122394
  - 0.5157172333600852
  - 0.5205006634684087
  train_level8__recall_weighted_masked:
  - 0.4858822433053762
  - 0.4749578014815738
  - 0.4938359194981866
  - 0.48571354924880095
  - 0.4912511252629635
  train_level8__recall_weighted_oob:
  - 0.5147200695993049
  - 0.5055471910100756
  - 0.5227224671613903
  - 0.5133079586058202
  - 0.5203592936613248
  train_level8__roc_auc_macro:
  - 0.683059856153851
  - 0.6670643886333675
  - 0.6771689046329619
  - 0.6574730676786779
  - 0.6699252430604751
  train_level8__roc_auc_macro_masked:
  - 0.6609962140854975
  - 0.645486020848412
  - 0.6534732029147227
  - 0.6371397903376651
  - 0.6439656238318066
  train_level8__roc_auc_macro_oob:
  - 0.6757727742704747
  - 0.6613056569800222
  - 0.6709086810063083
  - 0.6523800528202279
  - 0.6633668751380272
  train_level8__roc_auc_micro:
  - 0.5745223297469542
  - 0.528508987655377
  - 0.5538063463348294
  - 0.5255175250724285
  - 0.5441016613341327
  train_level8__roc_auc_micro_masked:
  - 0.5497280681055963
  - 0.506509839727852
  - 0.5301813653045002
  - 0.5052951932645642
  - 0.5225376699476347
  train_level8__roc_auc_micro_oob:
  - 0.5722715414423641
  - 0.5269981585853385
  - 0.5524338068494119
  - 0.5249836724159433
  - 0.5433568085430811
  train_level8__roc_auc_samples:
  - 0.5574442694602729
  - 0.5129124675995185
  - 0.5382446320406602
  - 0.5148191662705207
  - 0.5272632214264181
  train_level8__roc_auc_samples_masked:
  - 0.5340292278190617
  - 0.4945133323040756
  - 0.5170734987161042
  - 0.4971333348229257
  - 0.5077495685886501
  train_level8__roc_auc_samples_oob:
  - 0.555066730289455
  - 0.511355555717857
  - 0.5372088022170015
  - 0.5144345747335161
  - 0.5269217497365041
  train_level8__roc_auc_weighted:
  - 0.6869353078428877
  - 0.6841150205933693
  - 0.6930053116955199
  - 0.6796749138773844
  - 0.6799587781553641
  train_level8__roc_auc_weighted_masked:
  - 0.656083935919792
  - 0.6554135005226908
  - 0.6628265553572746
  - 0.6512719536464063
  - 0.6484449345606261
  train_level8__roc_auc_weighted_oob:
  - 0.6792580698431675
  - 0.6768517965609007
  - 0.6848081610738369
  - 0.6726383763189406
  - 0.6719709816343291
  train_level8__tn_macro:
  - 0.24759684706334711
  - 0.20967467211718616
  - 0.24451193266057678
  - 0.2260784072754086
  - 0.2534124771700471
  train_level8__tn_macro_masked:
  - 0.26969478703790606
  - 0.23019908339947814
  - 0.2666366804613025
  - 0.24740854115166544
  - 0.27541850607321416
  train_level8__tn_macro_oob:
  - 0.24697202729981738
  - 0.20660875489695113
  - 0.24405758285905588
  - 0.22566056286100528
  - 0.2526194367009516
  train_level8__tn_micro:
  - 0.24759684706334711
  - 0.20967467211718616
  - 0.24451193266057678
  - 0.22607840727540862
  - 0.2534124771700471
  train_level8__tn_micro_masked:
  - 0.26658559304491825
  - 0.22594855389778956
  - 0.2631714410727614
  - 0.24349437458636664
  - 0.2727907698675497
  train_level8__tn_micro_oob:
  - 0.24697202729981735
  - 0.2066087548969511
  - 0.2440575828590559
  - 0.22566056286100528
  - 0.25261943670095166
  train_level8__tn_samples:
  - 0.24759684706334706
  - 0.20967467211718613
  - 0.24451193266057672
  - 0.22607840727540857
  - 0.25341247717004706
  train_level8__tn_samples_masked:
  - 0.2669643237977178
  - 0.22628739257269906
  - 0.26348309110518553
  - 0.24376820437288862
  - 0.2730153461533187
  train_level8__tn_samples_oob:
  - 0.24697202729981732
  - 0.2066087548969511
  - 0.24405758285905585
  - 0.22566056286100522
  - 0.2526194367009516
  train_level8__tn_weighted:
  - 0.2776280817710334
  - 0.25418588704972156
  - 0.278978472678226
  - 0.26625823420502676
  - 0.27739333469429417
  train_level8__tn_weighted_masked:
  - 0.3109430691604637
  - 0.28637494610677366
  - 0.312752893854226
  - 0.29951800553755736
  - 0.3104758203449706
  train_level8__tn_weighted_oob:
  - 0.2764850721104624
  - 0.251136184094352
  - 0.27841259136625346
  - 0.26511743095451884
  - 0.2765588955802797
  train_level8__tp_macro:
  - 0.18081322695376334
  - 0.1888945665133708
  - 0.18157252857621126
  - 0.18525255007988203
  - 0.18100547918869556
  train_level8__tp_macro_masked:
  - 0.1312185353070139
  - 0.13833765812217025
  - 0.13224352442303766
  - 0.13594709122082532
  - 0.1324073941176306
  train_level8__tp_macro_oob:
  - 0.18018840719023357
  - 0.18894323186607295
  - 0.18128557080682967
  - 0.18434312400147473
  - 0.18131788907046045
  train_level8__tp_micro:
  - 0.18081322695376334
  - 0.1888945665133708
  - 0.1815725285762112
  - 0.18525255007988203
  - 0.18100547918869556
  train_level8__tp_micro_masked:
  - 0.12794969985510246
  - 0.13454125914466267
  - 0.128612977118884
  - 0.13217736598279287
  - 0.12880277317880795
  train_level8__tp_micro_oob:
  - 0.18018840719023357
  - 0.18894323186607295
  - 0.18128557080682958
  - 0.18434312400147473
  - 0.18131788907046045
  train_level8__tp_samples:
  - 0.1808132269537633
  - 0.18889456651337078
  - 0.18157252857621117
  - 0.18525255007988198
  - 0.18100547918869556
  train_level8__tp_samples_masked:
  - 0.1282573285309187
  - 0.1350192302114883
  - 0.12899917312838016
  - 0.1325304492064063
  - 0.1291884480077301
  train_level8__tp_samples_oob:
  - 0.18018840719023355
  - 0.1889432318660729
  - 0.18128557080682955
  - 0.18434312400147468
  - 0.1813178890704604
  train_level8__tp_weighted:
  - 0.23920202237324256
  - 0.2539321108705013
  - 0.2444130629340135
  - 0.24945899915505867
  - 0.2431073287741145
  train_level8__tp_weighted_masked:
  - 0.17493917414491245
  - 0.1885828553748001
  - 0.18108302564396067
  - 0.18619554371124375
  - 0.18077530491799293
  train_level8__tp_weighted_oob:
  - 0.23823499748884244
  - 0.25441100691572355
  - 0.2443098757951368
  - 0.24819052765130148
  - 0.2438003980810452
  train_level9__average_precision_macro:
  - 0.3686790259501058
  - 0.36388392793660973
  - 0.36306675536457444
  - 0.34996566271725205
  - 0.3515254697488712
  train_level9__average_precision_macro_masked:
  - 0.29078732420682984
  - 0.28621246351977087
  - 0.2860199518222967
  - 0.2759382579451756
  - 0.2731653810107262
  train_level9__average_precision_macro_oob:
  - 0.364083159469971
  - 0.3589495848280517
  - 0.35824591960290453
  - 0.3461723277539544
  - 0.34623174361354253
  train_level9__average_precision_micro:
  - 0.2623788651293937
  - 0.235194553168691
  - 0.24179311635264167
  - 0.23183235147460102
  - 0.23855389036159608
  train_level9__average_precision_micro_masked:
  - 0.1891769474063173
  - 0.16948702499304796
  - 0.17389614218453683
  - 0.1677697400876095
  - 0.17153921867321803
  train_level9__average_precision_micro_oob:
  - 0.2630598741914847
  - 0.23561673638347486
  - 0.24276128979165149
  - 0.23336514477837347
  - 0.23897757278946932
  train_level9__average_precision_samples:
  - 0.2751797382744569
  - 0.24769377623249822
  - 0.25595535351988924
  - 0.24366689505509082
  - 0.25016092257553935
  train_level9__average_precision_samples_masked:
  - 0.2070180318715668
  - 0.1853495866778099
  - 0.19124275901465437
  - 0.18179136761192652
  - 0.18685558688246046
  train_level9__average_precision_samples_oob:
  - 0.2758104975391376
  - 0.24814513993881276
  - 0.2570331729979101
  - 0.24505873441647644
  - 0.2505014129746901
  train_level9__average_precision_weighted:
  - 0.5023693222360635
  - 0.5015139254373626
  - 0.504047567948933
  - 0.49089589285004903
  - 0.4888254893943743
  train_level9__average_precision_weighted_masked:
  - 0.4089728650957081
  - 0.40815172185319876
  - 0.41182524151595035
  - 0.40151351971504134
  - 0.3960581875750064
  train_level9__average_precision_weighted_oob:
  - 0.4972875180943839
  - 0.4961069316033992
  - 0.49802899139437484
  - 0.48642815099613385
  - 0.4828506135630072
  train_level9__f1_macro:
  - 0.4279534749591465
  - 0.3990072268048762
  - 0.42675402936534507
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__f1_macro_masked:
  - 0.4003794817733101
  - 0.3691526239488136
  - 0.39972693040241175
  - 0.38334465908291
  - 0.40842494556212366
  train_level9__f1_macro_oob:
  - 0.4264875516677882
  - 0.39674428790422644
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.43350475824281454
  train_level9__f1_micro:
  - 0.4279534749591464
  - 0.39900722680487627
  - 0.42675402936534507
  - 0.41130637827209043
  - 0.43504277612227243
  train_level9__f1_micro_masked:
  - 0.39401780169737116
  - 0.3611191231612345
  - 0.3926595114920341
  - 0.3756717405691595
  - 0.4021885347682119
  train_level9__f1_micro_oob:
  - 0.4264875516677881
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__f1_samples:
  - 0.4279534749591463
  - 0.3990072268048762
  - 0.4267540293653451
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__f1_samples_masked:
  - 0.3947144768267523
  - 0.3619504644256286
  - 0.3933411861881873
  - 0.3762989154215953
  - 0.4027942734139755
  train_level9__f1_samples_oob:
  - 0.42648755166778807
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__f1_weighted:
  - 0.5161088467114024
  - 0.5081696309170124
  - 0.5236503908181194
  - 0.5157082277156652
  - 0.5212945289374298
  train_level9__f1_weighted_masked:
  - 0.48512175847060873
  - 0.47539562079701725
  - 0.49430477890240876
  - 0.48555996252024014
  - 0.4919028859361448
  train_level9__f1_weighted_oob:
  - 0.514350017674882
  - 0.5064249519554965
  - 0.5234475659751184
  - 0.5136438161683101
  - 0.5199071144227825
  train_level9__fn_macro:
  - -0.0528213015476305
  - -0.04757038226634547
  - -0.05112630924482281
  - -0.04972348531399779
  - -0.05229260790156686
  train_level9__fn_macro_masked:
  - -0.05107080256385117
  - -0.04632958141047605
  - -0.049230325637461866
  - -0.04773171664320039
  - -0.04977630353774011
  train_level9__fn_macro_oob:
  - -0.05347015284052678
  - -0.04749738423729226
  - -0.051054569802477405
  - -0.05041169964360329
  - -0.05210035566663463
  train_level9__fn_micro:
  - -0.05282130154763049
  - -0.047570382266345475
  - -0.0511263092448228
  - -0.04972348531399779
  - -0.052292607901566854
  train_level9__fn_micro_masked:
  - -0.04693645208031463
  - -0.042504654272753496
  - -0.04537616142897588
  - -0.04383851753805427
  - -0.04594370860927152
  train_level9__fn_micro_oob:
  - -0.05347015284052677
  - -0.04749738423729226
  - -0.051054569802477405
  - -0.05041169964360329
  - -0.052100355666634623
  train_level9__fn_samples:
  - -0.05282130154763048
  - -0.047570382266345475
  - -0.0511263092448228
  - -0.049723485313997784
  - -0.05229260790156685
  train_level9__fn_samples_masked:
  - -0.0468613145204783
  - -0.04230116194532315
  - -0.045228356845542536
  - -0.04373272523176391
  - -0.04578573690185135
  train_level9__fn_samples_oob:
  - -0.053470152840526766
  - -0.04749738423729226
  - -0.0510545698024774
  - -0.050411699643603286
  - -0.05210035566663463
  train_level9__fn_weighted:
  - -0.10579129988315222
  - -0.09598522470163873
  - -0.10173085650395888
  - -0.09977671299276106
  - -0.1025170970705318
  train_level9__fn_weighted_masked:
  - -0.10634130499591352
  - -0.09690069851574604
  - -0.10109416332214773
  - -0.09945215920618872
  - -0.1012288185359157
  train_level9__fn_weighted_oob:
  - -0.10661952346073171
  - -0.09539970651804626
  - -0.10104125203775584
  - -0.10086109852969612
  - -0.10210038787383892
  train_level9__fp_macro:
  - -0.519225223493223
  - -0.5534223909287782
  - -0.5221196613898322
  - -0.5389701364139118
  - -0.5126646159761606
  train_level9__fp_macro_masked:
  - -0.5485497156628388
  - -0.5845177946407103
  - -0.5510427439601263
  - -0.5689236242738896
  - -0.5417987509001361
  train_level9__fp_macro_oob:
  - -0.520042295491685
  - -0.5557583278584811
  - -0.5230522741403224
  - -0.5396091925771169
  - -0.5143948860905508
  train_level9__fp_micro:
  - -0.5192252234932231
  - -0.5534223909287782
  - -0.5221196613898321
  - -0.5389701364139118
  - -0.5126646159761608
  train_level9__fp_micro_masked:
  - -0.5590457462223142
  - -0.596376222566012
  - -0.56196432707899
  - -0.5804897418927862
  - -0.5518677566225165
  train_level9__fp_micro_oob:
  - -0.5200422954916851
  - -0.5557583278584811
  - -0.5230522741403224
  - -0.5396091925771169
  - -0.5143948860905508
  train_level9__fp_samples:
  - -0.5192252234932231
  - -0.5534223909287783
  - -0.5221196613898321
  - -0.5389701364139118
  - -0.5126646159761608
  train_level9__fp_samples_masked:
  - -0.5584242086527693
  - -0.5957483736290482
  - -0.5614304569662701
  - -0.5799683593466408
  - -0.5514199896841732
  train_level9__fp_samples_oob:
  - -0.520042295491685
  - -0.5557583278584811
  - -0.5230522741403223
  - -0.5396091925771169
  - -0.5143948860905508
  train_level9__fp_weighted:
  - -0.37809985340544555
  - -0.395845144381349
  - -0.3746187526779218
  - -0.3845150592915736
  - -0.37618837399203847
  train_level9__fp_weighted_masked:
  - -0.40853693653347783
  - -0.42770368068723663
  - -0.40460105777544353
  - -0.4149878782735712
  - -0.40686829552793957
  train_level9__fp_weighted_oob:
  - -0.37903045886438635
  - -0.3981753415264573
  - -0.3755111819871257
  - -0.3854950853019937
  - -0.3779924977033786
  train_level9__jaccard_macro:
  - 0.29197044832847746
  - 0.2739053026636101
  - 0.2953205876575934
  - 0.281430176480085
  - 0.29841401359599
  train_level9__jaccard_macro_masked:
  - 0.26938327137501883
  - 0.2500901982001769
  - 0.2733022364736283
  - 0.25878227399030856
  - 0.2767586063087473
  train_level9__jaccard_macro_oob:
  - 0.2907452795558581
  - 0.2722013175574968
  - 0.2948505436644901
  - 0.2802439506860237
  - 0.29720316257771673
  train_level9__jaccard_micro:
  - 0.27222697810933105
  - 0.2492248768922123
  - 0.27125702994376044
  - 0.2588959712853518
  - 0.2779902028531503
  train_level9__jaccard_micro_masked:
  - 0.24534381645936715
  - 0.22034494896163323
  - 0.24429143314651722
  - 0.23127821509477012
  - 0.25171213470412046
  train_level9__jaccard_micro_oob:
  - 0.27104173984758007
  - 0.24746164003096116
  - 0.27056178409746906
  - 0.2578451074354614
  - 0.27673544527115135
  train_level9__jaccard_samples:
  - 0.27739425374418475
  - 0.2530783394637449
  - 0.27600136083570304
  - 0.26335857118167344
  - 0.28252704127201644
  train_level9__jaccard_samples_masked:
  - 0.25055308306449453
  - 0.22419892019249887
  - 0.24912708599735636
  - 0.235780755037749
  - 0.2563084675476313
  train_level9__jaccard_samples_oob:
  - 0.2762103030780557
  - 0.25129326421807185
  - 0.2752731405623222
  - 0.2622502699499242
  - 0.28120079573853035
  train_level9__jaccard_weighted:
  - 0.3627719593202687
  - 0.35992801607075303
  - 0.3724249605610781
  - 0.3644697607337184
  - 0.36829380123038397
  train_level9__jaccard_weighted_masked:
  - 0.33508437496253496
  - 0.3306260742341979
  - 0.346097984798696
  - 0.33719077032990874
  - 0.34224239470794066
  train_level9__jaccard_weighted_oob:
  - 0.36116682193594946
  - 0.358495346754245
  - 0.3725206374943331
  - 0.3625397093768393
  - 0.367038480797429
  train_level9__label_ranking_average_precision_score:
  - 0.2751797382744569
  - 0.247693776232498
  - 0.25595535351988924
  - 0.24366689505509057
  - 0.25016092257553935
  train_level9__label_ranking_average_precision_score_oob:
  - 0.27581049753913783
  - 0.24814513993881282
  - 0.25703317299791
  - 0.24505873441647644
  - 0.25050141297469036
  train_level9__matthews_corrcoef_macro:
  - 0.1832265501706966
  - 0.17294201177421709
  - 0.1865638208092553
  - 0.1777485089921669
  - 0.1814969455014566
  train_level9__matthews_corrcoef_macro_masked:
  - 0.14351056979504567
  - 0.13721863842618712
  - 0.1473223190250807
  - 0.14243248946747603
  - 0.14260086336748326
  train_level9__matthews_corrcoef_macro_oob:
  - 0.1794579434296372
  - 0.16881078029577207
  - 0.1837734761517092
  - 0.17438962908010594
  - 0.1803229612811238
  train_level9__matthews_corrcoef_micro:
  - 0.0889935904592627
  - 0.0718798488663512
  - 0.0922691363031025
  - 0.07956398294146998
  - 0.0982862006138514
  train_level9__matthews_corrcoef_micro_masked:
  - 0.044226194259865605
  - 0.03028224824191649
  - 0.04809425790373482
  - 0.039074672110818824
  - 0.0554701200008473
  train_level9__matthews_corrcoef_micro_oob:
  - 0.08545821844877617
  - 0.06942338853629194
  - 0.09152133096028543
  - 0.0759885673558349
  - 0.09714445204359584
  train_level9__matthews_corrcoef_samples:
  - 0.08336046497355362
  - 0.06477376482782343
  - 0.08611286717366565
  - 0.07448630003897633
  - 0.09374711556042437
  train_level9__matthews_corrcoef_samples_masked:
  - 0.038444431425189954
  - 0.024456249513212805
  - 0.04379626438478284
  - 0.034753225371372876
  - 0.05194887246667856
  train_level9__matthews_corrcoef_samples_oob:
  - 0.07999456722346768
  - 0.06291071532587683
  - 0.08544837033500634
  - 0.07109652276372022
  - 0.09266131530942681
  train_level9__matthews_corrcoef_weighted:
  - 0.21798923345422047
  - 0.21979484612690578
  - 0.23081388200725328
  - 0.22852635761737242
  - 0.22073783035170624
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.16598055159689976
  - 0.171857277840757
  - 0.18124770877170698
  - 0.18271032107531493
  - 0.17392428417104294
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.21362594466795398
  - 0.21542111260313704
  - 0.22796943299324182
  - 0.22354599369269165
  - 0.21964267787791283
  train_level9__ndcg:
  - 0.6278537868195304
  - 0.6052479756227946
  - 0.6105174621002589
  - 0.603680968584274
  - 0.6074837062516729
  train_level9__ndcg_oob:
  - 0.6296408191256561
  - 0.6072649336730956
  - 0.6131964567294135
  - 0.6073825602319233
  - 0.6092522827195087
  train_level9__neg_coverage_error:
  - -92.66336633663366
  - -93.531328320802
  - -92.01477832512315
  - -93.5620253164557
  - -91.54702970297029
  train_level9__neg_coverage_error_oob:
  - -93.1559405940594
  - -94.08771929824562
  - -92.55172413793103
  - -94.06075949367089
  - -92.16584158415841
  train_level9__neg_hamming_loss_macro:
  - -0.5720465250408535
  - -0.6009927731951238
  - -0.5732459706346549
  - -0.5886936217279096
  - -0.5649572238777275
  train_level9__neg_hamming_loss_macro_masked:
  - -0.5996205182266899
  - -0.6308473760511863
  - -0.6002730695975883
  - -0.6166553409170901
  - -0.5915750544378763
  train_level9__neg_hamming_loss_macro_oob:
  - -0.5735124483322119
  - -0.6032557120957734
  - -0.5741068439427998
  - -0.5900208922207202
  - -0.5664952417571855
  train_level9__neg_hamming_loss_micro:
  - -0.5720465250408536
  - -0.6009927731951238
  - -0.5732459706346549
  - -0.5886936217279095
  - -0.5649572238777276
  train_level9__neg_hamming_loss_micro_masked:
  - -0.6059821983026289
  - -0.6388808768387655
  - -0.607340488507966
  - -0.6243282594308405
  - -0.5978114652317881
  train_level9__neg_hamming_loss_micro_oob:
  - -0.5735124483322118
  - -0.6032557120957734
  - -0.5741068439427998
  - -0.5900208922207202
  - -0.5664952417571855
  train_level9__neg_hamming_loss_samples:
  - -0.5720465250408536
  - -0.6009927731951237
  - -0.5732459706346549
  - -0.5886936217279095
  - -0.5649572238777276
  train_level9__neg_hamming_loss_samples_masked:
  - -0.6052855231732477
  - -0.6380495355743715
  - -0.6066588138118126
  - -0.6237010845784047
  - -0.5972057265860246
  train_level9__neg_hamming_loss_samples_oob:
  - -0.5735124483322118
  - -0.6032557120957734
  - -0.5741068439427998
  - -0.5900208922207202
  - -0.5664952417571855
  train_level9__neg_hamming_loss_weighted:
  - -0.48389115328859755
  - -0.49183036908298755
  - -0.4763496091818807
  - -0.4842917722843348
  - -0.47870547106257016
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.5148782415293912
  - -0.5246043792029826
  - -0.5056952210975914
  - -0.5144400374797599
  - -0.5080971140638552
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.48564998232511797
  - -0.49357504804450353
  - -0.47655243402488157
  - -0.4863561838316899
  - -0.4800928855772176
  train_level9__neg_label_ranking_loss:
  - -0.4585873077165843
  - -0.506145170262764
  - -0.4847269688977285
  - -0.518179336109714
  - -0.4982481690295547
  train_level9__neg_label_ranking_loss_oob:
  - -0.4631388026797612
  - -0.5096948504260504
  - -0.4884702802905173
  - -0.5214518429615996
  - -0.5022535030246221
  train_level9__precision_macro:
  - 0.4279534749591465
  - 0.3990072268048762
  - 0.42675402936534507
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__precision_macro_masked:
  - 0.4003794817733101
  - 0.3691526239488136
  - 0.39972693040241175
  - 0.38334465908291
  - 0.40842494556212366
  train_level9__precision_macro_oob:
  - 0.4264875516677882
  - 0.39674428790422644
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.43350475824281454
  train_level9__precision_micro:
  - 0.4279534749591464
  - 0.39900722680487627
  - 0.42675402936534507
  - 0.41130637827209043
  - 0.43504277612227243
  train_level9__precision_micro_masked:
  - 0.39401780169737116
  - 0.3611191231612345
  - 0.3926595114920341
  - 0.3756717405691595
  - 0.4021885347682119
  train_level9__precision_micro_oob:
  - 0.4264875516677881
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__precision_samples:
  - 0.4279534749591463
  - 0.3990072268048762
  - 0.4267540293653451
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__precision_samples_masked:
  - 0.3947144768267523
  - 0.3619504644256286
  - 0.3933411861881873
  - 0.3762989154215953
  - 0.4027942734139755
  train_level9__precision_samples_oob:
  - 0.42648755166778807
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__precision_weighted:
  - 0.5161088467114024
  - 0.5081696309170124
  - 0.5236503908181194
  - 0.5157082277156652
  - 0.5212945289374298
  train_level9__precision_weighted_masked:
  - 0.48512175847060873
  - 0.47539562079701725
  - 0.49430477890240876
  - 0.48555996252024014
  - 0.4919028859361448
  train_level9__precision_weighted_oob:
  - 0.514350017674882
  - 0.5064249519554965
  - 0.5234475659751184
  - 0.5136438161683101
  - 0.5199071144227825
  train_level9__recall_macro:
  - 0.4279534749591465
  - 0.3990072268048762
  - 0.42675402936534507
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__recall_macro_masked:
  - 0.4003794817733101
  - 0.3691526239488136
  - 0.39972693040241175
  - 0.38334465908291
  - 0.40842494556212366
  train_level9__recall_macro_oob:
  - 0.4264875516677882
  - 0.39674428790422644
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.43350475824281454
  train_level9__recall_micro:
  - 0.4279534749591464
  - 0.39900722680487627
  - 0.42675402936534507
  - 0.41130637827209043
  - 0.43504277612227243
  train_level9__recall_micro_masked:
  - 0.39401780169737116
  - 0.3611191231612345
  - 0.3926595114920341
  - 0.3756717405691595
  - 0.4021885347682119
  train_level9__recall_micro_oob:
  - 0.4264875516677881
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__recall_samples:
  - 0.4279534749591463
  - 0.3990072268048762
  - 0.4267540293653451
  - 0.4113063782720904
  - 0.43504277612227243
  train_level9__recall_samples_masked:
  - 0.3947144768267523
  - 0.3619504644256286
  - 0.3933411861881873
  - 0.3762989154215953
  - 0.4027942734139755
  train_level9__recall_samples_oob:
  - 0.42648755166778807
  - 0.3967442879042266
  - 0.42589315605720024
  - 0.4099791077792798
  - 0.4335047582428146
  train_level9__recall_weighted:
  - 0.5161088467114024
  - 0.5081696309170124
  - 0.5236503908181194
  - 0.5157082277156652
  - 0.5212945289374298
  train_level9__recall_weighted_masked:
  - 0.48512175847060873
  - 0.47539562079701725
  - 0.49430477890240876
  - 0.48555996252024014
  - 0.4919028859361448
  train_level9__recall_weighted_oob:
  - 0.514350017674882
  - 0.5064249519554965
  - 0.5234475659751184
  - 0.5136438161683101
  - 0.5199071144227825
  train_level9__roc_auc_macro:
  - 0.6821010585446133
  - 0.6678164496157444
  - 0.6778716384780379
  - 0.6578657566189038
  - 0.6677389855023669
  train_level9__roc_auc_macro_masked:
  - 0.6604869060259978
  - 0.6461497389742161
  - 0.6544031262663305
  - 0.6376383857215133
  - 0.6410496932446286
  train_level9__roc_auc_macro_oob:
  - 0.6750805273895417
  - 0.6617387962397198
  - 0.6712971822722609
  - 0.6527531004036996
  - 0.6616930384668133
  train_level9__roc_auc_micro:
  - 0.5752304914041355
  - 0.5297345835882685
  - 0.5534219925702667
  - 0.5270759822399822
  - 0.5452666401547555
  train_level9__roc_auc_micro_masked:
  - 0.5506546628909958
  - 0.5078864008385662
  - 0.5302303626867687
  - 0.5068238768297434
  - 0.5228731514816695
  train_level9__roc_auc_micro_oob:
  - 0.5730628600526131
  - 0.5282327708618239
  - 0.552236771538035
  - 0.5271133925125528
  - 0.5440296527434982
  train_level9__roc_auc_samples:
  - 0.5585931406136112
  - 0.5138306615205787
  - 0.5381739124049881
  - 0.5153703007542214
  - 0.5295252438977461
  train_level9__roc_auc_samples_masked:
  - 0.5353266033707647
  - 0.4957552521331906
  - 0.5175309868671877
  - 0.49768130636404384
  - 0.5092741392476822
  train_level9__roc_auc_samples_oob:
  - 0.556298718726759
  - 0.5125277607693953
  - 0.537201739284325
  - 0.5160516106587472
  - 0.5286094846779518
  train_level9__roc_auc_weighted:
  - 0.6866097551918496
  - 0.6850815758475785
  - 0.6936448303331186
  - 0.6799783602764192
  - 0.6785216549809745
  train_level9__roc_auc_weighted_masked:
  - 0.6560694194702065
  - 0.6563764853420629
  - 0.6636041179459867
  - 0.6517968877148281
  - 0.6466278297353091
  train_level9__roc_auc_weighted_oob:
  - 0.6791323520213123
  - 0.6776816897585161
  - 0.685340420698961
  - 0.6728231518460385
  - 0.6702946115730621
  train_level9__tn_macro:
  - 0.24721234259348265
  - 0.21035598705501615
  - 0.24556411114830934
  - 0.22610298635860884
  - 0.2542295491685091
  train_level9__tn_macro_masked:
  - 0.2692760238236757
  - 0.23091493279395275
  - 0.2677737627792609
  - 0.24742988739993932
  - 0.27631429638478716
  train_level9__tn_macro_oob:
  - 0.24639527059502062
  - 0.20802005012531324
  - 0.24463149839781909
  - 0.22546393019540373
  - 0.252499279054119
  train_level9__tn_micro:
  - 0.24721234259348265
  - 0.21035598705501618
  - 0.24556411114830934
  - 0.22610298635860882
  - 0.2542295491685091
  train_level9__tn_micro_masked:
  - 0.2661716000827986
  - 0.22668274903636887
  - 0.2643039147556173
  - 0.24352084712111186
  - 0.2736703228476821
  train_level9__tn_micro_oob:
  - 0.24639527059502067
  - 0.20802005012531327
  - 0.2446314983978191
  - 0.2254639301954037
  - 0.252499279054119
  train_level9__tn_samples:
  - 0.2472123425934826
  - 0.21035598705501615
  - 0.24556411114830928
  - 0.22610298635860876
  - 0.25422954916850904
  train_level9__tn_samples_masked:
  - 0.2665660577344735
  - 0.22703870192920658
  - 0.2645999854600577
  - 0.2437984388564708
  - 0.2738864433518512
  train_level9__tn_samples_oob:
  - 0.24639527059502062
  - 0.20802005012531327
  - 0.24463149839781903
  - 0.22546393019540364
  - 0.25249927905411895
  train_level9__tn_weighted:
  - 0.2771719475682519
  - 0.25465368200063404
  - 0.28006307852617324
  - 0.26619943264440155
  - 0.2783915994692253
  train_level9__tn_weighted_masked:
  - 0.3104493046074814
  - 0.2868482733151791
  - 0.3139584848649504
  - 0.29947309730238186
  - 0.3115910161579453
  train_level9__tn_weighted_oob:
  - 0.2762413421093112
  - 0.2523234848555257
  - 0.2791706492169693
  - 0.26521940663398147
  - 0.27658747575788506
  train_level9__tp_macro:
  - 0.18074113236566375
  - 0.18865123974986006
  - 0.18118991821703578
  - 0.1852033919134816
  - 0.18081322695376334
  train_level9__tp_macro_masked:
  - 0.13110345794963438
  - 0.1382376911548609
  - 0.13195316762315082
  - 0.13591477168297056
  - 0.1321106491773365
  train_level9__tp_macro_oob:
  - 0.18009228107276742
  - 0.18872423777891328
  - 0.18126165765938115
  - 0.1845151775838761
  - 0.18100547918869556
  train_level9__tp_micro:
  - 0.18074113236566375
  - 0.1886512397498601
  - 0.18118991821703573
  - 0.18520339191348162
  - 0.18081322695376334
  train_level9__tp_micro_masked:
  - 0.12784620161457255
  - 0.13443637412486562
  - 0.12835559673641675
  - 0.13215089344804765
  - 0.1285182119205298
  train_level9__tp_micro_oob:
  - 0.18009228107276748
  - 0.1887242377789133
  - 0.18126165765938113
  - 0.18451517758387612
  - 0.18100547918869556
  train_level9__tp_samples:
  - 0.1807411323656637
  - 0.18865123974986003
  - 0.18118991821703573
  - 0.18520339191348156
  - 0.1808132269537633
  train_level9__tp_samples_masked:
  - 0.1281484190922788
  - 0.134911762496422
  - 0.12874120072812964
  - 0.1325004765651245
  - 0.12890783006212428
  train_level9__tp_samples_oob:
  - 0.18009228107276742
  - 0.18872423777891323
  - 0.1812616576593811
  - 0.1845151775838761
  - 0.18100547918869556
  train_level9__tp_weighted:
  - 0.23893689914315028
  - 0.2535159489163783
  - 0.2435873122919461
  - 0.2495087950712638
  - 0.24290292946820452
  train_level9__tp_weighted_masked:
  - 0.1746724538631272
  - 0.1885473474818383
  - 0.1803462940374583
  - 0.1860868652178583
  - 0.1803118697781995
  train_level9__tp_weighted_oob:
  - 0.23810867556557078
  - 0.2541014670999707
  - 0.24427691675814914
  - 0.24842440953432876
  - 0.2433196386648974
start: 2023-12-31 13:39:27.525000
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
