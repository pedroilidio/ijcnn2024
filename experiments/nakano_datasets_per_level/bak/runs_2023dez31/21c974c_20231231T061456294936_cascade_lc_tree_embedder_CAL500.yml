active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            YGZmZmZm9r9AMzMzMzPjP4CZmZmZmdm/QDMzMzMz4z9AMzMzMzPjPw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb/AmZmZmZnpPwCZmZmZmcm/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87+YmZmZmZkJwICZmZmZmcm/aGZmZmZmDkCgmZmZmZnpPw==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+gmZmZmZnpPzAzMzMzM/O/oJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT+AmZmZmZnpvwCamZmZmck/AJqZmZmZyT8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8CgmZmZmZn5PzAzMzMzMwPAoJmZmZmZ+T+gmZmZmZn5Pw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb/MzMzMzMwcwDQzMzMzMxtAoJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+gmZmZmZnpP5iZmZmZmQHAoJmZmZmZ6T+gmZmZmZnpPw==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzA0CQmZmZmZn5v5yZmZmZmRFAkJmZmZmZ+b/IzMzMzMwMwA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMDMBkZmZmZmYSwJyZmZmZmRlAwJmZmZmZ2T9wZmZmZmb2Pw==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAQwAAAAAAAACRAAAAAAAAAEMAAAAAAAAAAwA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPw==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z8wMzMzMzMDwNDMzMzMzARAMDMzMzMzA8CgmZmZmZn5Pw==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzA0DIzMzMzMwEwCAzMzMzM+O/ODMzMzMzC0DIzMzMzMwEwA==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ2T/IzMzMzMwEwMjMzMzMzATAODMzMzMzC0BwZmZmZmb2Pw==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAcwAAAAAAAABRAAAAAAAAAEEAAAAAAAAAAAA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIMAAAAAAAADwvwAAAAAAACRAAAAAAAAAAMAAAAAAAADwPw==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb9oZmZmZmYGQMzMzMzMzBTAaGZmZmZmBkCAmZmZmZnJvw==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ6b8wMzMzMzMXwICZmZmZmem/0MzMzMzMFECgmZmZmZkBQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmEsBwZmZmZmb2PzgzMzMzMwNAODMzMzMzA0CQmZmZmZn5vw==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMDMCgmZmZmZn5v8zMzMzMzCJAoJmZmZmZ+b/QzMzMzMwEwA==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmBsCcmZmZmZkJQDgzMzMzM/M/yMzMzMzM/L/AmZmZmZnJPw==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAgwAAAAAAAAABAAAAAAAAAHEAAAAAAAADwvw==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D/gzMzMzMz8PyAzMzMzM/O/yMzMzMzMEMDgzMzMzMz8Pw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+YmZmZmZn5vzQzMzMzMwtANDMzMzMzC0DMzMzMzMwMwA==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAcwAAAAAAAABBAAAAAAAAAFEAAAAAAAAAUwA==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZEcBAMzMzMzPjP2hmZmZmZhZAMDMzMzMzC8CgmZmZmZn5Pw==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAYwAAAAAAAAPC/AAAAAAAAEEAAAAAAAAAAAA==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAQwAAAAAAAAPC/AAAAAAAAAEAAAAAAAAAAQA==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z+YmZmZmZkVwEAzMzMzM+M/YGZmZmZm9r9oZmZmZmYWQA==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz8z+YmZmZmZklwGhmZmZmZiBA0MzMzMzMEEBgZmZmZmYGwA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcBoZmZmZmYOQDAzMzMzM/O/mJmZmZmZCcBoZmZmZmYOQA==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUAwMzMzMzMfwNDMzMzMzBxAYGZmZmZmBsAAmpmZmZnJPw==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAUQAAAAAAAAPC/AAAAAAAACMAAAAAAAAAAAA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb/IzMzMzMwYwDgzMzMzMx9AwJmZmZmZ6T+QmZmZmZkBwA==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAHEAAAAAAAAAUwAAAAAAAAPA/AAAAAAAAAAAAAAAAAAAIwA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAIwAAAAAAAABBAAAAAAAAAAEAAAAAAAAAIwA==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsBoZmZmZmb2P2hmZmZmZvY/NDMzMzMzA0AwMzMzMzPjvw==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8CgmZmZmZn5P9DMzMzMzAxAMDMzMzMzA8CAmZmZmZnZvw==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZm9r8yMzMzMzMDwDIzMzMzMwvAnJmZmZmZ+T9nZmZmZmYWQA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzM/L+cmZmZmZkBQJyZmZmZmQlAkJmZmZmZ6b9kZmZmZmYGwA==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAAQAAAAAAAAAjAAAAAAAAACMAAAAAAAAAAQA==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0DMzMzMzMwEwMzMzMzMzATAaGZmZmZm9j+gmZmZmZnZPw==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz478wMzMzMzPjvzAzMzMzM+O/oJmZmZmZ2T9oZmZmZmb2Pw==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZyT80MzMzMzPzPzQzMzMzM/M/zMzMzMzM/L+YmZmZmZnpvw==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZAUCYmZmZmZklwNDMzMzMzBRA0MzMzMzMHEBgZmZmZmYOwA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8DQzMzMzMwEQJiZmZmZmRHAoJmZmZmZ+T/QzMzMzMwMQA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T80MzMzMzMDQDAzMzMzM+O/MDMzMzMz47+YmZmZmZn5vw==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r+YmZmZmZkRwNDMzMzMzARAoJmZmZmZ+T+gmZmZmZn5Pw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcDIzMzMzMwcwJCZmZmZmQHAODMzMzMzG0A4MzMzMzMTQA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb80MzMzMzMTQNDMzMzMzPw/zMzMzMzMEMCYmZmZmZkBwA==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAkwAAAAAAAAABAAAAAAAAAAEAAAAAAAAAIQA==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkCYmZmZmZkBwDQzMzMzMxtAMDMzMzMz87/MzMzMzMwcwA==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAUwAAAAAAAAAhAAAAAAAAAAEAAAAAAAADwPw==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAAwAAAAAAAABBAAAAAAAAACMAAAAAAAADwvw==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyb8AmpmZmZnJv4CZmZmZmek/AJqZmZmZyb8AmpmZmZnJvw==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcCAmZmZmZnJv2hmZmZmZgZAMDMzMzMz87/QzMzMzMz8Pw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b9oZmZmZmb2P6CZmZmZmdk/oJmZmZmZ2T8wMzMzMzPjvw==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMGMA0MzMzMzMTQDQzMzMzMxNAoJmZmZmZ6T/MzMzMzMwQwA==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+AmZmZmZnJv4CZmZmZmcm/oJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIkAAAAAAAAAkwAAAAAAAAAjAAAAAAAAAFEAAAAAAAADwvw==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBsDQzMzMzMz8v5iZmZmZmQFAMDMzMzMz8z8wMzMzMzPzPw==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzM/L+YmZmZmZnpv5qZmZmZmQlANDMzMzMz8z/MzMzMzMz8vw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAIQAAAAAAAABDAAAAAAAAAHMAAAAAAAAAIQA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAQwAAAAAAAABBAAAAAAAAAAMAAAAAAAAAAAA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAADwPwAAAAAAAADAAAAAAAAAAEAAAAAAAADwvw==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAAwAAAAAAAAPA/AAAAAAAAAAAAAAAAAAAAwA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzA0AgMzMzMzPjv2RmZmZmZhLAwJmZmZmZ2T84MzMzMzMDQA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmDsBgZmZmZmYOwGhmZmZmZiBAoJmZmZmZCUBgZmZmZmYOwA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmEkAwMzMzMzMLwDAzMzMzMwPAYGZmZmZm9r/QzMzMzMwEQA==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T+QmZmZmZkBwMCZmZmZmek/wJmZmZmZ6T8AmZmZmZnJvw==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAADwvwAAAAAAAAhAAAAAAAAA8L8AAAAAAAAAQA==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZEUBoZmZmZmYSwJiZmZmZmRVAmJmZmZmZFUA0MzMzMzMlwA==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZGcBAMzMzMzPjP2hmZmZmZhpAgJmZmZmZ2b+AmZmZmZnZvw==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ+b9gZmZmZmYSwKCZmZmZmRFAoJmZmZmZEUDAzMzMzMwEwA==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkCYmZmZmZkBwGhmZmZmZgZAoJmZmZmZ6T/MzMzMzMwUwA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcAwMzMzMzPzv2hmZmZmZg5AoJmZmZmZ6T8wMzMzMzPzvw==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZAcCAmZmZmZkJwEAzMzMzMx9AgJmZmZmZCcAAmpmZmZnpPw==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z+AmZmZmZnZv9DMzMzMzAxAYGZmZmZm9r8wMzMzMzMDwA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUAwMzMzMzMbwGhmZmZmZihAQDMzMzMz8z+YmZmZmZkjwA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAIQAAAAAAAACBAAAAAAAAAFMAAAAAAAAAIwA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZm9j+QmZmZmZn5v8CZmZmZmdk/IDMzMzMz47/AmZmZmZnZPw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcCAmZmZmZnJvzQzMzMzMxdAaGZmZmZmBkDMzMzMzMwYwA==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T8wMzMzMzMDwNDMzMzMzARAMDMzMzMzA8BAMzMzMzPjPw==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L+AmZmZmZnpv0AzMzMzM/M/gJmZmZmZ6b+gmZmZmZkBQA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZFUCYmZmZmZn5vzAzMzMzM+O/MDMzMzMz47/MzMzMzMwEwA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC8CYmZmZmZn5P2ZmZmZmZhJAmpmZmZmZFcDMzMzMzMwEQA==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMEEDQzMzMzMwUQGBmZmZmZgbAgJmZmZmZ6b8wMzMzMzMXwA==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzM/L+QmZmZmZnpv5yZmZmZmQFAyMzMzMzM/L+cmZmZmZkBQA==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87+YmZmZmZkJwKCZmZmZmek/aGZmZmZmBkCgmZmZmZnpPw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MjMzMzMzC8A4MzMzMzPjP87MzMzMzARAzszMzMzMBEAyMzMzMzMDwA==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+YmZmZmZn5vzAzMzMzM+O/mpmZmZmZEUAwMzMzMzPjvw==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAIQAAAAAAAAABAAAAAAAAA8L8AAAAAAAAUwA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwPwAAAAAAAAAAAAAAAAAA8L8AAAAAAAAAQA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAADwvwAAAAAAAAAAAAAAAAAACEAAAAAAAADwvw==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0CgmZmZmZnZPzAzMzMzM+O/NDMzMzMzC0BmZmZmZmYWwA==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T80MzMzMzMDQDAzMzMzM+O/oJmZmZmZ2T/MzMzMzMwEwA==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz478wMzMzMzPjvzQzMzMzMwNAoJmZmZmZ2T+YmZmZmZn5vw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMAwMzMzMzPjvzQzMzMzMwNAaGZmZmZm9j8wMzMzMzPjvw==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAIQAAAAAAAAABAAAAAAAAAEMAAAAAAAAAAAA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwEwKCZmZmZmdk/NDMzMzMzA0AwMzMzMzPjvw==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmBsCgmZmZmZnJP5qZmZmZmQlAmpmZmZmZCUBmZmZmZmYOwA==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAAAAAAAAAAPC/AAAAAAAA8L8AAAAAAAAQQA==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          QDMzMzMzC0BgZmZmZmYawNDMzMzMzCBAwMzMzMzMDMCAmZmZmZn5vw==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 06:20:20.052361
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - xt_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - xt
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.ExtraTreesRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.8
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    - - rf_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - rf
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.RandomForestRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.95
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_tree_embedder
  params: {}
hash: 21c974c100c4496e013d65ef8eb623f64756304ee7b5957d54f7000bd11a74d7
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/21c974c_20231231T061456294936_cascade_lc_tree_embedder_CAL500.yml
results:
  fit_time:
  - 306.02091002464294
  - 302.42411637306213
  - 314.8074185848236
  - 309.93228912353516
  - 309.05761075019836
  fitted_params:
    estimator.level1.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 203
    - 198
    - 206
    - 201
    - 200
    estimator.level1.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 201
    - 198
    - 206
    - 199
    - 198
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level10.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 216
    - 209
    - 213
    - 215
    - 220
    estimator.level10.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 229
    - 237
    - 227
    - 229
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level2.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 213
    - 208
    - 214
    - 213
    - 218
    estimator.level2.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 230
    - 225
    - 234
    - 224
    - 228
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level3.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 217
    - 210
    - 218
    - 215
    - 223
    estimator.level3.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 227
    - 238
    - 226
    - 229
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level4.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 209
    - 215
    - 215
    - 222
    estimator.level4.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 228
    - 238
    - 227
    - 231
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level5.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 214
    - 208
    - 214
    - 214
    - 222
    estimator.level5.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 228
    - 237
    - 227
    - 231
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level6.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 209
    - 217
    - 216
    - 221
    estimator.level6.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 232
    - 228
    - 238
    - 227
    - 230
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level7.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 216
    - 209
    - 214
    - 215
    - 219
    estimator.level7.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 228
    - 239
    - 225
    - 230
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level8.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 210
    - 216
    - 214
    - 218
    estimator.level8.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 233
    - 227
    - 237
    - 227
    - 230
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
    estimator.level9.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 209
    - 216
    - 214
    - 218
    estimator.level9.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 234
    - 228
    - 237
    - 226
    - 229
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.04424907957211327
      - 0.3157490137011605
      - 0.1563609340395054
      - 0.10073664912817695
      - 0.28950790046150865
      - 0.14578254104766203
      - 0.15491331378608164
      - 0.1049462388096778
      - 0.14341857734656643
      - 0.10663688163688163
      - 0.1772871269793618
      - 0.15243625327655694
      - 0.06992654739901594
      - 0.12007250702478794
      - 0.14682863432863427
      - 0.13619007126660188
      - 0.12159086600820765
      - 0.10818076629980128
      - 0.15944901247742155
      - 0.08698307078409118
      - 0.17913924137328385
      - 0.07048215244091532
      - 0.22587518387784147
      - 0.18002954799829793
      - 0.06191836884008354
      - 0.12428972936785433
      - 0.11033755806483075
      - 0.16208272144639485
      - 0.06274265299758723
      - 0.053346302032091224
      - 0.21664922277035675
      - 0.09788356058517347
      - 0.20688226227748285
      - 0.07968109074001961
      - 0.22700024399526697
      - 0.10459305733030792
      - 0.09275885548255249
      - 0.02955871121631991
      - 0.04666050176531543
      - 0.028320105820105818
      - 0.04953736305174494
      - 0.025323704073704073
      - 0.038421225364294674
      - 0.0709860755041478
      - 0.04031852566335324
      - 0.14649311282337496
      - 0.051550386590514474
      - 0.027268809621750795
      - 0.1500989606458356
      - 0.156882588293692
      - 0.04608920032058905
      - 0.28436264206130796
      - 0.12815280142546273
      - 0.06940189236145117
      - 0.09109432234432234
      - 0.3351227883543224
      - 0.0726686519399672
      - 0.02781009056148289
      - 0.0299093443032837
      - 0.0937585884776896
      - 0.17414471096536313
      - 0.08005776152327876
      - 0.032329402384347436
      - 0.2058446705624125
      - 0.13150758385133388
      - 0.13705018231637106
      - 0.13226767282582222
      - 0.1127840276030321
      - 0.23657094091545305
      - 0.09980455587456345
      - 0.1674341146038955
      - 0.04916288421723205
      - 0.1692020895770895
      - 0.06460125253729904
      - 0.28238023912660914
      - 0.08876988084678647
      - 0.09159525931584755
      - 0.43922139688268713
      - 0.26762774616554086
      - 0.3292386423046477
      - 0.15831705794205791
      - 0.09094391271810627
      - 0.037855815270588
      - 0.07069107042838209
      - 0.24280982713921723
      - 0.06513583341394587
      - 0.03258872101334648
      - 0.1450475015180897
      - 0.05553469634312987
      - 0.029571711501059326
      - 0.022885225307100306
      - 0.034694770444864145
      - 0.03532026548330896
      - 0.0939845484943524
      - 0.03664358509825543
      - 0.07460446898731828
      - 0.053123414284128576
      - 0.03678928032376308
      - 0.04270246222031937
      - 0.03416053641798554
      - 0.034735013630508
      - 0.03379983470344917
      - 0.033667482457805036
    - - 0.05378519912920114
      - 0.3264459278401488
      - 0.1507909625097125
      - 0.10243526650114718
      - 0.29386656974648684
      - 0.1600489668806492
      - 0.15441117956869993
      - 0.11304960795694108
      - 0.15139450518861697
      - 0.10525000408088639
      - 0.17803685010508613
      - 0.16405960111317253
      - 0.06935367595823902
      - 0.11779711856062025
      - 0.141781475063952
      - 0.13122975064151532
      - 0.1397831561910672
      - 0.11299075635013132
      - 0.1680202653712532
      - 0.09573407326633618
      - 0.18571471624780445
      - 0.07980181636351713
      - 0.22359429677009723
      - 0.18681937835163637
      - 0.067141019038821
      - 0.11519560135631562
      - 0.12473661085610227
      - 0.1578376288281948
      - 0.05862302619548996
      - 0.04806461945016161
      - 0.20485054555197213
      - 0.10873045732249026
      - 0.20576792488557194
      - 0.08609553844847961
      - 0.21086437716872497
      - 0.09518406714020496
      - 0.08932592844109696
      - 0.040659272491601804
      - 0.04333769263616202
      - 0.030390681965152086
      - 0.05953918319516084
      - 0.036268439163176
      - 0.02394356597755721
      - 0.07350817962231007
      - 0.03642814830933643
      - 0.12829389325601445
      - 0.06204486689780806
      - 0.03322347934362953
      - 0.14845758277362045
      - 0.16123031322787126
      - 0.054838767503160066
      - 0.26760161839892527
      - 0.11773634861870153
      - 0.06147074926775722
      - 0.08792109090404546
      - 0.34141133070486684
      - 0.0807402781009109
      - 0.03680073784240451
      - 0.04726127735491032
      - 0.09833528846625125
      - 0.15668897829223913
      - 0.0747691788569892
      - 0.03457596275125213
      - 0.21139642557162247
      - 0.12768784539751132
      - 0.14218015544546153
      - 0.12980703585542291
      - 0.1082504167840706
      - 0.237968538951685
      - 0.09260108355696592
      - 0.1619632491691315
      - 0.05430765904457546
      - 0.1687572969199475
      - 0.08283559861743846
      - 0.2868083801119514
      - 0.0772874265448523
      - 0.09711192422035796
      - 0.4472624562260534
      - 0.28058223570271756
      - 0.33301506449654583
      - 0.16907095206945083
      - 0.08591890039529146
      - 0.04042496833056605
      - 0.0657033978121163
      - 0.24791933794023607
      - 0.0635741197317552
      - 0.043708060730119555
      - 0.15023514695460394
      - 0.053806192857642654
      - 0.028923796111296106
      - 0.033813572225647494
      - 0.030999406568675034
      - 0.03721800493304851
      - 0.09395088829299356
      - 0.03413118488945695
      - 0.07289525187876839
      - 0.061276821335607384
      - 0.03509242493617494
      - 0.047107913044613814
      - 0.04623147471854471
      - 0.03808194755996954
      - 0.03386073614732152
      - 0.038269410189831696
    - - 0.043159056551913696
      - 0.30897594591063315
      - 0.15458975906662664
      - 0.09704958866890687
      - 0.2906336010927847
      - 0.14613220525011636
      - 0.16355447357922603
      - 0.10872941894108942
      - 0.16086999902402377
      - 0.10589765173098505
      - 0.18719284591377613
      - 0.16219006055025542
      - 0.07584966290323435
      - 0.11170146343018683
      - 0.14623583915131394
      - 0.1378208222503633
      - 0.14459808709808714
      - 0.0989517504966943
      - 0.1577394274901805
      - 0.08862384310681418
      - 0.19303876326310293
      - 0.07491633208962753
      - 0.22154736797593938
      - 0.17841624371796785
      - 0.07350980699194984
      - 0.12131187720108173
      - 0.11824774628216655
      - 0.15413266700698636
      - 0.060948255384725175
      - 0.056117599803824296
      - 0.22729520809877943
      - 0.1001716402284584
      - 0.21606559551956014
      - 0.07810792114693643
      - 0.22562889521737872
      - 0.10039213432070573
      - 0.0915444072045008
      - 0.02805377166361386
      - 0.05342778038561172
      - 0.027810312679953236
      - 0.054374129177204945
      - 0.024850438912938914
      - 0.03115220187129612
      - 0.06856204495093385
      - 0.032822001773614676
      - 0.13730221498078643
      - 0.04874896008916628
      - 0.02837534329469813
      - 0.15075254203161176
      - 0.15739991042410395
      - 0.045921016483516486
      - 0.2727992952130882
      - 0.13138175984643374
      - 0.06650911006610793
      - 0.0899573429067811
      - 0.32842999114550836
      - 0.09175728486073312
      - 0.02891084186815894
      - 0.04477432627966736
      - 0.09872286856661855
      - 0.15291403946295248
      - 0.08054565638763753
      - 0.036326104882413696
      - 0.19138208697867784
      - 0.1287212114300662
      - 0.13337012534913584
      - 0.12417197648290089
      - 0.10125576453121524
      - 0.2417447739458608
      - 0.09432203606336695
      - 0.15681022825351362
      - 0.056220469384814176
      - 0.17861518980959978
      - 0.08117588310887282
      - 0.2823675929499793
      - 0.08342471571638238
      - 0.09925526633675821
      - 0.4480402039339273
      - 0.2743330940739477
      - 0.33236309145400045
      - 0.16071962278811835
      - 0.08699072106877535
      - 0.04864828043543919
      - 0.07232127521601205
      - 0.24464526445776436
      - 0.05921647081440896
      - 0.04664862812704179
      - 0.13117623356025418
      - 0.059329452048524196
      - 0.026150943147500806
      - 0.03464156785785999
      - 0.036209882913179614
      - 0.03283823404791147
      - 0.09742675845303686
      - 0.02845378861531258
      - 0.06945528016956588
      - 0.056553732296306544
      - 0.040203152513403645
      - 0.04834450793359174
      - 0.041850757267423946
      - 0.03485491201008442
      - 0.035287734151370515
      - 0.04143604959993641
    - - 0.052645010173694724
      - 0.32132222341478806
      - 0.16182342524019822
      - 0.11151432654537347
      - 0.2978408763521122
      - 0.1534427679992937
      - 0.16048249702711417
      - 0.11503576351600667
      - 0.1551143132223674
      - 0.10781327778750455
      - 0.1755356418862411
      - 0.15854362185007342
      - 0.06941025468408835
      - 0.12498604256029996
      - 0.15114555404503857
      - 0.14379774880536889
      - 0.1350487045254487
      - 0.1139633234330204
      - 0.17639097811511606
      - 0.08986503798705274
      - 0.17949776273842485
      - 0.07374190617865667
      - 0.24268211371441706
      - 0.19113615879327844
      - 0.07320114607614608
      - 0.12450158567582809
      - 0.11694611787891863
      - 0.16919321135329904
      - 0.07115786707623442
      - 0.056524477506620374
      - 0.22718586670199561
      - 0.10032555127252096
      - 0.20759449720293088
      - 0.08244255744255743
      - 0.22782907818404333
      - 0.09931370576116169
      - 0.09463946379707248
      - 0.038542248080871214
      - 0.04545778622918001
      - 0.034412032871309874
      - 0.05617266004501821
      - 0.031303819319283235
      - 0.032007463381734325
      - 0.07266898053935092
      - 0.035629149102452774
      - 0.14080607110050564
      - 0.05764930744983936
      - 0.03450034397836596
      - 0.15727915713034757
      - 0.17612976046710987
      - 0.04185793758710425
      - 0.27551660296225505
      - 0.1258570761967501
      - 0.06857056800877026
      - 0.08550852941096843
      - 0.34591972547959043
      - 0.0841809107273025
      - 0.033732796507521784
      - 0.03936859092040351
      - 0.10108758203767482
      - 0.17165951945781488
      - 0.0859937833838933
      - 0.03365301274615
      - 0.19360682184756253
      - 0.13775464462277648
      - 0.13996416410386997
      - 0.1322098527437069
      - 0.11676362404384381
      - 0.23801111118819446
      - 0.09509191525320557
      - 0.16663054833023871
      - 0.056710172825584514
      - 0.1778447088235764
      - 0.07814437546580404
      - 0.291050672488407
      - 0.0815144894685973
      - 0.09971910165016476
      - 0.4437489241684893
      - 0.2782496168134465
      - 0.3302995691731955
      - 0.1555293495574509
      - 0.08893678784983133
      - 0.04440368659118659
      - 0.06319468490505678
      - 0.24988854988136594
      - 0.065087489670823
      - 0.03880205504537055
      - 0.13413511365592765
      - 0.05295420288783667
      - 0.03811193651309931
      - 0.03729201035235519
      - 0.05007695792579514
      - 0.030984199799427504
      - 0.09412135656828464
      - 0.04039514220325702
      - 0.07865722240722242
      - 0.057704345843550386
      - 0.03786220331031652
      - 0.05070202790035041
      - 0.038644307954389945
      - 0.04238091448523494
      - 0.037794438553627255
      - 0.036311203725153
    - - 0.053644605778356856
      - 0.3143404965728035
      - 0.1599163419280444
      - 0.10003093020506741
      - 0.2948988669159123
      - 0.15369131736319233
      - 0.1607932482372057
      - 0.11087008471090253
      - 0.1479309549788273
      - 0.11927727550401382
      - 0.178638739309471
      - 0.16541541153610115
      - 0.07277120430432155
      - 0.11791841564867879
      - 0.15632519918619053
      - 0.13134681312291013
      - 0.13632223206086844
      - 0.11210344929870872
      - 0.1705767995709651
      - 0.08899548532833133
      - 0.17916416057988027
      - 0.07694527694527695
      - 0.22984051072179446
      - 0.18890828237419144
      - 0.06388500135874087
      - 0.11135488229320573
      - 0.11871309806915867
      - 0.15847502437176347
      - 0.06272057928684434
      - 0.06283575132732436
      - 0.22295355343791515
      - 0.11184131335449222
      - 0.21666533890609083
      - 0.08051148170995612
      - 0.22186799354756004
      - 0.09936759557546074
      - 0.08739963739963738
      - 0.030358927996123115
      - 0.04648577917808687
      - 0.046448279475408596
      - 0.05482824965583586
      - 0.03960394763966192
      - 0.03056763838013838
      - 0.07279378442475123
      - 0.030383305896376292
      - 0.13200553083533711
      - 0.062053483756780464
      - 0.030320033754405278
      - 0.15003311526083857
      - 0.16997338670710938
      - 0.0417585389000997
      - 0.28161450496519935
      - 0.11267757401098794
      - 0.06833563624722161
      - 0.08964968817538257
      - 0.34753479681774874
      - 0.08615876813245235
      - 0.032422012428937635
      - 0.034742127220324895
      - 0.10056641495618868
      - 0.15951260174224707
      - 0.08294892979995283
      - 0.03289516415387159
      - 0.2025812100356456
      - 0.13730821317638303
      - 0.14202908249625418
      - 0.126568035184334
      - 0.11551053813327178
      - 0.23969513051959854
      - 0.1024794083467553
      - 0.16375697405273298
      - 0.05252497807442862
      - 0.15764823160952307
      - 0.07870421245421244
      - 0.27881337176478976
      - 0.07902206694820332
      - 0.09228032578493243
      - 0.446449129317394
      - 0.27370417404629677
      - 0.31173485783540134
      - 0.15802542409883125
      - 0.08824540495736145
      - 0.037809735158220004
      - 0.07086441705299117
      - 0.251410515454344
      - 0.06182250861165697
      - 0.04933063210502235
      - 0.13695191133046244
      - 0.06264645948450877
      - 0.030456310384544393
      - 0.02735126862917931
      - 0.03847497258712212
      - 0.029529117440433652
      - 0.0980572162212787
      - 0.03147778192022452
      - 0.06425176548656791
      - 0.051250509787028324
      - 0.03728551922138065
      - 0.04223729237933783
      - 0.04171517027645274
      - 0.029593808222840478
      - 0.02685171520398793
      - 0.039502663577447056
  score_time:
  - 8.701133728027344
  - 7.743441343307495
  - 8.360922813415527
  - 8.013445854187012
  - 8.684555530548096
  test_level0__average_precision_macro:
  - 0.33806707345325965
  - 0.30700798664066786
  - 0.3297508807814096
  - 0.29857397579058265
  - 0.32046843692151367
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.5235594898729009
  - 0.4993883512693451
  - 0.5205766930650555
  - 0.47752251650960786
  - 0.49255573252861035
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.5500473080852295
  - 0.5344273675675424
  - 0.5471537557725596
  - 0.5103273944071891
  - 0.5331800059526997
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.45663652518906866
  - 0.42930459030304463
  - 0.45851381873481006
  - 0.4084257431175932
  - 0.4236190185354164
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7546792112901611
  - 0.7674439706015785
  - 0.7660405234276068
  - 0.778846153846154
  - 0.7631829430801447
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7546792112901611
  - 0.7674439706015788
  - 0.7660405234276065
  - 0.7788461538461539
  - 0.7631829430801447
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.754679211290161
  - 0.7674439706015787
  - 0.7660405234276064
  - 0.7788461538461539
  - 0.7631829430801446
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.6425485915700304
  - 0.6495127328730055
  - 0.6451800516108852
  - 0.6662621359223302
  - 0.6470469782758047
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.24532078870983884
  - -0.23237455766264403
  - -0.23395947657239344
  - -0.22115384615384617
  - -0.23624595469255663
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.24532078870983887
  - -0.23237455766264403
  - -0.2339594765723934
  - -0.22115384615384615
  - -0.23624595469255663
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.24532078870983876
  - -0.23237455766264395
  - -0.23395947657239335
  - -0.2211538461538461
  - -0.23624595469255666
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.35745140842996964
  - -0.3498189320441246
  - -0.3548199483891148
  - -0.33373786407767
  - -0.35086825708938424
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0001814717357771527
  - -0.0
  - -0.0
  - -0.0005711022272986865
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.00018147173577715272
  - -0.0
  - -0.0
  - -0.0005711022272986865
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0001814717357771527
  - -0.0
  - -0.0
  - -0.0005711022272986864
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.000668335082869918
  - -0.0
  - -0.0
  - -0.0020847646348108313
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6309556914437169
  - 0.6489582243390793
  - 0.6474304178376787
  - 0.6618491401296318
  - 0.6429045801216317
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.6060118951936988
  - 0.6226442873969376
  - 0.6207987684939708
  - 0.6377952755905512
  - 0.6170540249345852
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6083063733496132
  - 0.6253737600801806
  - 0.6234157049126248
  - 0.6403508238034257
  - 0.6200003460957186
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5043336135397085
  - 0.5080272681234967
  - 0.5057142071559051
  - 0.5290299750660126
  - 0.5088254981922545
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5500473080852297
  - 0.5344273675675425
  - 0.5471537557725596
  - 0.5103273944071893
  - 0.5331800059526997
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0
  - -2.8971950285874368e-05
  - 0.0010267297960622314
  - 0.0
  - -0.005513275790453007
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.052579341050412495
  - 0.04909739703101127
  - 0.0
  - -0.005681891793981876
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.018756236928125433
  - 0.013047592205578162
  - 0.0
  - -0.0013170499906863795
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0
  - -0.0001066996505670212
  - 0.003851621712476257
  - 0.0
  - -0.020125788064706423
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.840521474872448
  - 0.82317653934421
  - 0.8370466568582272
  - 0.814639039524703
  - 0.8237331039957421
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -91.34020618556701
  - -88.41121495327103
  - -88.1413043478261
  - -89.89423076923077
  - -88.45098039215686
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.24532078870983884
  - -0.2325560293984212
  - -0.23395947657239344
  - -0.22115384615384617
  - -0.23681705691985533
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.24532078870983887
  - -0.23255602939842118
  - -0.2339594765723934
  - -0.22115384615384615
  - -0.23681705691985533
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.24532078870983876
  - -0.23255602939842107
  - -0.23395947657239335
  - -0.2211538461538461
  - -0.23681705691985533
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.35745140842996964
  - -0.3504872671269945
  - -0.3548199483891148
  - -0.33373786407767
  - -0.3529530217241951
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.25333907538483935
  - -0.24271269191867065
  - -0.24119380146483885
  - -0.2576547862444189
  - -0.250074220103691
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7546792112901611
  - 0.7674439706015785
  - 0.7660405234276068
  - 0.778846153846154
  - 0.7631829430801447
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7546792112901611
  - 0.7674439706015788
  - 0.7660405234276065
  - 0.7788461538461539
  - 0.7631829430801447
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.754679211290161
  - 0.7674439706015787
  - 0.7660405234276064
  - 0.7788461538461539
  - 0.7631829430801446
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.6425485915700304
  - 0.6495127328730055
  - 0.6451800516108852
  - 0.6662621359223302
  - 0.6470469782758047
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7546792112901611
  - 0.7674439706015785
  - 0.7660405234276068
  - 0.778846153846154
  - 0.7631829430801447
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7546792112901611
  - 0.7674439706015788
  - 0.7660405234276065
  - 0.7788461538461539
  - 0.7631829430801447
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.754679211290161
  - 0.7674439706015787
  - 0.7660405234276064
  - 0.7788461538461539
  - 0.7631829430801446
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.6425485915700304
  - 0.6495127328730055
  - 0.6451800516108852
  - 0.6662621359223302
  - 0.6470469782758047
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5833180717746542
  - 0.5706989507041054
  - 0.5955056995822865
  - 0.5615225835066244
  - 0.5798082426898317
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7442782516095309
  - 0.7552813434824341
  - 0.7580692823016821
  - 0.7391611969035295
  - 0.7434832568809296
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7466609246151608
  - 0.7572873080813295
  - 0.7588061985351611
  - 0.7423452137555812
  - 0.749925779896309
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5927274126788268
  - 0.5659015138965701
  - 0.6000323012732165
  - 0.5663177532476805
  - 0.5597062832314373
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7546792112901611
  - 0.7663551401869158
  - 0.7653018151118617
  - 0.778846153846154
  - 0.7630877593755948
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7546792112901611
  - 0.7663551401869159
  - 0.7653018151118616
  - 0.7788461538461539
  - 0.7630877593755949
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.754679211290161
  - 0.7663551401869156
  - 0.7653018151118616
  - 0.7788461538461539
  - 0.7630877593755949
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.6425485915700304
  - 0.645502722375786
  - 0.6424088989677823
  - 0.6662621359223302
  - 0.6466995175033362
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.0
  - 0.0010888304146629162
  - 0.0007387083157450402
  - 0.0
  - 9.518370454978108e-05
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0
  - 0.0010888304146629162
  - 0.0007387083157450401
  - 0.0
  - 9.518370454978108e-05
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.0
  - 0.0010888304146629162
  - 0.0007387083157450401
  - 0.0
  - 9.518370454978107e-05
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0
  - 0.004010010497219508
  - 0.0027711526431029093
  - 0.0
  - 0.0003474607724684719
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.2755428718256365
  - 0.255179042931142
  - 0.2618750444612162
  - 0.2504640993625289
  - 0.26964986575333083
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.23658517416001898
  - 0.21837066610221417
  - 0.21772913851131256
  - 0.23007300068880362
  - 0.23339241583330908
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.24083250138124349
  - 0.22343009457370902
  - 0.22215159159268955
  - 0.23812131805781134
  - 0.23806767314000007
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.38803687296210976
  - 0.3764234282521755
  - 0.3852347012556692
  - 0.362762039541054
  - 0.3851854251427754
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.2408325013812435
  - 0.2234300945737091
  - 0.22215159159268963
  - 0.2381213180578114
  - 0.23806767314000016
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6286919712545385
  - 0.6097385949013222
  - 0.609390503169129
  - 0.6175714841647644
  - 0.6224398365280136
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -96.61855670103093
  - -95.64485981308411
  - -97.8695652173913
  - -95.51923076923077
  - -95.82352941176471
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.6792682979279344
  - -0.6555745609319296
  - -0.6964187178969177
  - -0.5491371326431949
  - -0.6212657106095182
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5203035268167125
  - 0.5220888312591387
  - 0.5215960952490728
  - 0.5212391142101532
  - 0.5322818434402761
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.49038883604050537
  - 0.4780314439576488
  - 0.4694789294047388
  - 0.5358850006681148
  - 0.5065513922944752
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.49332755116079313
  - 0.48002108912107694
  - 0.4687969859559635
  - 0.5372790393313023
  - 0.5058884880999424
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.52187516072694
  - 0.5237363986790768
  - 0.5264679534142267
  - 0.5192395281664455
  - 0.5261148004733496
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.2787226096316778
  - 0.2608847268221655
  - 0.26613265736455965
  - 0.2510009865190526
  - 0.2668211018560304
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.23834288386802882
  - 0.22350159135456016
  - 0.22083307242728922
  - 0.2346121371703137
  - 0.23677633018510766
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.2426230512187867
  - 0.22867102880769882
  - 0.22512422754008754
  - 0.2429836622975442
  - 0.24151722512117257
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.3911299272057902
  - 0.38346843171459405
  - 0.3908075640102965
  - 0.36172823857729036
  - 0.3801677618775764
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.24262305121878674
  - 0.22867102880769877
  - 0.2251242275400876
  - 0.24298366229754434
  - 0.24151722512117257
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.6301968291341806
  - 0.6144855587049739
  - 0.6121099969037911
  - 0.6222541038719555
  - 0.6259541717033879
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -96.41237113402062
  - -95.53271028037383
  - -97.41304347826087
  - -95.53846153846153
  - -95.66666666666667
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.6710752757624824
  - -0.6340226213295197
  - -0.6812012433035578
  - -0.5346302402326815
  - -0.6090647223316253
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5328882111219382
  - 0.5282200207514058
  - 0.5281706637288472
  - 0.5208872225484225
  - 0.5305538546549151
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.4942721641250743
  - 0.48990999279375563
  - 0.47744569099271056
  - 0.5423922770481134
  - 0.5120740266016315
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.4970911186592837
  - 0.4907253417700465
  - 0.4751985341869529
  - 0.5431561479118584
  - 0.5113868297457465
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5340858210869374
  - 0.5277507175488703
  - 0.5330638756019429
  - 0.5201884115147363
  - 0.518302994264241
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.271403372607944
  - 0.26622760631079506
  - 0.2606268991646579
  - 0.253571119182748
  - 0.2702613135399388
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.23634800220346572
  - 0.21915635197659544
  - 0.2184513777079684
  - 0.23001699613405152
  - 0.2333819156301032
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.24051498122660214
  - 0.2241183936927393
  - 0.222664017406582
  - 0.2380073465234995
  - 0.23808684062360677
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.3851260366728983
  - 0.387735002119789
  - 0.38492045815748455
  - 0.3648561800923108
  - 0.38394565908634987
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.24051498122660228
  - 0.22411839369273945
  - 0.22266401740658193
  - 0.23800734652349947
  - 0.2380868406236067
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6283102454839888
  - 0.6100030601130477
  - 0.6098800900629172
  - 0.6174915077502425
  - 0.622679507791732
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -96.61855670103093
  - -95.69158878504673
  - -98.06521739130434
  - -95.46153846153847
  - -95.74509803921569
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.6789022160800159
  - -0.6521982292870913
  - -0.6958233586309204
  - -0.5497105921249273
  - -0.6213116699166794
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5254978477779161
  - 0.5340567697907819
  - 0.5216248333066859
  - 0.524731919391734
  - 0.5260526301466446
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.49015285808748016
  - 0.48119570013926677
  - 0.47127590949854575
  - 0.5358626880113286
  - 0.5062298991486869
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.4926385844803077
  - 0.48274703352202286
  - 0.46959583087435025
  - 0.5365429637522406
  - 0.5059023285808447
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5299805539309707
  - 0.534381564326973
  - 0.5255007372660817
  - 0.5209931072442157
  - 0.5214538256740956
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.27111062098110006
  - 0.2634783042775214
  - 0.2588890554232169
  - 0.25016678062249237
  - 0.2626521954148076
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.236481637521601
  - 0.2189779171449477
  - 0.2182770509375052
  - 0.23013818676663594
  - 0.2334106953096656
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.24061535824844385
  - 0.22387855266538503
  - 0.22257928827382756
  - 0.23830433208820667
  - 0.2379585807466558
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.3830086122106223
  - 0.3852526334664215
  - 0.38547638818421676
  - 0.3623916796187091
  - 0.37534570640436327
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.2406153582484439
  - 0.22387855266538495
  - 0.22257928827382753
  - 0.23830433208820656
  - 0.2379585807466558
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.628520388074423
  - 0.6100425820810944
  - 0.6098438239398584
  - 0.6176184101754985
  - 0.622750648242003
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -96.48453608247422
  - -95.6355140186916
  - -97.6413043478261
  - -95.64423076923077
  - -95.92156862745098
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.6793232096548943
  - -0.6535985090362771
  - -0.6961279967968145
  - -0.5495959758903282
  - -0.6219342890000132
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5248307028687383
  - 0.5276979166457546
  - 0.5209194444341123
  - 0.5204464704918853
  - 0.5274635278532765
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.49010285954847643
  - 0.4801422745601174
  - 0.4708415217632843
  - 0.5361131614975425
  - 0.5058208606759793
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.49274468937519555
  - 0.48171152567499337
  - 0.4698832705533219
  - 0.5370633674117148
  - 0.5052208253428843
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.5303888059640226
  - 0.5301459011552911
  - 0.5283935655992571
  - 0.5194392449827218
  - 0.5173824453958527
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.27898998949391296
  - 0.2570340610479215
  - 0.25686448200694495
  - 0.25017583241103913
  - 0.26088710524235337
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.23663642350575703
  - 0.2182783204303425
  - 0.2178497450565165
  - 0.22996243053281917
  - 0.2331691605076988
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.24073350946468172
  - 0.22334312184336738
  - 0.22216769246759466
  - 0.23814732929827354
  - 0.23775601104229885
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.3939248291086619
  - 0.3828720608673354
  - 0.38115664083433926
  - 0.36224078890015066
  - 0.3752014150353457
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.2407335094646818
  - 0.22334312184336735
  - 0.22216769246759466
  - 0.23814732929827354
  - 0.23775601104229896
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6285746766289418
  - 0.6094969296063095
  - 0.6096476996982716
  - 0.6175101560889888
  - 0.6224866822204737
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -96.6082474226804
  - -95.93457943925233
  - -98.08695652173913
  - -95.41346153846153
  - -95.57843137254902
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.6788489958756245
  - -0.6557107546544249
  - -0.6975279043150401
  - -0.5486038715640607
  - -0.622285045739288
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5270117168264464
  - 0.5195582898909089
  - 0.5145680099130335
  - 0.522791838318379
  - 0.5207355543786132
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.4906393969007399
  - 0.4781443865638507
  - 0.46908816024951683
  - 0.5358828250575892
  - 0.5054877968892193
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.4929850189036345
  - 0.47963320323163966
  - 0.4680993495433827
  - 0.5375686230423405
  - 0.5047462239576566
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5345357423721895
  - 0.5248710040091092
  - 0.5192644719619187
  - 0.5193313995244563
  - 0.5126882670796868
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.27906093814316296
  - 0.2619205655856489
  - 0.25932525017136165
  - 0.2471225676572794
  - 0.2665922254926925
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.2368835743604435
  - 0.2188071129966614
  - 0.21814194193051129
  - 0.22976994486023242
  - 0.23364213821834107
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.2410467953136482
  - 0.2237373959164516
  - 0.22256903332248995
  - 0.2379082884323483
  - 0.23829345359672993
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.3924455899761325
  - 0.3873557236662764
  - 0.38580131919648475
  - 0.35756916172703834
  - 0.3816884060689629
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.2410467953136482
  - 0.22373739591645167
  - 0.22256903332248987
  - 0.2379082884323484
  - 0.2382934535967298
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.6288292656036567
  - 0.6098211266523503
  - 0.6097769279548892
  - 0.6171858434721754
  - 0.6227748734202332
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -96.64948453608247
  - -95.6822429906542
  - -98.05434782608695
  - -95.25
  - -95.57843137254902
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.6783166889818503
  - -0.6527932176157363
  - -0.6957245819647176
  - -0.5484927371608673
  - -0.6200042261747005
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5287182394132335
  - 0.5270805448034259
  - 0.5134156154531005
  - 0.5162568599367275
  - 0.5244924803269317
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.49111903656494893
  - 0.4800510003724576
  - 0.4702896397719111
  - 0.5358137114767048
  - 0.5069573686886608
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.4938315922962292
  - 0.4814618403224613
  - 0.4695922071564651
  - 0.5371462272840581
  - 0.5063927970215595
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5335246312134577
  - 0.5332758369628209
  - 0.5231196565849601
  - 0.5159745819100852
  - 0.5197033145607601
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.27272143889927075
  - 0.2633723596787544
  - 0.2576734649392441
  - 0.2574587820714682
  - 0.2674868022300222
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.23648383224462505
  - 0.21868078791185946
  - 0.21804603005679246
  - 0.2304314424755216
  - 0.233683612258907
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.24074592431322198
  - 0.2237857373784676
  - 0.22223172603246882
  - 0.23827292928063942
  - 0.23819479094968066
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.3869045013607561
  - 0.38552963983107574
  - 0.38555982494126956
  - 0.3673705664264337
  - 0.3823647162880179
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.24074592431322198
  - 0.2237857373784677
  - 0.22223172603246888
  - 0.2382729292806395
  - 0.23819479094968085
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6286113603198725
  - 0.609859426787218
  - 0.6097211382125934
  - 0.6175509082577226
  - 0.6227472677725373
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -96.1340206185567
  - -95.8785046728972
  - -98.29347826086956
  - -95.45192307692308
  - -95.92156862745098
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.6792461151390983
  - -0.6528622686171306
  - -0.6972976795048765
  - -0.5493705928952776
  - -0.6212681380470637
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5188138686500648
  - 0.5249871440626933
  - 0.5184804039502438
  - 0.5229239548377641
  - 0.52938845996804
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.489987792564503
  - 0.47952624280111644
  - 0.4700924416286055
  - 0.5372626680867838
  - 0.5068910571193601
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.4930064160865283
  - 0.48175759791602824
  - 0.4690184194998896
  - 0.5374811172413406
  - 0.5058718388778093
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5252741085739256
  - 0.5281839553536675
  - 0.5262387618418439
  - 0.5265019235986207
  - 0.5232996789480446
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.27167288317189364
  - 0.2656359026355697
  - 0.25892299932698204
  - 0.25681359710920315
  - 0.2662733171358814
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.2363699532163216
  - 0.2185267708926534
  - 0.21781001210946585
  - 0.23018908849000355
  - 0.2336627715789185
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.24049680569544105
  - 0.22350523979681178
  - 0.2222164942251217
  - 0.23833380568801912
  - 0.2384165866057485
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.3855603751703736
  - 0.3848283362857941
  - 0.3852231410523648
  - 0.3700888723613305
  - 0.3818279585718284
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.2404968056954411
  - 0.22350523979681167
  - 0.22221649422512177
  - 0.23833380568801912
  - 0.2384165866057486
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.6284477672908327
  - 0.6096262591193587
  - 0.6094031615606201
  - 0.6176279913357658
  - 0.6227819988802544
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -96.76288659793815
  - -95.29906542056075
  - -97.41304347826087
  - -95.29807692307692
  - -96.02941176470588
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.679744809281781
  - -0.6546673933485312
  - -0.6959503938208512
  - -0.5497534564520934
  - -0.6200047981153392
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5223281093095211
  - 0.5294474565860698
  - 0.52171554096157
  - 0.5197632562452658
  - 0.5278622209851191
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.48964802976536403
  - 0.4791440091377239
  - 0.47001772892221244
  - 0.5361923941971509
  - 0.5071838872022636
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.492120376864161
  - 0.48072615325938167
  - 0.46949030854529694
  - 0.5372008420215427
  - 0.506816676094358
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5300085349560774
  - 0.5254011288905942
  - 0.5283148755829875
  - 0.5219202527345496
  - 0.5256958003555942
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.27584356273855765
  - 0.26631955936516716
  - 0.25657371041256477
  - 0.2535083545716663
  - 0.26317042598541657
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.23670550522010206
  - 0.21882353522509151
  - 0.2180551734872627
  - 0.22949430628850317
  - 0.23351743533800304
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.24076537094889877
  - 0.22389129050086687
  - 0.2224039811675244
  - 0.2377248341820641
  - 0.23808629774283666
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.39026815148862504
  - 0.39018320102005893
  - 0.38178401471813855
  - 0.36483878468752406
  - 0.37961129418978207
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.24076537094889888
  - 0.22389129050086698
  - 0.22240398116752444
  - 0.23772483418206405
  - 0.23808629774283654
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6286605605550581
  - 0.6098341145680722
  - 0.6097810829184356
  - 0.6170562705442583
  - 0.6227221105347946
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -96.85567010309278
  - -95.66355140186916
  - -98.22826086956522
  - -95.3173076923077
  - -96.07843137254902
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.6793538236100863
  - -0.6534568919487609
  - -0.6972759278238554
  - -0.5499043560512852
  - -0.6215808577109717
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5267202304402089
  - 0.531672202129828
  - 0.517661330182357
  - 0.5207033993141893
  - 0.5255188543255266
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.49052841529522406
  - 0.48009116285523334
  - 0.4700179149289503
  - 0.5347702026560966
  - 0.506383956836941
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.49266363193531026
  - 0.48174466275949196
  - 0.46904672973321376
  - 0.5361048093693024
  - 0.5056400053127441
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5348016000253688
  - 0.5328318464478489
  - 0.5212775747113219
  - 0.5210371505317877
  - 0.5192808093240303
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.2726858266421879
  - 0.258189203917027
  - 0.2547620241081281
  - 0.25327223823231815
  - 0.2667750388558562
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.23690619113609968
  - 0.218392167211852
  - 0.21798968046633027
  - 0.23025106042743043
  - 0.23349960108647086
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.2410462426699182
  - 0.2234441676345439
  - 0.22240876963392522
  - 0.23822372802782893
  - 0.23806676819103623
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.3855363309854364
  - 0.38674810250625635
  - 0.38303942734669927
  - 0.3645795175220993
  - 0.3821559664479
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.15210766073725687
  - 0.1439957180446632
  - 0.14538758487587036
  - 0.1348497936711426
  - 0.14568763407215723
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.13980948034909588
  - 0.13215881658020442
  - 0.13295074127211862
  - 0.12432432432432433
  - 0.134006152517675
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.14064364081016056
  - 0.1331081012460898
  - 0.13387392416310795
  - 0.1251627091367675
  - 0.1350509766259079
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.24007151238346253
  - 0.23356145244479865
  - 0.2389323329889815
  - 0.2195111775477249
  - 0.23285886714626164
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.24104624266991806
  - 0.22344416763454406
  - 0.2224087696339253
  - 0.23822372802782896
  - 0.23806676819103623
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.6289331162958401
  - 0.6095511175295547
  - 0.6099212973234528
  - 0.6176956971513342
  - 0.6226625913687034
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -96.26804123711341
  - -95.61682242990655
  - -98.01086956521739
  - -95.58653846153847
  - -95.66666666666667
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.7546792112901611
  - -0.766536611922693
  - -0.7653018151118617
  - -0.778846153846154
  - -0.7636588616028935
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.7546792112901611
  - -0.7665366119226931
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028935
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.754679211290161
  - -0.7665366119226928
  - -0.7653018151118616
  - -0.7788461538461539
  - -0.7636588616028934
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.6425485915700304
  - -0.6461710574586559
  - -0.6424088989677823
  - -0.6662621359223302
  - -0.6487842821381471
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.6792890747285413
  - -0.6541075060555089
  - -0.6970917015106294
  - -0.5493959478350446
  - -0.6220498592787858
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5250343363526603
  - 0.5233744335995518
  - 0.5109998132203699
  - 0.521542873778124
  - 0.5307066237493795
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.49095970680510415
  - 0.47875305750126607
  - 0.46943751190443117
  - 0.5366472485837914
  - 0.5065143461641619
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.49339212123032594
  - 0.48094691002841855
  - 0.46910854859290135
  - 0.5373054051273634
  - 0.5056591119560668
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5299678510159752
  - 0.5292735686096076
  - 0.5219614654125013
  - 0.5230671733104573
  - 0.5255404185168198
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.24532078870983884
  - 0.23346338807730693
  - 0.23469818488813846
  - 0.22115384615384617
  - 0.2363411383971064
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.24532078870983887
  - 0.23346338807730696
  - 0.23469818488813846
  - 0.22115384615384615
  - 0.2363411383971064
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.24532078870983876
  - 0.23346338807730688
  - 0.2346981848881384
  - 0.2211538461538461
  - 0.2363411383971064
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.35745140842996964
  - 0.3538289425413441
  - 0.3575911010322177
  - 0.33373786407767
  - 0.3512157178618527
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.6904359999578428
  - 0.6932032892214228
  - 0.6949076407391463
  - 0.6949702859214182
  - 0.6866758660996108
  train_level0__average_precision_macro_masked:
  - 0.21665660557176722
  - 0.22192840261046742
  - 0.22208582619102998
  - 0.2317192617775918
  - 0.2205121835968001
  train_level0__average_precision_macro_oob:
  - 0.2711466213871916
  - 0.27277587510599594
  - 0.26903402597887494
  - 0.28148550203358486
  - 0.2755200923637425
  train_level0__average_precision_micro:
  - 0.639583653623549
  - 0.6421235109412178
  - 0.641715471478883
  - 0.6481293643796174
  - 0.6432881685135499
  train_level0__average_precision_micro_masked:
  - 0.36783643736232147
  - 0.3729230995621197
  - 0.37195828155936256
  - 0.38069944068681044
  - 0.37379265645848025
  train_level0__average_precision_micro_oob:
  - 0.4948819468607194
  - 0.4994612655458852
  - 0.49458405223134616
  - 0.505354648299577
  - 0.5002981807452268
  train_level0__average_precision_samples:
  - 0.6542661576671677
  - 0.6570454462814821
  - 0.6561643785396966
  - 0.6607038712507346
  - 0.6549281787764368
  train_level0__average_precision_samples_masked:
  - 0.42986755381122976
  - 0.4312572944704698
  - 0.4314442831082525
  - 0.4375344897394023
  - 0.42962905939744295
  train_level0__average_precision_samples_oob:
  - 0.5323658419217154
  - 0.5316596528702311
  - 0.5273413119767176
  - 0.5382110516167603
  - 0.5319648482748671
  train_level0__average_precision_weighted:
  - 0.7457975494654691
  - 0.744616630972777
  - 0.7505296786231461
  - 0.7501982920396224
  - 0.7412695534300615
  train_level0__average_precision_weighted_masked:
  - 0.31442775348232566
  - 0.3159787453926897
  - 0.31997984216970543
  - 0.3297375166494483
  - 0.3210768646864158
  train_level0__average_precision_weighted_oob:
  - 0.3888038479579744
  - 0.3887313486896866
  - 0.3841322943830871
  - 0.39803159764548557
  - 0.3960594390679961
  train_level0__f1_macro:
  - 0.7700827040632866
  - 0.7679488755069435
  - 0.7678901255031968
  - 0.7635507635263696
  - 0.7682281553398058
  train_level0__f1_macro_masked:
  - 0.8586877497796034
  - 0.8567306396876352
  - 0.856986715019508
  - 0.8541530907181858
  - 0.8573748180486787
  train_level0__f1_macro_oob:
  - 0.7688601222581806
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__f1_micro:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031968
  - 0.7635507635263697
  - 0.7682281553398058
  train_level0__f1_micro_masked:
  - 0.8699167141423184
  - 0.8680596183312439
  - 0.868221214479298
  - 0.865819209039548
  - 0.8686815906715802
  train_level0__f1_micro_oob:
  - 0.7688601222581805
  - 0.7673343984269386
  - 0.7667298129291973
  - 0.7626725862321315
  - 0.7672330097087379
  train_level0__f1_samples:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031966
  - 0.7635507635263696
  - 0.7682281553398059
  train_level0__f1_samples_masked:
  - 0.8696385798047298
  - 0.8677560961380392
  - 0.8679353434603483
  - 0.8655085175381086
  - 0.8684691321776162
  train_level0__f1_samples_oob:
  - 0.7688601222581803
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__f1_weighted:
  - 0.6601351895993827
  - 0.6619725683035425
  - 0.6609390589653164
  - 0.6524609998920716
  - 0.6598286887802849
  train_level0__f1_weighted_masked:
  - 0.7724013272449971
  - 0.7706834199124739
  - 0.7717716918783062
  - 0.7671771315871451
  - 0.7715151463310918
  train_level0__f1_weighted_oob:
  - 0.6555738520847167
  - 0.6596851320630375
  - 0.6565462960218911
  - 0.649189065252271
  - 0.6560343662264738
  train_level0__fn_macro:
  - -0.22991729593671342
  - -0.23202654540985615
  - -0.23210987449680326
  - -0.23644923647363025
  - -0.2317718446601942
  train_level0__fn_macro_masked:
  - -0.14131225022039662
  - -0.1432250281759991
  - -0.1430132849804919
  - -0.14584690928181435
  - -0.14262518195132112
  train_level0__fn_macro_oob:
  - -0.2310200167805346
  - -0.2325672852402605
  - -0.2331754676770069
  - -0.23732741376786842
  - -0.23274271844660194
  train_level0__fn_micro:
  - -0.22991729593671342
  - -0.2320265454098562
  - -0.23210987449680323
  - -0.23644923647363028
  - -0.23177184466019418
  train_level0__fn_micro_masked:
  - -0.13008328585768156
  - -0.13191252263546455
  - -0.13177878552070196
  - -0.134180790960452
  - -0.1313184093284198
  train_level0__fn_micro_oob:
  - -0.23102001678053458
  - -0.23256728524026055
  - -0.23317546767700686
  - -0.23732741376786848
  - -0.23274271844660194
  train_level0__fn_samples:
  - -0.22991729593671337
  - -0.23202654540985615
  - -0.23210987449680315
  - -0.23644923647363023
  - -0.23177184466019413
  train_level0__fn_samples_masked:
  - -0.13036142019527025
  - -0.13221725496122794
  - -0.1320646565396517
  - -0.13449148246189144
  - -0.1315308678223837
  train_level0__fn_samples_oob:
  - -0.23102001678053452
  - -0.23256728524026046
  - -0.2331754676770068
  - -0.2373274137678684
  - -0.23274271844660185
  train_level0__fn_weighted:
  - -0.3398648104006172
  - -0.33793389341152985
  - -0.33906094103468376
  - -0.3475390001079284
  - -0.34017131121971506
  train_level0__fn_weighted_masked:
  - -0.22759867275500298
  - -0.2291469256716432
  - -0.22822830812169392
  - -0.23282286841285482
  - -0.22848485366890858
  train_level0__fn_weighted_oob:
  - -0.3439744923352896
  - -0.33994071479725174
  - -0.3430951110847682
  - -0.350810934747729
  - -0.3438730893209941
  train_level0__fp_macro:
  - -0.0
  - -2.4579083200196634e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -0.0
  - -4.433213636565146e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -0.0001198609612849095
  - -9.831633280078653e-05
  - -9.47193937958797e-05
  - -0.0
  - -2.4271844660194176e-05
  train_level0__fp_micro:
  - -0.0
  - -2.4579083200196634e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -0.0
  - -2.7859033291544782e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -0.00011986096128490951
  - -9.831633280078653e-05
  - -9.47193937958797e-05
  - -0.0
  - -2.4271844660194176e-05
  train_level0__fp_samples:
  - -0.0
  - -2.457908320019663e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -0.0
  - -2.664890073284477e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -0.00011986096128490948
  - -9.831633280078652e-05
  - -9.471939379587969e-05
  - -0.0
  - -2.4271844660194173e-05
  train_level0__fp_weighted:
  - -0.0
  - -9.353828492771377e-05
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.00016965441588273796
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.000451655579993577
  - -0.0003741531397108551
  - -0.00035859289334084105
  - -0.0
  - -9.254445253197463e-05
  train_level0__jaccard_macro:
  - 0.650136064121635
  - 0.6463505303960256
  - 0.646601668356102
  - 0.6420641269439135
  - 0.6473591556986219
  train_level0__jaccard_macro_masked:
  - 0.7697811528725688
  - 0.7668897291247787
  - 0.7671035794990826
  - 0.7633941392664333
  - 0.7677566157228906
  train_level0__jaccard_macro_oob:
  - 0.6493699019064665
  - 0.6459273944403666
  - 0.6458555736918784
  - 0.6415417346614355
  - 0.6467242332938827
  train_level0__jaccard_micro:
  - 0.6261255993451058
  - 0.6233092606631289
  - 0.6232318573185732
  - 0.6175350681634344
  - 0.6236773138386963
  train_level0__jaccard_micro_masked:
  - 0.7697810639523718
  - 0.7668775073219956
  - 0.7671297832993503
  - 0.763387297633873
  - 0.767848895155213
  train_level0__jaccard_micro_oob:
  - 0.6245107774986857
  - 0.6225000498494546
  - 0.6217046523684261
  - 0.616387043353114
  - 0.6223666075999212
  train_level0__jaccard_samples:
  - 0.6288916195395028
  - 0.626059613574095
  - 0.6259647375940963
  - 0.6202442082992377
  - 0.6263475576927569
  train_level0__jaccard_samples_masked:
  - 0.7717215862756832
  - 0.7686002771648035
  - 0.768940995771264
  - 0.7651017681913721
  - 0.7697493998096664
  train_level0__jaccard_samples_oob:
  - 0.6272708068377626
  - 0.6252047868987323
  - 0.6244316559943053
  - 0.6190730909630521
  - 0.6250044855748483
  train_level0__jaccard_weighted:
  - 0.5194961400547795
  - 0.5210072507867226
  - 0.5199292500511273
  - 0.512250161969852
  - 0.5189635595984852
  train_level0__jaccard_weighted_masked:
  - 0.6551359306942164
  - 0.6541969824420363
  - 0.6546622068368267
  - 0.6491245861560011
  - 0.6543754223772065
  train_level0__jaccard_weighted_oob:
  - 0.5166426029012182
  - 0.5194347617294894
  - 0.5171046516914011
  - 0.5103038199090646
  - 0.516542707488994
  train_level0__label_ranking_average_precision_score:
  - 0.6542661576671677
  - 0.657045446281482
  - 0.6561643785396969
  - 0.6607038712507346
  - 0.6549281787764366
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5323658419217151
  - 0.5316596528702312
  - 0.5273413119767175
  - 0.5382110516167602
  - 0.5319648482748668
  train_level0__matthews_corrcoef_macro:
  - 0.0019924935182712893
  - 0.0022106830912651735
  - 0.0016394742990601067
  - 0.0011402784253346284
  - 0.0015447191446320498
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - -0.000394572869394633
  - 0.00046540730438577574
  - 0.0
  - 0.000653854114926787
  train_level0__matthews_corrcoef_macro_oob:
  - -0.0010067440503949332
  - 0.0010716739737135054
  - -5.9309313263654076e-05
  - 0.0002494237269463544
  - 0.0006551331726479569
  train_level0__matthews_corrcoef_micro:
  - 0.0680222890605077
  - 0.08294851584441282
  - 0.0758332400240153
  - 0.054597105657902094
  - 0.07368369987204898
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.01444335820811585
  - 0.01879987854541385
  - 0.0
  - 0.026964239621730376
  train_level0__matthews_corrcoef_micro_oob:
  - 0.022724801746190872
  - 0.06889651968128925
  - 0.04260812399291103
  - 0.012519933808953207
  - 0.04593263890812644
  train_level0__matthews_corrcoef_samples:
  - 0.025743256475069327
  - 0.04074272355107451
  - 0.03253152019999679
  - 0.017442215516908933
  - 0.031229229715308063
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0015223987754997947
  - 0.0016681531478655632
  - 0.0
  - 0.00258531429883397
  train_level0__matthews_corrcoef_samples_oob:
  - 0.004739639777703624
  - 0.029166606673763865
  - 0.012392277114661619
  - 0.0007854821121065127
  - 0.012501334176977776
  train_level0__matthews_corrcoef_weighted:
  - 0.007033166047222617
  - 0.007763425690350582
  - 0.006206794711174396
  - 0.00424847750374394
  - 0.005889753727292087
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - -0.0015099888064990304
  - 0.0017660468910368446
  - 0.0
  - 0.002508424637595253
  train_level0__matthews_corrcoef_weighted_oob:
  - -0.0037935751817089205
  - 0.003704296676334195
  - -0.00022453583572445952
  - 0.0009293090786319005
  - 0.0024979123608875205
  train_level0__ndcg:
  - 0.8820324767794608
  - 0.8854476627363747
  - 0.8837853986364878
  - 0.886450194565478
  - 0.883230844597349
  train_level0__ndcg_oob:
  - 0.8252697850126578
  - 0.8266593062033769
  - 0.824272560206865
  - 0.8301278013140895
  - 0.8263962920803505
  train_level0__neg_coverage_error:
  - -78.28888888888889
  - -79.46835443037975
  - -79.34146341463415
  - -78.69095477386935
  - -79.415
  train_level0__neg_coverage_error_oob:
  - -89.18765432098765
  - -90.36455696202532
  - -90.02195121951219
  - -89.23869346733669
  - -89.5
  train_level0__neg_hamming_loss_macro:
  - -0.22991729593671342
  - -0.23205112449305634
  - -0.23210987449680326
  - -0.23644923647363025
  - -0.2317718446601942
  train_level0__neg_hamming_loss_macro_masked:
  - -0.14131225022039662
  - -0.14326936031236476
  - -0.1430132849804919
  - -0.14584690928181435
  - -0.14262518195132112
  train_level0__neg_hamming_loss_macro_oob:
  - -0.23113987774181952
  - -0.2326656015730613
  - -0.23327018707080274
  - -0.23732741376786842
  - -0.23276699029126216
  train_level0__neg_hamming_loss_micro:
  - -0.22991729593671342
  - -0.2320511244930564
  - -0.23210987449680323
  - -0.23644923647363028
  - -0.23177184466019418
  train_level0__neg_hamming_loss_micro_masked:
  - -0.13008328585768156
  - -0.1319403816687561
  - -0.13177878552070196
  - -0.134180790960452
  - -0.1313184093284198
  train_level0__neg_hamming_loss_micro_oob:
  - -0.2311398777418195
  - -0.23266560157306132
  - -0.23327018707080274
  - -0.23732741376786848
  - -0.23276699029126213
  train_level0__neg_hamming_loss_samples:
  - -0.22991729593671337
  - -0.23205112449305634
  - -0.23210987449680315
  - -0.23644923647363023
  - -0.23177184466019413
  train_level0__neg_hamming_loss_samples_masked:
  - -0.13036142019527025
  - -0.1322439038619608
  - -0.1320646565396517
  - -0.13449148246189144
  - -0.1315308678223837
  train_level0__neg_hamming_loss_samples_oob:
  - -0.23113987774181943
  - -0.23266560157306124
  - -0.23327018707080266
  - -0.2373274137678684
  - -0.23276699029126205
  train_level0__neg_hamming_loss_weighted:
  - -0.3398648104006172
  - -0.3380274316964576
  - -0.33906094103468376
  - -0.3475390001079284
  - -0.34017131121971506
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.22759867275500298
  - -0.22931658008752595
  - -0.22822830812169392
  - -0.23282286841285482
  - -0.22848485366890858
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.3444261479152832
  - -0.3403148679369626
  - -0.34345370397810904
  - -0.350810934747729
  - -0.34396563377352607
  train_level0__neg_label_ranking_loss:
  - -0.16208818016922863
  - -0.16291287299817966
  - -0.16332306314891445
  - -0.1612878292886111
  - -0.1633456027379271
  train_level0__neg_label_ranking_loss_oob:
  - -0.24919448027906724
  - -0.2539931953459911
  - -0.2548756044508064
  - -0.24920114815800673
  - -0.2508932022926534
  train_level0__precision_macro:
  - 0.7700827040632866
  - 0.7679488755069435
  - 0.7678901255031968
  - 0.7635507635263696
  - 0.7682281553398058
  train_level0__precision_macro_masked:
  - 0.8586877497796034
  - 0.8567306396876352
  - 0.856986715019508
  - 0.8541530907181858
  - 0.8573748180486787
  train_level0__precision_macro_oob:
  - 0.7688601222581806
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__precision_micro:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031968
  - 0.7635507635263697
  - 0.7682281553398058
  train_level0__precision_micro_masked:
  - 0.8699167141423184
  - 0.8680596183312439
  - 0.868221214479298
  - 0.865819209039548
  - 0.8686815906715802
  train_level0__precision_micro_oob:
  - 0.7688601222581805
  - 0.7673343984269386
  - 0.7667298129291973
  - 0.7626725862321315
  - 0.7672330097087379
  train_level0__precision_samples:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031966
  - 0.7635507635263696
  - 0.7682281553398059
  train_level0__precision_samples_masked:
  - 0.8696385798047298
  - 0.8677560961380392
  - 0.8679353434603483
  - 0.8655085175381086
  - 0.8684691321776162
  train_level0__precision_samples_oob:
  - 0.7688601222581803
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__precision_weighted:
  - 0.6601351895993827
  - 0.6619725683035425
  - 0.6609390589653164
  - 0.6524609998920716
  - 0.6598286887802849
  train_level0__precision_weighted_masked:
  - 0.7724013272449971
  - 0.7706834199124739
  - 0.7717716918783062
  - 0.7671771315871451
  - 0.7715151463310918
  train_level0__precision_weighted_oob:
  - 0.6555738520847167
  - 0.6596851320630375
  - 0.6565462960218911
  - 0.649189065252271
  - 0.6560343662264738
  train_level0__recall_macro:
  - 0.7700827040632866
  - 0.7679488755069435
  - 0.7678901255031968
  - 0.7635507635263696
  - 0.7682281553398058
  train_level0__recall_macro_masked:
  - 0.8586877497796034
  - 0.8567306396876352
  - 0.856986715019508
  - 0.8541530907181858
  - 0.8573748180486787
  train_level0__recall_macro_oob:
  - 0.7688601222581806
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__recall_micro:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031968
  - 0.7635507635263697
  - 0.7682281553398058
  train_level0__recall_micro_masked:
  - 0.8699167141423184
  - 0.8680596183312439
  - 0.868221214479298
  - 0.865819209039548
  - 0.8686815906715802
  train_level0__recall_micro_oob:
  - 0.7688601222581805
  - 0.7673343984269386
  - 0.7667298129291973
  - 0.7626725862321315
  - 0.7672330097087379
  train_level0__recall_samples:
  - 0.7700827040632866
  - 0.7679488755069436
  - 0.7678901255031966
  - 0.7635507635263696
  - 0.7682281553398059
  train_level0__recall_samples_masked:
  - 0.8696385798047298
  - 0.8677560961380392
  - 0.8679353434603483
  - 0.8655085175381086
  - 0.8684691321776162
  train_level0__recall_samples_oob:
  - 0.7688601222581803
  - 0.7673343984269386
  - 0.7667298129291972
  - 0.7626725862321315
  - 0.7672330097087378
  train_level0__recall_weighted:
  - 0.6601351895993827
  - 0.6619725683035425
  - 0.6609390589653164
  - 0.6524609998920716
  - 0.6598286887802849
  train_level0__recall_weighted_masked:
  - 0.7724013272449971
  - 0.7706834199124739
  - 0.7717716918783062
  - 0.7671771315871451
  - 0.7715151463310918
  train_level0__recall_weighted_oob:
  - 0.6555738520847167
  - 0.6596851320630375
  - 0.6565462960218911
  - 0.649189065252271
  - 0.6560343662264738
  train_level0__roc_auc_macro:
  - 0.8013635494339976
  - 0.8034176357609824
  - 0.8015698282950967
  - 0.8093770288653918
  - 0.7988152931122646
  train_level0__roc_auc_macro_masked:
  - 0.6174813232888618
  - 0.6234661338171447
  - 0.61571464948056
  - 0.6350501171595944
  - 0.6155351862966977
  train_level0__roc_auc_macro_oob:
  - 0.5511838331017114
  - 0.550407253291493
  - 0.5380450794585994
  - 0.5588262149893578
  - 0.5511678979956904
  train_level0__roc_auc_micro:
  - 0.8375534624000089
  - 0.8361593358810971
  - 0.8359012357798737
  - 0.8384725786155992
  - 0.8367868787538042
  train_level0__roc_auc_micro_masked:
  - 0.7665628542330609
  - 0.7640795841356786
  - 0.7632615194311162
  - 0.7683948030766775
  - 0.7650758663205286
  train_level0__roc_auc_micro_oob:
  - 0.7471566620707677
  - 0.7426187044401553
  - 0.7420196753647685
  - 0.7478294056904884
  - 0.7465172708471599
  train_level0__roc_auc_samples:
  - 0.8379118198307715
  - 0.8370871270018204
  - 0.8366769368510856
  - 0.8387121707113889
  - 0.8366543972620729
  train_level0__roc_auc_samples_masked:
  - 0.7685031175116659
  - 0.7680813596031506
  - 0.7659160625651806
  - 0.7705965741847471
  - 0.7676445165408627
  train_level0__roc_auc_samples_oob:
  - 0.7508055197209327
  - 0.7460068046540088
  - 0.7451243955491935
  - 0.7507988518419934
  - 0.7491067977073468
  train_level0__roc_auc_weighted:
  - 0.7938467286706955
  - 0.7954055573667687
  - 0.7984350450298976
  - 0.8000264278571414
  - 0.7925763955712009
  train_level0__roc_auc_weighted_masked:
  - 0.6152100085545453
  - 0.6196911795778149
  - 0.6179834945979434
  - 0.6277031526642292
  - 0.6158903813614727
  train_level0__roc_auc_weighted_oob:
  - 0.5520928207318584
  - 0.5546377324166383
  - 0.543749629051923
  - 0.5591350505190925
  - 0.5565077186120422
  train_level0__tn_macro:
  - 0.7686923169123816
  - 0.7658104952685265
  - 0.766137816717973
  - 0.7626237986046738
  - 0.7665776699029125
  train_level0__tn_macro_masked:
  - 0.8586877497796034
  - 0.856641975414904
  - 0.856901550652279
  - 0.8541530907181858
  - 0.8571998858349116
  train_level0__tn_macro_oob:
  - 0.7685724559510968
  - 0.7657367580189259
  - 0.766043097324177
  - 0.7626237986046738
  - 0.7665533980582523
  train_level0__tn_micro:
  - 0.7686923169123816
  - 0.7658104952685265
  - 0.766137816717973
  - 0.7626237986046739
  - 0.7665776699029127
  train_level0__tn_micro_masked:
  - 0.8699167141423184
  - 0.8680039002646608
  - 0.8681675476963533
  - 0.865819209039548
  - 0.8685715857213575
  train_level0__tn_micro_oob:
  - 0.7685724559510967
  - 0.7657367580189259
  - 0.7660430973241771
  - 0.7626237986046739
  - 0.7665533980582524
  train_level0__tn_samples:
  - 0.7686923169123816
  - 0.7658104952685264
  - 0.7661378167179729
  - 0.7626237986046737
  - 0.7665776699029127
  train_level0__tn_samples_masked:
  - 0.8696385798047298
  - 0.8676988673684577
  - 0.8678828913229237
  - 0.8655085175381086
  - 0.8683570009144634
  train_level0__tn_samples_oob:
  - 0.7685724559510966
  - 0.7657367580189258
  - 0.7660430973241771
  - 0.7626237986046737
  - 0.7665533980582524
  train_level0__tn_weighted:
  - 0.6549415342727257
  - 0.6539112688388632
  - 0.6543050904385108
  - 0.6490072911056155
  - 0.6535356660081105
  train_level0__tn_weighted_masked:
  - 0.7724013272449971
  - 0.7703441110807083
  - 0.7714485249134688
  - 0.7671771315871451
  - 0.770844042081833
  train_level0__tn_weighted_oob:
  - 0.6544898786927321
  - 0.6536306539840799
  - 0.6539464975451699
  - 0.6490072911056155
  - 0.6534431215555785
  train_level0__tp_macro:
  - 0.00139038715090495
  - 0.0021383802384171073
  - 0.0017523087852237744
  - 0.0009269649216958579
  - 0.001650485436893204
  train_level0__tp_macro_masked:
  - 0.0
  - 8.866427273130292e-05
  - 8.516436722875149e-05
  - 0.0
  - 0.00017493221376716522
  train_level0__tp_macro_oob:
  - 0.00028766630708378283
  - 0.0015976404080127813
  - 0.0006867156050201278
  - 4.878762745767674e-05
  - 0.000679611650485437
  train_level0__tp_micro:
  - 0.0013903871509049503
  - 0.002138380238417107
  - 0.0017523087852237746
  - 0.0009269649216958579
  - 0.0016504854368932038
  train_level0__tp_micro_masked:
  - 0.0
  - 5.5718066583089564e-05
  - 5.366678294469638e-05
  - 0.0
  - 0.00011000495022276003
  train_level0__tp_micro_oob:
  - 0.00028766630708378283
  - 0.0015976404080127811
  - 0.0006867156050201279
  - 4.878762745767673e-05
  - 0.0006796116504854369
  train_level0__tp_samples:
  - 0.00139038715090495
  - 0.002138380238417107
  - 0.0017523087852237744
  - 0.0009269649216958578
  - 0.0016504854368932036
  train_level0__tp_samples_masked:
  - 0.0
  - 5.7228769581454005e-05
  - 5.245213742460006e-05
  - 0.0
  - 0.00011213126315286688
  train_level0__tp_samples_oob:
  - 0.0002876663070837828
  - 0.001597640408012781
  - 0.0006867156050201278
  - 4.878762745767673e-05
  - 0.0006796116504854369
  train_level0__tp_weighted:
  - 0.005193655326657019
  - 0.008061299464679332
  - 0.00663396852680556
  - 0.0034537087864561734
  - 0.006293022772174275
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0003393088317654759
  - 0.00032316696483729166
  - 0.0
  - 0.0006711042492586748
  train_level0__tp_weighted_oob:
  - 0.0010839733919845848
  - 0.006054478078957474
  - 0.0025997984767210974
  - 0.0001817741466555881
  - 0.0025912446708952898
  train_level10__average_precision_macro:
  - 0.2548642176968659
  - 0.2613687031025668
  - 0.25129326087168846
  - 0.2741774278367262
  - 0.2662357439316136
  train_level10__average_precision_macro_masked:
  - 0.15711489653315897
  - 0.16233896907950549
  - 0.15637681475396722
  - 0.17164381196519063
  - 0.1672461012179751
  train_level10__average_precision_macro_oob:
  - 0.2536647121082779
  - 0.25894778325002965
  - 0.24943028874463385
  - 0.2685937088408737
  - 0.2633905216494898
  train_level10__average_precision_micro:
  - 0.22443140694859287
  - 0.22236856582857342
  - 0.21960072184420565
  - 0.24934784783515773
  - 0.22826820671193765
  train_level10__average_precision_micro_masked:
  - 0.12545018587626575
  - 0.1241441525964952
  - 0.12272916374264012
  - 0.14132452437189527
  - 0.12803045079047237
  train_level10__average_precision_micro_oob:
  - 0.22442658767848023
  - 0.22217612897087424
  - 0.2199577200280392
  - 0.24901692300495964
  - 0.2280497811539452
  train_level10__average_precision_samples:
  - 0.22808965478661608
  - 0.22763048853657925
  - 0.22368526561869523
  - 0.2567434596232946
  - 0.2330385354898957
  train_level10__average_precision_samples_masked:
  - 0.13082259892349768
  - 0.13064108216762413
  - 0.1283377535883646
  - 0.1506996796788441
  - 0.13433195194776315
  train_level10__average_precision_samples_oob:
  - 0.228039193443424
  - 0.2273933920477733
  - 0.22406842955016373
  - 0.2563381501784001
  - 0.23277486165489109
  train_level10__average_precision_weighted:
  - 0.3690227205929777
  - 0.3770215801610777
  - 0.3633818161883917
  - 0.3882348209984751
  - 0.3848730708203032
  train_level10__average_precision_weighted_masked:
  - 0.24581133207344366
  - 0.2536524276763504
  - 0.24333553922754061
  - 0.2615492108565341
  - 0.2589002211539264
  train_level10__average_precision_weighted_oob:
  - 0.367495437703802
  - 0.3740027215278528
  - 0.3613653937993436
  - 0.38204792145790467
  - 0.3816005976972303
  train_level10__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level10__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level10__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level10__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level10__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level10__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level10__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level10__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level10__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level10__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level10__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level10__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level10__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level10__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level10__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level10__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level10__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level10__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level10__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level10__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level10__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level10__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level10__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level10__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level10__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level10__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level10__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level10__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level10__label_ranking_average_precision_score:
  - 0.22808965478661627
  - 0.2276304885365791
  - 0.22368526561869512
  - 0.2567434596232945
  - 0.23303853548989586
  train_level10__label_ranking_average_precision_score_oob:
  - 0.2280391934434238
  - 0.22739339204777326
  - 0.22406842955016365
  - 0.2563381501784001
  - 0.23277486165489109
  train_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__ndcg:
  - 0.6151356304170089
  - 0.6133139183332946
  - 0.610941211073869
  - 0.6347158157313711
  - 0.617909409043489
  train_level10__ndcg_oob:
  - 0.6151836830650387
  - 0.6132914656356097
  - 0.611480786214212
  - 0.6348927587207923
  - 0.6179904684466035
  train_level10__neg_coverage_error:
  - -95.55308641975309
  - -95.97215189873418
  - -96.8829268292683
  - -94.32412060301507
  - -95.1925
  train_level10__neg_coverage_error_oob:
  - -95.5604938271605
  - -96.14936708860759
  - -96.8780487804878
  - -94.93969849246231
  - -95.5
  train_level10__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level10__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level10__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level10__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level10__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level10__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level10__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level10__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level10__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level10__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level10__neg_label_ranking_loss:
  - -0.6739911659900518
  - -0.6472155274957087
  - -0.6899651508053865
  - -0.5410380985477297
  - -0.6217579824368071
  train_level10__neg_label_ranking_loss_oob:
  - -0.6751523454117963
  - -0.6495534336680735
  - -0.6915218247033517
  - -0.5445147707832237
  - -0.6239626037510765
  train_level10__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level10__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level10__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level10__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level10__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level10__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level10__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level10__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level10__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__roc_auc_macro:
  - 0.5358109847884777
  - 0.5400635289237307
  - 0.5276824566902267
  - 0.557550393328677
  - 0.545951191790793
  train_level10__roc_auc_macro_masked:
  - 0.5260204352616049
  - 0.5300538395889962
  - 0.5234191785024813
  - 0.5452721810950961
  - 0.5372244595490854
  train_level10__roc_auc_macro_oob:
  - 0.5328596987402497
  - 0.5361503768566692
  - 0.525309531533455
  - 0.5496823311180888
  - 0.5397630463064126
  train_level10__roc_auc_micro:
  - 0.4964072603985237
  - 0.4876475895787697
  - 0.4768452605345788
  - 0.5450316468575155
  - 0.5035183302389507
  train_level10__roc_auc_micro_masked:
  - 0.4943080509067359
  - 0.48503474151905746
  - 0.4759827897925606
  - 0.5418790852148953
  - 0.502204360512243
  train_level10__roc_auc_micro_oob:
  - 0.49600870974110245
  - 0.48659872277083344
  - 0.4770823601794977
  - 0.5428730298899593
  - 0.5020126248021248
  train_level10__roc_auc_samples:
  - 0.49725970332450037
  - 0.4892268862805693
  - 0.47564195520550107
  - 0.5451058358652431
  - 0.5030733099938057
  train_level10__roc_auc_samples_masked:
  - 0.4943203121772803
  - 0.4858309142403287
  - 0.474508889044268
  - 0.542729580803222
  - 0.5014820340803816
  train_level10__roc_auc_samples_oob:
  - 0.49674208072826703
  - 0.4882525336384926
  - 0.47614429406637665
  - 0.5429320162132728
  - 0.5016509289265894
  train_level10__roc_auc_weighted:
  - 0.5319283149169294
  - 0.5435121738442557
  - 0.525747254772766
  - 0.5538319834639883
  - 0.5495364530089378
  train_level10__roc_auc_weighted_masked:
  - 0.5246697263403948
  - 0.5342196210501756
  - 0.523252612652432
  - 0.5436022851851653
  - 0.5428886271685484
  train_level10__roc_auc_weighted_oob:
  - 0.5290167099856036
  - 0.5376023697170377
  - 0.521595859016326
  - 0.5456701748411054
  - 0.5425400930303182
  train_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level10__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level10__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level10__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level10__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level10__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level10__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level10__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level10__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__average_precision_macro:
  - 0.2564781505181007
  - 0.2649000957515012
  - 0.26137971254145903
  - 0.2785960701601115
  - 0.26937185028376964
  train_level1__average_precision_macro_masked:
  - 0.1581242457263369
  - 0.16344969765373038
  - 0.16239970863336115
  - 0.17314519091814418
  - 0.16751674447044995
  train_level1__average_precision_macro_oob:
  - 0.2534113448885564
  - 0.2617082452084669
  - 0.26029080481676126
  - 0.27633090043650027
  - 0.26763407468925615
  train_level1__average_precision_micro:
  - 0.2255346978991185
  - 0.22667831237144231
  - 0.2232438978439811
  - 0.2550270841290791
  - 0.23127306559504363
  train_level1__average_precision_micro_masked:
  - 0.12604548610969354
  - 0.12668650504352147
  - 0.12491661796150319
  - 0.14492189544766432
  - 0.12974877006659583
  train_level1__average_precision_micro_oob:
  - 0.22534465879267296
  - 0.22650698774759292
  - 0.22369813146040535
  - 0.25421763756482
  - 0.23080590631281497
  train_level1__average_precision_samples:
  - 0.22919897615892146
  - 0.2323339113446901
  - 0.2274064946352918
  - 0.2627109501706825
  - 0.23624148532007386
  train_level1__average_precision_samples_masked:
  - 0.13148339194846606
  - 0.13366373923652708
  - 0.13071767155034406
  - 0.15472601442020825
  - 0.1363157748646755
  train_level1__average_precision_samples_oob:
  - 0.22895828248504618
  - 0.23211279432719673
  - 0.22785228315420475
  - 0.2618363171315304
  - 0.23573362194338088
  train_level1__average_precision_weighted:
  - 0.37087207219617996
  - 0.3780534840779319
  - 0.37426680488055625
  - 0.3923330810234315
  - 0.38675153955457237
  train_level1__average_precision_weighted_masked:
  - 0.2456856038799396
  - 0.2525491452802915
  - 0.24989797531566968
  - 0.2639974962540417
  - 0.2589307743402163
  train_level1__average_precision_weighted_oob:
  - 0.3679446571138656
  - 0.3759687329491851
  - 0.37353029551961264
  - 0.3891803746656853
  - 0.38446474670656916
  train_level1__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level1__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level1__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level1__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level1__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level1__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level1__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level1__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level1__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level1__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level1__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level1__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level1__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level1__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level1__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level1__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level1__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level1__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level1__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level1__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level1__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level1__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level1__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level1__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level1__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level1__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level1__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level1__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level1__label_ranking_average_precision_score:
  - 0.22919897615892135
  - 0.23233391134468986
  - 0.22740649463529167
  - 0.2627109501706823
  - 0.2362414853200736
  train_level1__label_ranking_average_precision_score_oob:
  - 0.22895828248504627
  - 0.23211279432719667
  - 0.22785228315420467
  - 0.26183631713153055
  - 0.23573362194338085
  train_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__ndcg:
  - 0.6162078061438795
  - 0.6177459722426875
  - 0.6143307820454601
  - 0.6404348340557867
  - 0.6209985742310812
  train_level1__ndcg_oob:
  - 0.6161080209162216
  - 0.61770730051289
  - 0.6149117439583168
  - 0.639963557518499
  - 0.6207317103655957
  train_level1__neg_coverage_error:
  - -95.72592592592592
  - -95.64303797468355
  - -96.51463414634146
  - -93.89949748743719
  - -95.12
  train_level1__neg_coverage_error_oob:
  - -95.720987654321
  - -95.89873417721519
  - -96.5170731707317
  - -94.20603015075378
  - -95.495
  train_level1__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level1__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level1__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level1__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level1__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level1__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level1__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level1__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level1__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level1__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level1__neg_label_ranking_loss:
  - -0.668228636257926
  - -0.6276222287116616
  - -0.6737078815815908
  - -0.5242722701776866
  - -0.6099244495427226
  train_level1__neg_label_ranking_loss_oob:
  - -0.6701301003169454
  - -0.6300616699063443
  - -0.6752222625682879
  - -0.5279556200972738
  - -0.6127671562368753
  train_level1__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level1__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level1__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level1__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level1__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level1__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level1__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level1__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level1__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__roc_auc_macro:
  - 0.5383361337672258
  - 0.543395043851154
  - 0.5380865693957991
  - 0.5605928876016608
  - 0.5502363728237786
  train_level1__roc_auc_macro_masked:
  - 0.5254558123619312
  - 0.5306666849060393
  - 0.5277129807102772
  - 0.5453486749575056
  - 0.5388803153864369
  train_level1__roc_auc_macro_oob:
  - 0.5342403090201058
  - 0.5405177955854058
  - 0.5352854189082946
  - 0.5547388862065549
  - 0.5453842275014852
  train_level1__roc_auc_micro:
  - 0.4986030195636827
  - 0.49617740419755463
  - 0.4855527809847987
  - 0.5532497206883857
  - 0.508886045250341
  train_level1__roc_auc_micro_masked:
  - 0.4958927256849744
  - 0.49280260991250363
  - 0.4839975196282032
  - 0.54971365307285
  - 0.5067115642248943
  train_level1__roc_auc_micro_oob:
  - 0.49776997666429484
  - 0.49524634574781207
  - 0.48611626819530096
  - 0.5510503569267625
  - 0.5071854668117495
  train_level1__roc_auc_samples:
  - 0.49919932150605795
  - 0.49774004444348974
  - 0.48433558409683725
  - 0.5532967362271521
  - 0.5083902242754944
  train_level1__roc_auc_samples_masked:
  - 0.4957519706651983
  - 0.4937387536583733
  - 0.48244654271553883
  - 0.5504288412785847
  - 0.5061572290577603
  train_level1__roc_auc_samples_oob:
  - 0.4982431058261003
  - 0.49675226295598157
  - 0.4851699810156993
  - 0.5512751178515646
  - 0.506641033939927
  train_level1__roc_auc_weighted:
  - 0.5341062842672832
  - 0.5446253069017766
  - 0.5369942865863073
  - 0.5564587669278693
  - 0.5532766067790608
  train_level1__roc_auc_weighted_masked:
  - 0.5235293376874408
  - 0.5317006489596254
  - 0.5290498653371198
  - 0.5462098991162594
  - 0.5443923075847973
  train_level1__roc_auc_weighted_oob:
  - 0.5315800382392536
  - 0.5408261045455911
  - 0.5341036515375124
  - 0.5497923498993614
  - 0.5475977690947076
  train_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level1__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level1__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level1__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level1__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level1__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level1__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level1__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level1__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__average_precision_macro:
  - 0.25342105965779205
  - 0.25945585388760367
  - 0.2538737276109754
  - 0.27450512778736635
  - 0.26702836883752057
  train_level2__average_precision_macro_masked:
  - 0.15639493912974728
  - 0.16002672240481783
  - 0.1579508410297329
  - 0.1711429607505266
  - 0.16675947323528734
  train_level2__average_precision_macro_oob:
  - 0.2519708017783117
  - 0.25682374843203193
  - 0.2508839389090698
  - 0.2693035462777106
  - 0.2623327029328589
  train_level2__average_precision_micro:
  - 0.22424581353538606
  - 0.22208718780208314
  - 0.2196027460621667
  - 0.2494891753307857
  - 0.22819255016097426
  train_level2__average_precision_micro_masked:
  - 0.12529768220219498
  - 0.1240266522721132
  - 0.12267307265442905
  - 0.14144866278614698
  - 0.12799932987672102
  train_level2__average_precision_micro_oob:
  - 0.22435993642179558
  - 0.22198464059942108
  - 0.21989410302568804
  - 0.24890840456725818
  - 0.22786124026667492
  train_level2__average_precision_samples:
  - 0.22782729113078934
  - 0.2273950621925685
  - 0.22375448829107297
  - 0.25690568122418944
  - 0.23298757363321027
  train_level2__average_precision_samples_masked:
  - 0.13065291656536068
  - 0.13059253483960886
  - 0.12837209802797978
  - 0.1508474328195731
  - 0.13430623326637214
  train_level2__average_precision_samples_oob:
  - 0.2279247066639641
  - 0.22720585224688333
  - 0.22391306185095552
  - 0.25630092909428803
  - 0.2325587100684519
  train_level2__average_precision_weighted:
  - 0.3688208406392813
  - 0.37395290496266104
  - 0.3673465388808521
  - 0.3895311802046164
  - 0.384558927974544
  train_level2__average_precision_weighted_masked:
  - 0.24562124166937443
  - 0.25143577190448185
  - 0.24636594783902094
  - 0.26302170018640353
  - 0.2582664586945638
  train_level2__average_precision_weighted_oob:
  - 0.36812304133276547
  - 0.37106291593201296
  - 0.3644740644965195
  - 0.38372200967313913
  - 0.3786769105406542
  train_level2__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level2__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level2__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level2__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level2__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level2__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level2__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level2__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level2__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level2__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level2__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level2__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level2__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level2__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level2__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level2__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level2__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level2__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level2__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level2__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level2__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level2__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level2__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level2__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level2__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level2__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level2__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level2__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level2__label_ranking_average_precision_score:
  - 0.2278272911307893
  - 0.22739506219256858
  - 0.2237544882910731
  - 0.2569056812241897
  - 0.23298757363321013
  train_level2__label_ranking_average_precision_score_oob:
  - 0.2279247066639643
  - 0.22720585224688336
  - 0.22391306185095552
  - 0.256300929094288
  - 0.23255871006845194
  train_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__ndcg:
  - 0.6149743575176759
  - 0.6131475805728278
  - 0.6109128134526419
  - 0.6348206505162715
  - 0.6179002325657746
  train_level2__ndcg_oob:
  - 0.6151898873003471
  - 0.6132163282547707
  - 0.6113029335553051
  - 0.6347004379927996
  - 0.6178059863767207
  train_level2__neg_coverage_error:
  - -95.75555555555556
  - -96.01518987341773
  - -96.68048780487806
  - -94.28894472361809
  - -95.345
  train_level2__neg_coverage_error_oob:
  - -95.89382716049383
  - -96.06075949367089
  - -96.90243902439025
  - -94.60050251256281
  - -95.6
  train_level2__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level2__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level2__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level2__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level2__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level2__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level2__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level2__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level2__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level2__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level2__neg_label_ranking_loss:
  - -0.6747657439853576
  - -0.6474859798706365
  - -0.6892860668669988
  - -0.5407517535267953
  - -0.6221223756124463
  train_level2__neg_label_ranking_loss_oob:
  - -0.6757896729731312
  - -0.6499260793342009
  - -0.6913530654472857
  - -0.5437484645673267
  - -0.6246662977278004
  train_level2__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level2__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level2__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level2__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level2__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level2__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level2__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level2__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level2__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__roc_auc_macro:
  - 0.5337728935089838
  - 0.5355529035838908
  - 0.5299455567624131
  - 0.5566781982715285
  - 0.5459361783000097
  train_level2__roc_auc_macro_masked:
  - 0.5225384964746694
  - 0.5261508788226235
  - 0.5232127902847376
  - 0.5447380118209284
  - 0.536506391267479
  train_level2__roc_auc_macro_oob:
  - 0.5311741741662906
  - 0.5317407394369245
  - 0.5262893975486473
  - 0.5495029292739693
  - 0.5391943420029428
  train_level2__roc_auc_micro:
  - 0.4958279901987568
  - 0.48676805007276147
  - 0.4770887696313561
  - 0.5454417411847988
  - 0.503141024408713
  train_level2__roc_auc_micro_masked:
  - 0.49350555784741945
  - 0.4843102205199475
  - 0.47577590445891793
  - 0.5423281533045308
  - 0.5018732547513765
  train_level2__roc_auc_micro_oob:
  - 0.4956347611556709
  - 0.4858069217811455
  - 0.4772194075923913
  - 0.5430464256434631
  - 0.5014481797181874
  train_level2__roc_auc_samples:
  - 0.4963603947973128
  - 0.48860730502205924
  - 0.4761149636540858
  - 0.5453990797310054
  - 0.5026572753365735
  train_level2__roc_auc_samples_masked:
  - 0.4935023982036918
  - 0.4854569768882103
  - 0.47501709460136154
  - 0.5430063004026565
  - 0.5012008816787731
  train_level2__roc_auc_samples_oob:
  - 0.4961977398095094
  - 0.48745587873600993
  - 0.47617955441656795
  - 0.543292540549021
  - 0.5007432205926472
  train_level2__roc_auc_weighted:
  - 0.5310287766586211
  - 0.538005518237467
  - 0.5287805807823729
  - 0.5535356357070121
  - 0.5494708445852491
  train_level2__roc_auc_weighted_masked:
  - 0.521673538655024
  - 0.5288146410890749
  - 0.5236525963489563
  - 0.5443124865505408
  - 0.5431436033148174
  train_level2__roc_auc_weighted_oob:
  - 0.5288331112799014
  - 0.5350751095153424
  - 0.5248730464837531
  - 0.5458295622756998
  - 0.5415897617621321
  train_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level2__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level2__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level2__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level2__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level2__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level2__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level2__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level2__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__average_precision_macro:
  - 0.2521766207076933
  - 0.2599677666979744
  - 0.25015619589326665
  - 0.2753154862208269
  - 0.26775608681339175
  train_level3__average_precision_macro_masked:
  - 0.15655324318454295
  - 0.16126127006585494
  - 0.15505840620060002
  - 0.17248817032058594
  - 0.16745068266152435
  train_level3__average_precision_macro_oob:
  - 0.24917453456041036
  - 0.2578687781541907
  - 0.2490058099001031
  - 0.2705060186013654
  - 0.26281824563080086
  train_level3__average_precision_micro:
  - 0.22411891684557633
  - 0.222225312902589
  - 0.2195913673338169
  - 0.24913339524712128
  - 0.22814700239709582
  train_level3__average_precision_micro_masked:
  - 0.12531591556214305
  - 0.12414465254207471
  - 0.12271787683530173
  - 0.1412586900934053
  - 0.1278301634846986
  train_level3__average_precision_micro_oob:
  - 0.2240974820780297
  - 0.2221124305157618
  - 0.21976028966151318
  - 0.2487921001062262
  - 0.22783424556975435
  train_level3__average_precision_samples:
  - 0.22776651045793023
  - 0.22750931508829492
  - 0.2237195002251022
  - 0.25655121161494604
  - 0.23301588971831233
  train_level3__average_precision_samples_masked:
  - 0.130681751202501
  - 0.13066599969765924
  - 0.1283320860962119
  - 0.15071556533212122
  - 0.13421005893791935
  train_level3__average_precision_samples_oob:
  - 0.22772018497928623
  - 0.22736408032845734
  - 0.2238466969183646
  - 0.256193424312833
  - 0.23257550804074079
  train_level3__average_precision_weighted:
  - 0.36738769877035493
  - 0.3756663257164717
  - 0.36305248675455065
  - 0.3882423224935942
  - 0.38644959135416557
  train_level3__average_precision_weighted_masked:
  - 0.24551541392545698
  - 0.2530982508125846
  - 0.24192813265778382
  - 0.2617541809967272
  - 0.25881999148452006
  train_level3__average_precision_weighted_oob:
  - 0.3632738854115795
  - 0.3732789811387865
  - 0.3610122927540375
  - 0.3832839729259953
  - 0.380758034295135
  train_level3__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level3__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level3__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level3__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level3__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level3__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level3__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level3__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level3__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level3__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level3__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level3__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level3__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level3__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level3__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level3__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level3__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level3__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level3__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level3__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level3__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level3__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level3__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level3__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level3__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level3__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level3__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level3__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level3__label_ranking_average_precision_score:
  - 0.22776651045793028
  - 0.22750931508829517
  - 0.22371950022510237
  - 0.256551211614946
  - 0.2330158897183124
  train_level3__label_ranking_average_precision_score_oob:
  - 0.22772018497928614
  - 0.2273640803284571
  - 0.22384669691836462
  - 0.25619342431283304
  - 0.23257550804074065
  train_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__ndcg:
  - 0.614886051748594
  - 0.613207799897628
  - 0.6109234496261718
  - 0.6346081919633261
  - 0.6178723378965777
  train_level3__ndcg_oob:
  - 0.6149704605129427
  - 0.6132661820520948
  - 0.6112358536082378
  - 0.6347211180441353
  - 0.6178004243363389
  train_level3__neg_coverage_error:
  - -95.93827160493827
  - -95.88607594936708
  - -96.77560975609757
  - -94.34924623115577
  - -95.305
  train_level3__neg_coverage_error_oob:
  - -96.12592592592593
  - -96.14683544303797
  - -96.87317073170732
  - -94.76884422110552
  - -95.6225
  train_level3__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level3__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level3__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level3__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level3__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level3__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level3__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level3__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level3__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level3__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level3__neg_label_ranking_loss:
  - -0.6748252541441284
  - -0.6470901345610555
  - -0.6897316739377622
  - -0.5412141435865215
  - -0.6219630664530518
  train_level3__neg_label_ranking_loss_oob:
  - -0.676196050606096
  - -0.649031360939914
  - -0.6918563137581686
  - -0.544188259797605
  - -0.6247805168862012
  train_level3__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level3__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level3__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level3__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level3__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level3__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level3__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level3__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level3__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__roc_auc_macro:
  - 0.5309899804066055
  - 0.5371495778449876
  - 0.52569405226189
  - 0.5563185919562064
  - 0.5445455703205233
  train_level3__roc_auc_macro_masked:
  - 0.5231495824889322
  - 0.5275639393802952
  - 0.5200016453035569
  - 0.5454533224432071
  - 0.5356845564366662
  train_level3__roc_auc_macro_oob:
  - 0.5267681790788878
  - 0.5337932293234146
  - 0.5209342784370483
  - 0.5488206738580559
  - 0.5397723383108809
  train_level3__roc_auc_micro:
  - 0.4954325503524615
  - 0.4873130718521062
  - 0.4768577602175489
  - 0.5445231731498166
  - 0.5030870363283448
  train_level3__roc_auc_micro_masked:
  - 0.49364610803044584
  - 0.4850793262279921
  - 0.47573954830367865
  - 0.5418041062926079
  - 0.5012700056355989
  train_level3__roc_auc_micro_oob:
  - 0.4948634254369794
  - 0.4864801817002704
  - 0.4767342374365918
  - 0.5424678399041368
  - 0.5013784870919382
  train_level3__roc_auc_samples:
  - 0.49612911124574177
  - 0.48893357973055135
  - 0.47583012090581955
  - 0.544655039464445
  - 0.5028234736859637
  train_level3__roc_auc_samples_masked:
  - 0.4935025796379305
  - 0.486070861305721
  - 0.4745271258784295
  - 0.5427674075079564
  - 0.5009628502264064
  train_level3__roc_auc_samples_oob:
  - 0.4954536953943528
  - 0.48806385895381865
  - 0.475775591646405
  - 0.5429030759538525
  - 0.5008183739848975
  train_level3__roc_auc_weighted:
  - 0.5282378629361375
  - 0.5389955893446827
  - 0.5257208123473358
  - 0.5512516434037857
  - 0.5496524101557866
  train_level3__roc_auc_weighted_masked:
  - 0.5222305108298642
  - 0.5308406655081876
  - 0.5200742563793315
  - 0.5432732291347181
  - 0.5420457496288146
  train_level3__roc_auc_weighted_oob:
  - 0.5229745473527014
  - 0.5357290232073747
  - 0.5187417425715573
  - 0.5440108576884481
  - 0.5432490660235085
  train_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level3__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level3__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level3__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level3__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level3__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level3__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level3__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level3__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__average_precision_macro:
  - 0.25207236696684326
  - 0.261383490014061
  - 0.25375782283461396
  - 0.2735713924704996
  - 0.26539040550838683
  train_level4__average_precision_macro_masked:
  - 0.1542240824185311
  - 0.16343138492615394
  - 0.15779085070538443
  - 0.17154670224922486
  - 0.16703793024921745
  train_level4__average_precision_macro_oob:
  - 0.250063892011652
  - 0.26045278532859106
  - 0.253641744803308
  - 0.27030532655313744
  - 0.26302779057562636
  train_level4__average_precision_micro:
  - 0.2241310007155102
  - 0.22240784025857374
  - 0.21967137951036667
  - 0.24908171942168852
  - 0.2279886774155591
  train_level4__average_precision_micro_masked:
  - 0.1252236553484807
  - 0.12422969314510283
  - 0.12268362508237347
  - 0.14114674847627134
  - 0.12778899857795345
  train_level4__average_precision_micro_oob:
  - 0.22413935977019248
  - 0.22235470311366745
  - 0.21992847386393602
  - 0.24869308572678048
  - 0.22772194814618008
  train_level4__average_precision_samples:
  - 0.2278002001956462
  - 0.2276718006589636
  - 0.22379816781931014
  - 0.2565907857286735
  - 0.23283610408299754
  train_level4__average_precision_samples_masked:
  - 0.13063180386294004
  - 0.13079200738677432
  - 0.12830691053991958
  - 0.15059326102874987
  - 0.13411126824072864
  train_level4__average_precision_samples_oob:
  - 0.22773861866969589
  - 0.22760004733749145
  - 0.22400210474295054
  - 0.25619224182188455
  - 0.232495138031904
  train_level4__average_precision_weighted:
  - 0.3659750668163612
  - 0.3764513804654259
  - 0.3674712013643668
  - 0.387335967409296
  - 0.38264906358487755
  train_level4__average_precision_weighted_masked:
  - 0.24140791934491565
  - 0.2551128847833897
  - 0.24507721244151695
  - 0.26117322556597267
  - 0.2571589728704936
  train_level4__average_precision_weighted_oob:
  - 0.3640875479107084
  - 0.3759582116855946
  - 0.36831045651806793
  - 0.38356804972642494
  - 0.3784537106256828
  train_level4__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level4__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level4__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level4__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level4__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level4__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level4__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level4__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level4__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level4__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level4__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level4__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level4__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level4__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level4__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level4__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level4__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level4__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level4__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level4__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level4__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level4__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level4__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level4__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level4__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level4__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level4__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level4__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level4__label_ranking_average_precision_score:
  - 0.22780020019564612
  - 0.22767180065896364
  - 0.22379816781931028
  - 0.2565907857286734
  - 0.2328361040829977
  train_level4__label_ranking_average_precision_score_oob:
  - 0.22773861866969608
  - 0.22760004733749126
  - 0.22400210474295068
  - 0.25619224182188455
  - 0.23249513803190416
  train_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__ndcg:
  - 0.6149091374637138
  - 0.613345831263268
  - 0.6109092428577506
  - 0.6346735304334444
  - 0.6177146667708843
  train_level4__ndcg_oob:
  - 0.6149979384676111
  - 0.6134375724075631
  - 0.6111887171111742
  - 0.6347578048637028
  - 0.6176741680431006
  train_level4__neg_coverage_error:
  - -95.66913580246914
  - -96.02784810126582
  - -96.86585365853658
  - -94.28391959798995
  - -95.1475
  train_level4__neg_coverage_error_oob:
  - -95.83703703703704
  - -96.0379746835443
  - -96.95121951219512
  - -94.73366834170854
  - -95.48
  train_level4__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level4__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level4__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level4__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level4__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level4__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level4__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level4__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level4__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level4__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level4__neg_label_ranking_loss:
  - -0.6747810494075485
  - -0.6470118862696529
  - -0.6891704223244797
  - -0.5413362446435345
  - -0.6221242498089601
  train_level4__neg_label_ranking_loss_oob:
  - -0.6761400620538036
  - -0.648898192659723
  - -0.6906425929257403
  - -0.5444052987355245
  - -0.6245431400419226
  train_level4__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level4__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level4__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level4__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level4__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level4__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level4__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level4__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level4__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__roc_auc_macro:
  - 0.5348880569512773
  - 0.5381331479401299
  - 0.5300964566322219
  - 0.5523653957092336
  - 0.5406929511328274
  train_level4__roc_auc_macro_masked:
  - 0.5243301789868047
  - 0.5293196170773913
  - 0.5220226783694557
  - 0.5434836466907895
  - 0.5315805583714835
  train_level4__roc_auc_macro_oob:
  - 0.5313672687463908
  - 0.5345287305799588
  - 0.5272468553004942
  - 0.5468455555802195
  - 0.5354063987785169
  train_level4__roc_auc_micro:
  - 0.49548403629660154
  - 0.4877843793983165
  - 0.47737899605851264
  - 0.5443165416077673
  - 0.5026844567147833
  train_level4__roc_auc_micro_masked:
  - 0.4932240119716589
  - 0.4855465798043661
  - 0.47588050311181385
  - 0.5414858040314259
  - 0.5009981074190688
  train_level4__roc_auc_micro_oob:
  - 0.49505659953586895
  - 0.48716018762638064
  - 0.47760065105259103
  - 0.5422303212008703
  - 0.5010833239383166
  train_level4__roc_auc_samples:
  - 0.4962765838825758
  - 0.4894792168983657
  - 0.47621904490536254
  - 0.5447131154132383
  - 0.5023278927525903
  train_level4__roc_auc_samples_masked:
  - 0.4934341954020815
  - 0.4867039209331208
  - 0.47460627166241043
  - 0.5426514429086868
  - 0.5002331718084433
  train_level4__roc_auc_samples_oob:
  - 0.4956350221025847
  - 0.48888144562825453
  - 0.47627246855558597
  - 0.5428558237888059
  - 0.5005154676778264
  train_level4__roc_auc_weighted:
  - 0.5301377848791922
  - 0.5400770742820925
  - 0.5303601091214412
  - 0.5494266008586479
  - 0.5430930811623959
  train_level4__roc_auc_weighted_masked:
  - 0.522212250566475
  - 0.5322072188586865
  - 0.5224332268263625
  - 0.5428094457679209
  - 0.535626971815751
  train_level4__roc_auc_weighted_oob:
  - 0.5285871627579856
  - 0.5372670763356846
  - 0.5286270485478355
  - 0.5438914019840101
  - 0.5365317342288037
  train_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level4__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level4__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level4__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level4__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level4__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level4__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level4__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level4__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__average_precision_macro:
  - 0.25402101357071166
  - 0.2611251029471399
  - 0.25351681096599027
  - 0.27752393923665647
  - 0.2660365624434079
  train_level5__average_precision_macro_masked:
  - 0.15728371025386378
  - 0.16038035364152226
  - 0.15811265737842375
  - 0.17757531271571725
  - 0.16655024674617125
  train_level5__average_precision_macro_oob:
  - 0.25314566445636094
  - 0.25691986422188934
  - 0.2525852297216131
  - 0.2721932621808214
  - 0.26390346736993114
  train_level5__average_precision_micro:
  - 0.2242474680237855
  - 0.22212266138124317
  - 0.21968357711923636
  - 0.24953431728661965
  - 0.2282143788248786
  train_level5__average_precision_micro_masked:
  - 0.1253168233536905
  - 0.1239598450831353
  - 0.12274880436825351
  - 0.14148776449596234
  - 0.12794260656263057
  train_level5__average_precision_micro_oob:
  - 0.2242925288477413
  - 0.22183180739796504
  - 0.21992260079126996
  - 0.24907558214803863
  - 0.22799088448498211
  train_level5__average_precision_samples:
  - 0.22791531539684745
  - 0.22739775763619827
  - 0.2238159450360538
  - 0.2570997312058512
  - 0.2331310601876104
  train_level5__average_precision_samples_masked:
  - 0.13070019786099935
  - 0.13046430378932455
  - 0.12838665779927874
  - 0.15100340572173712
  - 0.1343553437842865
  train_level5__average_precision_samples_oob:
  - 0.22794879983532126
  - 0.2271123701508413
  - 0.22403157811134689
  - 0.2566116122295246
  - 0.232842635131133
  train_level5__average_precision_weighted:
  - 0.3674633917853498
  - 0.37568294972492866
  - 0.3660104339564138
  - 0.391983693330719
  - 0.38440946232416173
  train_level5__average_precision_weighted_masked:
  - 0.2431164331530555
  - 0.2515672714328367
  - 0.24668387542423714
  - 0.2680640360107333
  - 0.2585726266800751
  train_level5__average_precision_weighted_oob:
  - 0.36680365031220197
  - 0.3720221742742586
  - 0.36492536758673244
  - 0.38596653214947707
  - 0.38083072253354344
  train_level5__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level5__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level5__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level5__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level5__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level5__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level5__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level5__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level5__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level5__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level5__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level5__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level5__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level5__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level5__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level5__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level5__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level5__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level5__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level5__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level5__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level5__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level5__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level5__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level5__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level5__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level5__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level5__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level5__label_ranking_average_precision_score:
  - 0.22791531539684745
  - 0.22739775763619818
  - 0.22381594503605393
  - 0.2570997312058513
  - 0.23313106018761037
  train_level5__label_ranking_average_precision_score_oob:
  - 0.22794879983532138
  - 0.22711237015084132
  - 0.2240315781113471
  - 0.2566116122295247
  - 0.23284263513113312
  train_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__ndcg:
  - 0.6149907676139866
  - 0.6131579438624113
  - 0.6109794257066282
  - 0.6349185874837736
  - 0.6178633787111526
  train_level5__ndcg_oob:
  - 0.6151410711742122
  - 0.6130987502044218
  - 0.61131299324779
  - 0.634855405069772
  - 0.6178787799745978
  train_level5__neg_coverage_error:
  - -95.84197530864198
  - -95.77721518987342
  - -96.72439024390243
  - -94.13316582914572
  - -95.1525
  train_level5__neg_coverage_error_oob:
  - -95.89876543209877
  - -96.02025316455696
  - -96.78536585365853
  - -94.51507537688443
  - -95.4225
  train_level5__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level5__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level5__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level5__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level5__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level5__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level5__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level5__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level5__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level5__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level5__neg_label_ranking_loss:
  - -0.6744934498312787
  - -0.647654265560987
  - -0.6893707333250014
  - -0.5398937120981971
  - -0.6210875035152551
  train_level5__neg_label_ranking_loss_oob:
  - -0.6756447783115372
  - -0.6499340432768862
  - -0.6906551214485425
  - -0.5427230895565849
  - -0.6233129804109148
  train_level5__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level5__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level5__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level5__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level5__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level5__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level5__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level5__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level5__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__roc_auc_macro:
  - 0.5347039136410563
  - 0.5365809486114326
  - 0.5291833968684926
  - 0.5562091786088409
  - 0.5443172046133102
  train_level5__roc_auc_macro_masked:
  - 0.5248838049788145
  - 0.5264252764707349
  - 0.5240421100958829
  - 0.5430200443894336
  - 0.5340421917540298
  train_level5__roc_auc_macro_oob:
  - 0.5323653256514681
  - 0.5316561075138395
  - 0.5282032038208384
  - 0.5504247711166357
  - 0.5379089515995615
  train_level5__roc_auc_micro:
  - 0.49581610447624747
  - 0.4868581231622857
  - 0.477141977783588
  - 0.5456194496031793
  - 0.5035152255457084
  train_level5__roc_auc_micro_masked:
  - 0.49360186924166505
  - 0.4840629229170119
  - 0.4761363991094799
  - 0.5426927355908281
  - 0.5018731884977601
  train_level5__roc_auc_micro_oob:
  - 0.49554153701425363
  - 0.48551881927757556
  - 0.47738393459124334
  - 0.5437344501846826
  - 0.5021405674656905
  train_level5__roc_auc_samples:
  - 0.49662451760577264
  - 0.4883770972780628
  - 0.4760631879888927
  - 0.5461038116892759
  - 0.5033932399796889
  train_level5__roc_auc_samples_masked:
  - 0.49360930016605803
  - 0.4847677134023602
  - 0.4746667025955599
  - 0.5440935588440158
  - 0.5015862262754949
  train_level5__roc_auc_samples_oob:
  - 0.49638252597787447
  - 0.4871606618058406
  - 0.47639205095665066
  - 0.5442882086863453
  - 0.5020763021344827
  train_level5__roc_auc_weighted:
  - 0.5301349021977027
  - 0.539477483180703
  - 0.5288024297839825
  - 0.5547013448279697
  - 0.5474025149661447
  train_level5__roc_auc_weighted_masked:
  - 0.5214782517931386
  - 0.5286825332483225
  - 0.5254367710815269
  - 0.5453112427721543
  - 0.5400138218544956
  train_level5__roc_auc_weighted_oob:
  - 0.5279664488118317
  - 0.5345126993395232
  - 0.5271101235682433
  - 0.548400592653377
  - 0.5403780449438972
  train_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level5__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level5__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level5__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level5__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level5__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level5__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level5__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level5__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__average_precision_macro:
  - 0.2533711035964541
  - 0.2630450521310036
  - 0.2531649741565058
  - 0.27687575472220927
  - 0.26970216697265936
  train_level6__average_precision_macro_masked:
  - 0.1577488910472428
  - 0.1627101986510542
  - 0.15755841291209763
  - 0.17353875876973954
  - 0.16987907314226486
  train_level6__average_precision_macro_oob:
  - 0.250154556832637
  - 0.2587524853258662
  - 0.25049985092451615
  - 0.2717376579484391
  - 0.26590467540055135
  train_level6__average_precision_micro:
  - 0.2242907810843318
  - 0.22242440490644544
  - 0.2196890309367515
  - 0.24964203725377612
  - 0.22828884699812685
  train_level6__average_precision_micro_masked:
  - 0.12543329080488344
  - 0.1242356503969718
  - 0.12276382929411594
  - 0.1414848318160934
  - 0.12799544359384785
  train_level6__average_precision_micro_oob:
  - 0.2243524195422677
  - 0.2222077292217921
  - 0.21982939106301563
  - 0.24898231511701038
  - 0.22799128370410773
  train_level6__average_precision_samples:
  - 0.22790104996242272
  - 0.22773493687688678
  - 0.22382618002169813
  - 0.2569921666666828
  - 0.23301040709397916
  train_level6__average_precision_samples_masked:
  - 0.13078789582100658
  - 0.13079758929871865
  - 0.12836615495557965
  - 0.1508824451720196
  - 0.13431149828941957
  train_level6__average_precision_samples_oob:
  - 0.2279294152615211
  - 0.22748205857261083
  - 0.22392103694720056
  - 0.2563429329807611
  - 0.23278529822806376
  train_level6__average_precision_weighted:
  - 0.37059835653007844
  - 0.37805926631775766
  - 0.36561506243639036
  - 0.3895971906703507
  - 0.3877448625979178
  train_level6__average_precision_weighted_masked:
  - 0.24805761915488084
  - 0.25391695463111175
  - 0.2438552926413034
  - 0.2616187638602687
  - 0.26222615595208165
  train_level6__average_precision_weighted_oob:
  - 0.36629737868481366
  - 0.3729884788666615
  - 0.3629497678055666
  - 0.3835353136817267
  - 0.3838929832349905
  train_level6__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level6__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level6__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level6__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level6__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level6__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level6__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level6__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level6__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level6__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level6__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level6__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level6__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level6__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level6__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level6__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level6__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level6__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level6__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level6__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level6__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level6__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level6__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level6__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level6__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level6__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level6__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level6__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level6__label_ranking_average_precision_score:
  - 0.2279010499624227
  - 0.22773493687688662
  - 0.22382618002169805
  - 0.2569921666666829
  - 0.23301040709397916
  train_level6__label_ranking_average_precision_score_oob:
  - 0.227929415261521
  - 0.227482058572611
  - 0.22392103694720053
  - 0.2563429329807609
  - 0.2327852982280636
  train_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__ndcg:
  - 0.6149688483986292
  - 0.6133916680827096
  - 0.6109975088988765
  - 0.6348702994218481
  - 0.6178087549326604
  train_level6__ndcg_oob:
  - 0.6151705128377136
  - 0.6133959218673044
  - 0.6112603130580456
  - 0.634681214848497
  - 0.617761989415351
  train_level6__neg_coverage_error:
  - -95.67407407407407
  - -95.89113924050633
  - -96.72195121951219
  - -94.22110552763819
  - -95.3
  train_level6__neg_coverage_error_oob:
  - -95.76296296296296
  - -96.08607594936709
  - -96.78780487804877
  - -94.62562814070351
  - -95.5775
  train_level6__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level6__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level6__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level6__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level6__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level6__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level6__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level6__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level6__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level6__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level6__neg_label_ranking_loss:
  - -0.6743985468204303
  - -0.6468075085099241
  - -0.6896873928290407
  - -0.5402249520085842
  - -0.6218446770672865
  train_level6__neg_label_ranking_loss_oob:
  - -0.6758141821354146
  - -0.6492799587472339
  - -0.6914102668638974
  - -0.543667519210315
  - -0.6235316870851676
  train_level6__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level6__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level6__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level6__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level6__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level6__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level6__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level6__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level6__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__roc_auc_macro:
  - 0.5337164959798338
  - 0.5394816332876726
  - 0.5278121537230326
  - 0.5564061423447051
  - 0.5464407411692512
  train_level6__roc_auc_macro_masked:
  - 0.525903172358431
  - 0.5300287203634568
  - 0.5220968336700885
  - 0.5435993801753842
  - 0.5368223654294777
  train_level6__roc_auc_macro_oob:
  - 0.5284514835011129
  - 0.5343413074705733
  - 0.524456103778544
  - 0.550135757140089
  - 0.541847619817466
  train_level6__roc_auc_micro:
  - 0.4960300539454403
  - 0.48773735610817637
  - 0.4771103780592645
  - 0.5460095781328537
  - 0.5037584764504457
  train_level6__roc_auc_micro_masked:
  - 0.49420172042191135
  - 0.4852505002085227
  - 0.4759644575834643
  - 0.5427911351107042
  - 0.5021834243694463
  train_level6__roc_auc_micro_oob:
  - 0.4955144155892536
  - 0.4864565361456983
  - 0.47695419304963554
  - 0.5435862960116598
  - 0.5022923023516478
  train_level6__roc_auc_samples:
  - 0.496646199675181
  - 0.48945072880816437
  - 0.47599766398815385
  - 0.5459085602046304
  - 0.5028484240486045
  train_level6__roc_auc_samples_masked:
  - 0.4941249359055075
  - 0.48663531392895776
  - 0.4744224496360168
  - 0.5434446856348237
  - 0.5011555511621172
  train_level6__roc_auc_samples_oob:
  - 0.4960797280556401
  - 0.4882071299089768
  - 0.47588233611705316
  - 0.5436019582193066
  - 0.5017949494829348
  train_level6__roc_auc_weighted:
  - 0.531769444972778
  - 0.540431066560722
  - 0.5265780376981953
  - 0.5531535502570399
  - 0.550925977096175
  train_level6__roc_auc_weighted_masked:
  - 0.5249635844260183
  - 0.5313905021191034
  - 0.5209806652158536
  - 0.5435064427681124
  - 0.5440188027624145
  train_level6__roc_auc_weighted_oob:
  - 0.5262317567300605
  - 0.5343495673045371
  - 0.5221471455545764
  - 0.5451228417453811
  - 0.5453937093077569
  train_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level6__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level6__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level6__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level6__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level6__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level6__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level6__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level6__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__average_precision_macro:
  - 0.25502546174790447
  - 0.2622569055026069
  - 0.25446036412712847
  - 0.27656665203249975
  - 0.26629880828263147
  train_level7__average_precision_macro_masked:
  - 0.15715992080438165
  - 0.16251681900171147
  - 0.1596186041772408
  - 0.1739304112560158
  - 0.16805239111685086
  train_level7__average_precision_macro_oob:
  - 0.25246068508216385
  - 0.25807977636562823
  - 0.2527965214833386
  - 0.2722389439800326
  - 0.2631959779677912
  train_level7__average_precision_micro:
  - 0.22429479288968007
  - 0.22231858794428022
  - 0.21965749072586443
  - 0.24970312673234
  - 0.2281784689731317
  train_level7__average_precision_micro_masked:
  - 0.12535147666756627
  - 0.12419956519277081
  - 0.12274412426951743
  - 0.14144197795193217
  - 0.12800475168232378
  train_level7__average_precision_micro_oob:
  - 0.22432561802081075
  - 0.22205585776251074
  - 0.21995980749989757
  - 0.2494417742548984
  - 0.22788141982330612
  train_level7__average_precision_samples:
  - 0.22793824609664848
  - 0.22761460851075577
  - 0.2238452981311532
  - 0.2572052528191812
  - 0.23297088819681747
  train_level7__average_precision_samples_masked:
  - 0.13071464883018927
  - 0.13078137098165268
  - 0.1284264195642987
  - 0.150837196638549
  - 0.1342870996129582
  train_level7__average_precision_samples_oob:
  - 0.22792937059449583
  - 0.22736018391705742
  - 0.2240917756853652
  - 0.25683050847515837
  - 0.23262807129724156
  train_level7__average_precision_weighted:
  - 0.3693291902696497
  - 0.3776593596185371
  - 0.3680700690954004
  - 0.39061727735430346
  - 0.3834430799400005
  train_level7__average_precision_weighted_masked:
  - 0.24477473668878857
  - 0.25419057539767337
  - 0.24801170498069403
  - 0.262821388553741
  - 0.2577832797288965
  train_level7__average_precision_weighted_oob:
  - 0.36661401010245087
  - 0.37347986108160586
  - 0.3671818162285608
  - 0.38643351155012207
  - 0.3796057860231455
  train_level7__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level7__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level7__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level7__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level7__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level7__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level7__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level7__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level7__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level7__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level7__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level7__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level7__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level7__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level7__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level7__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level7__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level7__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level7__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level7__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level7__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level7__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level7__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level7__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level7__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level7__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level7__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level7__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level7__label_ranking_average_precision_score:
  - 0.2279382460966485
  - 0.22761460851075568
  - 0.2238452981311529
  - 0.25720525281918105
  - 0.23297088819681733
  train_level7__label_ranking_average_precision_score_oob:
  - 0.2279293705944957
  - 0.22736018391705753
  - 0.22409177568536506
  - 0.2568305084751582
  - 0.23262807129724178
  train_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__ndcg:
  - 0.6150012294252541
  - 0.6132595160055623
  - 0.6109347344634354
  - 0.6351224414118494
  - 0.6178067813597251
  train_level7__ndcg_oob:
  - 0.6151232587857922
  - 0.6131956086048538
  - 0.61137207820136
  - 0.6352228282763475
  - 0.6177570174316667
  train_level7__neg_coverage_error:
  - -95.78765432098766
  - -95.88860759493672
  - -96.63658536585366
  - -94.18090452261306
  - -95.1025
  train_level7__neg_coverage_error_oob:
  - -95.93827160493827
  - -96.04303797468354
  - -96.72439024390243
  - -94.5929648241206
  - -95.5075
  train_level7__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level7__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level7__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level7__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level7__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level7__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level7__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level7__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level7__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level7__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level7__neg_label_ranking_loss:
  - -0.6743676580301105
  - -0.6468683166414768
  - -0.6890539948295139
  - -0.5403454865599918
  - -0.621890553841675
  train_level7__neg_label_ranking_loss_oob:
  - -0.6756016916384993
  - -0.6490898840218682
  - -0.6906053597931567
  - -0.5433964796740263
  - -0.624333162341021
  train_level7__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level7__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level7__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level7__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level7__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level7__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level7__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level7__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level7__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__roc_auc_macro:
  - 0.5348493873976717
  - 0.5386156431463137
  - 0.5308754173020703
  - 0.555788578103941
  - 0.5439798927743946
  train_level7__roc_auc_macro_masked:
  - 0.525393535270651
  - 0.5291534116091118
  - 0.5263344787777932
  - 0.542807122523705
  - 0.534217626007281
  train_level7__roc_auc_macro_oob:
  - 0.5320523197645114
  - 0.5329438009323317
  - 0.5279016049482249
  - 0.5492686761238045
  - 0.5391810276965265
  train_level7__roc_auc_micro:
  - 0.4960293138147932
  - 0.48757643899672964
  - 0.47734251882895407
  - 0.545622550974606
  - 0.5032785856950861
  train_level7__roc_auc_micro_masked:
  - 0.4938305685607896
  - 0.48525100496664386
  - 0.4763021879585923
  - 0.5421310439707443
  - 0.501997546535828
  train_level7__roc_auc_micro_oob:
  - 0.4956326167160013
  - 0.48628350990960295
  - 0.47751740015958033
  - 0.5439453105707595
  - 0.5016685635530262
  train_level7__roc_auc_samples:
  - 0.4966790730907772
  - 0.48912049768664223
  - 0.47647682934113866
  - 0.5461241134259333
  - 0.5027374994450556
  train_level7__roc_auc_samples_masked:
  - 0.4939122772728323
  - 0.48634427369536676
  - 0.4752855101697787
  - 0.5432476889416245
  - 0.5011309631935765
  train_level7__roc_auc_samples_oob:
  - 0.4961519121271051
  - 0.48785371563664015
  - 0.47665380433988963
  - 0.5444379230806798
  - 0.5009641418794236
  train_level7__roc_auc_weighted:
  - 0.5307906994398183
  - 0.5415016832553553
  - 0.5306881206750623
  - 0.5520113504341575
  - 0.5470799181326415
  train_level7__roc_auc_weighted_masked:
  - 0.5219753801086661
  - 0.5328894849382657
  - 0.5270583833280471
  - 0.5408118487862196
  - 0.5406213085427878
  train_level7__roc_auc_weighted_oob:
  - 0.5278178505311216
  - 0.5343774991047543
  - 0.5280397683533601
  - 0.546403164986447
  - 0.5408565909194026
  train_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level7__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level7__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level7__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level7__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level7__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level7__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level7__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level7__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__average_precision_macro:
  - 0.253736494253673
  - 0.2605857531859037
  - 0.2525574079190664
  - 0.2764489158875366
  - 0.26630013352558285
  train_level8__average_precision_macro_masked:
  - 0.15708169415617593
  - 0.16231527732801454
  - 0.15912577471018888
  - 0.17324004825217448
  - 0.1659925197517472
  train_level8__average_precision_macro_oob:
  - 0.2530393755730065
  - 0.25639569357525627
  - 0.2519259317909028
  - 0.2734285055413145
  - 0.26505460717580315
  train_level8__average_precision_micro:
  - 0.2242131424799747
  - 0.22229317283070943
  - 0.21980354471156002
  - 0.2493393557096894
  - 0.22827965238890593
  train_level8__average_precision_micro_masked:
  - 0.12528297820054216
  - 0.12417287707876419
  - 0.1228330410272764
  - 0.14150847170880618
  - 0.12798388404105704
  train_level8__average_precision_micro_oob:
  - 0.22430812442945008
  - 0.22212786959653616
  - 0.22021809011926777
  - 0.24892344536664113
  - 0.228130836862301
  train_level8__average_precision_samples:
  - 0.22787643025796783
  - 0.2275510400156875
  - 0.22391431858602792
  - 0.25682425411752824
  - 0.23314139448618973
  train_level8__average_precision_samples_masked:
  - 0.13065706402101224
  - 0.1306635830380768
  - 0.12845314382997006
  - 0.15094245243603407
  - 0.13429150396795997
  train_level8__average_precision_samples_oob:
  - 0.22791391685981213
  - 0.2273878280305238
  - 0.22427197018469375
  - 0.25635625438595466
  - 0.23287567885599691
  train_level8__average_precision_weighted:
  - 0.3699235633197543
  - 0.3761154831733407
  - 0.3675449313164563
  - 0.38914988239933174
  - 0.38394108964239465
  train_level8__average_precision_weighted_masked:
  - 0.2458985534129314
  - 0.2542621952290842
  - 0.24772059543740158
  - 0.2631439679163661
  - 0.2574671692645931
  train_level8__average_precision_weighted_oob:
  - 0.3689592094681114
  - 0.37021508098998623
  - 0.3657743766024884
  - 0.38520939348804883
  - 0.38284770479846425
  train_level8__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level8__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level8__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level8__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level8__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level8__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level8__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level8__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level8__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level8__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level8__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level8__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level8__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level8__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level8__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level8__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level8__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level8__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08284695383244599
  train_level8__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level8__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level8__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.0703363014202664
  train_level8__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level8__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level8__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07096776340239623
  train_level8__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level8__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level8__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207656799868823
  train_level8__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level8__label_ranking_average_precision_score:
  - 0.22787643025796772
  - 0.22755104001568766
  - 0.223914318586028
  - 0.2568242541175283
  - 0.23314139448618953
  train_level8__label_ranking_average_precision_score_oob:
  - 0.22791391685981233
  - 0.22738782803052374
  - 0.22427197018469391
  - 0.25635625438595466
  - 0.23287567885599703
  train_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__ndcg:
  - 0.6149127414541427
  - 0.613276384823647
  - 0.6110973965362477
  - 0.634798849800711
  - 0.6179742356562629
  train_level8__ndcg_oob:
  - 0.6151209853082339
  - 0.6133244825924018
  - 0.6116574200936943
  - 0.6348987319747144
  - 0.6180085928582811
  train_level8__neg_coverage_error:
  - -95.71851851851852
  - -95.82025316455696
  - -96.69024390243902
  - -94.18844221105527
  - -95.165
  train_level8__neg_coverage_error_oob:
  - -95.89382716049383
  - -95.98227848101266
  - -96.76585365853659
  - -94.53266331658291
  - -95.6075
  train_level8__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level8__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level8__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level8__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level8__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level8__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level8__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level8__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level8__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level8__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level8__neg_label_ranking_loss:
  - -0.6741842411833483
  - -0.6472780599807635
  - -0.6893341531896867
  - -0.5407309736576968
  - -0.6213885456217849
  train_level8__neg_label_ranking_loss_oob:
  - -0.6754589029150793
  - -0.6495116165910428
  - -0.6910878163587925
  - -0.5435630643278232
  - -0.6237574145960536
  train_level8__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level8__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level8__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level8__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level8__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level8__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level8__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level8__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level8__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__roc_auc_macro:
  - 0.5357919076482942
  - 0.537178001065976
  - 0.5286169324449396
  - 0.5555960622465773
  - 0.5475238987029327
  train_level8__roc_auc_macro_masked:
  - 0.5268282555421208
  - 0.5280047343657228
  - 0.5237336347088218
  - 0.5465994647438792
  - 0.5381208445860384
  train_level8__roc_auc_macro_oob:
  - 0.5324695324820211
  - 0.5322758423527464
  - 0.5253882392613862
  - 0.5488318435147246
  - 0.5428363849749935
  train_level8__roc_auc_micro:
  - 0.49590689006494326
  - 0.4873370829206647
  - 0.4774915025940879
  - 0.5451190999436845
  - 0.5034042286468492
  train_level8__roc_auc_micro_masked:
  - 0.4936050235804711
  - 0.48494481327018724
  - 0.4764420418276087
  - 0.5427040349150769
  - 0.5017821195892751
  train_level8__roc_auc_micro_oob:
  - 0.49565101655780847
  - 0.4862449372354542
  - 0.47785733269959874
  - 0.5430579501884775
  - 0.5022793370473125
  train_level8__roc_auc_samples:
  - 0.496690499915151
  - 0.48883287429267386
  - 0.476502410541864
  - 0.545348440211065
  - 0.5032543412839859
  train_level8__roc_auc_samples_masked:
  - 0.49336027492887874
  - 0.48563103443851147
  - 0.47545764840564475
  - 0.5435056445423321
  - 0.5012921053512812
  train_level8__roc_auc_samples_oob:
  - 0.49632318012126625
  - 0.48785211950057067
  - 0.47698795101233904
  - 0.5437318951540235
  - 0.5018222407069616
  train_level8__roc_auc_weighted:
  - 0.5329157250512072
  - 0.5390475800598744
  - 0.5281611397684438
  - 0.5512867298239712
  - 0.5499131479892564
  train_level8__roc_auc_weighted_masked:
  - 0.5249610125083508
  - 0.5299614403423681
  - 0.5238437542651795
  - 0.5451484885302929
  - 0.5424185781787858
  train_level8__roc_auc_weighted_oob:
  - 0.5297373291772919
  - 0.533157874138301
  - 0.5245544665025431
  - 0.5452766574786179
  - 0.54560505859302
  train_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14280011416508828
  train_level8__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level8__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13142841427864255
  train_level8__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level8__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.1316429990855366
  train_level8__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level8__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level8__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291559579181672
  train_level8__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level9__average_precision_macro:
  - 0.2534868203024752
  - 0.2603447883170804
  - 0.2508150571520394
  - 0.2752419057986418
  - 0.26807802409059767
  train_level9__average_precision_macro_masked:
  - 0.15646548604625982
  - 0.16031200825651026
  - 0.1567093767201396
  - 0.17429484785616017
  - 0.16725767117737037
  train_level9__average_precision_macro_oob:
  - 0.2525451346085201
  - 0.25642689278053865
  - 0.24998679136019528
  - 0.2717537879243534
  - 0.2651792721633011
  train_level9__average_precision_micro:
  - 0.22440575346643155
  - 0.22237395918335656
  - 0.21969296851207104
  - 0.2493038949184363
  - 0.22822297970936412
  train_level9__average_precision_micro_masked:
  - 0.1254567497988966
  - 0.1242176936378477
  - 0.12283837381052533
  - 0.14145091123513762
  - 0.1278993513127612
  train_level9__average_precision_micro_oob:
  - 0.22438017403078808
  - 0.2219999239899712
  - 0.21987985062024873
  - 0.2490744018171745
  - 0.22795616482450437
  train_level9__average_precision_samples:
  - 0.22804086327324347
  - 0.22763192246546626
  - 0.22386226372704046
  - 0.2567845804962522
  - 0.2330106915574376
  train_level9__average_precision_samples_masked:
  - 0.13081991279071856
  - 0.13075247042046753
  - 0.1284852596394138
  - 0.15088482850499046
  - 0.1342064873390723
  train_level9__average_precision_samples_oob:
  - 0.22799513533150448
  - 0.22726190191049989
  - 0.22398596162422627
  - 0.25640930800943534
  - 0.23271059392474022
  train_level9__average_precision_weighted:
  - 0.3689780145548453
  - 0.3756229430476302
  - 0.36590160086544843
  - 0.38798269777309324
  - 0.3853341701600813
  train_level9__average_precision_weighted_masked:
  - 0.24606600294352035
  - 0.25155070043540434
  - 0.24655435535867806
  - 0.2624233288852527
  - 0.25849030959480357
  train_level9__average_precision_weighted_oob:
  - 0.36822995020484406
  - 0.3712357041364222
  - 0.3644112550053712
  - 0.3843951933624711
  - 0.3816962052650864
  train_level9__f1_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23339805825242718
  train_level9__f1_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14277502698714492
  train_level9__f1_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level9__f1_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23339805825242718
  train_level9__f1_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13140091304108684
  train_level9__f1_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level9__f1_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.23339805825242713
  train_level9__f1_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.13161611736510648
  train_level9__f1_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level9__f1_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34645757512737857
  train_level9__f1_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291489288888167
  train_level9__f1_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.4271844660194176e-05
  train_level9__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.5087177943353153e-05
  train_level9__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.4271844660194176e-05
  train_level9__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.7501237555690007e-05
  train_level9__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.4271844660194173e-05
  train_level9__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.688172043010753e-05
  train_level9__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -6.7588645107621924e-06
  train_level9__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -7.029029350523095e-06
  train_level9__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fp_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level9__fp_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8571998858349116
  train_level9__fp_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level9__fp_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level9__fp_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685715857213575
  train_level9__fp_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level9__fp_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level9__fp_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683570009144634
  train_level9__fp_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level9__fp_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level9__fp_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.770844042081833
  train_level9__fp_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level9__jaccard_macro:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14347556627761318
  train_level9__jaccard_macro_masked:
  - 0.08176637833385306
  - 0.08321390947601535
  - 0.08294636678687418
  - 0.08476174778260848
  - 0.08283399505271702
  train_level9__jaccard_macro_oob:
  - 0.1419914099628122
  - 0.1439495560842559
  - 0.14366681293677258
  - 0.1463294662968246
  - 0.14348851449848718
  train_level9__jaccard_micro:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.13211694877995164
  train_level9__jaccard_micro_masked:
  - 0.0695663528080433
  - 0.07064560869759742
  - 0.07056778845463293
  - 0.07191521574564724
  - 0.07032054867100344
  train_level9__jaccard_micro_oob:
  - 0.13077892682397907
  - 0.13260860487451806
  - 0.13241445886517214
  - 0.1346720732939369
  - 0.1321325034692167
  train_level9__jaccard_samples:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13303115791980782
  train_level9__jaccard_samples_masked:
  - 0.0702630511586873
  - 0.07131633100502482
  - 0.07124185026645007
  - 0.07259905385992269
  - 0.07095300430889022
  train_level9__jaccard_samples_oob:
  - 0.13173108449976287
  - 0.1335467229054631
  - 0.1333588325804478
  - 0.13561959957478822
  - 0.13304580691286733
  train_level9__jaccard_weighted:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.2294290235353899
  train_level9__jaccard_weighted_masked:
  - 0.14019452204149943
  - 0.14261493870418268
  - 0.1414008858121865
  - 0.1443222635069346
  - 0.14207293715414812
  train_level9__jaccard_weighted_oob:
  - 0.22772757106409205
  - 0.22947154178397194
  - 0.22864510132035384
  - 0.2328907905399297
  - 0.22943262916453627
  train_level9__label_ranking_average_precision_score:
  - 0.22804086327324347
  - 0.2276319224654662
  - 0.22386226372704035
  - 0.25678458049625236
  - 0.23301069155743762
  train_level9__label_ranking_average_precision_score_oob:
  - 0.22799513533150448
  - 0.2272619019105
  - 0.22398596162422615
  - 0.2564093080094356
  - 0.23271059392474006
  train_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0018434249218795837
  train_level9__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.002650533196529939
  train_level9__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.008928192484874208
  train_level9__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.01348156362162763
  train_level9__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0005204784652772269
  train_level9__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0007962775715882577
  train_level9__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0005133297224491551
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0007426373614048104
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__ndcg:
  - 0.6151328090521996
  - 0.6133150218907033
  - 0.6110173725034526
  - 0.6348623176941738
  - 0.6178052008805275
  train_level9__ndcg_oob:
  - 0.6152471960288199
  - 0.6131770644550085
  - 0.6112865645413429
  - 0.6350579467444574
  - 0.617781381093117
  train_level9__neg_coverage_error:
  - -95.67901234567901
  - -95.88607594936708
  - -96.89268292682927
  - -94.10804020100502
  - -95.1175
  train_level9__neg_coverage_error_oob:
  - -95.75802469135803
  - -95.91645569620253
  - -96.84634146341463
  - -94.49748743718592
  - -95.545
  train_level9__neg_hamming_loss_macro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7666019417475728
  train_level9__neg_hamming_loss_macro_masked:
  - -0.8586877497796034
  - -0.8566863075512696
  - -0.856901550652279
  - -0.8541530907181858
  - -0.8572249730128549
  train_level9__neg_hamming_loss_macro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046738
  - -0.7665776699029125
  train_level9__neg_hamming_loss_micro:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7666019417475728
  train_level9__neg_hamming_loss_micro_masked:
  - -0.8699167141423184
  - -0.8680317592979524
  - -0.8681675476963533
  - -0.865819209039548
  - -0.8685990869589132
  train_level9__neg_hamming_loss_micro_oob:
  - -0.7686923169123816
  - -0.7658350743517267
  - -0.766137816717973
  - -0.7626237986046739
  - -0.7665776699029127
  train_level9__neg_hamming_loss_samples:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7666019417475728
  train_level9__neg_hamming_loss_samples_masked:
  - -0.8696385798047298
  - -0.8677255162691905
  - -0.8678828913229237
  - -0.8655085175381086
  - -0.8683838826348935
  train_level9__neg_hamming_loss_samples_oob:
  - -0.7686923169123816
  - -0.7658350743517266
  - -0.7661378167179729
  - -0.7626237986046737
  - -0.7665776699029127
  train_level9__neg_hamming_loss_weighted:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535424248726214
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.7724013272449971
  - -0.7705137654965911
  - -0.7714485249134688
  - -0.7671771315871451
  - -0.7708510711111836
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.6549415342727257
  - -0.6540048071237908
  - -0.6543050904385108
  - -0.6490072911056155
  - -0.6535356660081105
  train_level9__neg_label_ranking_loss:
  - -0.6743156578815853
  - -0.6471543645210126
  - -0.6889660900541039
  - -0.541251375948578
  - -0.6216812616750648
  train_level9__neg_label_ranking_loss_oob:
  - -0.6755665641455273
  - -0.6496563911955081
  - -0.6906083835167486
  - -0.5440945033918314
  - -0.6240180903874575
  train_level9__precision_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23339805825242718
  train_level9__precision_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14277502698714492
  train_level9__precision_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level9__precision_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23339805825242718
  train_level9__precision_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13140091304108684
  train_level9__precision_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level9__precision_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.23339805825242713
  train_level9__precision_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.13161611736510648
  train_level9__precision_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level9__precision_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34645757512737857
  train_level9__precision_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291489288888167
  train_level9__precision_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level9__recall_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23339805825242718
  train_level9__recall_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14277502698714492
  train_level9__recall_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level9__recall_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23339805825242718
  train_level9__recall_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13140091304108684
  train_level9__recall_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level9__recall_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.23339805825242713
  train_level9__recall_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.13161611736510648
  train_level9__recall_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level9__recall_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34645757512737857
  train_level9__recall_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291489288888167
  train_level9__recall_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
  train_level9__roc_auc_macro:
  - 0.5349766080146888
  - 0.5399278082305777
  - 0.5270986768955611
  - 0.5528112077412203
  - 0.5490357507867
  train_level9__roc_auc_macro_masked:
  - 0.5265822078724445
  - 0.5303687467640203
  - 0.522873720327694
  - 0.5444575726150389
  - 0.5400744164863714
  train_level9__roc_auc_macro_oob:
  - 0.5297510377619311
  - 0.535112741569235
  - 0.5231224188902742
  - 0.5476559419129915
  - 0.544592387516553
  train_level9__roc_auc_micro:
  - 0.49618706829900405
  - 0.48764779507511236
  - 0.47719582281250594
  - 0.5448109005418519
  - 0.503508035036651
  train_level9__roc_auc_micro_masked:
  - 0.49417648245956736
  - 0.48524714305887184
  - 0.47645378727523496
  - 0.5423599353360437
  - 0.5017097772654784
  train_level9__roc_auc_micro_oob:
  - 0.4956343506902029
  - 0.4860790865273883
  - 0.47720814723702676
  - 0.5431437728769491
  - 0.501986086753472
  train_level9__roc_auc_samples:
  - 0.4969570346770005
  - 0.4890240702259847
  - 0.47632390977900824
  - 0.5451138958398308
  - 0.5027991802170478
  train_level9__roc_auc_samples_masked:
  - 0.4942390927867243
  - 0.48617851811136675
  - 0.4754769175082653
  - 0.5433410098499901
  - 0.5008966609142985
  train_level9__roc_auc_samples_oob:
  - 0.49640260479640896
  - 0.48761851092897307
  - 0.4762534582458977
  - 0.5436233172125745
  - 0.5012872770130218
  train_level9__roc_auc_weighted:
  - 0.5330419012394401
  - 0.5430529422274998
  - 0.5295483659073362
  - 0.549995063922578
  - 0.5491611463171483
  train_level9__roc_auc_weighted_masked:
  - 0.5258902518773031
  - 0.5344183449953476
  - 0.5266694037028001
  - 0.5427614923796922
  - 0.5418180034403416
  train_level9__roc_auc_weighted_oob:
  - 0.5283508108122842
  - 0.5384626493036715
  - 0.5249273630642882
  - 0.5448131791888947
  - 0.543594689052555
  train_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tp_macro:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23339805825242718
  train_level9__tp_macro_masked:
  - 0.14131225022039662
  - 0.1433136924487304
  - 0.14309844934772065
  - 0.14584690928181435
  - 0.14277502698714492
  train_level9__tp_macro_oob:
  - 0.2313076830876184
  - 0.23416492564827326
  - 0.23386218328202701
  - 0.23737620139532611
  - 0.23342233009708738
  train_level9__tp_micro:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23339805825242718
  train_level9__tp_micro_masked:
  - 0.13008328585768156
  - 0.13196824070204763
  - 0.13183245230364665
  - 0.134180790960452
  - 0.13140091304108684
  train_level9__tp_micro_oob:
  - 0.23130768308761837
  - 0.23416492564827332
  - 0.233862183282027
  - 0.23737620139532614
  - 0.23342233009708738
  train_level9__tp_samples:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.23339805825242713
  train_level9__tp_samples_masked:
  - 0.13036142019527025
  - 0.1322744837308094
  - 0.13211710867707627
  - 0.13449148246189144
  - 0.13161611736510648
  train_level9__tp_samples_oob:
  - 0.23130768308761832
  - 0.23416492564827326
  - 0.23386218328202693
  - 0.23737620139532611
  - 0.2334223300970873
  train_level9__tp_weighted:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34645757512737857
  train_level9__tp_weighted_masked:
  - 0.22759867275500298
  - 0.22948623450340866
  - 0.22855147508653123
  - 0.23282286841285482
  - 0.2291489288888167
  train_level9__tp_weighted_oob:
  - 0.3450584657272742
  - 0.3459951928762092
  - 0.34569490956148935
  - 0.3509927088943846
  - 0.34646433399188936
start: 2023-12-31 06:14:56.294936
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
