active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            0MzMzMzMDEAwMzMzMzMDwJiZmZmZmRnAaGZmZmZmFkCAmZmZmZnZvw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJvwCZmZmZmcm/AJmZmZmZyb/AmZmZmZnpPw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEMA0MzMzMzMbQMzMzMzMzBDAMDMzMzMz879oZmZmZmYGQA==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+AmZmZmZnJv4CZmZmZmcm/oJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ6b8AmpmZmZnJPwCamZmZmck/AJqZmZmZyT8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBECgmZmZmZn5P0AzMzMzM+M/oJmZmZmZ+T+YmZmZmZkZwA==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMFMBoZmZmZmYGQMzMzMzMzBDAaGZmZmZmBkBoZmZmZmYOQA==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkAwMzMzMzPzvzAzMzMzM/O/MDMzMzMz87+AmZmZmZnJvw==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmHsCcmZmZmZkRQCAzMzMzM+O/wJmZmZmZ2T84MzMzMzMLQA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b84MzMzMzMLQGRmZmZmZhLAkJmZmZmZ+b+cmZmZmZkRQA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAHMAAAAAAAAAcQAAAAAAAAAAAAAAAAAAACEAAAAAAAAAIwA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+AmZmZmZnZv0AzMzMzM+M/mJmZmZmZGcBoZmZmZmYaQA==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUA4MzMzMzMDQGRmZmZmZhbAyMzMzMzMBMBwZmZmZmb2Pw==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b/AmZmZmZnZPzgzMzMzMwNAcGZmZmZm9j/IzMzMzMwEwA==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAUQAAAAAAAABTAAAAAAAAAAAAAAAAAAADwvw==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAYQAAAAAAAABTAAAAAAAAAAEAAAAAAAAAIwA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZIUCYmZmZmZkBwKCZmZmZmek/MDMzMzMz87/MzMzMzMwYwA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZIcBoZmZmZmYiQJiZmZmZmSfAoJmZmZmZAUBoZmZmZmYiQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ2T84MzMzMzMLQHBmZmZmZvY/yMzMzMzMBMDIzMzMzMwEwA==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmGsDMzMzMzMwgQICZmZmZmdk/gJmZmZmZ2T/QzMzMzMwEwA==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b9kZmZmZmYGwJCZmZmZmem/zszMzMzMEEDAmZmZmZnJPw==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAQAAAAAAAABTAAAAAAAAA8D8AAAAAAAAIQA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzE0DgzMzMzMz8P3BmZmZmZg5AyMzMzMzMFMDIzMzMzMwUwA==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsCYmZmZmZn5vzAzMzMzM+O/mpmZmZmZHUAwMzMzMzPjvw==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAAAAAAAAAAAPA/AAAAAAAAFMAAAAAAAADwPw==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9oZmZmZmYWQGBmZmZmZva/QDMzMzMz4z8wMzMzMzMLwA==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAQwAAAAAAAAPA/AAAAAAAA8D8AAAAAAADwvw==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAIQAAAAAAAAPC/AAAAAAAAFMAAAAAAAAAIQA==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r+AmZmZmZnZvzAzMzMzMwPA0MzMzMzMDEBAMzMzMzPjPw==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmDsBAMzMzMzPzPzAzMzMzMxPAwMzMzMzM/L9oZmZmZmYiQA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D+YmZmZmZkJwGhmZmZmZgZAoJmZmZmZ6T+YmZmZmZkBwA==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzE8DAzMzMzMz8vzAzMzMzMxfA0MzMzMzMHEDQzMzMzMwUQA==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAUwAAAAAAAABDAAAAAAAAAEEAAAAAAAAAAQA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb9wZmZmZmYGQJCZmZmZmQHAAJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAAAAAAAAAABBAAAAAAAAAEMAAAAAAAAAQwA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAYwAAAAAAAAAAAAAAAAAAAGEAAAAAAAADwvw==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j9oZmZmZmb2PzAzMzMzM+O/NDMzMzMzA0BmZmZmZmYSwA==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBECgmZmZmZn5P9DMzMzMzARAMDMzMzMzA8CYmZmZmZkRwA==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZm9r8yMzMzMzMLwJyZmZmZmfk/zszMzMzMBEA4MzMzMzPjPw==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzM/L/AmZmZmZnJP5yZmZmZmQlAMjMzMzMzE8CcmZmZmZkJQA==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAQAAAAAAAAAhAAAAAAAAAAMAAAAAAAADwvw==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZEUBmZmZmZmYawGhmZmZmZvY/mJmZmZmZ+b80MzMzMzMDQA==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsCgmZmZmZnZPzQzMzMzMwNAoJmZmZmZ2T9oZmZmZmb2Pw==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmBsBmZmZmZmYGwJiZmZmZmem/mpmZmZmZCUCamZmZmZkJQA==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMFECgmZmZmZkBQGBmZmZmZgbAgJmZmZmZ6b9gZmZmZmYOwA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8CgmZmZmZn5P0AzMzMzM+M/gJmZmZmZ2b9AMzMzMzPjPw==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwMwJqZmZmZmRFAzMzMzMzMBMBoZmZmZmb2Pw==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZEcCgmZmZmZn5P0AzMzMzM+M/oJmZmZmZ+T9AMzMzMzPjPw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcA4MzMzMzMTQMjMzMzMzBTAAJmZmZmZyb9wZmZmZmYGQA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz879oZmZmZmYGQJiZmZmZmQnAoJmZmZmZ6T+gmZmZmZnpPw==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAAAAAAAAA8D8AAAAAAADwPw==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D80MzMzMzMTQICZmZmZmcm/zMzMzMzMHMCgmZmZmZnpPw==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAIQAAAAAAAAPC/AAAAAAAA8L8AAAAAAADwvw==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIMAAAAAAAAAYQAAAAAAAAADAAAAAAAAAEEAAAAAAAAAAAA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBkDAzMzMzMz8P2BmZmZmZgZAoJmZmZmZCcDQzMzMzMwQwA==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcCYmZmZmZkBwICZmZmZmcm/NDMzMzMzG0AwMzMzMzPzvw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz4780MzMzMzMDQJiZmZmZmfm/zMzMzMzMBMA0MzMzMzMDQA==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcAwMzMzMzPzvzAzMzMzM/O/0MzMzMzM/D9oZmZmZmYOQA==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmJMBoZmZmZmYOQGhmZmZmZgZAaGZmZmZmDkCAmZmZmZnJvw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAwAAAAAAAABBAAAAAAAAAEEAAAAAAAAAQwA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz8z+YmZmZmZkJQNDMzMzMzPy/NDMzMzMzF8CYmZmZmZkJQA==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzM/L+amZmZmZkBQKCZmZmZmck/mJmZmZmZ6b+gmZmZmZnJPw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAjAAAAAAAAA8D8AAAAAAADwPw==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwPwAAAAAAABzAAAAAAAAAGMAAAAAAAAAmQA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAADwPwAAAAAAABBAAAAAAAAA8L8AAAAAAAAIwA==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAUQAAAAAAAABzAAAAAAAAAAEAAAAAAAAAAAA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZm9j9wZmZmZmb2PyAzMzMzM+O/kJmZmZmZ+b8gMzMzMzPjvw==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmDsDQzMzMzMwcQDAzMzMzMx/A0MzMzMzMFECAmZmZmZnpvw==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9AMzMzMzPjP2BmZmZmZva/MDMzMzMzA8BoZmZmZmYSQA==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZmDkAAmZmZmZnJv3BmZmZmZgZAcGZmZmZmBkBkZmZmZmYiwA==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAQAAAAAAAAPC/AAAAAAAAAMAAAAAAAAAIQA==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2T8wMzMzMzMDQDAzMzMzMwtAaGZmZmZmEsCgmZmZmZn5vw==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8BoZmZmZmYWQEAzMzMzM+M/QDMzMzMz4z8wMzMzMzMLwA==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ADMzMzMz479AMzMzMzMDQMDMzMzMzATAAJqZmZmZ2T8AmpmZmZnZPw==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb/MzMzMzMwQwGhmZmZmZg5AgJmZmZmZyb+gmZmZmZnpPw==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcCgmZmZmZnpP9DMzMzMzPw/oJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ADMzMzMz879AMzMzMzMTQMDMzMzMzBTAgJmZmZmZCcBAMzMzMzMTQA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZEcBAMzMzMzPjP4CZmZmZmdm/aGZmZmZmFkBgZmZmZmb2vw==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT9gZmZmZmYGwEAzMzMzM/M/YGZmZmZmBsDQzMzMzMwQQA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAYQAAAAAAAABDAAAAAAAAA8L8AAAAAAAAIQA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b+QmZmZmZn5vyAzMzMzM+O/ODMzMzMzA0BwZmZmZmb2Pw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T8wMzMzMzPzvzAzMzMzM/O/gJmZmZmZyb/QzMzMzMz8Pw==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZFcBoZmZmZmYaQGBmZmZmZva/mJmZmZmZFcBoZmZmZmYWQA==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZAUCgmZmZmZkBQKCZmZmZmQlAAJqZmZmZyT8wMzMzMzMfwA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMBoZmZmZmb2P5iZmZmZmfm/oJmZmZmZ2T80MzMzMzMLQA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2b+YmZmZmZn5PzAzMzMzM+M/zMzMzMzMBECamZmZmZkRwA==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMFEBgZmZmZmYGwICZmZmZmem/AJqZmZmZyT/AzMzMzMz8vw==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZAUAyMzMzMzMTwJyZmZmZmQlAwJmZmZmZyT+QmZmZmZnpvw==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T/QzMzMzMz8P5iZmZmZmQHA0MzMzMzM/D+YmZmZmZkBwA==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zszMzMzMBEDOzMzMzMwMQGRmZmZmZva/zszMzMzMBECZmZmZmZkdwA==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+gmZmZmZnZP8zMzMzMzATANDMzMzMzC0AwMzMzMzPjvw==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAYQAAAAAAAAPA/AAAAAAAAEMAAAAAAAADwvw==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAwAAAAAAAAPC/AAAAAAAA8L8AAAAAAAAUQA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFMAAAAAAAAAIQAAAAAAAAAhAAAAAAAAAAAAAAAAAAADwvw==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0BoZmZmZmb2P2ZmZmZmZhrANDMzMzMzA0CgmZmZmZnZPw==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMAwMzMzMzPjv2hmZmZmZvY/mpmZmZmZFUDMzMzMzMwMwA==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T+gmZmZmZnZPzQzMzMzMwtAMDMzMzMz47/MzMzMzMwMwA==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T9oZmZmZmb2PzAzMzMzM+O/NDMzMzMzA0DMzMzMzMwMwA==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAwAAAAAAAAABAAAAAAAAACMAAAAAAAAAIQA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T9oZmZmZmb2P2hmZmZmZvY/MDMzMzMz47/MzMzMzMwEwA==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMz8z80MzMzMzPzP8zMzMzMzPy/NDMzMzMz8z/MzMzMzMz8vw==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAiwAAAAAAAAAhAAAAAAAAAEEAAAAAAAADwvw==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          wMzMzMzMBMCgmZmZmZkRQMDMzMzMzAzAgGZmZmZm9j8AmpmZmZnZPw==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 02:47:48.060370
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder_proba
  final_params:
    final_estimator:
      call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
      params:
        estimator:
          call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
          params:
            estimators:
            - - rf
              - call: sklearn.ensemble._forest.RandomForestRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: sqrt
                  max_leaf_nodes: null
                  max_samples: 0.5
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 5
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  monotonic_cst: null
                  n_estimators: 150
                  n_jobs: 14
                  oob_score: true
                  random_state: 0
                  verbose: true
                  warm_start: false
            - - xt
              - call: sklearn.ensemble._forest.ExtraTreesRegressor
                params:
                  bootstrap: true
                  ccp_alpha: 0.0
                  criterion: squared_error
                  max_depth: null
                  max_features: sqrt
                  max_leaf_nodes: null
                  max_samples: 0.5
                  min_impurity_decrease: 0.0
                  min_samples_leaf: 5
                  min_samples_split: 2
                  min_weight_fraction_leaf: 0.0
                  monotonic_cst: null
                  n_estimators: 150
                  n_jobs: 14
                  oob_score: true
                  random_state: 0
                  verbose: true
                  warm_start: false
    keep_original_features: true
    level:
      call: deep_forest.cascade.SequentialLevel
      params:
        last_level: null
        memory: null
        steps:
        - - alternating_forests
          - call: deep_forest.cascade.AlternatingLevel
            params:
              last_level: null
              n_jobs: null
              sparse_threshold: 0.3
              transformer_weights: null
              transformers:
              - - xt
                - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                  params:
                    estimator:
                      call: deep_forest.tree_embedder.ForestEmbedder
                      params:
                        estimator:
                          call: sklearn.ensemble._forest.ExtraTreesRegressor
                          params:
                            bootstrap: true
                            ccp_alpha: 0.0
                            criterion: squared_error
                            max_depth: null
                            max_features: sqrt
                            max_leaf_nodes: null
                            max_samples: 0.5
                            min_impurity_decrease: 0.0
                            min_samples_leaf: 5
                            min_samples_split: 2
                            min_weight_fraction_leaf: 0.0
                            monotonic_cst: null
                            n_estimators: 150
                            n_jobs: 14
                            oob_score: false
                            random_state: 0
                            verbose: true
                            warm_start: false
                        max_node_size: 0.8
                        max_pvalue: 1.0
                        method: path
                        node_weights: log_node_size
                    method: predict
                    post_transformer:
                      call: sklearn.pipeline.Pipeline
                      params:
                        memory: null
                        steps:
                        - - densifier
                          - call: nakano_datasets_v2.estimators.Densifier
                            params: {}
                        - - pca
                          - call: sklearn.decomposition._pca.PCA
                            params:
                              copy: true
                              iterated_power: auto
                              n_components: 0.8
                              n_oversamples: 10
                              power_iteration_normalizer: auto
                              random_state: 0
                              svd_solver: auto
                              tol: 0.0
                              whiten: false
                        verbose: false
              - - rf
                - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                  params:
                    estimator:
                      call: deep_forest.tree_embedder.ForestEmbedder
                      params:
                        estimator:
                          call: sklearn.ensemble._forest.RandomForestRegressor
                          params:
                            bootstrap: true
                            ccp_alpha: 0.0
                            criterion: squared_error
                            max_depth: null
                            max_features: sqrt
                            max_leaf_nodes: null
                            max_samples: 0.5
                            min_impurity_decrease: 0.0
                            min_samples_leaf: 5
                            min_samples_split: 2
                            min_weight_fraction_leaf: 0.0
                            monotonic_cst: null
                            n_estimators: 150
                            n_jobs: 14
                            oob_score: false
                            random_state: 0
                            verbose: true
                            warm_start: false
                        max_node_size: 0.95
                        max_pvalue: 1.0
                        method: path
                        node_weights: log_node_size
                    method: predict
                    post_transformer:
                      call: sklearn.pipeline.Pipeline
                      params:
                        memory: null
                        steps:
                        - - densifier
                          - call: nakano_datasets_v2.estimators.Densifier
                            params: {}
                        - - pca
                          - call: sklearn.decomposition._pca.PCA
                            params:
                              copy: true
                              iterated_power: auto
                              n_components: 0.8
                              n_oversamples: 10
                              power_iteration_normalizer: auto
                              random_state: 0
                              svd_solver: auto
                              tol: 0.0
                              whiten: false
                        verbose: false
              verbose: false
              verbose_feature_names_out: true
        - - label_imputer
          - call: deep_forest.weak_labels.LabelComplementImputer
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
              label_freq_percentile: 0.5
              last_level: null
              threshold: 0.5
              verbose: true
              weight_proba: true
        verbose: false
    max_levels: 10
    memory: null
    verbose: 10
    warm_start: false
  name: cascade_lc_tree_embedder_proba
  params: {}
hash: fa76025f54b9a1a070d1cf658e23a7e804faa439ed42206329fcfac79404f6df
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/fa76025_20231231T024250736008_cascade_lc_tree_embedder_proba_CAL500.yml
results:
  fit_time:
  - 275.4185245037079
  - 279.1813313961029
  - 277.140499830246
  - 286.9069080352783
  - 278.60838055610657
  fitted_params:
    level1.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 198
    - 202
    - 199
    - 201
    - 202
    level1.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 199
    - 201
    - 198
    - 199
    - 200
    level1.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level10.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 24
    - 23
    - 24
    - 23
    - 24
    level10.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 22
    - 22
    - 23
    - 19
    - 20
    level10.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level2.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 181
    - 185
    - 179
    - 179
    - 183
    level2.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 184
    - 189
    - 183
    - 183
    - 187
    level2.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level3.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 49
    - 51
    - 54
    - 50
    - 56
    level3.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 82
    - 86
    - 84
    - 85
    - 91
    level3.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level4.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 40
    - 39
    - 39
    - 38
    - 41
    level4.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 35
    - 36
    - 37
    - 34
    - 38
    level4.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level5.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 25
    - 27
    - 28
    - 25
    - 28
    level5.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 33
    - 32
    - 33
    - 30
    - 35
    level5.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level6.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 28
    - 28
    - 28
    - 29
    - 31
    level6.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 26
    - 28
    - 28
    - 25
    - 27
    level6.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level7.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 23
    - 24
    - 24
    - 21
    - 22
    level7.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 28
    - 27
    - 27
    - 27
    - 29
    level7.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level8.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 25
    - 25
    - 26
    - 26
    - 27
    level8.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 23
    - 25
    - 26
    - 22
    - 22
    level8.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
    level9.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 21
    - 22
    - 22
    - 19
    - 20
    level9.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 26
    - 25
    - 26
    - 24
    - 26
    level9.label_imputer.label_frequency_estimates_:
    - - 0.27126296827761365
      - 0.7410915724168735
      - 0.464021223698643
      - 0.3975637411683922
      - 0.6316836317529919
      - 0.486034591207005
      - 0.44936794600018765
      - 0.42744327830534723
      - 0.40059382214565836
      - 0.4612364068469481
      - 0.5103071398389527
      - 0.3275084059459059
      - 0.18257493012745113
      - 0.422130969909206
      - 0.5197841828875953
      - 0.5013216827872
      - 0.43480472181102425
      - 0.3664391120954179
      - 0.45544801863317913
      - 0.3613706554297952
      - 0.4753904625116748
      - 0.26135265124448503
      - 0.5683343746462557
      - 0.5036797592150337
      - 0.2843856570906481
      - 0.40071913292021977
      - 0.34911929857582025
      - 0.4300374444396185
      - 0.21806817337929937
      - 0.17116834259379393
      - 0.5081412787456743
      - 0.46621437105308094
      - 0.575217893190157
      - 0.34454192569165826
      - 0.5571767285002577
      - 0.26166847378198393
      - 0.21311437270739597
      - 0.220294197101426
      - 0.13302876169723996
      - 0.09597376138073813
      - 0.17586203479060614
      - 0.09944826344944083
      - 0.09763047858232375
      - 0.1502558542956466
      - 0.12302088185519268
      - 0.36708792767617154
      - 0.16503017663161942
      - 0.10405376095931479
      - 0.3020948439315786
      - 0.3695594198711207
      - 0.13407509011763213
      - 0.6047020608810382
      - 0.27697741326773573
      - 0.20930394047174128
      - 0.1847645424217432
      - 0.7104915971963313
      - 0.21913628983656727
      - 0.10946664751609803
      - 0.13781083347800474
      - 0.20282385914738854
      - 0.43640903204364984
      - 0.25501495017410136
      - 0.07506098292388613
      - 0.46441559893594775
      - 0.41999242587477886
      - 0.46194555763521283
      - 0.3696145331512479
      - 0.3707580049149818
      - 0.6474481822796428
      - 0.3871915625628497
      - 0.4105245323618819
      - 0.16910102433295687
      - 0.47429132052553863
      - 0.2591925952298292
      - 0.5735442272374088
      - 0.22684838037779204
      - 0.2730215445431631
      - 0.8893426246898735
      - 0.6183730483678689
      - 0.7235412603269742
      - 0.3566629495869171
      - 0.19518830548660088
      - 0.11850806071540682
      - 0.2733296331420063
      - 0.5838832287989391
      - 0.19321396114450679
      - 0.09122307210161304
      - 0.31765774013174547
      - 0.18672215465693723
      - 0.07332021671510308
      - 0.09059488713900476
      - 0.2128944274324709
      - 0.08178974518533093
      - 0.25693955592211404
      - 0.08624979671491298
      - 0.22667566701725117
      - 0.13223546255724472
      - 0.10536822132828312
      - 0.13402386064228167
      - 0.14318502925645782
      - 0.12460745162405203
      - 0.1068433301712953
      - 0.08427431646480896
    - - 0.2363078545074409
      - 0.7244982058757568
      - 0.49372946205187257
      - 0.38274486684812764
      - 0.6277112278618301
      - 0.48678130163504196
      - 0.4862788304867908
      - 0.3914378550742187
      - 0.44548309878805015
      - 0.4507420194184899
      - 0.5732374207917688
      - 0.32572104730586865
      - 0.17957791147414015
      - 0.43662208307437766
      - 0.4708350072876406
      - 0.49975684038184043
      - 0.46425790682625323
      - 0.3101029468216969
      - 0.5123131203967601
      - 0.3730631174381174
      - 0.5518738957455112
      - 0.22205869552841193
      - 0.5774327338479697
      - 0.5066882500215834
      - 0.30282757193553766
      - 0.4458598769901693
      - 0.4220111271121193
      - 0.4004754682491491
      - 0.2067209621186894
      - 0.1891226422444502
      - 0.5421826654248529
      - 0.4068081805439287
      - 0.5854973528886573
      - 0.2689536819001105
      - 0.5657761420823071
      - 0.24346491221403438
      - 0.19577731576152002
      - 0.1828583650392161
      - 0.14100177978603767
      - 0.08906653382459834
      - 0.16585509162039774
      - 0.11728586639783148
      - 0.057636963535839955
      - 0.15605310176489187
      - 0.11860050796427767
      - 0.34680604721365593
      - 0.16452524857736606
      - 0.08401262442981033
      - 0.35767834230827644
      - 0.36586245679079993
      - 0.16398282338292375
      - 0.598114475929856
      - 0.27996549074879945
      - 0.21600640521095069
      - 0.19529705749930465
      - 0.6989818636796656
      - 0.19986837236837238
      - 0.1309279318646782
      - 0.16807586638489325
      - 0.24003882353601452
      - 0.4225750394324927
      - 0.25091579470016
      - 0.08072624543212778
      - 0.4077665870685351
      - 0.4169208260874928
      - 0.458318865600419
      - 0.39848022933465954
      - 0.38576759841465724
      - 0.6710842221045459
      - 0.3813578413312455
      - 0.3784770784770785
      - 0.1908728687801651
      - 0.5189887661773559
      - 0.30949389745908346
      - 0.557452839309411
      - 0.22184394468877222
      - 0.2677298557729372
      - 0.8914869660644531
      - 0.625184450965701
      - 0.7092797667286581
      - 0.39035470945670125
      - 0.23579808549416761
      - 0.11434538384751891
      - 0.3282586837182425
      - 0.6055219237284453
      - 0.21856848889815922
      - 0.10317587159310235
      - 0.30300562461676683
      - 0.14440693086288459
      - 0.07342089870179758
      - 0.09343560391969115
      - 0.16000241837591228
      - 0.1064649446837289
      - 0.19228740175168743
      - 0.09682757301178355
      - 0.20549726633910298
      - 0.11788829997163328
      - 0.1167444215148971
      - 0.11909220736927953
      - 0.14436706931630394
      - 0.12953515928515927
      - 0.10240228121863099
      - 0.05734892502133883
    - - 0.2497169465199419
      - 0.7405872841266098
      - 0.4430744129607765
      - 0.39218407726060794
      - 0.6438356265483924
      - 0.5169635618005185
      - 0.4665185616216544
      - 0.3682345729715024
      - 0.4410605397018441
      - 0.4479124540980212
      - 0.5548144602414322
      - 0.3324135583131794
      - 0.17720560266291968
      - 0.3912242534727055
      - 0.5047067487592529
      - 0.5029488140065063
      - 0.4280486874236874
      - 0.33725490742071274
      - 0.4439182084343374
      - 0.3228766251864077
      - 0.4994097795900681
      - 0.22046310830413463
      - 0.5676245187274598
      - 0.5277606232151686
      - 0.3481424474402003
      - 0.4063707480161561
      - 0.3888175977461692
      - 0.40360832150305825
      - 0.21126766226198038
      - 0.18609005252496805
      - 0.5047101045245106
      - 0.39873045590760203
      - 0.5571140034208217
      - 0.28567872472583067
      - 0.570000439137037
      - 0.2554228873230322
      - 0.2258922421542195
      - 0.17768745296217822
      - 0.1372553964123731
      - 0.09879549019364897
      - 0.21677611979336114
      - 0.09423198988072407
      - 0.10669254117529978
      - 0.1679366506807057
      - 0.11461272519792313
      - 0.34034475533822217
      - 0.15513803326303321
      - 0.12852618943794572
      - 0.35115660305877683
      - 0.36582697941756737
      - 0.1250436992369982
      - 0.5927090453558892
      - 0.28102852941562617
      - 0.19872525061918997
      - 0.18515949417275518
      - 0.7161551964949697
      - 0.22109090256149078
      - 0.10212116495412005
      - 0.1511515893767415
      - 0.2430433715322281
      - 0.442722857184754
      - 0.23565076750172903
      - 0.08046653167620907
      - 0.4427034493284493
      - 0.3981483076310661
      - 0.4650244773650386
      - 0.3421194448826027
      - 0.4048277860024848
      - 0.6003800094832704
      - 0.36697486723802525
      - 0.4104142388896177
      - 0.1755165894196506
      - 0.5069236617623715
      - 0.3132343803539455
      - 0.5748004180588451
      - 0.25898948273948263
      - 0.2623443798748676
      - 0.8858646621577655
      - 0.6367538113019385
      - 0.7205810558422119
      - 0.37443224821617854
      - 0.24658119658119648
      - 0.100012527536566
      - 0.3331282984692075
      - 0.592085693197187
      - 0.20408276820515905
      - 0.10585364798600091
      - 0.29434532263833335
      - 0.1914391207144115
      - 0.06522652974265877
      - 0.08550610974391462
      - 0.19717309006782685
      - 0.09784824348777836
      - 0.22475555994074503
      - 0.0935204142621725
      - 0.1560813701802074
      - 0.13037457711370753
      - 0.12204569058017334
      - 0.11917928248573403
      - 0.17279366475337168
      - 0.15147501077733636
      - 0.10281450274871329
      - 0.0841164727528364
    - - 0.28202234974421114
      - 0.7538202769452769
      - 0.45183593701958014
      - 0.3999741767252542
      - 0.6200307268489085
      - 0.5311229579009751
      - 0.4938637693960496
      - 0.36102464190405736
      - 0.4232491867107251
      - 0.39664321382476364
      - 0.5441466106644679
      - 0.35254320029542313
      - 0.1557770731302928
      - 0.35491940719213455
      - 0.5004792198392715
      - 0.45249423768141556
      - 0.4821979058662296
      - 0.35918666579165714
      - 0.4888282618465545
      - 0.29932663170163165
      - 0.5249905829045765
      - 0.2681747265080598
      - 0.5610585492938434
      - 0.5110169367984828
      - 0.34662622600766935
      - 0.38647954609493074
      - 0.395783028890614
      - 0.4174138221202998
      - 0.19515058911126323
      - 0.2136220218182076
      - 0.5124760765550239
      - 0.41681447587326625
      - 0.6068231216208642
      - 0.34081270767762695
      - 0.5395001322207205
      - 0.2295829064382897
      - 0.2230699832916581
      - 0.21177321449151593
      - 0.10548356809103415
      - 0.10374620298400783
      - 0.18012147982315505
      - 0.07581167332977547
      - 0.09405209476881489
      - 0.16074492618841124
      - 0.1150397561871169
      - 0.3576671304320505
      - 0.16309769475807206
      - 0.11012368313504675
      - 0.34393184950150035
      - 0.35109877202900464
      - 0.1392232595007657
      - 0.5754716236571075
      - 0.2477125668170936
      - 0.21935886278669778
      - 0.20083556744278236
      - 0.6786271133757544
      - 0.23479118901112594
      - 0.11348050623618802
      - 0.18391980424947452
      - 0.23726371942664065
      - 0.4173829191329743
      - 0.2362094029707667
      - 0.07214674476945818
      - 0.44235155525478104
      - 0.38467683906937733
      - 0.46869148860907095
      - 0.37987283086739365
      - 0.4011266442578324
      - 0.6414207505316114
      - 0.39102079018181235
      - 0.39921510151425577
      - 0.1686413000463752
      - 0.46385517420000183
      - 0.3232398369970022
      - 0.5717466524812851
      - 0.21347861203124352
      - 0.2603736103801242
      - 0.8824781437351661
      - 0.6339968303238647
      - 0.7065222649444032
      - 0.378805755647861
      - 0.21233354011007458
      - 0.12098683480262426
      - 0.2534659069452883
      - 0.5804787804787804
      - 0.16946397246145972
      - 0.08884485565520048
      - 0.2911487322201607
      - 0.21089059299286572
      - 0.08245493683805372
      - 0.08258694907046556
      - 0.1900564082382264
      - 0.07971383012591804
      - 0.23721638503615255
      - 0.10310052293945215
      - 0.1902242600144175
      - 0.14362697487697484
      - 0.11743707681207678
      - 0.1440909061520422
      - 0.1527067281377626
      - 0.12886516827843358
      - 0.11790905050289627
      - 0.08254912239124954
    - - 0.2461766125556233
      - 0.7215876708518751
      - 0.47788837329050504
      - 0.3899826278858537
      - 0.616459928959929
      - 0.4823060092081831
      - 0.4489768232974754
      - 0.38254056549511095
      - 0.4148226112511827
      - 0.4456103116962118
      - 0.5217097557614797
      - 0.3473255730708384
      - 0.2120108363858363
      - 0.4055667512564064
      - 0.49263398135680747
      - 0.48155446892288994
      - 0.4292848462906601
      - 0.3271880412868784
      - 0.48304434315590494
      - 0.3497502497502498
      - 0.5044543853137603
      - 0.2744543020111202
      - 0.5770153142312233
      - 0.4551411045551671
      - 0.2912544540353529
      - 0.4047723668413325
      - 0.37156247277215015
      - 0.38889173075920064
      - 0.21353965328150104
      - 0.18590054269402087
      - 0.5532809690427208
      - 0.4626546467272274
      - 0.5882388354930033
      - 0.35008539491124624
      - 0.5613633367894733
      - 0.2533997866920913
      - 0.21625675911390196
      - 0.13563293134514062
      - 0.10897195861902913
      - 0.10916520495008869
      - 0.2312092120792796
      - 0.09618056674508288
      - 0.1146288978496586
      - 0.16472116349833743
      - 0.1090174386545354
      - 0.3528121704684205
      - 0.16644585368812168
      - 0.13024588911685686
      - 0.3340016315822766
      - 0.3894678319891388
      - 0.1832156530697666
      - 0.6074625537860832
      - 0.3044348022393785
      - 0.18776550004228573
      - 0.19028104159845863
      - 0.6859796816939672
      - 0.2080266246231668
      - 0.14062493221975977
      - 0.20461012146405405
      - 0.256151089858955
      - 0.4241124222458382
      - 0.25013400440241573
      - 0.07309453253602191
      - 0.44215612818553984
      - 0.44188487982605634
      - 0.4924015948209495
      - 0.345639903711791
      - 0.4003277694527695
      - 0.6522199452788313
      - 0.41711905591215925
      - 0.384791723428087
      - 0.17567880730380725
      - 0.5046892290144103
      - 0.26390826713860416
      - 0.5768482269409467
      - 0.22715005485157846
      - 0.2577760653980166
      - 0.9009042010312789
      - 0.6082468965710724
      - 0.7336991656268763
      - 0.4000941280941281
      - 0.22187190050093272
      - 0.11572250315227842
      - 0.30684606417043625
      - 0.5610683645814364
      - 0.20975946568051823
      - 0.08264005909224138
      - 0.3169742757242756
      - 0.20987997978367973
      - 0.06586667300953016
      - 0.047527417027417015
      - 0.17633275155077477
      - 0.08199764153372402
      - 0.240306144472811
      - 0.10400532202002791
      - 0.1984740704432743
      - 0.11854253202937413
      - 0.10378405179940266
      - 0.10035928405119454
      - 0.20938978805358116
      - 0.12643575062929902
      - 0.10780372825827372
      - 0.07704246811389669
  score_time:
  - 10.483044147491455
  - 10.53087067604065
  - 10.441181421279907
  - 9.938328266143799
  - 10.115019798278809
  test_level0__average_precision_macro:
  - 0.3348308197644716
  - 0.32813443681264975
  - 0.32834780403413644
  - 0.3202218850328642
  - 0.3530708452944818
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.5035760951322389
  - 0.5111075383378131
  - 0.5086053952626799
  - 0.5119131183918146
  - 0.5144214704834502
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.5352692557823278
  - 0.544385738732381
  - 0.5406480321275138
  - 0.5452984684343952
  - 0.5424220148635798
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.44769841528848603
  - 0.44585120249005616
  - 0.4402990483048137
  - 0.4416498019260725
  - 0.4727639643472829
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7849938731265906
  - 0.7905542071197412
  - 0.7881814787154595
  - 0.7885652642934194
  - 0.7889320388349516
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7849938731265906
  - 0.7905542071197411
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7849938731265905
  - 0.790554207119741
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.7111933510565621
  - 0.7223831961294049
  - 0.7138179209478849
  - 0.7190048166268443
  - 0.7176645962732919
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.179753039871807
  - -0.17769012944983817
  - -0.17550410754294246
  - -0.17730705109345887
  - -0.17902912621359224
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.17975303987180696
  - -0.1776901294498382
  - -0.1755041075429425
  - -0.17730705109345887
  - -0.17902912621359224
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.1797530398718069
  - -0.17769012944983817
  - -0.17550410754294246
  - -0.17730705109345882
  - -0.17902912621359218
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.20393034068417915
  - -0.19748339110340846
  - -0.19940834336141197
  - -0.19996375941307107
  - -0.20262111801242239
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.035253087001602415
  - -0.03175566343042071
  - -0.03631441374159821
  - -0.0341276846131215
  - -0.03203883495145632
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.035253087001602415
  - -0.03175566343042071
  - -0.03631441374159821
  - -0.0341276846131215
  - -0.03203883495145631
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.03525308700160241
  - -0.03175566343042071
  - -0.0363144137415982
  - -0.0341276846131215
  - -0.032038834951456305
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.08487630825925883
  - -0.0801334127671866
  - -0.08677373569070321
  - -0.08103142396008478
  - -0.07971428571428571
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6631497944298591
  - 0.6692550375975238
  - 0.6676760140963376
  - 0.6679304319725162
  - 0.6671965364738395
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.6460822342901474
  - 0.6536499707333389
  - 0.6504121408212002
  - 0.6509349955476402
  - 0.6514349847683181
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.648540997179183
  - 0.6565307156544657
  - 0.6531623710199969
  - 0.6534978032550464
  - 0.6534215399373025
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5667652668996345
  - 0.5786408924209933
  - 0.5696957185082802
  - 0.5753123916596634
  - 0.5727428830691976
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5352692557823279
  - 0.544385738732381
  - 0.5406480321275138
  - 0.5452984684343953
  - 0.5424220148635797
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.007517418353754576
  - 0.009275234306472492
  - 0.012246763635958379
  - 0.009205410093662084
  - 0.0132501171178097
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.2771682920212234
  - 0.2954052044153343
  - 0.2881489310130407
  - 0.29521357218681693
  - 0.2917902004937464
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.2815665311340444
  - 0.2993986437014154
  - 0.2927537324953167
  - 0.2996438790341743
  - 0.293147779333926
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.016732109074409897
  - 0.014615574603491636
  - 0.023347465483603835
  - 0.017001560310121542
  - 0.023525407152501305
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8270692299691484
  - 0.8331190239090601
  - 0.8320547973230705
  - 0.8368070109322533
  - 0.8302226243531049
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -88.03883495145631
  - -90.8125
  - -87.27884615384616
  - -88.3030303030303
  - -89.43
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.21500612687340936
  - -0.20944579288025889
  - -0.21181852128454068
  - -0.21143473570658036
  - -0.21106796116504856
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.21500612687340936
  - -0.2094457928802589
  - -0.2118185212845407
  - -0.21143473570658036
  - -0.21106796116504856
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.21500612687340936
  - -0.2094457928802588
  - -0.21181852128454062
  - -0.21143473570658033
  - -0.21106796116504853
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.2888066489434379
  - -0.277616803870595
  - -0.2861820790521152
  - -0.2809951833731558
  - -0.28233540372670807
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.24749610238015346
  - -0.2495532391761409
  - -0.2407728716563703
  - -0.24778489198098727
  - -0.2418547375132025
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7849938731265906
  - 0.7905542071197412
  - 0.7881814787154595
  - 0.7885652642934194
  - 0.7889320388349516
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7849938731265906
  - 0.7905542071197411
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7849938731265905
  - 0.790554207119741
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.7111933510565621
  - 0.7223831961294049
  - 0.7138179209478849
  - 0.7190048166268443
  - 0.7176645962732919
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7849938731265906
  - 0.7905542071197412
  - 0.7881814787154595
  - 0.7885652642934194
  - 0.7889320388349516
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7849938731265906
  - 0.7905542071197411
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7849938731265905
  - 0.790554207119741
  - 0.7881814787154593
  - 0.7885652642934197
  - 0.7889320388349514
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.7111933510565621
  - 0.7223831961294049
  - 0.7138179209478849
  - 0.7190048166268443
  - 0.7176645962732919
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5996239509021261
  - 0.586418494735381
  - 0.603040398429175
  - 0.5757160627659759
  - 0.622119265635385
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7508655449113524
  - 0.7479670344745591
  - 0.7558258146535815
  - 0.7487918659007521
  - 0.7554208202538825
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7525038976198464
  - 0.7504467608238592
  - 0.7592271283436296
  - 0.7522151080190128
  - 0.7581452624867977
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.597190759122347
  - 0.5894487083228505
  - 0.5990919568256344
  - 0.5724438749764591
  - 0.6199281610583682
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7303233103968328
  - 0.7348300970873787
  - 0.7309559372666171
  - 0.7308031774051189
  - 0.7334951456310679
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7303233103968328
  - 0.7348300970873787
  - 0.7309559372666169
  - 0.7308031774051191
  - 0.733495145631068
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.730323310396833
  - 0.7348300970873787
  - 0.7309559372666168
  - 0.7308031774051191
  - 0.7334951456310677
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.5674009704834069
  - 0.5682544410745232
  - 0.5634353111789936
  - 0.5624412670720557
  - 0.5707329192546584
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.05467056272975775
  - 0.05572411003236245
  - 0.05722554144884242
  - 0.057762086888300486
  - 0.05543689320388349
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.05467056272975775
  - 0.05572411003236246
  - 0.05722554144884242
  - 0.05776208688830048
  - 0.055436893203883494
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.054670562729757746
  - 0.055724110032362446
  - 0.057225541448842406
  - 0.057762086888300465
  - 0.055436893203883494
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.14379238057315516
  - 0.15412875505488158
  - 0.15038260976889137
  - 0.1565635495547886
  - 0.14693167701863352
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.30040132149025306
  - 0.2904875368661073
  - 0.3025327515814809
  - 0.2846695628307408
  - 0.3225219181482956
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.3149040019493621
  - 0.2968056244821928
  - 0.30863668215000567
  - 0.28875977979169953
  - 0.32588103255612405
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.34717686468735165
  - 0.3226756351246037
  - 0.3364072352945338
  - 0.3134513839636677
  - 0.34842759082062835
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.4198227072771775
  - 0.4090471560155693
  - 0.4208637600440032
  - 0.4075483309612662
  - 0.44381282967070307
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.4337826373833537
  - 0.42404935275080924
  - 0.4424010455563852
  - 0.4320878689810729
  - 0.44058252427184474
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.43378263738335376
  - 0.42404935275080907
  - 0.4424010455563854
  - 0.4320878689810729
  - 0.44058252427184463
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.4337826373833537
  - 0.42404935275080896
  - 0.4424010455563853
  - 0.4320878689810729
  - 0.4405825242718447
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.49026198367432966
  - 0.4831564124783363
  - 0.49737727174550267
  - 0.490617480604965
  - 0.4940207039337475
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.03383919313790178
  - -0.03519417475728155
  - -0.03342046303211352
  - -0.038834951456310676
  - -0.028932038834951452
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.033839193137901784
  - -0.03519417475728155
  - -0.03342046303211352
  - -0.038834951456310676
  - -0.028932038834951455
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.03383919313790178
  - -0.03519417475728155
  - -0.03342046303211351
  - -0.038834951456310676
  - -0.028932038834951452
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.03728124109446794
  - -0.03758665511265164
  - -0.03902465364559227
  - -0.04363198105375828
  - -0.03192132505175983
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.5323781694787444
  - -0.5407564724919094
  - -0.5241784914115012
  - -0.5290771795626164
  - -0.5304854368932039
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.5323781694787445
  - -0.5407564724919094
  - -0.5241784914115011
  - -0.5290771795626165
  - -0.5304854368932039
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.5323781694787444
  - -0.5407564724919093
  - -0.5241784914115011
  - -0.5290771795626164
  - -0.5304854368932038
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.47245677523120233
  - -0.47925693240901196
  - -0.4635980746089051
  - -0.4657505383412769
  - -0.47405797101449293
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.2889320043653353
  - 0.2815082155728124
  - 0.2967912299035973
  - 0.2885110265651808
  - 0.2956812516637374
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.27696196437168996
  - 0.26907527433741896
  - 0.2840275696733593
  - 0.27558168626469853
  - 0.2825301954924667
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.2827809216853293
  - 0.27489508976622584
  - 0.29012334960220476
  - 0.2806699331018491
  - 0.28900246751311487
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.33757173655938527
  - 0.33274530150210974
  - 0.3443383127332228
  - 0.33976669715065794
  - 0.3411401963395862
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.3471768646873515
  - 0.32267563512460373
  - 0.33640723529453403
  - 0.31345138396366773
  - 0.34842759082062824
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.09540441268419461
  - 0.07790176666798933
  - 0.1108135159159415
  - 0.06957729525879809
  - 0.11222692769739574
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.15345366578919853
  - 0.13851010451649723
  - 0.16365801013127282
  - 0.13597133158905644
  - 0.17650885631582036
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.15168303465445324
  - 0.13916193689605036
  - 0.1616789749325898
  - 0.13824182033714832
  - 0.17593081690908807
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.10359502137915219
  - 0.0816577428606709
  - 0.10691262360132728
  - 0.07234714812459349
  - 0.11473179087758817
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6976942142884576
  - 0.6784125529224013
  - 0.6855727333563195
  - 0.6708859734022897
  - 0.6897564934395072
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -86.76699029126213
  - -87.91666666666667
  - -85.9326923076923
  - -88.52525252525253
  - -86.71
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.5662173626166462
  - -0.5759506472491909
  - -0.5575989544436147
  - -0.5679121310189271
  - -0.5594174757281553
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.5662173626166462
  - -0.575950647249191
  - -0.5575989544436146
  - -0.5679121310189271
  - -0.5594174757281554
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.5662173626166461
  - -0.575950647249191
  - -0.5575989544436146
  - -0.567912131018927
  - -0.5594174757281553
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5097380163256703
  - -0.5168435875216638
  - -0.5026227282544974
  - -0.509382519395035
  - -0.5059792960662525
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.4047988626981913
  - -0.4242842874559227
  - -0.4105156348584249
  - -0.4378210909646467
  - -0.3799013418515463
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.4337826373833537
  - 0.42404935275080924
  - 0.4424010455563852
  - 0.4320878689810729
  - 0.44058252427184474
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.43378263738335376
  - 0.42404935275080907
  - 0.4424010455563854
  - 0.4320878689810729
  - 0.44058252427184463
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.4337826373833537
  - 0.42404935275080896
  - 0.4424010455563853
  - 0.4320878689810729
  - 0.4405825242718447
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.49026198367432966
  - 0.4831564124783363
  - 0.49737727174550267
  - 0.490617480604965
  - 0.4940207039337475
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.4337826373833537
  - 0.42404935275080924
  - 0.4424010455563852
  - 0.4320878689810729
  - 0.44058252427184474
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.43378263738335376
  - 0.42404935275080907
  - 0.4424010455563854
  - 0.4320878689810729
  - 0.44058252427184463
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.4337826373833537
  - 0.42404935275080896
  - 0.4424010455563853
  - 0.4320878689810729
  - 0.4405825242718447
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.49026198367432966
  - 0.4831564124783363
  - 0.49737727174550267
  - 0.490617480604965
  - 0.4940207039337475
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5899866658414653
  - 0.5714993506602453
  - 0.6023486935082194
  - 0.5640647523951019
  - 0.6194559025019835
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.6321741561413613
  - 0.6125321527050571
  - 0.6304029430598888
  - 0.5988945851117315
  - 0.6517216561571555
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.63514597526969
  - 0.6126066799374631
  - 0.6240317226796617
  - 0.6037373932827452
  - 0.6488055453926428
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5971260200704442
  - 0.5743372309010403
  - 0.5930272989750053
  - 0.5624850013492529
  - 0.6189590027152566
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.23319822791969078
  - 0.22582928802588997
  - 0.24309185959671395
  - 0.23585368245562421
  - 0.23504854368932035
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.23319822791969083
  - 0.22582928802588997
  - 0.24309185959671398
  - 0.23585368245562421
  - 0.23504854368932038
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.23319822791969078
  - 0.22582928802588995
  - 0.24309185959671392
  - 0.2358536824556241
  - 0.23504854368932032
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.17982050351146348
  - 0.16913092143269784
  - 0.18661097226079176
  - 0.17772215269086358
  - 0.17638923395445139
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.20058440946366293
  - 0.1982200647249191
  - 0.19930918595967143
  - 0.19623418652544874
  - 0.20553398058252428
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.20058440946366293
  - 0.1982200647249191
  - 0.1993091859596714
  - 0.19623418652544866
  - 0.20553398058252428
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.20058440946366288
  - 0.19822006472491904
  - 0.19930918595967134
  - 0.19623418652544863
  - 0.20553398058252426
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.3104414801628664
  - 0.3140254910456383
  - 0.3107662994847111
  - 0.3128953279141014
  - 0.31763146997929603
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.3252521978969773
  - 0.321832114027297
  - 0.3201712223773023
  - 0.30668663262071316
  - 0.34915854786021217
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.3476422085005686
  - 0.34477677163919795
  - 0.33781699078384175
  - 0.327212459040507
  - 0.3656773489081865
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.3852374330970958
  - 0.38336644557999017
  - 0.3790473841571776
  - 0.3633919055742999
  - 0.3995129171914333
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.4361399904623368
  - 0.43660316730633686
  - 0.43728632653748534
  - 0.4301448011630011
  - 0.4665851339727736
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.4552738241116033
  - 0.44447815533980595
  - 0.4609783420463031
  - 0.45778170050014716
  - 0.47883495145631066
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.45527382411160333
  - 0.44447815533980584
  - 0.4609783420463032
  - 0.4577817005001471
  - 0.47883495145631066
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.4552738241116034
  - 0.4444781553398058
  - 0.46097834204630317
  - 0.45778170050014705
  - 0.47883495145631066
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.4978821912781414
  - 0.49104112507221265
  - 0.5024838779351415
  - 0.5016245053791987
  - 0.5093995859213252
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.03704401922895654
  - -0.04207119741100324
  - -0.0371545929798357
  - -0.04187506129253702
  - -0.0345631067961165
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.037044019228956546
  - -0.042071197411003236
  - -0.0371545929798357
  - -0.04187506129253702
  - -0.0345631067961165
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.037044019228956546
  - -0.042071197411003236
  - -0.0371545929798357
  - -0.04187506129253703
  - -0.034563106796116495
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.037035302017090814
  - -0.041215337954939334
  - -0.040764139590854384
  - -0.04369097735806122
  - -0.03339544513457557
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.50768215665944
  - -0.513450647249191
  - -0.5018670649738612
  - -0.500343238207316
  - -0.48660194174757276
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.50768215665944
  - -0.513450647249191
  - -0.5018670649738611
  - -0.5003432382073159
  - -0.4866019417475728
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.5076821566594399
  - -0.513450647249191
  - -0.5018670649738611
  - -0.5003432382073159
  - -0.4866019417475729
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.46508250670476775
  - -0.46774353697284815
  - -0.4567519824740043
  - -0.45468451726274006
  - -0.45720496894409934
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.31321372992641977
  - 0.30372598816870106
  - 0.3181060019350436
  - 0.31348581120469277
  - 0.33799510706600594
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.2947278496460825
  - 0.2857421494051102
  - 0.29952687128472644
  - 0.29683326974437235
  - 0.3147817207046209
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.29901091941407776
  - 0.2906887372320614
  - 0.3051771456466098
  - 0.3012821640322799
  - 0.3193021374122462
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.3471192992222963
  - 0.34201464842819285
  - 0.35149105583503054
  - 0.35113580455311627
  - 0.35887727938450925
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.38523743309709574
  - 0.38336644557999017
  - 0.37904738415717776
  - 0.3633919055742999
  - 0.3995129171914333
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.08772444751594166
  - 0.05280348689795067
  - 0.10649101164104939
  - 0.0694929953708986
  - 0.10458691685920213
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.16614344331882702
  - 0.13907533695862836
  - 0.17133992972746495
  - 0.15430097398948414
  - 0.19812808525438627
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.1652998590264778
  - 0.13985812057532646
  - 0.16913514703120686
  - 0.15600953429587544
  - 0.1975380816158948
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.09182152829199217
  - 0.05912798945791091
  - 0.09521394905190803
  - 0.06640166736865012
  - 0.1106919655392742
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.7232873602515109
  - 0.7236924244862067
  - 0.7119933355947984
  - 0.7042071900977892
  - 0.7226607116990946
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -86.46601941747574
  - -87.89583333333333
  - -86.64423076923077
  - -87.77777777777777
  - -86.14
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.5447261758883967
  - -0.555521844660194
  - -0.5390216579536969
  - -0.542218299499853
  - -0.5211650485436893
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.5447261758883967
  - -0.5555218446601942
  - -0.5390216579536968
  - -0.5422182994998529
  - -0.5211650485436893
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.5447261758883967
  - -0.555521844660194
  - -0.5390216579536968
  - -0.5422182994998529
  - -0.5211650485436894
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.5021178087218586
  - -0.5089588749277874
  - -0.49751612206485857
  - -0.49837549462080133
  - -0.49060041407867494
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.34462699882267506
  - -0.3550844030441287
  - -0.35063380154316537
  - -0.3640236648681977
  - -0.32360205180556745
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.4552738241116033
  - 0.44447815533980595
  - 0.4609783420463031
  - 0.45778170050014716
  - 0.47883495145631066
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.45527382411160333
  - 0.44447815533980584
  - 0.4609783420463032
  - 0.4577817005001471
  - 0.47883495145631066
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.4552738241116034
  - 0.4444781553398058
  - 0.46097834204630317
  - 0.45778170050014705
  - 0.47883495145631066
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.4978821912781414
  - 0.49104112507221265
  - 0.5024838779351415
  - 0.5016245053791987
  - 0.5093995859213252
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.4552738241116033
  - 0.44447815533980595
  - 0.4609783420463031
  - 0.45778170050014716
  - 0.47883495145631066
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.45527382411160333
  - 0.44447815533980584
  - 0.4609783420463032
  - 0.4577817005001471
  - 0.47883495145631066
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.4552738241116034
  - 0.4444781553398058
  - 0.46097834204630317
  - 0.45778170050014705
  - 0.47883495145631066
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.4978821912781414
  - 0.49104112507221265
  - 0.5024838779351415
  - 0.5016245053791987
  - 0.5093995859213252
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5925018347268073
  - 0.5845151626740053
  - 0.6085728217499143
  - 0.573134871681818
  - 0.6176591481371846
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.6547748117841439
  - 0.6460381008125917
  - 0.6526153019182511
  - 0.6343751270284437
  - 0.6795215907763121
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.657029805507175
  - 0.6463326749634472
  - 0.6503153682817666
  - 0.6372893202257972
  - 0.6768115560848537
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5949553112515623
  - 0.5843247023462613
  - 0.6018913227078391
  - 0.5744644828037592
  - 0.6217680886324105
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.25789424073899514
  - 0.2531351132686085
  - 0.265403286034354
  - 0.2645876238109249
  - 0.2789320388349515
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.2578942407389952
  - 0.25313511326860844
  - 0.265403286034354
  - 0.26458762381092477
  - 0.27893203883495143
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.25789424073899514
  - 0.2531351132686084
  - 0.2654032860343539
  - 0.2645876238109247
  - 0.2789320388349514
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.187194772037898
  - 0.18064431686886193
  - 0.19345706439569255
  - 0.1887881737694003
  - 0.19324223602484475
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.19737958337260822
  - 0.1913430420711974
  - 0.19557505601194922
  - 0.1931940766892224
  - 0.19990291262135923
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.19737958337260816
  - 0.1913430420711974
  - 0.19557505601194922
  - 0.1931940766892223
  - 0.19990291262135923
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.19737958337260808
  - 0.19134304207119737
  - 0.19557505601194916
  - 0.19319407668922234
  - 0.19990291262135923
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.31068741924024346
  - 0.31039680820335064
  - 0.30902681353944894
  - 0.31283633160979846
  - 0.3161573498964803
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.3047262800153497
  - 0.30109936534762755
  - 0.3061810388569891
  - 0.29145112624753794
  - 0.33231620382881694
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.3125241410300944
  - 0.3090995086169064
  - 0.3067465604513733
  - 0.29440577324668926
  - 0.3335659981331737
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.3452446283214143
  - 0.333992046070692
  - 0.33801559690313143
  - 0.32344413110325615
  - 0.35477241625041167
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.4203728261862088
  - 0.41908886962345604
  - 0.4236027553188591
  - 0.41840914970918786
  - 0.4541283385984339
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.4308605900650392
  - 0.4198017799352751
  - 0.4392270351008216
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.48684225936032405
  - 0.48003773108030046
  - 0.49360517140300525
  - 0.48924370951905377
  - 0.49380124223602484
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.031954001319634266
  - -0.03499190938511327
  - -0.03370052277819268
  - -0.04001176816710798
  - -0.029708737864077663
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.03195400131963427
  - -0.03499190938511327
  - -0.03370052277819268
  - -0.040011768167107976
  - -0.02970873786407767
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.031954001319634266
  - -0.03499190938511327
  - -0.03370052277819268
  - -0.040011768167107976
  - -0.029708737864077666
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.035692396578714175
  - -0.0373925837666089
  - -0.039352494677404426
  - -0.044866689422384046
  - -0.03227743271221533
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.5371854086153267
  - -0.5452063106796116
  - -0.5270724421209858
  - -0.526919682259488
  - -0.5281553398058253
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.5371854086153266
  - -0.5452063106796117
  - -0.5270724421209858
  - -0.526919682259488
  - -0.5281553398058253
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.5371854086153265
  - -0.5452063106796117
  - -0.5270724421209858
  - -0.526919682259488
  - -0.5281553398058253
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.4774653440609618
  - -0.4825696851530907
  - -0.46704233391959027
  - -0.46588960105856225
  - -0.4739213250517598
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.286960894449281
  - 0.27804406927526376
  - 0.29435573907121276
  - 0.28909457113395026
  - 0.29735287946299144
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.2745840091307743
  - 0.265664
  - 0.2814163526526706
  - 0.2763800225309801
  - 0.28380904898417053
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.28017420994387515
  - 0.27201233627018456
  - 0.2875064551894448
  - 0.28154668337535016
  - 0.29016268962594044
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.33463477682387127
  - 0.33030333863593814
  - 0.3412450051097365
  - 0.3384064983047778
  - 0.34123434626760296
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.34524462832141434
  - 0.33399204607069216
  - 0.33801559690313143
  - 0.32344413110325615
  - 0.3547724162504117
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.10122224449834107
  - 0.0719164789443182
  - 0.10488397889917736
  - 0.0651105006589238
  - 0.1099154906275181
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.1564103845365355
  - 0.13453920397189467
  - 0.15942660687027158
  - 0.13339651258570756
  - 0.17559333231497046
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.1543562026609858
  - 0.13592559902090207
  - 0.15994696956415508
  - 0.13442200186453465
  - 0.1740060483504275
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.10424319567452503
  - 0.08029215465578736
  - 0.09830131171579443
  - 0.06604005347323333
  - 0.11461323416126347
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6931916634349194
  - 0.6882779715758017
  - 0.6845673088696316
  - 0.6760570784535173
  - 0.6949904696516253
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -86.55339805825243
  - -87.69791666666667
  - -85.84615384615384
  - -88.16161616161617
  - -86.79
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.5691394099349608
  - -0.5801982200647249
  - -0.5607729648991785
  - -0.566931450426596
  - -0.5578640776699029
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.5691394099349609
  - -0.5801982200647249
  - -0.5607729648991785
  - -0.5669314504265961
  - -0.5578640776699029
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.5691394099349608
  - -0.5801982200647249
  - -0.5607729648991785
  - -0.566931450426596
  - -0.557864077669903
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.513157740639676
  - -0.5199622689196995
  - -0.5063948285969947
  - -0.5107562904809463
  - -0.5061987577639752
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.38961968215442605
  - -0.4065650536253451
  - -0.3931576081992201
  - -0.4171381935795942
  - -0.36825262068847153
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.4308605900650392
  - 0.4198017799352751
  - 0.4392270351008216
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.48684225936032405
  - 0.48003773108030046
  - 0.49360517140300525
  - 0.48924370951905377
  - 0.49380124223602484
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.4308605900650392
  - 0.4198017799352751
  - 0.4392270351008216
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.43086059006503913
  - 0.41980177993527507
  - 0.4392270351008215
  - 0.43306854957340396
  - 0.4421359223300971
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.48684225936032405
  - 0.48003773108030046
  - 0.49360517140300525
  - 0.48924370951905377
  - 0.49380124223602484
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5912173196638795
  - 0.5800712825137316
  - 0.604657393719331
  - 0.5713587290107643
  - 0.6226516621702923
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.6332227261642343
  - 0.6207546997251729
  - 0.6317217592395341
  - 0.6076218670774365
  - 0.6577742680430778
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.6334992084051281
  - 0.6196380288927371
  - 0.6279837970216614
  - 0.6116698440320741
  - 0.6532606060016137
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5947879822738318
  - 0.5810597173607489
  - 0.5936046456123459
  - 0.5714253760318934
  - 0.6231230598774654
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.22839098878310868
  - 0.2213794498381877
  - 0.24019790888722933
  - 0.23801117975875252
  - 0.237378640776699
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.22839098878310868
  - 0.2213794498381877
  - 0.24019790888722928
  - 0.23801117975875258
  - 0.23737864077669904
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.22839098878310865
  - 0.22137944983818766
  - 0.24019790888722922
  - 0.23801117975875252
  - 0.23737864077669898
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.17481193468170403
  - 0.16581816868861934
  - 0.18316671295010648
  - 0.17758308997357808
  - 0.17652587991718424
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.20246960128193048
  - 0.19842233009708735
  - 0.19902912621359226
  - 0.19505736981465144
  - 0.20475728155339806
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.20246960128193045
  - 0.19842233009708737
  - 0.19902912621359223
  - 0.19505736981465135
  - 0.20475728155339806
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.2024696012819304
  - 0.19842233009708732
  - 0.1990291262135922
  - 0.19505736981465133
  - 0.204757281553398
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.3120303246786202
  - 0.3142195623916811
  - 0.3104384584528989
  - 0.3116606195454757
  - 0.3172753623188406
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.30101411450468196
  - 0.28867314452491616
  - 0.30466362976555444
  - 0.2846740944162688
  - 0.3299477887932421
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.31247813620018994
  - 0.2983177934262656
  - 0.3072477903620181
  - 0.2881101816317383
  - 0.3308096218385628
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.3428598904934605
  - 0.3253246481290996
  - 0.33640421471967374
  - 0.3144822193364115
  - 0.3529041109890494
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.4171218345536983
  - 0.4073314526227781
  - 0.4211041989617526
  - 0.4109666831906132
  - 0.4521247311420501
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.4318974455650863
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.4418446601941748
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.43189744556508625
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.44184466019417473
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.4318974455650862
  - 0.4214199029126213
  - 0.44053398058252424
  - 0.4333627537511032
  - 0.44184466019417473
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.487107717412096
  - 0.48155419555170437
  - 0.4941220031472738
  - 0.4896903958230616
  - 0.4941656314699792
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.03289659722876802
  - -0.03509304207119741
  - -0.034260642270351006
  - -0.04060017652250663
  - -0.029126213592233004
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.032896597228768025
  - -0.035093042071197414
  - -0.034260642270351006
  - -0.04060017652250662
  - -0.02912621359223301
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.03289659722876802
  - -0.03509304207119741
  - -0.034260642270351006
  - -0.040600176522506616
  - -0.029126213592233007
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.03677374776019769
  - -0.03735196418255344
  - -0.040185596593538826
  - -0.046050829530178715
  - -0.03197515527950311
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.5352059572061457
  - -0.5434870550161811
  - -0.5252053771471249
  - -0.52603706972639
  - -0.5290291262135922
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.5352059572061457
  - -0.5434870550161812
  - -0.5252053771471247
  - -0.5260370697263901
  - -0.5290291262135922
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.5352059572061457
  - -0.5434870550161812
  - -0.5252053771471247
  - -0.5260370697263901
  - -0.5290291262135921
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.47611853482770605
  - -0.4810938402657423
  - -0.46569240025918746
  - -0.4642587746467596
  - -0.47385921325051783
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.2874375820130809
  - 0.27937995683422867
  - 0.2950536312376619
  - 0.2892880034169282
  - 0.29687726902761585
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.27542678528492426
  - 0.2669613684412839
  - 0.28249027237354085
  - 0.27661971830985915
  - 0.28356906972397034
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.2810382452554386
  - 0.27322380349137587
  - 0.2887449160649239
  - 0.2817696791481253
  - 0.28975196534301206
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.33472234327300576
  - 0.33165613028905366
  - 0.34135462754773394
  - 0.33870386016111304
  - 0.341378290433824
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.3428598904934605
  - 0.32532464812909967
  - 0.33640421471967386
  - 0.31448221933641163
  - 0.35290411098904934
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.0974935481871383
  - 0.07298668341241431
  - 0.10312414184660534
  - 0.0643720507718462
  - 0.1135011811285625
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.1544674075983946
  - 0.1359774264680317
  - 0.1590160155514646
  - 0.1319057622292949
  - 0.17718766094190117
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.15273332704703457
  - 0.13620674216379527
  - 0.15867922934424245
  - 0.13341744061308908
  - 0.17642066884446894
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0999280673050037
  - 0.08211935390513452
  - 0.09700879971572396
  - 0.06554063341978981
  - 0.11716001505785865
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.6922752219341414
  - 0.6788315681263696
  - 0.6821099079246461
  - 0.6710632664615314
  - 0.694276379455633
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -86.59223300970874
  - -87.77083333333333
  - -85.72115384615384
  - -88.0909090909091
  - -86.73
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.5681025544349136
  - -0.5785800970873787
  - -0.5594660194174758
  - -0.5666372462488967
  - -0.5581553398058252
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.5681025544349138
  - -0.5785800970873787
  - -0.5594660194174758
  - -0.5666372462488968
  - -0.5581553398058252
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.5681025544349136
  - -0.5785800970873786
  - -0.5594660194174756
  - -0.5666372462488967
  - -0.5581553398058252
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.512892282587904
  - -0.5184458044482956
  - -0.5058779968527262
  - -0.5103096041769384
  - -0.5058343685300206
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.39858100414840625
  - -0.4190965957725627
  - -0.40232777192074437
  - -0.42931385030049923
  - -0.3723501329636712
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.4318974455650863
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.4418446601941748
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.43189744556508625
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.44184466019417473
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.4318974455650862
  - 0.4214199029126213
  - 0.44053398058252424
  - 0.4333627537511032
  - 0.44184466019417473
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.487107717412096
  - 0.48155419555170437
  - 0.4941220031472738
  - 0.4896903958230616
  - 0.4941656314699792
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.4318974455650863
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.4418446601941748
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.43189744556508625
  - 0.4214199029126214
  - 0.4405339805825243
  - 0.4333627537511033
  - 0.44184466019417473
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.4318974455650862
  - 0.4214199029126213
  - 0.44053398058252424
  - 0.4333627537511032
  - 0.44184466019417473
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.487107717412096
  - 0.48155419555170437
  - 0.4941220031472738
  - 0.4896903958230616
  - 0.4941656314699792
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5913872866155402
  - 0.5749327808094827
  - 0.6034612905692409
  - 0.5671178503771009
  - 0.6215793119203554
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.6322580447135744
  - 0.6147064186516557
  - 0.6313221978346768
  - 0.6018864927312987
  - 0.6562288382034185
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.6328009768718498
  - 0.6148223754274195
  - 0.626667922714315
  - 0.6052639252489348
  - 0.6519603009124326
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.5943840793356238
  - 0.575953838510247
  - 0.5931404523357309
  - 0.5663794483503296
  - 0.6221190779232717
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.23037044019228956
  - 0.22309870550161814
  - 0.24206497386109044
  - 0.23889379229185054
  - 0.23650485436893207
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.23037044019228956
  - 0.22309870550161812
  - 0.24206497386109035
  - 0.23889379229185054
  - 0.23650485436893204
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.23037044019228956
  - 0.22309870550161806
  - 0.24206497386109033
  - 0.23889379229185048
  - 0.23650485436893198
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.17615874391495973
  - 0.16729401357596765
  - 0.18451664661050945
  - 0.1792139163853807
  - 0.17658799171842654
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.20152700537279672
  - 0.19832119741100318
  - 0.19846900672143392
  - 0.1944689614592528
  - 0.2053398058252427
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.2015270053727967
  - 0.19832119741100324
  - 0.19846900672143392
  - 0.19446896145925271
  - 0.20533980582524272
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.20152700537279666
  - 0.19832119741100318
  - 0.19846900672143383
  - 0.19446896145925271
  - 0.2053398058252427
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.3109489734971366
  - 0.3142601819757365
  - 0.3096053565367646
  - 0.310476479437681
  - 0.3175776397515528
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.30203108895648767
  - 0.29141712393559227
  - 0.30572442399910676
  - 0.28667402496868927
  - 0.3285782993958302
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.3141292743297983
  - 0.2980005246346524
  - 0.31190955084196365
  - 0.29189458434497817
  - 0.32909420533414185
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.3447164174133303
  - 0.3210890529124121
  - 0.3392264486214601
  - 0.31539705384537187
  - 0.3507661102791162
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.419305866573586
  - 0.41184862337420114
  - 0.42589610248397347
  - 0.4143167801253375
  - 0.4509995503805738
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.4334055990197003
  - 0.42324029126213597
  - 0.4393203883495145
  - 0.43355888986956953
  - 0.4413592233009708
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.43340559901970027
  - 0.4232402912621359
  - 0.4393203883495146
  - 0.4335588898695695
  - 0.4413592233009709
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.4334055990197002
  - 0.42324029126213586
  - 0.4393203883495146
  - 0.43355888986956953
  - 0.4413592233009709
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.488962019979622
  - 0.4831744656268053
  - 0.4933583263908172
  - 0.4902171485400521
  - 0.4936273291925464
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.033273635592421524
  - -0.03620550161812298
  - -0.0340739357729649
  - -0.03991370010787486
  - -0.02932038834951456
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.03327363559242153
  - -0.03620550161812298
  - -0.0340739357729649
  - -0.039913700107874865
  - -0.029320388349514562
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.033273635592421524
  - -0.03620550161812298
  - -0.0340739357729649
  - -0.039913700107874865
  - -0.02932038834951456
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.037093858940275844
  - -0.03841258665511265
  - -0.040023604554290465
  - -0.045161670943898724
  - -0.032484472049689433
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.5333207653878781
  - -0.540554207119741
  - -0.5266056758775206
  - -0.5265274100225557
  - -0.5293203883495146
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.5333207653878782
  - -0.5405542071197411
  - -0.5266056758775205
  - -0.5265274100225557
  - -0.5293203883495146
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.5333207653878782
  - -0.5405542071197411
  - -0.5266056758775205
  - -0.5265274100225557
  - -0.5293203883495146
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.4739441210801021
  - -0.4784129477180821
  - -0.46661806905489217
  - -0.464621180516049
  - -0.4738881987577641
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.2886507683162717
  - 0.28064711664709174
  - 0.293949687773894
  - 0.28937240670607356
  - 0.29637524894035394
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.2766546329723225
  - 0.2684240908216279
  - 0.28149300155520995
  - 0.2767795655168096
  - 0.2831693036003488
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.2822594213793686
  - 0.2747109197040653
  - 0.28761035898166953
  - 0.28194266276509733
  - 0.2894533768860764
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.3363329680343532
  - 0.3329444485422251
  - 0.3407018828451644
  - 0.3391552636226935
  - 0.34076802320481303
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.34471641741333037
  - 0.32108905291241213
  - 0.33922644862146006
  - 0.315397053845372
  - 0.3507661102791161
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.09945008855772021
  - 0.07077037914027168
  - 0.10390649702880837
  - 0.06728292710427192
  - 0.11215497925288728
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.15486399785356056
  - 0.1343897873698624
  - 0.15833181527809906
  - 0.13423310102934066
  - 0.17604884326217085
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.15287378489306355
  - 0.1349649223013237
  - 0.15813108807907492
  - 0.13576628482047517
  - 0.17565500155337793
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.1055238830400499
  - 0.08146599694059116
  - 0.09673863049389593
  - 0.06762991951093536
  - 0.11453620839873913
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6938641208850812
  - 0.6781526079224739
  - 0.68659057892956
  - 0.6724043438779089
  - 0.692608097079919
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -86.50485436893204
  - -87.6875
  - -85.625
  - -88.15151515151516
  - -86.48
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.5665944009802997
  - -0.576759708737864
  - -0.5606796116504855
  - -0.5664411101304305
  - -0.5586407766990292
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.5665944009802998
  - -0.5767597087378641
  - -0.5606796116504854
  - -0.5664411101304305
  - -0.5586407766990291
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.5665944009802998
  - -0.5767597087378641
  - -0.5606796116504854
  - -0.5664411101304305
  - -0.5586407766990291
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.511037980020378
  - -0.5168255343731946
  - -0.5066416736091828
  - -0.509782851459948
  - -0.5063726708074535
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.39993141983114183
  - -0.4232240984826152
  - -0.402215012030779
  - -0.4342221671293773
  - -0.37393979834291996
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.4334055990197003
  - 0.42324029126213597
  - 0.4393203883495145
  - 0.43355888986956953
  - 0.4413592233009708
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.43340559901970027
  - 0.4232402912621359
  - 0.4393203883495146
  - 0.4335588898695695
  - 0.4413592233009709
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.4334055990197002
  - 0.42324029126213586
  - 0.4393203883495146
  - 0.43355888986956953
  - 0.4413592233009709
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.488962019979622
  - 0.4831744656268053
  - 0.4933583263908172
  - 0.4902171485400521
  - 0.4936273291925464
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.4334055990197003
  - 0.42324029126213597
  - 0.4393203883495145
  - 0.43355888986956953
  - 0.4413592233009708
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.43340559901970027
  - 0.4232402912621359
  - 0.4393203883495146
  - 0.4335588898695695
  - 0.4413592233009709
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.4334055990197002
  - 0.42324029126213586
  - 0.4393203883495146
  - 0.43355888986956953
  - 0.4413592233009709
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.488962019979622
  - 0.4831744656268053
  - 0.4933583263908172
  - 0.4902171485400521
  - 0.4936273291925464
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5931758479155392
  - 0.5757314337163182
  - 0.6068556217968893
  - 0.5689717196775061
  - 0.6220467153982154
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.6334801098685339
  - 0.6137110852238171
  - 0.6335749833076841
  - 0.6038648470844966
  - 0.6545024425915495
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.6343502336981722
  - 0.611455205844908
  - 0.6281758955032652
  - 0.6059316954382862
  - 0.6498909311661858
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5970452045803869
  - 0.579038748540192
  - 0.597901889109958
  - 0.5702396231527718
  - 0.6218035513617648
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.23225563201055704
  - 0.22603155339805828
  - 0.2406646751306946
  - 0.238403451995685
  - 0.23621359223300972
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.23225563201055707
  - 0.22603155339805825
  - 0.24066467513069456
  - 0.238403451995685
  - 0.2362135922330097
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.23225563201055707
  - 0.22603155339805822
  - 0.2406646751306945
  - 0.23840345199568494
  - 0.23621359223300967
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.17833315766256375
  - 0.16997490612362795
  - 0.18359097781480452
  - 0.17885151051609124
  - 0.17655900621118015
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.2011499670091432
  - 0.1972087378640776
  - 0.19865571321882
  - 0.19515543787388454
  - 0.20514563106796116
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.20114996700914317
  - 0.19720873786407767
  - 0.19865571321882
  - 0.19515543787388448
  - 0.20514563106796116
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.20114996700914317
  - 0.19720873786407764
  - 0.19865571321881997
  - 0.19515543787388448
  - 0.20514563106796113
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.3106288623170585
  - 0.3131995595031773
  - 0.3097673485760129
  - 0.311365638023961
  - 0.31706832298136645
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.2997264982505939
  - 0.2886253255350049
  - 0.30394042373637575
  - 0.281759509151209
  - 0.32842706801018995
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.3125856639928284
  - 0.295127020748129
  - 0.30714012385099415
  - 0.2873262984651573
  - 0.33064336096222935
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.3424486805801939
  - 0.3244153393085189
  - 0.33874305298237734
  - 0.313737412716245
  - 0.35213641492834585
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.41611595013362
  - 0.40689278846600296
  - 0.4223564654256311
  - 0.4062848622865487
  - 0.4518023626628327
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.43227448392873974
  - 0.4231391585760519
  - 0.4410941000746825
  - 0.4320878689810729
  - 0.44048543689320385
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.43227448392873974
  - 0.4231391585760518
  - 0.4410941000746826
  - 0.4320878689810729
  - 0.4404854368932039
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.4322744839287398
  - 0.4231391585760518
  - 0.44109410007468264
  - 0.43208786898107276
  - 0.44048543689320385
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.48735756028435223
  - 0.4819152585210862
  - 0.4950438149896633
  - 0.48939541430154704
  - 0.4931759834368529
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.033179376001508144
  - -0.03610436893203883
  - -0.03416728902165795
  - -0.04010983622634108
  - -0.029514563106796114
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.03317937600150815
  - -0.03610436893203883
  - -0.03416728902165796
  - -0.04010983622634108
  - -0.029514563106796118
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.03317937600150815
  - -0.036104368932038826
  - -0.03416728902165795
  - -0.040109836226341074
  - -0.02951456310679611
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.03687524642705174
  - -0.03871046360485269
  - -0.04000046283439784
  - -0.04515324290042687
  - -0.03273706004140787
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.5345461400697521
  - -0.5407564724919094
  - -0.5247386109036596
  - -0.527802294792586
  - -0.5300000000000001
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.5345461400697521
  - -0.5407564724919094
  - -0.5247386109036595
  - -0.527802294792586
  - -0.53
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.5345461400697521
  - -0.5407564724919093
  - -0.5247386109036595
  - -0.5278022947925859
  - -0.53
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.47576719328859596
  - -0.4793742778740612
  - -0.4649557221759389
  - -0.4654513427980262
  - -0.47408695652173916
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.2876420902971176
  - 0.2805867725408291
  - 0.295413491307829
  - 0.2882405615027884
  - 0.2957137341820746
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.2757335257335257
  - 0.26834273986659823
  - 0.28295107491466553
  - 0.27558168626469853
  - 0.28245035174002364
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.2814048755043502
  - 0.2744090451222944
  - 0.28913555643319333
  - 0.28070783454504955
  - 0.2887650598760628
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.3348900313642191
  - 0.33165943233897716
  - 0.3420960993739524
  - 0.3384766978836446
  - 0.34034217659490196
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.34244868058019395
  - 0.3244153393085188
  - 0.3387430529823774
  - 0.31373741271624517
  - 0.35213641492834596
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.09622842481991903
  - 0.06989690409299994
  - 0.10599872187412912
  - 0.06509026306814647
  - 0.1113597562099802
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.15395943228859202
  - 0.13460295087691923
  - 0.15990321546608316
  - 0.13202437287327737
  - 0.1745046569103895
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.15190854330260703
  - 0.13509793092137495
  - 0.1589222737244972
  - 0.13388369099127007
  - 0.17429420839318716
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.10029078814465832
  - 0.07691864564679607
  - 0.09973582684752823
  - 0.06693757626627352
  - 0.11382237220816756
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.6913274953396934
  - 0.6787897325953732
  - 0.6859411650842215
  - 0.6707392552767094
  - 0.6946378447623489
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -86.44660194174757
  - -87.625
  - -85.63461538461539
  - -88.17171717171718
  - -86.66
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.5677255160712603
  - -0.5768608414239482
  - -0.5589058999253175
  - -0.5679121310189271
  - -0.5595145631067961
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.5677255160712602
  - -0.5768608414239482
  - -0.5589058999253174
  - -0.5679121310189271
  - -0.5595145631067961
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.5677255160712602
  - -0.5768608414239482
  - -0.5589058999253174
  - -0.5679121310189271
  - -0.5595145631067961
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.5126424397156477
  - -0.5180847414789139
  - -0.5049561850103367
  - -0.5106045856984529
  - -0.5068240165631471
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.3983147985904591
  - -0.4190836580536841
  - -0.4053383412985477
  - -0.4356003006638025
  - -0.3768011322277318
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.43227448392873974
  - 0.4231391585760519
  - 0.4410941000746825
  - 0.4320878689810729
  - 0.44048543689320385
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.43227448392873974
  - 0.4231391585760518
  - 0.4410941000746826
  - 0.4320878689810729
  - 0.4404854368932039
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.4322744839287398
  - 0.4231391585760518
  - 0.44109410007468264
  - 0.43208786898107276
  - 0.44048543689320385
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.48735756028435223
  - 0.4819152585210862
  - 0.4950438149896633
  - 0.48939541430154704
  - 0.4931759834368529
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.43227448392873974
  - 0.4231391585760519
  - 0.4410941000746825
  - 0.4320878689810729
  - 0.44048543689320385
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.43227448392873974
  - 0.4231391585760518
  - 0.4410941000746826
  - 0.4320878689810729
  - 0.4404854368932039
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.4322744839287398
  - 0.4231391585760518
  - 0.44109410007468264
  - 0.43208786898107276
  - 0.44048543689320385
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.48735756028435223
  - 0.4819152585210862
  - 0.4950438149896633
  - 0.48939541430154704
  - 0.4931759834368529
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5908304499722808
  - 0.5705701406130124
  - 0.6048714342494088
  - 0.5646736571530944
  - 0.6217126308573737
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.6320098939503889
  - 0.6117185320761102
  - 0.6310570680762931
  - 0.5994018966015211
  - 0.6544880272971586
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.6321255541974279
  - 0.6137201823584275
  - 0.626065231021941
  - 0.6051106688191454
  - 0.650245944914294
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5943634512149221
  - 0.5728172820654941
  - 0.5957882861526554
  - 0.5641990788850907
  - 0.6239096641152538
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.23103025732868318
  - 0.22582928802589
  - 0.2425317401045556
  - 0.2371285672256546
  - 0.23553398058252428
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.23103025732868318
  - 0.22582928802588997
  - 0.24253174010455564
  - 0.2371285672256546
  - 0.23553398058252428
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.23103025732868315
  - 0.22582928802588995
  - 0.24253174010455558
  - 0.23712856722565454
  - 0.23553398058252423
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.17651008545406988
  - 0.16901357596764874
  - 0.18525332469375788
  - 0.17802134823411422
  - 0.17636024844720496
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.20124422660005659
  - 0.19730987055016175
  - 0.198562359970127
  - 0.1949593017554183
  - 0.20495145631067965
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.20124422660005656
  - 0.1973098705501618
  - 0.19856235997012697
  - 0.19495930175541826
  - 0.20495145631067962
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.2012442266000565
  - 0.19730987055016178
  - 0.19856235997012692
  - 0.19495930175541826
  - 0.2049514563106796
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.3108474748302826
  - 0.3129016825534373
  - 0.3097904902959055
  - 0.3113740660674328
  - 0.31681573498964805
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.30473448823126636
  - 0.2926367752009409
  - 0.3044488351286409
  - 0.28283715150381483
  - 0.3254533685037523
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.31151924696620586
  - 0.29963909514515386
  - 0.3063509240862071
  - 0.2885395810048221
  - 0.32739142824731327
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.3431278120332052
  - 0.3229836117023672
  - 0.33254328793531557
  - 0.3156509458950564
  - 0.3496717067726802
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.42251073724441907
  - 0.41313433762560686
  - 0.42031103468946684
  - 0.40550543214630624
  - 0.44729054837892074
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.43302856065604667
  - 0.42425161812297746
  - 0.4420276325616131
  - 0.4326762773364715
  - 0.4409708737864077
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.4330285606560468
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.4326762773364715
  - 0.44097087378640776
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.4330285606560469
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.43267627733647146
  - 0.4409708737864077
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.4888175795690991
  - 0.48261933131138074
  - 0.496648307568885
  - 0.48965246962743847
  - 0.49313457556935814
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0337449335469884
  - -0.03580097087378641
  - -0.033140403286034355
  - -0.03932529175247622
  - -0.02980582524271844
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.033744933546988404
  - -0.035800970873786406
  - -0.033140403286034355
  - -0.03932529175247622
  - -0.029805825242718447
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.0337449335469884
  - -0.0358009708737864
  - -0.033140403286034355
  - -0.03932529175247621
  - -0.029805825242718444
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.036879150221930744
  - -0.03821400202195263
  - -0.038708383473726425
  - -0.0446138481182286
  - -0.03327536231884059
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.5332265057969648
  - -0.5399474110032362
  - -0.5248319641523527
  - -0.5279984309110523
  - -0.5292233009708739
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.5332265057969648
  - -0.5399474110032363
  - -0.5248319641523524
  - -0.5279984309110523
  - -0.5292233009708738
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.5332265057969648
  - -0.5399474110032362
  - -0.5248319641523524
  - -0.5279984309110523
  - -0.5292233009708738
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.47430327020897023
  - -0.4791666666666667
  - -0.4646433089573887
  - -0.46573368225433304
  - -0.4735900621118013
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.28829303998355793
  - 0.2813515472785697
  - 0.296501861851305
  - 0.28896616338522535
  - 0.2960330518998595
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.2763474494706448
  - 0.2692381746999551
  - 0.2837198154473006
  - 0.2760605681391565
  - 0.2828496699464441
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.28197740635616936
  - 0.27535093059281984
  - 0.2897962463475418
  - 0.28103354414536924
  - 0.2892188463186141
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.33625549815318795
  - 0.3320978208234853
  - 0.34376049021223165
  - 0.3388781408319745
  - 0.340263307694405
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.3431278120332051
  - 0.3229836117023673
  - 0.33254328793531557
  - 0.31565094589505627
  - 0.34967170677268017
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.09474648312443464
  - 0.07198743044882358
  - 0.1105351118563773
  - 0.06831569153739717
  - 0.11025846263397751
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.15294965478297445
  - 0.1367837640895146
  - 0.16416192149847217
  - 0.13509076022378963
  - 0.1740625754217909
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.15103732072591552
  - 0.1375929556436105
  - 0.16340438245218442
  - 0.13722046576698435
  - 0.17430967554420806
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.10309408786330775
  - 0.07918415955633193
  - 0.10508117708505309
  - 0.06837874771775405
  - 0.11048791273097981
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6919255937511128
  - 0.6800160857106592
  - 0.6793168377821852
  - 0.6719407882294041
  - 0.6910010897251841
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -86.47572815533981
  - -87.61458333333333
  - -85.84615384615384
  - -88.41414141414141
  - -86.84
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.5669714393439533
  - -0.5757483818770225
  - -0.557972367438387
  - -0.5673237226635285
  - -0.5590291262135922
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.5669714393439532
  - -0.5757483818770227
  - -0.5579723674383869
  - -0.5673237226635285
  - -0.5590291262135922
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.566971439343953
  - -0.5757483818770227
  - -0.5579723674383869
  - -0.5673237226635285
  - -0.5590291262135922
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5111824204309009
  - -0.5173806686886193
  - -0.503351692431115
  - -0.5103475303725615
  - -0.5068654244306419
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.3990803476171535
  - -0.42348453583302703
  - -0.4075547062754932
  - -0.4350596324974622
  - -0.3773823009078602
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.43302856065604667
  - 0.42425161812297746
  - 0.4420276325616131
  - 0.4326762773364715
  - 0.4409708737864077
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.4330285606560468
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.4326762773364715
  - 0.44097087378640776
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.4330285606560469
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.43267627733647146
  - 0.4409708737864077
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.4888175795690991
  - 0.48261933131138074
  - 0.496648307568885
  - 0.48965246962743847
  - 0.49313457556935814
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.43302856065604667
  - 0.42425161812297746
  - 0.4420276325616131
  - 0.4326762773364715
  - 0.4409708737864077
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.4330285606560468
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.4326762773364715
  - 0.44097087378640776
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.4330285606560469
  - 0.42425161812297735
  - 0.44202763256161315
  - 0.43267627733647146
  - 0.4409708737864077
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.4888175795690991
  - 0.48261933131138074
  - 0.496648307568885
  - 0.48965246962743847
  - 0.49313457556935814
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5900792896293195
  - 0.5763610882941685
  - 0.6047754435323619
  - 0.5641049588435028
  - 0.6196495175500852
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.6314853490304223
  - 0.614613904601638
  - 0.6302465494453944
  - 0.600124300674989
  - 0.6531903094561968
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.6334185378506675
  - 0.6132473382503374
  - 0.6236004678078745
  - 0.6046039739377542
  - 0.649590131849639
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5954831677999116
  - 0.5796714428094255
  - 0.5924100893331729
  - 0.5625677811778272
  - 0.6196443766573743
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.23234989160147038
  - 0.22663834951456313
  - 0.24243838685586253
  - 0.23693243110718837
  - 0.23631067961165053
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.23234989160147046
  - 0.2266383495145631
  - 0.24243838685586258
  - 0.2369324311071884
  - 0.23631067961165048
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.2323498916014704
  - 0.22663834951456308
  - 0.24243838685586253
  - 0.2369324311071883
  - 0.23631067961165045
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.17797400853369558
  - 0.1692211871750433
  - 0.1855657379123083
  - 0.17773900877780727
  - 0.17685714285714288
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.20067866905457632
  - 0.19761326860841422
  - 0.19958924570575054
  - 0.1957438462292832
  - 0.2046601941747573
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.2006786690545763
  - 0.19761326860841424
  - 0.19958924570575057
  - 0.19574384622928312
  - 0.20466019417475728
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.20067866905457624
  - 0.19761326860841422
  - 0.19958924570575048
  - 0.19574384622928306
  - 0.20466019417475725
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.31084357103540355
  - 0.3133981441363373
  - 0.31108256965657693
  - 0.3119134608496311
  - 0.31627743271221537
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.29633263053403475
  - 0.29399791459596214
  - 0.30282298623097287
  - 0.27958616861023183
  - 0.32267976586978
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.30739323128581475
  - 0.2995820355487043
  - 0.30778346042713645
  - 0.2838947134073537
  - 0.3270739657090425
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.3418153297956399
  - 0.32438259383142437
  - 0.33490122962174207
  - 0.31020038859263116
  - 0.3501302510309134
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.4144910959806397
  - 0.41054956427718337
  - 0.42085010198492656
  - 0.40177000578274064
  - 0.44460324768027515
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.4341596757470072
  - 0.4258697411003237
  - 0.4421209858103061
  - 0.43159752868490736
  - 0.4422330097087379
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.43415967574700726
  - 0.4258697411003236
  - 0.4421209858103062
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.4341596757470074
  - 0.4258697411003236
  - 0.4421209858103061
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.4905352493158599
  - 0.48462774407856735
  - 0.4959617698787373
  - 0.4897620341925725
  - 0.4947701863354037
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.032802337637854645
  - -0.03549757281553398
  - -0.033607169529499624
  - -0.03952142787094243
  - -0.029223300970873785
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.03280233763785465
  - -0.03549757281553398
  - -0.033607169529499624
  - -0.039521427870942434
  - -0.029223300970873785
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.03280233763785465
  - -0.03549757281553397
  - -0.03360716952949962
  - -0.03952142787094243
  - -0.02922330097087378
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.03614914057955739
  - -0.03819594887348353
  - -0.03945277546360579
  - -0.04462227616170043
  - -0.0321656314699793
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.5330379866151381
  - -0.5386326860841424
  - -0.5242718446601942
  - -0.5288810434441501
  - -0.5285436893203884
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.5330379866151381
  - -0.5386326860841424
  - -0.5242718446601942
  - -0.5288810434441502
  - -0.5285436893203883
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.533037986615138
  - -0.5386326860841424
  - -0.5242718446601942
  - -0.5288810434441502
  - -0.5285436893203883
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.4733156101045826
  - -0.4771763070479491
  - -0.4645854546576569
  - -0.4656156896457273
  - -0.473064182194617
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.28939621119042136
  - 0.282693045442839
  - 0.2964523620443839
  - 0.2880728455586471
  - 0.2970802652593106
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.27726944377558393
  - 0.2705428846771603
  - 0.2837967401725791
  - 0.2751828925154755
  - 0.28388906201308817
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.2832012833151676
  - 0.27648950594476335
  - 0.2900495288957594
  - 0.2802301387246786
  - 0.29033148725879077
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.33777275155152686
  - 0.33383118195263356
  - 0.34297910579864893
  - 0.3389133081801158
  - 0.34174793714187063
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.34181532979563994
  - 0.3243825938314245
  - 0.3349012296217419
  - 0.3102003885926311
  - 0.3501302510309132
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.09931077081013
  - 0.08006833454022845
  - 0.10968207500073626
  - 0.0665408976732176
  - 0.11288442033168578
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.1571825890256342
  - 0.13950975092582238
  - 0.16276814961792516
  - 0.13330787217645845
  - 0.17727485527406778
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.15551227954533506
  - 0.13986854562796738
  - 0.1610817630382326
  - 0.1351617137504712
  - 0.17747239017823133
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.10816749532325125
  - 0.08350467901122567
  - 0.10302278588499786
  - 0.06816798201304841
  - 0.1163565172989448
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.6906855074919026
  - 0.6804677004317847
  - 0.6821385717408737
  - 0.6667162621833869
  - 0.6903404467255366
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -86.30097087378641
  - -87.58333333333333
  - -85.90384615384616
  - -88.66666666666667
  - -86.4
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.5658403242529928
  - -0.5741302588996763
  - -0.5578790141896939
  - -0.5684024713150926
  - -0.5577669902912621
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.5658403242529927
  - -0.5741302588996764
  - -0.5578790141896938
  - -0.5684024713150927
  - -0.5577669902912621
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.5658403242529926
  - -0.5741302588996764
  - -0.5578790141896938
  - -0.5684024713150927
  - -0.5577669902912621
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.5094647506841401
  - -0.5153722559214327
  - -0.5040382301212627
  - -0.5102379658074275
  - -0.5052298136645963
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.4023735873057742
  - -0.4206714725272768
  - -0.4102229787224426
  - -0.4356739703142741
  - -0.37679277785951526
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.4341596757470072
  - 0.4258697411003237
  - 0.4421209858103061
  - 0.43159752868490736
  - 0.4422330097087379
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.43415967574700726
  - 0.4258697411003236
  - 0.4421209858103062
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.4341596757470074
  - 0.4258697411003236
  - 0.4421209858103061
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.4905352493158599
  - 0.48462774407856735
  - 0.4959617698787373
  - 0.4897620341925725
  - 0.4947701863354037
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.4341596757470072
  - 0.4258697411003237
  - 0.4421209858103061
  - 0.43159752868490736
  - 0.4422330097087379
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.43415967574700726
  - 0.4258697411003236
  - 0.4421209858103062
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.4341596757470074
  - 0.4258697411003236
  - 0.4421209858103061
  - 0.4315975286849073
  - 0.44223300970873786
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.4905352493158599
  - 0.48462774407856735
  - 0.4959617698787373
  - 0.4897620341925725
  - 0.4947701863354037
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5891019808501928
  - 0.5749696868205855
  - 0.603806903478109
  - 0.5594990391825703
  - 0.6186324646038646
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.6293921942488034
  - 0.6141491908378794
  - 0.6306907912540806
  - 0.5958583913652751
  - 0.6524058181073428
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.6326279683201568
  - 0.6143873352585388
  - 0.6238473573928787
  - 0.6023038777490114
  - 0.6501464523400018
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5949105903866599
  - 0.5751701048043483
  - 0.5935506294776753
  - 0.5580661056699032
  - 0.6194866053914648
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.23253841078329715
  - 0.22795307443365692
  - 0.24299850634802095
  - 0.23604981857409044
  - 0.23699029126213592
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.2325384107832972
  - 0.22795307443365695
  - 0.24299850634802092
  - 0.2360498185740904
  - 0.23699029126213592
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.23253841078329718
  - 0.22795307443365695
  - 0.24299850634802087
  - 0.23604981857409035
  - 0.2369902912621359
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.17896166863808305
  - 0.17121154679376083
  - 0.1856235922120399
  - 0.17785700138641314
  - 0.17738302277432713
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.2016212649637101
  - 0.1979166666666666
  - 0.1991224794622853
  - 0.19554771011081695
  - 0.20524271844660194
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.20162126496371005
  - 0.19791666666666666
  - 0.19912247946228528
  - 0.1955477101108169
  - 0.20524271844660194
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.20162126496371
  - 0.19791666666666663
  - 0.19912247946228526
  - 0.19554771011081684
  - 0.2052427184466019
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.31157358067777696
  - 0.31341619728480646
  - 0.3103381776666976
  - 0.3119050328061592
  - 0.31738716356107655
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.30136704210093807
  - 0.2861033210785993
  - 0.30923828655234076
  - 0.28210348270492824
  - 0.3232271242513578
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.31208562743311224
  - 0.2928312801808519
  - 0.3091945959188425
  - 0.2868864725164263
  - 0.3300892253358895
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.34581944726396185
  - 0.32352122327001964
  - 0.33765081775373457
  - 0.3119961961574468
  - 0.35161476717942364
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.4196697381264421
  - 0.403264888093898
  - 0.42661583729238917
  - 0.40669687056563636
  - 0.44429392498001946
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.43491375247431424
  - 0.42354368932038844
  - 0.443427931292009
  - 0.43355888986956953
  - 0.44174757281553406
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695695
  - 0.441747572815534
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695694
  - 0.4417475728155339
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.490800707367632
  - 0.48221313547082617
  - 0.4977282544972076
  - 0.49069754701794754
  - 0.4945341614906832
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.033273635592421524
  - -0.03580097087378641
  - -0.03360716952949963
  - -0.03912915563401
  - -0.029417475728155333
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.03327363559242153
  - -0.035800970873786406
  - -0.033607169529499624
  - -0.03912915563401
  - -0.02941747572815534
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.033273635592421524
  - -0.0358009708737864
  - -0.03360716952949962
  - -0.039129155634009996
  - -0.029417475728155337
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.03665663391382763
  - -0.03834488734835356
  - -0.03940649202382053
  - -0.044167161814220646
  - -0.0326583850931677
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.5318126119332642
  - -0.5406553398058251
  - -0.5229648991784913
  - -0.5273119544964203
  - -0.5288349514563107
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.5318126119332642
  - -0.5406553398058253
  - -0.5229648991784914
  - -0.5273119544964205
  - -0.5288349514563107
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.5318126119332642
  - -0.5406553398058253
  - -0.5229648991784914
  - -0.5273119544964204
  - -0.5288349514563107
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.47254265871854034
  - -0.4794419771808202
  - -0.4628652534789718
  - -0.4651352911678318
  - -0.47280745341614916
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.2901151286531152
  - 0.28084845945650105
  - 0.29757159923888243
  - 0.28977284476751586
  - 0.29657417941241926
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.2778848470248133
  - 0.2686682063125481
  - 0.2848746551517332
  - 0.2767795655168096
  - 0.2834890965732087
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.283715478868587
  - 0.27458684597689764
  - 0.2910872888277479
  - 0.28177296446569416
  - 0.289898351239457
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.33820986850708107
  - 0.33178260550006894
  - 0.3445621288130167
  - 0.33981052833870645
  - 0.34145954668868356
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.34581944726396197
  - 0.32352122327001964
  - 0.33765081775373446
  - 0.31199619615744667
  - 0.3516147671794236
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.09792139120356959
  - 0.0762049288712446
  - 0.1114050552930941
  - 0.06863655691305443
  - 0.11266454212196973
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.15647121875182662
  - 0.1360142749219361
  - 0.16413865395298502
  - 0.13665820673891674
  - 0.17613677771089353
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.15524484913318792
  - 0.1360119544922276
  - 0.1627605256434631
  - 0.13855922770140783
  - 0.17615206281476736
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.10683521916048438
  - 0.08071559662652976
  - 0.10720323046886988
  - 0.06873292939179591
  - 0.11614926120795648
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6938772308988587
  - 0.6780390684452642
  - 0.6844266050750242
  - 0.6694862029364241
  - 0.6950268663401471
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -86.25242718446601
  - -87.92708333333333
  - -85.90384615384616
  - -88.55555555555556
  - -86.69
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.5650862475256857
  - -0.5764563106796117
  - -0.556572068707991
  - -0.5664411101304305
  - -0.558252427184466
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.5650862475256857
  - -0.5764563106796117
  - -0.556572068707991
  - -0.5664411101304305
  - -0.558252427184466
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.5650862475256857
  - -0.5764563106796117
  - -0.556572068707991
  - -0.5664411101304305
  - -0.5582524271844661
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.5091992926323681
  - -0.5177868645291739
  - -0.5022717455027924
  - -0.5093024529820525
  - -0.5054658385093168
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.40410534410855653
  - -0.4236746849841459
  - -0.4071461880347084
  - -0.4391249369133815
  - -0.37848918822418454
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.43491375247431424
  - 0.42354368932038844
  - 0.443427931292009
  - 0.43355888986956953
  - 0.44174757281553406
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695695
  - 0.441747572815534
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695694
  - 0.4417475728155339
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.490800707367632
  - 0.48221313547082617
  - 0.4977282544972076
  - 0.49069754701794754
  - 0.4945341614906832
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.43491375247431424
  - 0.42354368932038844
  - 0.443427931292009
  - 0.43355888986956953
  - 0.44174757281553406
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695695
  - 0.441747572815534
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.43491375247431424
  - 0.42354368932038833
  - 0.44342793129200897
  - 0.4335588898695694
  - 0.4417475728155339
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.490800707367632
  - 0.48221313547082617
  - 0.4977282544972076
  - 0.49069754701794754
  - 0.4945341614906832
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5938711793600796
  - 0.5714238271804789
  - 0.6061768846831078
  - 0.5630845148663842
  - 0.6212000710827239
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.6320451177445048
  - 0.6099470180581024
  - 0.6318250536957917
  - 0.5985761314891478
  - 0.6532760660162716
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.6337471624745257
  - 0.6132452167977986
  - 0.6261519466727878
  - 0.6029338368780548
  - 0.6506580752049446
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5995254801820251
  - 0.5729343587404662
  - 0.5982191426657618
  - 0.5629149915897915
  - 0.6197625237187331
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.23376378546517104
  - 0.22593042071197406
  - 0.2443054518297237
  - 0.2376189075218201
  - 0.23669902912621354
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.23376378546517107
  - 0.2259304207119741
  - 0.24430545182972369
  - 0.23761890752182013
  - 0.2366990291262136
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.23376378546517104
  - 0.22593042071197403
  - 0.24430545182972363
  - 0.23761890752182008
  - 0.23669902912621357
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.17973462002412546
  - 0.16894587666088962
  - 0.1873437933907248
  - 0.1783373998643085
  - 0.17763975155279504
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.2011499670091432
  - 0.1976132686084142
  - 0.1991224794622853
  - 0.19593998234774943
  - 0.2050485436893204
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.20114996700914317
  - 0.19761326860841424
  - 0.19912247946228528
  - 0.19593998234774934
  - 0.20504854368932038
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.20114996700914314
  - 0.1976132686084142
  - 0.1991224794622852
  - 0.1959399823477493
  - 0.20504854368932032
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.3110660873435067
  - 0.3132672588099364
  - 0.3103844611064828
  - 0.312360147153639
  - 0.3168944099378882
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.29865350388339995
  - 0.2924310646915523
  - 0.3060222508498295
  - 0.28018395052123335
  - 0.32566742007328864
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.3130788730998541
  - 0.2964638594022871
  - 0.30863637713758946
  - 0.2846069821869896
  - 0.3266159047617316
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.3464652712206962
  - 0.3222736195255012
  - 0.3396339596190743
  - 0.3114173657581801
  - 0.3528814288197008
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.41721124647227265
  - 0.4099278372362562
  - 0.4250158084718661
  - 0.40317984987840544
  - 0.44630819712053404
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.43321707983787344
  - 0.42415048543689327
  - 0.44380134428678114
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.4332170798378735
  - 0.4241504854368932
  - 0.4438013442867812
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.43321707983787355
  - 0.42415048543689315
  - 0.4438013442867812
  - 0.43277434539570453
  - 0.4401941747572814
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.4890908452106292
  - 0.4833595103986135
  - 0.4974621247184424
  - 0.49045313375726385
  - 0.49313043478260865
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.0333678951833349
  - -0.03549757281553398
  - -0.03416728902165795
  - -0.03893301951554379
  - -0.028737864077669904
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.033367895183334904
  - -0.03549757281553398
  - -0.03416728902165796
  - -0.03893301951554379
  - -0.028737864077669904
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.033367895183334904
  - -0.03549757281553397
  - -0.03416728902165795
  - -0.03893301951554378
  - -0.0287378640776699
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.03692989955535777
  - -0.03778975303292894
  - -0.039742046962263564
  - -0.043703619423268995
  - -0.031879917184265014
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.5334150249787916
  - -0.5403519417475727
  - -0.522031366691561
  - -0.5282926350887515
  - -0.5310679611650486
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.5334150249787916
  - -0.5403519417475728
  - -0.5220313666915609
  - -0.5282926350887516
  - -0.5310679611650485
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.5334150249787916
  - -0.5403519417475727
  - -0.5220313666915608
  - -0.5282926350887516
  - -0.5310679611650485
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.4739792552340131
  - -0.47885073656845745
  - -0.4627958283192941
  - -0.46584324681946715
  - -0.47498964803312643
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.28865241980119755
  - 0.281509859490581
  - 0.2979756919879096
  - 0.28905425625358516
  - 0.2954405845392033
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.27650102274094573
  - 0.26915671929149015
  - 0.2851829634073185
  - 0.27614041674488454
  - 0.282210880119507
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.2823539509400954
  - 0.27504970403530876
  - 0.29129016431258614
  - 0.281333284879136
  - 0.28850460367330505
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.3365266972509554
  - 0.3329071817251211
  - 0.34442679535562215
  - 0.3395822006001515
  - 0.3403973855715536
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.34646527122069637
  - 0.3222736195255012
  - 0.33963395961907433
  - 0.31141736575818
  - 0.35288142881970086
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.0960390721059334
  - 0.07414412258653465
  - 0.10943191449589143
  - 0.06844416422901647
  - 0.11224000750832697
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.15436016420470253
  - 0.1376459498538679
  - 0.16274818147651487
  - 0.13641354099625333
  - 0.17674057086512432
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.1525766169440011
  - 0.13740218525520462
  - 0.16113469371383018
  - 0.13848500653404192
  - 0.17643070842633662
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.1026209163660001
  - 0.08322536937234733
  - 0.10543576024964521
  - 0.06934031797080273
  - 0.11334060201307353
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.6958963207186941
  - 0.6789491668069187
  - 0.687032822602368
  - 0.667844848991211
  - 0.6934459121892275
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -86.54368932038835
  - -87.44791666666667
  - -85.96153846153847
  - -88.64646464646465
  - -86.43
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.5667829201621266
  - -0.5758495145631066
  - -0.5561986557132189
  - -0.5672256546042954
  - -0.5598058252427184
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.5667829201621265
  - -0.5758495145631068
  - -0.5561986557132188
  - -0.5672256546042954
  - -0.5598058252427185
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.5667829201621264
  - -0.5758495145631067
  - -0.5561986557132188
  - -0.5672256546042954
  - -0.5598058252427185
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5109091547893708
  - -0.5166404896013865
  - -0.5025378752815576
  - -0.5095468662427362
  - -0.5068695652173913
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.4031528415180628
  - -0.4229518010590148
  - -0.4064628497428433
  - -0.4365156683653278
  - -0.37079315490602965
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.43321707983787344
  - 0.42415048543689327
  - 0.44380134428678114
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.4332170798378735
  - 0.4241504854368932
  - 0.4438013442867812
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.43321707983787355
  - 0.42415048543689315
  - 0.4438013442867812
  - 0.43277434539570453
  - 0.4401941747572814
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.4890908452106292
  - 0.4833595103986135
  - 0.4974621247184424
  - 0.49045313375726385
  - 0.49313043478260865
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.43321707983787344
  - 0.42415048543689327
  - 0.44380134428678114
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.4332170798378735
  - 0.4241504854368932
  - 0.4438013442867812
  - 0.43277434539570464
  - 0.44019417475728156
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.43321707983787355
  - 0.42415048543689315
  - 0.4438013442867812
  - 0.43277434539570453
  - 0.4401941747572814
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.4890908452106292
  - 0.4833595103986135
  - 0.4974621247184424
  - 0.49045313375726385
  - 0.49313043478260865
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5929633884806338
  - 0.5743024849527233
  - 0.6058557034793798
  - 0.5611106579862936
  - 0.6190669477829178
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.6323603991680155
  - 0.6118789526392083
  - 0.6307713428723434
  - 0.5964440860905191
  - 0.6526198156470274
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.634379133204199
  - 0.6136455373854882
  - 0.6258938743102791
  - 0.6025110350824509
  - 0.6519014765194291
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5981353897434334
  - 0.5763197712765755
  - 0.5965114339202295
  - 0.5600859800800533
  - 0.6194452754967634
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.23216137241964366
  - 0.22623381877022652
  - 0.24523898431665425
  - 0.23663822692948902
  - 0.2344660194174757
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.23216137241964369
  - 0.22623381877022652
  - 0.24523898431665422
  - 0.23663822692948908
  - 0.23446601941747572
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.2321613724196437
  - 0.2262338187702265
  - 0.2452389843166542
  - 0.23663822692948902
  - 0.2344660194174757
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.17829802350865273
  - 0.16953711727325246
  - 0.18741321855040266
  - 0.17762944421267324
  - 0.17545755693581785
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.20105570741822984
  - 0.1979166666666666
  - 0.198562359970127
  - 0.19613611846621565
  - 0.20572815533980585
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.2010557074182298
  - 0.19791666666666666
  - 0.19856235997012697
  - 0.19613611846621556
  - 0.20572815533980582
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.20105570741822973
  - 0.19791666666666663
  - 0.19856235997012692
  - 0.1961361184662155
  - 0.20572815533980582
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.31079282170197653
  - 0.313822393125361
  - 0.3100489061680398
  - 0.31282368954459067
  - 0.3176728778467909
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.8570616881019935
  - 0.8558139782576736
  - 0.8561569668096803
  - 0.8564358357956104
  - 0.8630864542337577
  train_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro_oob:
  - 0.2741636889949285
  - 0.277265569715071
  - 0.28213376704854365
  - 0.28508770427635904
  - 0.27136939608619254
  train_level0__average_precision_micro:
  - 0.657809997067478
  - 0.6572488748080856
  - 0.6564648760420533
  - 0.6562368352931462
  - 0.6562569237557061
  train_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_micro_oob:
  - 0.5051445108558146
  - 0.5042278822632615
  - 0.5077502139488829
  - 0.5064268646024929
  - 0.5024170178925544
  train_level0__average_precision_samples:
  - 0.6703534994681102
  - 0.6681749614325138
  - 0.6678300983942017
  - 0.6682120006587978
  - 0.6687268070622467
  train_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_samples_oob:
  - 0.5382088760013272
  - 0.536411497648323
  - 0.5405597393912871
  - 0.5380472229894734
  - 0.5362590222060009
  train_level0__average_precision_weighted:
  - 0.8637572826955207
  - 0.8674419543561986
  - 0.8630622426368424
  - 0.864276055160068
  - 0.870653147855274
  train_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_weighted_oob:
  - 0.39333491898932726
  - 0.39636101813438823
  - 0.4030180497861746
  - 0.40265035125031423
  - 0.3893183903403974
  train_level0__f1_macro:
  - 0.8116164196900018
  - 0.8128078817733991
  - 0.8109967312289604
  - 0.8117516683128959
  - 0.8104381007583442
  train_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_macro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__f1_micro:
  - 0.8116164196900018
  - 0.812807881773399
  - 0.8109967312289603
  - 0.811751668312896
  - 0.8104381007583442
  train_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_micro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__f1_samples:
  - 0.8116164196900016
  - 0.812807881773399
  - 0.8109967312289602
  - 0.8117516683128959
  - 0.810438100758344
  train_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_samples_oob:
  - 0.7889626980071536
  - 0.786096896073461
  - 0.7886032102258866
  - 0.7874918692331783
  - 0.7874704149157126
  train_level0__f1_weighted:
  - 0.7673182748820455
  - 0.7694991789819378
  - 0.7663073355745104
  - 0.767892256085133
  - 0.7651435645725939
  train_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__f1_weighted_oob:
  - 0.7215985454116932
  - 0.7157008636788049
  - 0.7219963144545459
  - 0.7185833651509382
  - 0.7187128374647157
  train_level0__fn_macro:
  - -0.1650972090420225
  - -0.16497680424697503
  - -0.1651705127579646
  - -0.16519309065503862
  - -0.16603873834709945
  train_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_macro_oob:
  - -0.1773608779229627
  - -0.17987469510737003
  - -0.177782114455774
  - -0.17839504685730806
  - -0.17842824711394484
  train_level0__fn_micro:
  - -0.16509720904202252
  - -0.164976804246975
  - -0.16517051275796457
  - -0.16519309065503868
  - -0.16603873834709945
  train_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_micro_oob:
  - -0.17736087792296273
  - -0.17987469510737003
  - -0.17778211445577402
  - -0.17839504685730806
  - -0.17842824711394484
  train_level0__fn_samples:
  - -0.1650972090420225
  - -0.16497680424697497
  - -0.16517051275796454
  - -0.16519309065503862
  - -0.1660387383470994
  train_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_samples_oob:
  - -0.1773608779229627
  - -0.17987469510736998
  - -0.177782114455774
  - -0.17839504685730803
  - -0.1784282471139448
  train_level0__fn_weighted:
  - -0.1723681407826233
  - -0.1731832459995492
  - -0.17193545535526078
  - -0.1727704894932856
  - -0.17389793418041444
  train_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fn_weighted_oob:
  - -0.1958419923730057
  - -0.20148044850123956
  - -0.1951602500898372
  - -0.19795954744241442
  - -0.19758281386048596
  train_level0__fp_macro:
  - -0.02328637126797576
  - -0.022215313979626
  - -0.023832756013075083
  - -0.023055241032065334
  - -0.023523160894556343
  train_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_macro_oob:
  - -0.03367642406988344
  - -0.03402840881916878
  - -0.03361467531833927
  - -0.034113083909513606
  - -0.03410133797034246
  train_level0__fp_micro:
  - -0.023286371267975763
  - -0.022215313979626
  - -0.023832756013075083
  - -0.023055241032065334
  - -0.023523160894556343
  train_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_micro_oob:
  - -0.03367642406988345
  - -0.03402840881916878
  - -0.03361467531833927
  - -0.0341130839095136
  - -0.03410133797034246
  train_level0__fp_samples:
  - -0.023286371267975763
  - -0.022215313979625995
  - -0.023832756013075083
  - -0.023055241032065327
  - -0.02352316089455634
  train_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_samples_oob:
  - -0.03367642406988344
  - -0.03402840881916877
  - -0.03361467531833926
  - -0.03411308390951359
  - -0.034101337970342455
  train_level0__fp_weighted:
  - -0.060313584335331204
  - -0.05731757501851315
  - -0.06175720907022883
  - -0.059337254421581526
  - -0.06095850124699168
  train_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__fp_weighted_oob:
  - -0.08255946221530107
  - -0.08281868781995558
  - -0.08284343545561679
  - -0.0834570874066474
  - -0.08370434867479844
  train_level0__jaccard_macro:
  - 0.692544305155726
  - 0.6942173455165048
  - 0.691461686173314
  - 0.6924206326986219
  - 0.6912910808269411
  train_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_macro_oob:
  - 0.6667536718115709
  - 0.6638715641816111
  - 0.666032922246157
  - 0.6650370825786995
  - 0.6653373590083523
  train_level0__jaccard_micro:
  - 0.6829582915293106
  - 0.6846473029045643
  - 0.6820811620368471
  - 0.6831498489548486
  - 0.6812912394680743
  train_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_micro_oob:
  - 0.6514767932489451
  - 0.6475779603254339
  - 0.6509867096254531
  - 0.6494734750645738
  - 0.6494442895271482
  train_level0__jaccard_samples:
  - 0.6856447494565632
  - 0.6870724089111448
  - 0.6846856744469706
  - 0.6856601673150704
  - 0.6840994809799023
  train_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_samples_oob:
  - 0.6542319667320866
  - 0.6500904010118916
  - 0.6535653788372545
  - 0.6519633409223005
  - 0.6521576280435858
  train_level0__jaccard_weighted:
  - 0.6296137139668442
  - 0.6325858925010326
  - 0.628285438680881
  - 0.6300196904357407
  - 0.6274247367994293
  train_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__jaccard_weighted_oob:
  - 0.5777486001945282
  - 0.5716596453241685
  - 0.578205454370156
  - 0.5745289805425576
  - 0.5750743773631075
  train_level0__label_ranking_average_precision_score:
  - 0.6703534994681104
  - 0.6681749614325132
  - 0.6678300983942015
  - 0.6682120006587984
  - 0.6687268070622471
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5382088760013267
  - 0.5364114976483223
  - 0.5405597393912868
  - 0.538047222989473
  - 0.5362590222060012
  train_level0__matthews_corrcoef_macro:
  - 0.08003263953191819
  - 0.09081123311159855
  - 0.08477482054455114
  - 0.08794705800220812
  - 0.07702479072306409
  train_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_macro_oob:
  - 0.006817515871349424
  - 0.0028330288360783698
  - 0.010249850782896244
  - 0.007566051237855348
  - 0.0006182718685096737
  train_level0__matthews_corrcoef_micro:
  - 0.3861652443270649
  - 0.3915328916631519
  - 0.38512375539269317
  - 0.3861557114577537
  - 0.38111315238331844
  train_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_micro_oob:
  - 0.2922487064499597
  - 0.27966436896314567
  - 0.292036245328833
  - 0.2851546583310055
  - 0.28558013671258403
  train_level0__matthews_corrcoef_samples:
  - 0.3878867306718397
  - 0.3921899768973179
  - 0.3861125000361313
  - 0.3867834719299809
  - 0.3833177973139884
  train_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_samples_oob:
  - 0.29642673147477927
  - 0.2841573917324327
  - 0.29547375178750074
  - 0.28936173547960153
  - 0.290301115387054
  train_level0__matthews_corrcoef_weighted:
  - 0.15555752066247874
  - 0.17516904241855527
  - 0.15884147756195388
  - 0.17081499420652932
  - 0.1497624972077488
  train_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.014165706129063633
  - 0.005963195276165812
  - 0.01871529101297548
  - 0.015002587792479849
  - 0.0020044215582748328
  train_level0__ndcg:
  - 0.887850413775694
  - 0.8871157095905449
  - 0.8864674808676328
  - 0.8866205471397206
  - 0.8877609110254593
  train_level0__ndcg_oob:
  - 0.8309228692240133
  - 0.8293106832432259
  - 0.8312674907858104
  - 0.8285373847828729
  - 0.8297712577756318
  train_level0__neg_coverage_error:
  - -65.63659147869674
  - -66.1871921182266
  - -65.85678391959799
  - -66.56823821339951
  - -67.12437810945273
  train_level0__neg_coverage_error_oob:
  - -88.78696741854637
  - -88.32019704433498
  - -89.08291457286433
  - -88.91315136476427
  - -89.16169154228855
  train_level0__neg_hamming_loss_macro:
  - -0.18838358030999824
  - -0.187192118226601
  - -0.18900326877103965
  - -0.188248331687104
  - -0.1895618992416558
  train_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_macro_oob:
  - -0.21103730199284615
  - -0.21390310392653883
  - -0.2113967897741133
  - -0.21250813076682165
  - -0.2125295850842873
  train_level0__neg_hamming_loss_micro:
  - -0.1883835803099983
  - -0.18719211822660098
  - -0.18900326877103965
  - -0.188248331687104
  - -0.1895618992416558
  train_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_micro_oob:
  - -0.2110373019928462
  - -0.2139031039265388
  - -0.21139678977411328
  - -0.21250813076682165
  - -0.2125295850842873
  train_level0__neg_hamming_loss_samples:
  - -0.18838358030999824
  - -0.18719211822660095
  - -0.18900326877103962
  - -0.18824833168710398
  - -0.18956189924165576
  train_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_samples_oob:
  - -0.21103730199284615
  - -0.21390310392653875
  - -0.21139678977411322
  - -0.2125081307668216
  - -0.21252958508428724
  train_level0__neg_hamming_loss_weighted:
  - -0.23268172511795454
  - -0.23050082101806232
  - -0.23369266442548958
  - -0.23210774391486702
  - -0.23485643542740617
  train_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.2784014545883068
  - -0.2842991363211951
  - -0.27800368554545396
  - -0.2814166348490617
  - -0.2812871625352844
  train_level0__neg_label_ranking_loss:
  - -0.14198759355800591
  - -0.14342842604028483
  - -0.14256584076381532
  - -0.14240758890562885
  - -0.14353585276897288
  train_level0__neg_label_ranking_loss_oob:
  - -0.24851406678977703
  - -0.2474248404948129
  - -0.24740512230150874
  - -0.2462466552794969
  - -0.24933514792906095
  train_level0__precision_macro:
  - 0.8116164196900018
  - 0.8128078817733991
  - 0.8109967312289604
  - 0.8117516683128959
  - 0.8104381007583442
  train_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_macro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__precision_micro:
  - 0.8116164196900018
  - 0.812807881773399
  - 0.8109967312289603
  - 0.811751668312896
  - 0.8104381007583442
  train_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_micro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__precision_samples:
  - 0.8116164196900016
  - 0.812807881773399
  - 0.8109967312289602
  - 0.8117516683128959
  - 0.810438100758344
  train_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_samples_oob:
  - 0.7889626980071536
  - 0.786096896073461
  - 0.7886032102258866
  - 0.7874918692331783
  - 0.7874704149157126
  train_level0__precision_weighted:
  - 0.7673182748820455
  - 0.7694991789819378
  - 0.7663073355745104
  - 0.767892256085133
  - 0.7651435645725939
  train_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__precision_weighted_oob:
  - 0.7215985454116932
  - 0.7157008636788049
  - 0.7219963144545459
  - 0.7185833651509382
  - 0.7187128374647157
  train_level0__recall_macro:
  - 0.8116164196900018
  - 0.8128078817733991
  - 0.8109967312289604
  - 0.8117516683128959
  - 0.8104381007583442
  train_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_macro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__recall_micro:
  - 0.8116164196900018
  - 0.812807881773399
  - 0.8109967312289603
  - 0.811751668312896
  - 0.8104381007583442
  train_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_micro_oob:
  - 0.7889626980071538
  - 0.7860968960734612
  - 0.7886032102258868
  - 0.7874918692331784
  - 0.7874704149157127
  train_level0__recall_samples:
  - 0.8116164196900016
  - 0.812807881773399
  - 0.8109967312289602
  - 0.8117516683128959
  - 0.810438100758344
  train_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_samples_oob:
  - 0.7889626980071536
  - 0.786096896073461
  - 0.7886032102258866
  - 0.7874918692331783
  - 0.7874704149157126
  train_level0__recall_weighted:
  - 0.7673182748820455
  - 0.7694991789819378
  - 0.7663073355745104
  - 0.767892256085133
  - 0.7651435645725939
  train_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__recall_weighted_oob:
  - 0.7215985454116932
  - 0.7157008636788049
  - 0.7219963144545459
  - 0.7185833651509382
  - 0.7187128374647157
  train_level0__roc_auc_macro:
  - 0.9402643800156448
  - 0.9411774763863426
  - 0.9392369111495447
  - 0.9395760854758192
  - 0.9445374111910316
  train_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_macro_oob:
  - 0.5577842129277333
  - 0.5620827261809257
  - 0.5644962851327243
  - 0.5747575757215693
  - 0.5528446577233653
  train_level0__roc_auc_micro:
  - 0.8585473224802262
  - 0.8578285134647543
  - 0.8580880663472368
  - 0.8588352086264708
  - 0.8571275692494269
  train_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_micro_oob:
  - 0.7480719477101392
  - 0.7494909479695624
  - 0.7494054262221427
  - 0.7513081260075827
  - 0.7472859107795758
  train_level0__roc_auc_samples:
  - 0.8580124064419941
  - 0.8565715739597152
  - 0.8574341592361845
  - 0.8575924110943711
  - 0.8564641472310272
  train_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_samples_oob:
  - 0.7514859332102228
  - 0.7525751595051869
  - 0.7525948776984913
  - 0.753753344720503
  - 0.750664852070939
  train_level0__roc_auc_weighted:
  - 0.9201605158008526
  - 0.9225849229887204
  - 0.9200567490445563
  - 0.9197546746677022
  - 0.9271599395560379
  train_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__roc_auc_weighted_oob:
  - 0.5617911390930039
  - 0.5654534910064503
  - 0.5708392278619111
  - 0.5783326938715823
  - 0.5576725349374196
  train_level0__tn_macro:
  - 0.7428036109691705
  - 0.7436271462049835
  - 0.7418158754939749
  - 0.7431882242405261
  - 0.7425735400666569
  train_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_macro_oob:
  - 0.7324135581672628
  - 0.7318140513654408
  - 0.7320339561887106
  - 0.732130381363078
  - 0.7319953629908709
  train_level0__tn_micro:
  - 0.7428036109691705
  - 0.7436271462049835
  - 0.7418158754939748
  - 0.7431882242405261
  - 0.742573540066657
  train_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_micro_oob:
  - 0.7324135581672628
  - 0.7318140513654408
  - 0.7320339561887106
  - 0.7321303813630778
  - 0.7319953629908709
  train_level0__tn_samples:
  - 0.7428036109691705
  - 0.7436271462049835
  - 0.7418158754939745
  - 0.7431882242405261
  - 0.742573540066657
  train_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_samples_oob:
  - 0.7324135581672628
  - 0.7318140513654406
  - 0.7320339561887105
  - 0.7321303813630778
  - 0.7319953629908708
  train_level0__tn_weighted:
  - 0.5920241152136557
  - 0.5958717179400497
  - 0.591292833481449
  - 0.5952371027455887
  - 0.5915828703668031
  train_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tn_weighted_oob:
  - 0.5697782373336858
  - 0.5703706051386073
  - 0.5702066070960611
  - 0.5711172697605228
  - 0.5688370229389964
  train_level0__tp_macro:
  - 0.06881280872083119
  - 0.06918073556841553
  - 0.0691808557349856
  - 0.06856344407236985
  - 0.0678645606916872
  train_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_macro_oob:
  - 0.05654913983989098
  - 0.05428284470802047
  - 0.056569254037176164
  - 0.05536148787010046
  - 0.055475051924841805
  train_level0__tp_micro:
  - 0.0688128087208312
  - 0.06918073556841552
  - 0.06918085573498561
  - 0.06856344407236985
  - 0.0678645606916872
  train_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_micro_oob:
  - 0.05654913983989099
  - 0.05428284470802047
  - 0.05656925403717617
  - 0.05536148787010046
  - 0.05547505192484181
  train_level0__tp_samples:
  - 0.06881280872083119
  - 0.0691807355684155
  - 0.06918085573498559
  - 0.06856344407236983
  - 0.06786456069168718
  train_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_samples_oob:
  - 0.056549139839890974
  - 0.054282844708020465
  - 0.05656925403717616
  - 0.05536148787010045
  - 0.055475051924841805
  train_level0__tp_weighted:
  - 0.17529415966838974
  - 0.173627461041888
  - 0.17501450209306132
  - 0.1726551533395443
  - 0.17356069420579087
  train_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__tp_weighted_oob:
  - 0.15182030807800734
  - 0.14533025854019768
  - 0.15178970735848493
  - 0.1474660953904154
  - 0.14987581452571938
  train_level10__average_precision_macro:
  - 0.37747881333732014
  - 0.3789302270195566
  - 0.384333347274946
  - 0.3781771391292028
  - 0.38548273014441603
  train_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_macro_oob:
  - 0.3726456763378194
  - 0.3752636212682924
  - 0.38133158431681086
  - 0.3713860411921606
  - 0.38015676506917817
  train_level10__average_precision_micro:
  - 0.3868300965776031
  - 0.3744036757402316
  - 0.3826944976062247
  - 0.3725916155966645
  - 0.38364661269723566
  train_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_micro_oob:
  - 0.383405298144308
  - 0.37225041222004107
  - 0.3810622596781289
  - 0.3677950943615379
  - 0.38077807470176284
  train_level10__average_precision_samples:
  - 0.39021456037689933
  - 0.3763887161958438
  - 0.38699811892402314
  - 0.3755461157834705
  - 0.38834331897351904
  train_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_samples_oob:
  - 0.3865884965713449
  - 0.37413559226678006
  - 0.38544890479517224
  - 0.37205201246727937
  - 0.38585722972113884
  train_level10__average_precision_weighted:
  - 0.5008685233271861
  - 0.5058016799140864
  - 0.5104010080101831
  - 0.5009437095109589
  - 0.508809542892716
  train_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__average_precision_weighted_oob:
  - 0.49580529634334686
  - 0.5011162731157044
  - 0.5070318557228565
  - 0.4934320328915025
  - 0.5033211833314577
  train_level10__f1_macro:
  - 0.4974085699686109
  - 0.498876082069922
  - 0.49321851978338305
  - 0.4961092775060831
  - 0.5000241510892143
  train_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_macro_oob:
  - 0.4949266369808015
  - 0.49674781194700834
  - 0.49092550129287216
  - 0.4941338023079332
  - 0.49710186929430517
  train_level10__f1_micro:
  - 0.4974085699686108
  - 0.49887608206992207
  - 0.49321851978338294
  - 0.496109277506083
  - 0.5000241510892142
  train_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_micro_oob:
  - 0.4949266369808015
  - 0.49674781194700846
  - 0.4909255012928721
  - 0.49413380230793325
  - 0.49710186929430517
  train_level10__f1_samples:
  - 0.4974085699686109
  - 0.49887608206992207
  - 0.4932185197833829
  - 0.49610927750608297
  - 0.5000241510892142
  train_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_samples_oob:
  - 0.49492663698080147
  - 0.4967478119470084
  - 0.4909255012928721
  - 0.49413380230793313
  - 0.49710186929430517
  train_level10__f1_weighted:
  - 0.5568527059873756
  - 0.5608997190830354
  - 0.5512364570850505
  - 0.5515896569810722
  - 0.5572329370185727
  train_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__f1_weighted_oob:
  - 0.5533458112148154
  - 0.5575326394925785
  - 0.5481746716302446
  - 0.5483970704105481
  - 0.5539452967480615
  train_level10__fn_macro:
  - -0.014039954254568459
  - -0.014060930699698694
  - -0.012733570766453628
  - -0.013298320846081572
  - -0.013741969762836306
  train_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_macro_oob:
  - -0.015086259337664547
  - -0.015160935482328183
  - -0.013782504756793676
  - -0.014189693801344284
  - -0.014732164420615371
  train_level10__fn_micro:
  - -0.01403995425456846
  - -0.014060930699698694
  - -0.012733570766453628
  - -0.013298320846081573
  - -0.013741969762836304
  train_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_micro_oob:
  - -0.01508625933766455
  - -0.015160935482328185
  - -0.013782504756793677
  - -0.014189693801344288
  - -0.01473216442061537
  train_level10__fn_samples:
  - -0.014039954254568457
  - -0.014060930699698692
  - -0.012733570766453626
  - -0.013298320846081572
  - -0.0137419697628363
  train_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_samples_oob:
  - -0.015086259337664547
  - -0.015160935482328181
  - -0.013782504756793677
  - -0.014189693801344286
  - -0.014732164420615368
  train_level10__fn_weighted:
  - -0.01605178034027125
  - -0.016631904198460994
  - -0.014507323753146914
  - -0.01462979012656033
  - -0.01489275357851938
  train_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fn_weighted_oob:
  - -0.017523523778759282
  - -0.018189675295405515
  - -0.015882995700894395
  - -0.015964978726745124
  - -0.016080156779345402
  train_level10__fp_macro:
  - -0.4885514757768206
  - -0.4870629872303793
  - -0.4940479094501634
  - -0.49059240164783535
  - -0.4862338791479496
  train_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_macro_oob:
  - -0.48998710368153386
  - -0.48809125257066344
  - -0.49529199395033413
  - -0.4916765038907224
  - -0.4881659662850794
  train_level10__fp_micro:
  - -0.4885514757768207
  - -0.4870629872303793
  - -0.4940479094501634
  - -0.4905924016478354
  - -0.4862338791479496
  train_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_micro_oob:
  - -0.4899871036815339
  - -0.4880912525706633
  - -0.4952919939503342
  - -0.4916765038907225
  - -0.48816596628507947
  train_level10__fp_samples:
  - -0.48855147577682073
  - -0.4870629872303792
  - -0.49404790945016347
  - -0.49059240164783535
  - -0.4862338791479496
  train_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_samples_oob:
  - -0.489987103681534
  - -0.4880912525706634
  - -0.4952919939503342
  - -0.4916765038907224
  - -0.48816596628507947
  train_level10__fp_weighted:
  - -0.42709551367235316
  - -0.42246837671850346
  - -0.4342562191618025
  - -0.4337805528923673
  - -0.42787430940290805
  train_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__fp_weighted_oob:
  - -0.4291306650064254
  - -0.4242776852120158
  - -0.4359423326688611
  - -0.4356379508627068
  - -0.42997454647259314
  train_level10__jaccard_macro:
  - 0.3467093579408484
  - 0.34912422385606456
  - 0.3436012025538266
  - 0.3461016073566151
  - 0.34991096990480475
  train_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_macro_oob:
  - 0.3443314910218507
  - 0.34714203973923763
  - 0.34148327484390106
  - 0.34421228744580484
  - 0.34723554272959894
  train_level10__jaccard_micro:
  - 0.33103381267003495
  - 0.3323350431707395
  - 0.32733248069419935
  - 0.3298838606327593
  - 0.33335480131384043
  train_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_micro_oob:
  - 0.32883887864972355
  - 0.33044875363886544
  - 0.3253156167660799
  - 0.32813924840417874
  - 0.3307621848334378
  train_level10__jaccard_samples:
  - 0.3376497264264677
  - 0.33982019657555274
  - 0.33481530164118395
  - 0.33762150313536476
  - 0.34130999776044996
  train_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_samples_oob:
  - 0.3353806828782784
  - 0.3378964931582568
  - 0.33271955859427366
  - 0.3358470779161063
  - 0.33875956135591706
  train_level10__jaccard_weighted:
  - 0.40076897162622105
  - 0.4056876260956549
  - 0.3958108573522414
  - 0.39634001436394556
  - 0.40129405380206656
  train_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__jaccard_weighted_oob:
  - 0.397326808927917
  - 0.40239711554411783
  - 0.39280545172767267
  - 0.3932216191679387
  - 0.39822214871761047
  train_level10__label_ranking_average_precision_score:
  - 0.3902145603768993
  - 0.3763887161958437
  - 0.386998118924023
  - 0.37554611578347036
  - 0.38834331897351915
  train_level10__label_ranking_average_precision_score_oob:
  - 0.3865884965713447
  - 0.37413559226678
  - 0.3854489047951723
  - 0.37205201246727915
  - 0.38585722972113884
  train_level10__matthews_corrcoef_macro:
  - 0.23745633504759386
  - 0.24275411531284788
  - 0.23729122580759873
  - 0.23512816691941352
  - 0.23592959582822384
  train_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_macro_oob:
  - 0.2304853142377508
  - 0.23631390819686549
  - 0.23000310347045586
  - 0.22888869143485796
  - 0.22822859949276303
  train_level10__matthews_corrcoef_micro:
  - 0.28152447867649666
  - 0.28286358226849995
  - 0.2820817889529579
  - 0.2827725101259972
  - 0.284950332204587
  train_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_micro_oob:
  - 0.2757211844331346
  - 0.27722269610091516
  - 0.27641018446393667
  - 0.2779461443804797
  - 0.27893334114383517
  train_level10__matthews_corrcoef_samples:
  - 0.2809905319657192
  - 0.2814704626233942
  - 0.28183191401690605
  - 0.2827377828009701
  - 0.2831771662566482
  train_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_samples_oob:
  - 0.27481698937760557
  - 0.2754243184010519
  - 0.27553740207832367
  - 0.2777427175909177
  - 0.27677669356068324
  train_level10__matthews_corrcoef_weighted:
  - 0.2518735253138726
  - 0.2647266980914719
  - 0.2495851759047623
  - 0.2503599607194994
  - 0.24624184337816563
  train_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.24193958644112595
  - 0.2552815746502457
  - 0.23876383968409204
  - 0.24122163294468948
  - 0.23624187887960466
  train_level10__ndcg:
  - 0.724505676884032
  - 0.7150616865746627
  - 0.7206109966615375
  - 0.7145573727050049
  - 0.719070569396598
  train_level10__ndcg_oob:
  - 0.7222455428232128
  - 0.7141433895977702
  - 0.7200528959305564
  - 0.7123888033217809
  - 0.7180117866587318
  train_level10__neg_coverage_error:
  - -75.3157894736842
  - -75.9039408866995
  - -75.42462311557789
  - -75.3970223325062
  - -74.87064676616916
  train_level10__neg_coverage_error_oob:
  - -78.11779448621554
  - -78.71428571428571
  - -77.99748743718592
  - -78.43424317617865
  - -78.03233830845771
  train_level10__neg_hamming_loss_macro:
  - -0.5025914300313891
  - -0.501123917930078
  - -0.506781480216617
  - -0.503890722493917
  - -0.49997584891078567
  train_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_macro_oob:
  - -0.5050733630191984
  - -0.5032521880529917
  - -0.5090744987071278
  - -0.5058661976920668
  - -0.5028981307056948
  train_level10__neg_hamming_loss_micro:
  - -0.5025914300313892
  - -0.5011239179300779
  - -0.5067814802166171
  - -0.503890722493917
  - -0.4999758489107859
  train_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_micro_oob:
  - -0.5050733630191985
  - -0.5032521880529915
  - -0.5090744987071278
  - -0.5058661976920668
  - -0.5028981307056948
  train_level10__neg_hamming_loss_samples:
  - -0.5025914300313891
  - -0.5011239179300779
  - -0.5067814802166171
  - -0.503890722493917
  - -0.4999758489107858
  train_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_samples_oob:
  - -0.5050733630191985
  - -0.5032521880529915
  - -0.5090744987071278
  - -0.5058661976920668
  - -0.5028981307056948
  train_level10__neg_hamming_loss_weighted:
  - -0.4431472940126244
  - -0.4391002809169646
  - -0.44876354291494935
  - -0.44841034301892757
  - -0.4427670629814274
  train_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.44665418878518465
  - -0.44246736050742147
  - -0.4518253283697555
  - -0.4516029295894519
  - -0.4460547032519386
  train_level10__neg_label_ranking_loss:
  - -0.34527324238747215
  - -0.35311765469763545
  - -0.33920214249886993
  - -0.35555967692552193
  - -0.3329992965841717
  train_level10__neg_label_ranking_loss_oob:
  - -0.35469259203306
  - -0.3629725571498356
  - -0.3462266656008475
  - -0.36678227780035405
  - -0.34181789687664804
  train_level10__precision_macro:
  - 0.4974085699686109
  - 0.498876082069922
  - 0.49321851978338305
  - 0.4961092775060831
  - 0.5000241510892143
  train_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_macro_oob:
  - 0.4949266369808015
  - 0.49674781194700834
  - 0.49092550129287216
  - 0.4941338023079332
  - 0.49710186929430517
  train_level10__precision_micro:
  - 0.4974085699686108
  - 0.49887608206992207
  - 0.49321851978338294
  - 0.496109277506083
  - 0.5000241510892142
  train_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_micro_oob:
  - 0.4949266369808015
  - 0.49674781194700846
  - 0.4909255012928721
  - 0.49413380230793325
  - 0.49710186929430517
  train_level10__precision_samples:
  - 0.4974085699686109
  - 0.49887608206992207
  - 0.4932185197833829
  - 0.49610927750608297
  - 0.5000241510892142
  train_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_samples_oob:
  - 0.49492663698080147
  - 0.4967478119470084
  - 0.4909255012928721
  - 0.49413380230793313
  - 0.49710186929430517
  train_level10__precision_weighted:
  - 0.5568527059873756
  - 0.5608997190830354
  - 0.5512364570850505
  - 0.5515896569810722
  - 0.5572329370185727
  train_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__precision_weighted_oob:
  - 0.5533458112148154
  - 0.5575326394925785
  - 0.5481746716302446
  - 0.5483970704105481
  - 0.5539452967480615
  train_level10__recall_macro:
  - 0.4974085699686109
  - 0.498876082069922
  - 0.49321851978338305
  - 0.4961092775060831
  - 0.5000241510892143
  train_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_macro_oob:
  - 0.4949266369808015
  - 0.49674781194700834
  - 0.49092550129287216
  - 0.4941338023079332
  - 0.49710186929430517
  train_level10__recall_micro:
  - 0.4974085699686108
  - 0.49887608206992207
  - 0.49321851978338294
  - 0.496109277506083
  - 0.5000241510892142
  train_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_micro_oob:
  - 0.4949266369808015
  - 0.49674781194700846
  - 0.4909255012928721
  - 0.49413380230793325
  - 0.49710186929430517
  train_level10__recall_samples:
  - 0.4974085699686109
  - 0.49887608206992207
  - 0.4932185197833829
  - 0.49610927750608297
  - 0.5000241510892142
  train_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_samples_oob:
  - 0.49492663698080147
  - 0.4967478119470084
  - 0.4909255012928721
  - 0.49413380230793313
  - 0.49710186929430517
  train_level10__recall_weighted:
  - 0.5568527059873756
  - 0.5608997190830354
  - 0.5512364570850505
  - 0.5515896569810722
  - 0.5572329370185727
  train_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__recall_weighted_oob:
  - 0.5533458112148154
  - 0.5575326394925785
  - 0.5481746716302446
  - 0.5483970704105481
  - 0.5539452967480615
  train_level10__roc_auc_macro:
  - 0.7194947177394079
  - 0.7201623134768753
  - 0.7227194739204184
  - 0.7150152457467358
  - 0.7247756330941388
  train_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_macro_oob:
  - 0.7104526031235766
  - 0.7124690894149684
  - 0.7150503576434432
  - 0.7043063407228267
  - 0.7149404422113584
  train_level10__roc_auc_micro:
  - 0.73314152637843
  - 0.7234471798903996
  - 0.730007643990567
  - 0.7211936026750447
  - 0.7310858464506388
  train_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_micro_oob:
  - 0.7286525095321847
  - 0.7195738047191231
  - 0.7265235100855272
  - 0.7156010934682733
  - 0.7264999562118593
  train_level10__roc_auc_samples:
  - 0.7224105699398277
  - 0.7097877920920301
  - 0.7183621001258311
  - 0.70827723581362
  - 0.7191598920231045
  train_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_samples_oob:
  - 0.7179996649447463
  - 0.705742103978767
  - 0.7151815198645198
  - 0.7034444855190028
  - 0.7144245486386017
  train_level10__roc_auc_weighted:
  - 0.7119958863531417
  - 0.7153456846510705
  - 0.7184420065900057
  - 0.7095313752650096
  - 0.7157729823972016
  train_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__roc_auc_weighted_oob:
  - 0.7037903515875695
  - 0.7075301364306718
  - 0.7107751765960353
  - 0.6996226038275828
  - 0.7069246874152156
  train_level10__tn_macro:
  - 0.2775385064603256
  - 0.2787794729542302
  - 0.27160072205688635
  - 0.27565106362475605
  - 0.2798628218132638
  train_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_macro_oob:
  - 0.27610287855561233
  - 0.2777512076139461
  - 0.27035663755671563
  - 0.27456696138186903
  - 0.27793073467613394
  train_level10__tn_micro:
  - 0.2775385064603256
  - 0.2787794729542302
  - 0.2716007220568864
  - 0.27565106362475605
  - 0.2798628218132638
  train_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_micro_oob:
  - 0.27610287855561233
  - 0.27775120761394617
  - 0.27035663755671563
  - 0.274566961381869
  - 0.2779307346761339
  train_level10__tn_samples:
  - 0.2775385064603255
  - 0.27877947295423017
  - 0.2716007220568863
  - 0.275651063624756
  - 0.2798628218132637
  train_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_samples_oob:
  - 0.2761028785556123
  - 0.2777512076139461
  - 0.2703566375567156
  - 0.2745669613818689
  - 0.27793073467613383
  train_level10__tn_weighted:
  - 0.22524218587663364
  - 0.23072091624005917
  - 0.21879382338987532
  - 0.22079380427480289
  - 0.2246670622108867
  train_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tn_weighted_oob:
  - 0.22320703454256155
  - 0.22891160774654687
  - 0.21710770988281686
  - 0.21893640630446337
  - 0.2225668251412016
  train_level10__tp_macro:
  - 0.21987006350828525
  - 0.22009660911569184
  - 0.22161779772649653
  - 0.22045821388132697
  - 0.2201613292759504
  train_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_macro_oob:
  - 0.21882375842518914
  - 0.21899660433306237
  - 0.22056886373615653
  - 0.21956684092606432
  - 0.21917113461817134
  train_level10__tp_micro:
  - 0.21987006350828528
  - 0.22009660911569182
  - 0.22161779772649656
  - 0.22045821388132694
  - 0.22016132927595033
  train_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_micro_oob:
  - 0.2188237584251892
  - 0.2189966043330623
  - 0.2205688637361565
  - 0.21956684092606424
  - 0.21917113461817128
  train_level10__tp_samples:
  - 0.2198700635082852
  - 0.22009660911569176
  - 0.22161779772649653
  - 0.2204582138813269
  - 0.22016132927595028
  train_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_samples_oob:
  - 0.21882375842518914
  - 0.21899660433306226
  - 0.22056886373615645
  - 0.21956684092606416
  - 0.2191711346181712
  train_level10__tp_weighted:
  - 0.3316105201107418
  - 0.3301788028429763
  - 0.3324426336951751
  - 0.3307958527062695
  - 0.33256587480768596
  train_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level10__tp_weighted_oob:
  - 0.33013877667225383
  - 0.3286210317460318
  - 0.33106696174742767
  - 0.32946066410608477
  - 0.3313784716068599
  train_level1__average_precision_macro:
  - 0.4400967654256877
  - 0.44379395168990865
  - 0.4399261495350348
  - 0.43850464734024514
  - 0.4477284019150306
  train_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_macro_oob:
  - 0.4328540503061049
  - 0.43669401976681993
  - 0.4316849258136337
  - 0.43087594019140474
  - 0.4379914298942334
  train_level1__average_precision_micro:
  - 0.42638648191668604
  - 0.41446158728866467
  - 0.4166329273809556
  - 0.4136265563946673
  - 0.4332499100049304
  train_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_micro_oob:
  - 0.42263804084067813
  - 0.4099041787292277
  - 0.4126000977684624
  - 0.40903012354912727
  - 0.42794469182629324
  train_level1__average_precision_samples:
  - 0.44498976340219965
  - 0.4316815041360639
  - 0.437916806092559
  - 0.4318148566342452
  - 0.45804712401833125
  train_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_samples_oob:
  - 0.4409190293219674
  - 0.4265395212782057
  - 0.4326430725319619
  - 0.42645542686965293
  - 0.45250405740968536
  train_level1__average_precision_weighted:
  - 0.5615053555354202
  - 0.5665869904180718
  - 0.5619730852900192
  - 0.5603337982630479
  - 0.5669669233759002
  train_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__average_precision_weighted_oob:
  - 0.5547630394187031
  - 0.5597442433389413
  - 0.555112500803922
  - 0.5532687125897799
  - 0.5583960097838546
  train_level1__f1_macro:
  - 0.524198846631141
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_macro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.511238526584596
  - 0.5219774911848525
  train_level1__f1_micro:
  - 0.5241988466311409
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_micro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__f1_samples:
  - 0.5241988466311409
  - 0.5197761729398824
  - 0.5171244572376446
  - 0.5233322893830255
  - 0.5328454813312079
  train_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_samples_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__f1_weighted:
  - 0.5686409928910491
  - 0.5668038048552754
  - 0.5621641568935548
  - 0.5617949885801865
  - 0.5705219385776334
  train_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__f1_weighted_oob:
  - 0.5531474061206278
  - 0.5529038483209375
  - 0.5471792709775589
  - 0.548167676774393
  - 0.5581591269260306
  train_level1__fn_macro:
  - -0.014891597926855973
  - -0.015137022334879716
  - -0.01390447382543787
  - -0.014382423088968659
  - -0.015529150364681447
  train_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_macro_oob:
  - -0.01759252500182495
  - -0.017958773733798845
  - -0.01712445723764453
  - -0.01683972150617938
  - -0.018161619089020916
  train_level1__fn_micro:
  - -0.014891597926855975
  - -0.015137022334879718
  - -0.01390447382543787
  - -0.014382423088968657
  - -0.015529150364681447
  train_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_micro_oob:
  - -0.01759252500182495
  - -0.017958773733798842
  - -0.01712445723764453
  - -0.01683972150617938
  - -0.018161619089020916
  train_level1__fn_samples:
  - -0.014891597926855973
  - -0.015137022334879714
  - -0.01390447382543787
  - -0.014382423088968654
  - -0.015529150364681445
  train_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_samples_oob:
  - -0.017592525001824948
  - -0.01795877373379884
  - -0.01712445723764453
  - -0.01683972150617938
  - -0.018161619089020913
  train_level1__fn_weighted:
  - -0.014466625317063593
  - -0.015613177742361312
  - -0.013780257590649199
  - -0.013842384323080352
  - -0.014768182833894545
  train_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fn_weighted_oob:
  - -0.017130363618397912
  - -0.018654516404262855
  - -0.01702930181248702
  - -0.016294108726445912
  - -0.017240334209181248
  train_level1__fp_macro:
  - -0.460909555442003
  - -0.46508680472523795
  - -0.4689710689369176
  - -0.462285287528006
  - -0.4516253683041105
  train_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_macro_oob:
  - -0.4716645983891769
  - -0.47419771390310395
  - -0.478118749085232
  - -0.4719217519092246
  - -0.4598608897261267
  train_level1__fp_micro:
  - -0.46090955544200307
  - -0.46508680472523795
  - -0.4689710689369176
  - -0.46228528752800596
  - -0.45162536830411054
  train_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_micro_oob:
  - -0.47166459838917685
  - -0.47419771390310395
  - -0.478118749085232
  - -0.47192175190922453
  - -0.45986088972612665
  train_level1__fp_samples:
  - -0.46090955544200307
  - -0.4650868047252379
  - -0.4689710689369176
  - -0.46228528752800596
  - -0.4516253683041105
  train_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_samples_oob:
  - -0.47166459838917685
  - -0.4741977139031039
  - -0.47811874908523194
  - -0.4719217519092245
  - -0.45986088972612665
  train_level1__fp_weighted:
  - -0.4168923817918874
  - -0.41758301740236325
  - -0.4240555855157959
  - -0.42436262709673334
  - -0.41470987858847214
  train_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__fp_weighted_oob:
  - -0.42972223026097445
  - -0.4284416352747995
  - -0.4357914272099542
  - -0.435538214499161
  - -0.424600538864788
  train_level1__jaccard_macro:
  - 0.377326395626294
  - 0.3734449372181921
  - 0.3726572370085211
  - 0.3766854045760997
  - 0.38912056475149537
  train_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_macro_oob:
  - 0.36531659061035093
  - 0.36247072719345963
  - 0.3618613787718611
  - 0.365639380020122
  - 0.38032229018729335
  train_level1__jaccard_micro:
  - 0.355196122075481
  - 0.3511470113085622
  - 0.3487308559114313
  - 0.35440084835630964
  - 0.3631829330523959
  train_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_micro_oob:
  - 0.3429514410822822
  - 0.34034199266013876
  - 0.3375750456799791
  - 0.3433985468550253
  - 0.353159365349107
  train_level1__jaccard_samples:
  - 0.360156524699178
  - 0.35683302266075334
  - 0.35426379627518273
  - 0.3600535861227347
  - 0.36899306361581724
  train_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_samples_oob:
  - 0.34793393393286487
  - 0.34608108509767027
  - 0.343291644618536
  - 0.34918810442265075
  - 0.35883099198695756
  train_level1__jaccard_weighted:
  - 0.41578345453639814
  - 0.4138480495321736
  - 0.4104280511478873
  - 0.4091226043670216
  - 0.41874622776166526
  train_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__jaccard_weighted_oob:
  - 0.40091045189007185
  - 0.4002434964101231
  - 0.3961489651030806
  - 0.3958979393006325
  - 0.40751479922209255
  train_level1__label_ranking_average_precision_score:
  - 0.44498976340219976
  - 0.431681504136064
  - 0.4379168060925596
  - 0.4318148566342449
  - 0.45804712401833103
  train_level1__label_ranking_average_precision_score_oob:
  - 0.4409190293219675
  - 0.42653952127820566
  - 0.4326430725319619
  - 0.42645542686965304
  - 0.4525040574096856
  train_level1__matthews_corrcoef_macro:
  - 0.2505093964420304
  - 0.2476676783513545
  - 0.2488524010975935
  - 0.24379294144975533
  - 0.2523861513891424
  train_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_macro_oob:
  - 0.22242276411008657
  - 0.22177074297606492
  - 0.2196055268483444
  - 0.21941646201054846
  - 0.22919998153824128
  train_level1__matthews_corrcoef_micro:
  - 0.3037114579544374
  - 0.2988513265408081
  - 0.30039736227246033
  - 0.3044992068732024
  - 0.30977212572716367
  train_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_micro_oob:
  - 0.28242373896534445
  - 0.2785588827512165
  - 0.27836901842771977
  - 0.28527660547871436
  - 0.29124064333463284
  train_level1__matthews_corrcoef_samples:
  - 0.30338334463185845
  - 0.2985474840333404
  - 0.30112661019369286
  - 0.3042656006136058
  - 0.3088457462939902
  train_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_samples_oob:
  - 0.2818514344008435
  - 0.2780466154352796
  - 0.2785584628257789
  - 0.2847077548847057
  - 0.2899373590592516
  train_level1__matthews_corrcoef_weighted:
  - 0.25778839936636233
  - 0.2569689037470219
  - 0.25033335187853184
  - 0.2454441220157304
  - 0.2502861896067235
  train_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.22136307915722747
  - 0.2240879642441248
  - 0.2124437908010599
  - 0.21677961503853904
  - 0.22403892781443926
  train_level1__ndcg:
  - 0.7542928925148735
  - 0.7475637878977271
  - 0.7404520086050357
  - 0.7415129499044414
  - 0.7548213682147646
  train_level1__ndcg_oob:
  - 0.753378643465109
  - 0.7454787017569702
  - 0.7395520833399407
  - 0.7394651142846888
  - 0.7533639133363175
  train_level1__neg_coverage_error:
  - -74.92481203007519
  - -75.02463054187191
  - -74.80904522613065
  - -74.41687344913151
  - -73.56965174129353
  train_level1__neg_coverage_error_oob:
  - -78.27318295739349
  - -78.37192118226601
  - -78.09045226130654
  - -77.84367245657569
  - -76.96268656716418
  train_level1__neg_hamming_loss_macro:
  - -0.47580115336885903
  - -0.4802238270601177
  - -0.4828755427623554
  - -0.47666771061697466
  - -0.46715451866879193
  train_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_macro_oob:
  - -0.4892571233910018
  - -0.4921564876369028
  - -0.4952432063228766
  - -0.48876147341540394
  - -0.4780225088151476
  train_level1__neg_hamming_loss_micro:
  - -0.47580115336885903
  - -0.4802238270601176
  - -0.48287554276235545
  - -0.4766677106169746
  - -0.467154518668792
  train_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_micro_oob:
  - -0.4892571233910018
  - -0.4921564876369028
  - -0.4952432063228765
  - -0.4887614734154039
  - -0.4780225088151476
  train_level1__neg_hamming_loss_samples:
  - -0.47580115336885903
  - -0.48022382706011757
  - -0.48287554276235545
  - -0.4766677106169746
  - -0.46715451866879193
  train_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_samples_oob:
  - -0.48925712339100175
  - -0.4921564876369028
  - -0.49524320632287644
  - -0.4887614734154039
  - -0.4780225088151475
  train_level1__neg_hamming_loss_weighted:
  - -0.4313590071089509
  - -0.4331961951447247
  - -0.43783584310644513
  - -0.43820501141981355
  - -0.42947806142236666
  train_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.44685259387937215
  - -0.44709615167906247
  - -0.45282072902244114
  - -0.45183232322560696
  - -0.44184087307396935
  train_level1__neg_label_ranking_loss:
  - -0.25181879347889635
  - -0.26336201608782295
  - -0.2555021965240614
  - -0.26059095669781185
  - -0.2485553307518991
  train_level1__neg_label_ranking_loss_oob:
  - -0.26043616656002944
  - -0.27250106230075144
  - -0.26475186486260494
  - -0.2697772289035023
  - -0.2581094849606291
  train_level1__precision_macro:
  - 0.524198846631141
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_macro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.511238526584596
  - 0.5219774911848525
  train_level1__precision_micro:
  - 0.5241988466311409
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_micro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__precision_samples:
  - 0.5241988466311409
  - 0.5197761729398824
  - 0.5171244572376446
  - 0.5233322893830255
  - 0.5328454813312079
  train_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_samples_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__precision_weighted:
  - 0.5686409928910491
  - 0.5668038048552754
  - 0.5621641568935548
  - 0.5617949885801865
  - 0.5705219385776334
  train_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__precision_weighted_oob:
  - 0.5531474061206278
  - 0.5529038483209375
  - 0.5471792709775589
  - 0.548167676774393
  - 0.5581591269260306
  train_level1__recall_macro:
  - 0.524198846631141
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_macro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.511238526584596
  - 0.5219774911848525
  train_level1__recall_micro:
  - 0.5241988466311409
  - 0.5197761729398823
  - 0.5171244572376446
  - 0.5233322893830253
  - 0.532845481331208
  train_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_micro_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__recall_samples:
  - 0.5241988466311409
  - 0.5197761729398824
  - 0.5171244572376446
  - 0.5233322893830255
  - 0.5328454813312079
  train_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_samples_oob:
  - 0.5107428766089982
  - 0.5078435123630972
  - 0.5047567936771234
  - 0.5112385265845961
  - 0.5219774911848525
  train_level1__recall_weighted:
  - 0.5686409928910491
  - 0.5668038048552754
  - 0.5621641568935548
  - 0.5617949885801865
  - 0.5705219385776334
  train_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__recall_weighted_oob:
  - 0.5531474061206278
  - 0.5529038483209375
  - 0.5471792709775589
  - 0.548167676774393
  - 0.5581591269260306
  train_level1__roc_auc_macro:
  - 0.7435956742919997
  - 0.7423357552000233
  - 0.7463027394018135
  - 0.7430531433147426
  - 0.7526916480481837
  train_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_macro_oob:
  - 0.7315390244258789
  - 0.7308824645563151
  - 0.7338336025492564
  - 0.7297670775310625
  - 0.738310416953685
  train_level1__roc_auc_micro:
  - 0.7568034669574296
  - 0.7493482639743484
  - 0.7537506809866581
  - 0.7516490166678258
  - 0.7609590860896657
  train_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_micro_oob:
  - 0.7486166871760007
  - 0.7409604074370335
  - 0.7446798141703719
  - 0.7431548354421612
  - 0.751356129543044
  train_level1__roc_auc_samples:
  - 0.7498187737083947
  - 0.738314068304959
  - 0.745254712439606
  - 0.7409289584656203
  - 0.7519178779164116
  train_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_samples_oob:
  - 0.7415909037018739
  - 0.7296783549528694
  - 0.7362536858591607
  - 0.732123226791281
  - 0.7425484703193099
  train_level1__roc_auc_weighted:
  - 0.7341160471000401
  - 0.7372688702463697
  - 0.7391761629592616
  - 0.7370976267281295
  - 0.7415709767530194
  train_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__roc_auc_weighted_oob:
  - 0.7236638592912051
  - 0.7269344204107111
  - 0.728508059882861
  - 0.7253621886623841
  - 0.7296559428061874
  train_level1__tn_macro:
  - 0.3051804267951432
  - 0.30075565545937155
  - 0.29667756257013217
  - 0.3039581777445855
  - 0.3144713326571028
  train_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_macro_oob:
  - 0.29442538384796946
  - 0.2916447462815056
  - 0.2875298824218178
  - 0.294321713363367
  - 0.30623581123508675
  train_level1__tn_micro:
  - 0.3051804267951432
  - 0.30075565545937155
  - 0.2966775625701322
  - 0.3039581777445855
  - 0.3144713326571028
  train_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_micro_oob:
  - 0.29442538384796946
  - 0.29164474628150555
  - 0.2875298824218178
  - 0.294321713363367
  - 0.3062358112350867
  train_level1__tn_samples:
  - 0.3051804267951431
  - 0.3007556554593715
  - 0.2966775625701321
  - 0.30395817774458544
  - 0.31447133265710275
  train_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_samples_oob:
  - 0.2944253838479694
  - 0.2916447462815055
  - 0.28752988242181776
  - 0.29432171336336693
  - 0.30623581123508664
  train_level1__tn_weighted:
  - 0.23544531775709943
  - 0.23560627555619948
  - 0.22899445703588206
  - 0.23021173007043685
  - 0.23783149302532253
  train_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tn_weighted_oob:
  - 0.22261546928801254
  - 0.2247476576837631
  - 0.2172586153417237
  - 0.21903614266800916
  - 0.22794083274900662
  train_level1__tp_macro:
  - 0.21901841983599768
  - 0.21902051748051082
  - 0.22044689466751236
  - 0.2193741116384399
  - 0.2183741486741052
  train_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_macro_oob:
  - 0.2163174927610288
  - 0.2161987660815917
  - 0.21722691125530563
  - 0.2169168132212292
  - 0.21574167994976576
  train_level1__tp_micro:
  - 0.21901841983599776
  - 0.2190205174805108
  - 0.22044689466751233
  - 0.21937411163843987
  - 0.2183741486741052
  train_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_micro_oob:
  - 0.2163174927610288
  - 0.21619876608159166
  - 0.21722691125530566
  - 0.21691681322122913
  - 0.21574167994976573
  train_level1__tp_samples:
  - 0.2190184198359977
  - 0.2190205174805107
  - 0.22044689466751224
  - 0.21937411163843978
  - 0.21837414867410515
  train_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_samples_oob:
  - 0.2163174927610287
  - 0.21619876608159158
  - 0.21722691125530558
  - 0.21691681322122905
  - 0.21574167994976565
  train_level1__tp_weighted:
  - 0.3331956751339495
  - 0.3311975292990759
  - 0.3331696998576729
  - 0.33158325850974946
  - 0.33269044555231075
  train_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level1__tp_weighted_oob:
  - 0.33053193683261517
  - 0.3281561906371744
  - 0.32992065563583506
  - 0.329131534106384
  - 0.33021829417702403
  train_level2__average_precision_macro:
  - 0.39511970978321653
  - 0.39752521416252906
  - 0.3965385735864985
  - 0.3924355555869405
  - 0.3976864810711731
  train_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_macro_oob:
  - 0.3891217038352599
  - 0.3934091843159385
  - 0.39094154189668984
  - 0.38773507860162565
  - 0.39398123852411576
  train_level2__average_precision_micro:
  - 0.39167416788385784
  - 0.38835381068270947
  - 0.3891589570385061
  - 0.3851088453917543
  - 0.38952125561379625
  train_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_micro_oob:
  - 0.38940304231033906
  - 0.38624487322799783
  - 0.3873884855669135
  - 0.3833767535020722
  - 0.388034421246831
  train_level2__average_precision_samples:
  - 0.3976140214431712
  - 0.3919592722669621
  - 0.39815337078744717
  - 0.3899708441777863
  - 0.3967201355774729
  train_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_samples_oob:
  - 0.39553024629780303
  - 0.3889510605938218
  - 0.39665850414671516
  - 0.38856272190572755
  - 0.39507013342451697
  train_level2__average_precision_weighted:
  - 0.5197795604822447
  - 0.5244215385987001
  - 0.523292582427144
  - 0.5166475837820521
  - 0.5221893671587537
  train_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__average_precision_weighted_oob:
  - 0.5132034857916496
  - 0.5191719966991492
  - 0.5178782886875258
  - 0.5123619144932025
  - 0.5179581206147054
  train_level2__f1_macro:
  - 0.49633793220916356
  - 0.49636520158783304
  - 0.4931941259696541
  - 0.49408561998602724
  - 0.4972226247403757
  train_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_macro_oob:
  - 0.49044942453220436
  - 0.49155865895069123
  - 0.48804703127286925
  - 0.4887614734154038
  - 0.49234410471912293
  train_level2__f1_micro:
  - 0.49633793220916367
  - 0.496365201587833
  - 0.4931941259696541
  - 0.4940856199860271
  - 0.4972226247403758
  train_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_micro_oob:
  - 0.4904494245322043
  - 0.49155865895069106
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__f1_samples:
  - 0.49633793220916367
  - 0.4963652015878329
  - 0.49319412596965406
  - 0.4940856199860271
  - 0.49722262474037576
  train_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_samples_oob:
  - 0.49044942453220425
  - 0.4915586589506911
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__f1_weighted:
  - 0.5545724813437943
  - 0.5576518682185517
  - 0.5502836865706695
  - 0.549688016982801
  - 0.5537272337332441
  train_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__f1_weighted_oob:
  - 0.5471819567643754
  - 0.5510736622235102
  - 0.5436948456239772
  - 0.5427952113247316
  - 0.5480778862527836
  train_level2__fn_macro:
  - -0.014283281018079175
  - -0.01382179922521402
  - -0.012928721276284335
  - -0.013033318075598065
  - -0.014249142636332899
  train_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_macro_oob:
  - -0.01574324159914349
  - -0.015352240661915921
  - -0.014733863492218372
  - -0.01450287889373389
  - -0.015601603632323817
  train_level2__fn_micro:
  - -0.014283281018079179
  - -0.013821799225214022
  - -0.012928721276284335
  - -0.013033318075598063
  - -0.014249142636332899
  train_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_micro_oob:
  - -0.01574324159914349
  - -0.015352240661915921
  - -0.014733863492218374
  - -0.01450287889373389
  - -0.015601603632323819
  train_level2__fn_samples:
  - -0.014283281018079177
  - -0.01382179922521402
  - -0.012928721276284333
  - -0.013033318075598061
  - -0.014249142636332899
  train_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_samples_oob:
  - -0.01574324159914349
  - -0.01535224066191592
  - -0.014733863492218372
  - -0.014502878893733888
  - -0.015601603632323817
  train_level2__fn_weighted:
  - -0.01627651777941681
  - -0.01644274807624199
  - -0.014720212910079702
  - -0.014312935371603625
  - -0.015519203158189438
  train_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fn_weighted_oob:
  - -0.018254832962985842
  - -0.01851793159792653
  - -0.016888596202622355
  - -0.01609923921613356
  - -0.0169066900911036
  train_level2__fp_macro:
  - -0.48937878677275715
  - -0.48981299918695304
  - -0.4938771527540616
  - -0.4928810619383748
  - -0.4885282326232912
  train_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_macro_oob:
  - -0.49380733386865217
  - -0.49308910038739295
  - -0.4972191052349124
  - -0.4967356476908622
  - -0.4920542916485533
  train_level2__fp_micro:
  - -0.48937878677275715
  - -0.489812999186953
  - -0.4938771527540616
  - -0.49288106193837483
  - -0.4885282326232913
  train_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_micro_oob:
  - -0.4938073338686522
  - -0.493089100387393
  - -0.4972191052349124
  - -0.4967356476908622
  - -0.49205429164855335
  train_level2__fp_samples:
  - -0.4893787867727571
  - -0.4898129991869529
  - -0.49387715275406163
  - -0.4928810619383748
  - -0.4885282326232913
  train_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_samples_oob:
  - -0.4938073338686522
  - -0.49308910038739295
  - -0.49721910523491253
  - -0.4967356476908622
  - -0.49205429164855324
  train_level2__fp_weighted:
  - -0.42915100087678887
  - -0.42590538370520625
  - -0.4349961005192508
  - -0.4359990476455953
  - -0.43075356310856666
  train_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__fp_weighted_oob:
  - -0.43456321027263883
  - -0.4304084061785634
  - -0.4394165581734006
  - -0.44110554945913477
  - -0.43501542365611284
  train_level2__jaccard_macro:
  - 0.3458411367607655
  - 0.3469355260748379
  - 0.3440434019746576
  - 0.34438363505014596
  - 0.3474502332163454
  train_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_macro_oob:
  - 0.34030062282035006
  - 0.34242086657777415
  - 0.3392215379819732
  - 0.33932951039237336
  - 0.3429979694698301
  train_level2__jaccard_micro:
  - 0.3300860897145446
  - 0.33011021167639437
  - 0.3273109923911284
  - 0.3280967540674143
  - 0.3308691180251993
  train_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_micro_oob:
  - 0.32489764337986393
  - 0.3258719086873811
  - 0.3227924686597506
  - 0.32341782241351824
  - 0.32656265017781055
  train_level2__jaccard_samples:
  - 0.3368710345677571
  - 0.33764086208632016
  - 0.3347610605287561
  - 0.33579296541943365
  - 0.33915114461279816
  train_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_samples_oob:
  - 0.3315465939193867
  - 0.33338892737024245
  - 0.33028935956402816
  - 0.33124377162423363
  - 0.3349090595161413
  train_level2__jaccard_weighted:
  - 0.39867232379027645
  - 0.4024737033720898
  - 0.3952108499357402
  - 0.394705053809197
  - 0.398052595341765
  train_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__jaccard_weighted_oob:
  - 0.39136001129570097
  - 0.39586301021052994
  - 0.3887152011269796
  - 0.3879280028059771
  - 0.3926185262846413
  train_level2__label_ranking_average_precision_score:
  - 0.3976140214431712
  - 0.3919592722669619
  - 0.39815337078744695
  - 0.38997084417778627
  - 0.3967201355774729
  train_level2__label_ranking_average_precision_score_oob:
  - 0.39553024629780303
  - 0.3889510605938219
  - 0.3966585041467153
  - 0.3885627219057277
  - 0.3950701334245172
  train_level2__matthews_corrcoef_macro:
  - 0.2349918620183114
  - 0.23984823454184453
  - 0.23483446380708048
  - 0.23242313023836308
  - 0.23122872344204734
  train_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_macro_oob:
  - 0.22209702721681263
  - 0.2281736549666023
  - 0.22136940934998198
  - 0.21967385154410746
  - 0.21936431334400647
  train_level2__matthews_corrcoef_micro:
  - 0.2797148309612987
  - 0.28132095619475306
  - 0.28140024511031786
  - 0.2817868346338916
  - 0.2806528700118068
  train_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_micro_oob:
  - 0.2693275003962023
  - 0.27171427598624043
  - 0.27051427896484836
  - 0.27187438945955117
  - 0.2715812476724491
  train_level2__matthews_corrcoef_samples:
  - 0.27946063296370466
  - 0.2813148726157434
  - 0.28231710189755715
  - 0.28252854970370495
  - 0.2790971590933781
  train_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_samples_oob:
  - 0.2691386630866424
  - 0.27106929375357663
  - 0.27102409480597117
  - 0.2721642407083492
  - 0.2697319645083268
  train_level2__matthews_corrcoef_weighted:
  - 0.24864693068720942
  - 0.2591353903108909
  - 0.24309067562541747
  - 0.2462931800740351
  - 0.23957325256519454
  train_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.23044381980678538
  - 0.24129847403332447
  - 0.22631665770466702
  - 0.22979492657659872
  - 0.22597721505602636
  train_level2__ndcg:
  - 0.7270894453030349
  - 0.7247638563442446
  - 0.72663504085939
  - 0.7222277081763113
  - 0.7199485209380146
  train_level2__ndcg_oob:
  - 0.7261826459201023
  - 0.7231068250645241
  - 0.7263458281739855
  - 0.7216880055167495
  - 0.7197776216981895
  train_level2__neg_coverage_error:
  - -75.28571428571429
  - -75.9039408866995
  - -75.19849246231156
  - -75.51116625310173
  - -75.07711442786069
  train_level2__neg_coverage_error_oob:
  - -77.83709273182957
  - -78.39408866995073
  - -77.55778894472361
  - -78.05707196029776
  - -77.62189054726367
  train_level2__neg_hamming_loss_macro:
  - -0.5036620677908363
  - -0.503634798412167
  - -0.5068058740303458
  - -0.5059143800139727
  - -0.5027773752596242
  train_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_macro_oob:
  - -0.5095505754677957
  - -0.5084413410493088
  - -0.5119529687271308
  - -0.5112385265845961
  - -0.5076558952808771
  train_level2__neg_hamming_loss_micro:
  - -0.5036620677908363
  - -0.503634798412167
  - -0.5068058740303459
  - -0.5059143800139728
  - -0.5027773752596242
  train_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_micro_oob:
  - -0.5095505754677957
  - -0.5084413410493089
  - -0.5119529687271308
  - -0.5112385265845961
  - -0.5076558952808772
  train_level2__neg_hamming_loss_samples:
  - -0.5036620677908363
  - -0.503634798412167
  - -0.5068058740303459
  - -0.5059143800139728
  - -0.5027773752596242
  train_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_samples_oob:
  - -0.5095505754677957
  - -0.5084413410493089
  - -0.5119529687271308
  - -0.511238526584596
  - -0.5076558952808771
  train_level2__neg_hamming_loss_weighted:
  - -0.44542751865620567
  - -0.4423481317814482
  - -0.44971631342933044
  - -0.45031198301719894
  - -0.4462727662667559
  train_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.4528180432356246
  - -0.44892633777648977
  - -0.4563051543760228
  - -0.4572047886752684
  - -0.4519221137472164
  train_level2__neg_label_ranking_loss:
  - -0.31040804017603224
  - -0.31996744132062216
  - -0.3098529999765418
  - -0.32143873087255853
  - -0.30288630270029554
  train_level2__neg_label_ranking_loss_oob:
  - -0.3183665520524139
  - -0.3283970867964246
  - -0.31655590881986956
  - -0.32912115185334334
  - -0.30953863915226876
  train_level2__precision_macro:
  - 0.49633793220916356
  - 0.49636520158783304
  - 0.4931941259696541
  - 0.49408561998602724
  - 0.4972226247403757
  train_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_macro_oob:
  - 0.49044942453220436
  - 0.49155865895069123
  - 0.48804703127286925
  - 0.4887614734154038
  - 0.49234410471912293
  train_level2__precision_micro:
  - 0.49633793220916367
  - 0.496365201587833
  - 0.4931941259696541
  - 0.4940856199860271
  - 0.4972226247403758
  train_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_micro_oob:
  - 0.4904494245322043
  - 0.49155865895069106
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__precision_samples:
  - 0.49633793220916367
  - 0.4963652015878329
  - 0.49319412596965406
  - 0.4940856199860271
  - 0.49722262474037576
  train_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_samples_oob:
  - 0.49044942453220425
  - 0.4915586589506911
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__precision_weighted:
  - 0.5545724813437943
  - 0.5576518682185517
  - 0.5502836865706695
  - 0.549688016982801
  - 0.5537272337332441
  train_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__precision_weighted_oob:
  - 0.5471819567643754
  - 0.5510736622235102
  - 0.5436948456239772
  - 0.5427952113247316
  - 0.5480778862527836
  train_level2__recall_macro:
  - 0.49633793220916356
  - 0.49636520158783304
  - 0.4931941259696541
  - 0.49408561998602724
  - 0.4972226247403757
  train_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_macro_oob:
  - 0.49044942453220436
  - 0.49155865895069123
  - 0.48804703127286925
  - 0.4887614734154038
  - 0.49234410471912293
  train_level2__recall_micro:
  - 0.49633793220916367
  - 0.496365201587833
  - 0.4931941259696541
  - 0.4940856199860271
  - 0.4972226247403758
  train_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_micro_oob:
  - 0.4904494245322043
  - 0.49155865895069106
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__recall_samples:
  - 0.49633793220916367
  - 0.4963652015878329
  - 0.49319412596965406
  - 0.4940856199860271
  - 0.49722262474037576
  train_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_samples_oob:
  - 0.49044942453220425
  - 0.4915586589506911
  - 0.4880470312728692
  - 0.4887614734154039
  - 0.4923441047191228
  train_level2__recall_weighted:
  - 0.5545724813437943
  - 0.5576518682185517
  - 0.5502836865706695
  - 0.549688016982801
  - 0.5537272337332441
  train_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__recall_weighted_oob:
  - 0.5471819567643754
  - 0.5510736622235102
  - 0.5436948456239772
  - 0.5427952113247316
  - 0.5480778862527836
  train_level2__roc_auc_macro:
  - 0.725215386592419
  - 0.728073554775764
  - 0.7277867427091872
  - 0.7228216609936485
  - 0.7298247307038668
  train_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_macro_oob:
  - 0.717469900694244
  - 0.7208010377016199
  - 0.7211112084519764
  - 0.7147364823533517
  - 0.7215596518969908
  train_level2__roc_auc_micro:
  - 0.7366530826719095
  - 0.7329703317035301
  - 0.7348226105389343
  - 0.7304572055533856
  - 0.7358546475899344
  train_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_micro_oob:
  - 0.732521932876782
  - 0.7290616885167648
  - 0.7310271461802786
  - 0.7266119961044623
  - 0.7316705275801245
  train_level2__roc_auc_samples:
  - 0.7272867986664333
  - 0.7194066189052389
  - 0.7241762246914444
  - 0.7173335373959571
  - 0.7244924623390903
  train_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_samples_oob:
  - 0.7236564431277984
  - 0.715668807792064
  - 0.7208505522958985
  - 0.7140159692982779
  - 0.7204721443441642
  train_level2__roc_auc_weighted:
  - 0.717627348279751
  - 0.7227149409859974
  - 0.7242218283154215
  - 0.718220507862114
  - 0.7208132720191694
  train_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__roc_auc_weighted_oob:
  - 0.7098199426755294
  - 0.7155117430751241
  - 0.7173838168238975
  - 0.7109489136044973
  - 0.7129655672560788
  train_level2__tn_macro:
  - 0.2767111954643891
  - 0.2760294609976565
  - 0.2717714787529882
  - 0.2733624033342167
  - 0.2775684683379221
  train_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_macro_oob:
  - 0.27228264836849403
  - 0.2727533597972165
  - 0.2684295262721373
  - 0.26950781758172926
  - 0.27404240931266
  train_level2__tn_micro:
  - 0.2767111954643891
  - 0.2760294609976565
  - 0.27177147875298824
  - 0.2733624033342167
  - 0.27756846833792204
  train_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_micro_oob:
  - 0.27228264836849403
  - 0.2727533597972165
  - 0.2684295262721374
  - 0.26950781758172926
  - 0.27404240931266
  train_level2__tn_samples:
  - 0.27671119546438905
  - 0.27602946099765646
  - 0.2717714787529882
  - 0.27336240333421663
  - 0.277568468337922
  train_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_samples_oob:
  - 0.27228264836849403
  - 0.2727533597972165
  - 0.26842952627213734
  - 0.2695078175817292
  - 0.27404240931265994
  train_level2__tn_weighted:
  - 0.22318669867219798
  - 0.2272839092533566
  - 0.21805394203242714
  - 0.2185753095215749
  - 0.22178780850522806
  train_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tn_weighted_oob:
  - 0.21777448927634804
  - 0.22278088677999938
  - 0.2136334843782774
  - 0.2134688077080353
  - 0.2175259479576819
  train_level2__tp_macro:
  - 0.21962673674477454
  - 0.22033574059017652
  - 0.22142264721666588
  - 0.2207232166518105
  - 0.2196541564024538
  train_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_macro_oob:
  - 0.2181667761637102
  - 0.21880529915347463
  - 0.2196175050007318
  - 0.21925365583367468
  - 0.21830169540646283
  train_level2__tp_micro:
  - 0.21962673674477456
  - 0.22033574059017647
  - 0.22142264721666585
  - 0.22072321665181044
  - 0.21965415640245375
  train_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_micro_oob:
  - 0.21816677616371025
  - 0.21880529915347458
  - 0.21961750500073182
  - 0.21925365583367462
  - 0.21830169540646283
  train_level2__tp_samples:
  - 0.2196267367447745
  - 0.2203357405901764
  - 0.2214226472166658
  - 0.22072321665181038
  - 0.2196541564024537
  train_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_samples_oob:
  - 0.2181667761637102
  - 0.21880529915347455
  - 0.21961750500073174
  - 0.21925365583367457
  - 0.21830169540646277
  train_level2__tp_weighted:
  - 0.33138578267159624
  - 0.3303679589651952
  - 0.3322297445382424
  - 0.3311127074612263
  - 0.33193942522801584
  train_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level2__tp_weighted_oob:
  - 0.32940746748802724
  - 0.32829277544351076
  - 0.33006136124569974
  - 0.3293264036166963
  - 0.3305519382951017
  train_level3__average_precision_macro:
  - 0.38588805696102146
  - 0.3903547001153539
  - 0.38983554184609626
  - 0.3841692500809425
  - 0.3941013325952839
  train_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_macro_oob:
  - 0.379351457423596
  - 0.38564562344727854
  - 0.3854134847744547
  - 0.3770588304981974
  - 0.3894028113194775
  train_level3__average_precision_micro:
  - 0.3891673427170308
  - 0.3838177056188211
  - 0.38684665926859263
  - 0.37561254063256705
  - 0.3882181974641113
  train_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_micro_oob:
  - 0.38527262012979513
  - 0.380412399928611
  - 0.38451352250457416
  - 0.37190564762375444
  - 0.3862107696937283
  train_level3__average_precision_samples:
  - 0.3944044644621428
  - 0.386369774020807
  - 0.3951824286210875
  - 0.38129618986422936
  - 0.3924730743094365
  train_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_samples_oob:
  - 0.3912696808831635
  - 0.383291217886189
  - 0.3932880670579728
  - 0.3780623617240597
  - 0.390684232099338
  train_level3__average_precision_weighted:
  - 0.509859758061427
  - 0.5171815525649143
  - 0.5160060451015425
  - 0.5075414374234759
  - 0.517946844358867
  train_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__average_precision_weighted_oob:
  - 0.5037440466505719
  - 0.5112940813422707
  - 0.5113450678323902
  - 0.5005417470168886
  - 0.5127628261121135
  train_level3__f1_macro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.49426745377372305
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_macro_oob:
  - 0.4930773535781201
  - 0.4938782342531923
  - 0.490632775528126
  - 0.4910501337059433
  - 0.4940105298748974
  train_level3__f1_micro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.494267453773723
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_micro_oob:
  - 0.49307735357812005
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.4910501337059433
  - 0.49401052987489735
  train_level3__f1_samples:
  - 0.4962162688274083
  - 0.4980152087617772
  - 0.4942674537737229
  - 0.49463971668794715
  - 0.49833357484422547
  train_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_samples_oob:
  - 0.4930773535781201
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.49105013370594325
  - 0.49401052987489735
  train_level3__f1_weighted:
  - 0.5553116120166223
  - 0.5597806292057053
  - 0.5519167085557902
  - 0.5500864509684527
  - 0.5554588955069772
  train_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__f1_weighted_oob:
  - 0.5506601727453972
  - 0.5538742795968963
  - 0.5461480400859299
  - 0.5450009193646844
  - 0.5501290655653073
  train_level3__fn_macro:
  - -0.01455094045794097
  - -0.01391745181500789
  - -0.012879933648826657
  - -0.013587414777518127
  - -0.014128387190262279
  train_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_macro_oob:
  - -0.015572912864685986
  - -0.015423980104261322
  - -0.01431916865882812
  - -0.014743790503264352
  - -0.015480848186253197
  train_level3__fn_micro:
  - -0.014550940457940968
  - -0.013917451815007892
  - -0.012879933648826657
  - -0.013587414777518129
  - -0.01412838719026228
  train_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_micro_oob:
  - -0.015572912864685987
  - -0.015423980104261322
  - -0.01431916865882812
  - -0.014743790503264352
  - -0.0154808481862532
  train_level3__fn_samples:
  - -0.014550940457940966
  - -0.01391745181500789
  - -0.012879933648826657
  - -0.013587414777518127
  - -0.014128387190262277
  train_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_samples_oob:
  - -0.015572912864685984
  - -0.015423980104261319
  - -0.01431916865882812
  - -0.01474379050326435
  - -0.015480848186253199
  train_level3__fn_weighted:
  - -0.01650699097687003
  - -0.016508902411539326
  - -0.014755258545250453
  - -0.015219513342807434
  - -0.015370488805328032
  train_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fn_weighted_oob:
  - -0.017885137268428532
  - -0.018663823287935862
  - -0.01672278327203834
  - -0.016752895998756106
  - -0.016909515406961066
  train_level3__fp_macro:
  - -0.4892327907146507
  - -0.48806733942321495
  - -0.4928526125774503
  - -0.4917728685345347
  - -0.48753803796551215
  train_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_macro_oob:
  - -0.4913497335571939
  - -0.4906977856425463
  - -0.49504805581304584
  - -0.4942060757907924
  - -0.4905086219388494
  train_level3__fp_micro:
  - -0.4892327907146507
  - -0.4880673394232149
  - -0.49285261257745033
  - -0.49177286853453467
  - -0.48753803796551226
  train_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_micro_oob:
  - -0.49134973355719397
  - -0.4906977856425463
  - -0.4950480558130458
  - -0.49420607579079234
  - -0.4905086219388494
  train_level3__fp_samples:
  - -0.48923279071465076
  - -0.48806733942321484
  - -0.49285261257745033
  - -0.49177286853453467
  - -0.4875380379655123
  train_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_samples_oob:
  - -0.49134973355719397
  - -0.49069778564254624
  - -0.49504805581304584
  - -0.49420607579079234
  - -0.4905086219388494
  train_level3__fp_weighted:
  - -0.42818139700650776
  - -0.42371046838275533
  - -0.43332803289895927
  - -0.43469403568873966
  - -0.42917061568769477
  train_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__fp_weighted_oob:
  - -0.4314546899861743
  - -0.42746189711516797
  - -0.43712917664203177
  - -0.43824618463655957
  - -0.43296141902773183
  train_level3__jaccard_macro:
  - 0.345655927018676
  - 0.348341628474509
  - 0.344836263994795
  - 0.344591356374824
  - 0.3483362740558172
  train_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_macro_oob:
  - 0.34254492731364955
  - 0.3444567920999671
  - 0.34132945677800014
  - 0.34129255457646024
  - 0.3442941707104457
  train_level3__jaccard_micro:
  - 0.32997847931263247
  - 0.3315714058270976
  - 0.3282571363768914
  - 0.3285856031751112
  - 0.33185371031554567
  train_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_micro_oob:
  - 0.3272081382205716
  - 0.32791388152358575
  - 0.3250585858585859
  - 0.32542508182326174
  - 0.32803053386147507
  train_level3__jaccard_samples:
  - 0.336879022927025
  - 0.3390449461105425
  - 0.33570367380686056
  - 0.336337405332315
  - 0.3400047784649055
  train_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_samples_oob:
  - 0.3339479270288486
  - 0.3354598018830512
  - 0.3324158664731087
  - 0.3330851561990576
  - 0.33619625503480005
  train_level3__jaccard_weighted:
  - 0.39941039549156404
  - 0.4045123343045101
  - 0.3966841105306051
  - 0.3948306472497306
  - 0.3996796738467098
  train_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__jaccard_weighted_oob:
  - 0.3946566166457109
  - 0.3986113990613866
  - 0.3908833028747171
  - 0.3899250841452423
  - 0.3946157704478428
  train_level3__label_ranking_average_precision_score:
  - 0.3944044644621426
  - 0.3863697740208072
  - 0.395182428621088
  - 0.38129618986422953
  - 0.3924730743094365
  train_level3__label_ranking_average_precision_score_oob:
  - 0.39126968088316333
  - 0.383291217886189
  - 0.39328806705797303
  - 0.3780623617240598
  - 0.39068423209933795
  train_level3__matthews_corrcoef_macro:
  - 0.234793670506472
  - 0.24169906328980412
  - 0.2378361591319263
  - 0.23228818089133085
  - 0.23298142974646024
  train_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_macro_oob:
  - 0.2262774896887301
  - 0.23161776920782257
  - 0.22653381958446928
  - 0.22231161365050114
  - 0.22159089595204237
  train_level3__matthews_corrcoef_micro:
  - 0.27870935877261493
  - 0.28253891233246076
  - 0.28256103949976785
  - 0.2804367840333069
  - 0.2820907196088894
  train_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_micro_oob:
  - 0.2723672671927334
  - 0.2736560584808192
  - 0.2743318525906347
  - 0.27320780088284163
  - 0.27354904928623025
  train_level3__matthews_corrcoef_samples:
  - 0.2782793299724038
  - 0.2819254973009466
  - 0.28297850632131866
  - 0.2809455534746315
  - 0.2803359669468476
  train_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_samples_oob:
  - 0.27191365611650603
  - 0.2723771707232244
  - 0.2743394657089551
  - 0.2735910140535092
  - 0.27147725543107903
  train_level3__matthews_corrcoef_weighted:
  - 0.2495913136537686
  - 0.26193296553654305
  - 0.24859048319960128
  - 0.24608072558541766
  - 0.24272622602251429
  train_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.2372748427970354
  - 0.24737963570564198
  - 0.23098737626002608
  - 0.23128171565948202
  - 0.22850638510123475
  train_level3__ndcg:
  - 0.7264813509392299
  - 0.7217867291154403
  - 0.7250745053527927
  - 0.7157352142903269
  - 0.7197531196410077
  train_level3__ndcg_oob:
  - 0.7246711428163225
  - 0.7202988196376682
  - 0.7245887338822995
  - 0.7142045548400896
  - 0.7193807527707948
  train_level3__neg_coverage_error:
  - -75.14786967418546
  - -75.8768472906404
  - -75.19346733668341
  - -75.42679900744417
  - -74.92786069651741
  train_level3__neg_coverage_error_oob:
  - -77.79448621553885
  - -78.54187192118226
  - -77.56030150753769
  - -78.1910669975186
  - -77.7636815920398
  train_level3__neg_hamming_loss_macro:
  - -0.5037837311725916
  - -0.5019847912382228
  - -0.5057325462262771
  - -0.5053602833120528
  - -0.5016664251557745
  train_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_macro_oob:
  - -0.5069226464218799
  - -0.5061217657468076
  - -0.509367224471874
  - -0.5089498662940567
  - -0.5059894701251026
  train_level3__neg_hamming_loss_micro:
  - -0.5037837311725917
  - -0.5019847912382228
  - -0.5057325462262771
  - -0.5053602833120528
  - -0.5016664251557745
  train_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_micro_oob:
  - -0.5069226464218799
  - -0.5061217657468076
  - -0.5093672244718739
  - -0.5089498662940567
  - -0.5059894701251026
  train_level3__neg_hamming_loss_samples:
  - -0.5037837311725917
  - -0.5019847912382228
  - -0.505732546226277
  - -0.5053602833120528
  - -0.5016664251557745
  train_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_samples_oob:
  - -0.5069226464218799
  - -0.5061217657468076
  - -0.5093672244718739
  - -0.5089498662940566
  - -0.5059894701251026
  train_level3__neg_hamming_loss_weighted:
  - -0.44468838798337773
  - -0.4402193707942948
  - -0.4480832914442098
  - -0.44991354903154723
  - -0.44454110449302275
  train_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.44933982725460275
  - -0.4461257204031038
  - -0.4538519599140701
  - -0.4549990806353156
  - -0.4498709344346927
  train_level3__neg_label_ranking_loss:
  - -0.32813031642741236
  - -0.3358568875239947
  - -0.32285307965781124
  - -0.3376210362852455
  - -0.31681717637055307
  train_level3__neg_label_ranking_loss_oob:
  - -0.33777997489517114
  - -0.34481514377942296
  - -0.3296568043621511
  - -0.34692919792357885
  - -0.32484366108221946
  train_level3__precision_macro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.49426745377372305
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_macro_oob:
  - 0.4930773535781201
  - 0.4938782342531923
  - 0.490632775528126
  - 0.4910501337059433
  - 0.4940105298748974
  train_level3__precision_micro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.494267453773723
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_micro_oob:
  - 0.49307735357812005
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.4910501337059433
  - 0.49401052987489735
  train_level3__precision_samples:
  - 0.4962162688274083
  - 0.4980152087617772
  - 0.4942674537737229
  - 0.49463971668794715
  - 0.49833357484422547
  train_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_samples_oob:
  - 0.4930773535781201
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.49105013370594325
  - 0.49401052987489735
  train_level3__precision_weighted:
  - 0.5553116120166223
  - 0.5597806292057053
  - 0.5519167085557902
  - 0.5500864509684527
  - 0.5554588955069772
  train_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__precision_weighted_oob:
  - 0.5506601727453972
  - 0.5538742795968963
  - 0.5461480400859299
  - 0.5450009193646844
  - 0.5501290655653073
  train_level3__recall_macro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.49426745377372305
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_macro_oob:
  - 0.4930773535781201
  - 0.4938782342531923
  - 0.490632775528126
  - 0.4910501337059433
  - 0.4940105298748974
  train_level3__recall_micro:
  - 0.4962162688274083
  - 0.49801520876177724
  - 0.494267453773723
  - 0.4946397166879472
  - 0.49833357484422547
  train_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_micro_oob:
  - 0.49307735357812005
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.4910501337059433
  - 0.49401052987489735
  train_level3__recall_samples:
  - 0.4962162688274083
  - 0.4980152087617772
  - 0.4942674537737229
  - 0.49463971668794715
  - 0.49833357484422547
  train_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_samples_oob:
  - 0.4930773535781201
  - 0.4938782342531924
  - 0.49063277552812606
  - 0.49105013370594325
  - 0.49401052987489735
  train_level3__recall_weighted:
  - 0.5553116120166223
  - 0.5597806292057053
  - 0.5519167085557902
  - 0.5500864509684527
  - 0.5554588955069772
  train_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__recall_weighted_oob:
  - 0.5506601727453972
  - 0.5538742795968963
  - 0.5461480400859299
  - 0.5450009193646844
  - 0.5501290655653073
  train_level3__roc_auc_macro:
  - 0.7228466374131859
  - 0.7250759315923624
  - 0.7258622452520733
  - 0.7188705084905482
  - 0.7269637711273332
  train_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_macro_oob:
  - 0.7141718890123225
  - 0.716947211620922
  - 0.7179061290315267
  - 0.7100157223772539
  - 0.7180919532831458
  train_level3__roc_auc_micro:
  - 0.7342721824640258
  - 0.7296544494689567
  - 0.7329238950572056
  - 0.724426958048235
  - 0.7335971374192619
  train_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_micro_oob:
  - 0.7294144215202799
  - 0.7251647848597482
  - 0.7289149114738154
  - 0.7194934249466594
  - 0.7292952508282519
  train_level3__roc_auc_samples:
  - 0.7248460227149396
  - 0.7166359761568599
  - 0.7225655213660293
  - 0.7112221882316648
  - 0.7207461881790808
  train_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_samples_oob:
  - 0.7207365372126642
  - 0.7123872868406061
  - 0.719197685784066
  - 0.7068946222329562
  - 0.7165965637289667
  train_level3__roc_auc_weighted:
  - 0.71472989704344
  - 0.7193594029559096
  - 0.7209309049710523
  - 0.7138014942440781
  - 0.717734980166125
  train_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__roc_auc_weighted_oob:
  - 0.7066194675556935
  - 0.711471022063124
  - 0.7132873189338155
  - 0.7055830558578471
  - 0.7095314646814875
  train_level3__tn_macro:
  - 0.27685719152249555
  - 0.2777751207613946
  - 0.2727960189295994
  - 0.2744705967380568
  - 0.27855866299570115
  train_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_macro_oob:
  - 0.2747402486799523
  - 0.2751446745420632
  - 0.270600575694004
  - 0.2720373894817991
  - 0.275588079022364
  train_level3__tn_micro:
  - 0.27685719152249555
  - 0.2777751207613946
  - 0.2727960189295994
  - 0.2744705967380568
  - 0.2785586629957011
  train_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_micro_oob:
  - 0.2747402486799523
  - 0.2751446745420632
  - 0.270600575694004
  - 0.2720373894817991
  - 0.27558807902236393
  train_level3__tn_samples:
  - 0.2768571915224955
  - 0.2777751207613946
  - 0.27279601892959937
  - 0.2744705967380568
  - 0.27855866299570103
  train_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_samples_oob:
  - 0.2747402486799522
  - 0.27514467454206315
  - 0.2706005756940039
  - 0.27203738948179906
  - 0.2755880790223638
  train_level3__tn_weighted:
  - 0.22415630254247915
  - 0.22947882457580737
  - 0.21972200965271868
  - 0.21988032147843045
  - 0.22337075592610003
  train_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tn_weighted_oob:
  - 0.22088300956281273
  - 0.22572739584339482
  - 0.2159208659096461
  - 0.21632817253061076
  - 0.21957995258606292
  train_level3__tp_macro:
  - 0.21935907730491266
  - 0.22024008800038264
  - 0.22147143484412352
  - 0.22016911994989047
  - 0.21977491184852438
  train_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_macro_oob:
  - 0.21833710489816768
  - 0.21873355971112923
  - 0.22003219983412206
  - 0.2190127442241442
  - 0.21842245085253348
  train_level3__tp_micro:
  - 0.21935907730491278
  - 0.2202400880003826
  - 0.22147143484412354
  - 0.22016911994989039
  - 0.21977491184852438
  train_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_micro_oob:
  - 0.21833710489816774
  - 0.21873355971112918
  - 0.22003219983412206
  - 0.21901274422414416
  - 0.21842245085253345
  train_level3__tp_samples:
  - 0.21935907730491272
  - 0.22024008800038258
  - 0.2214714348441235
  - 0.2201691199498903
  - 0.2197749118485243
  train_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_samples_oob:
  - 0.21833710489816766
  - 0.21873355971112912
  - 0.220032199834122
  - 0.2190127442241441
  - 0.21842245085253337
  train_level3__tp_weighted:
  - 0.33115530947414307
  - 0.3303018046298979
  - 0.3321946989030716
  - 0.3302061294900224
  - 0.33208813958087724
  train_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level3__tp_weighted_oob:
  - 0.3297771631825846
  - 0.32814688375350143
  - 0.3302271741762837
  - 0.3286727468340737
  - 0.33054911297924416
  train_level4__average_precision_macro:
  - 0.38125835573619005
  - 0.38627697377052084
  - 0.39272526387243495
  - 0.3808909846905858
  - 0.3950353892540184
  train_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_macro_oob:
  - 0.3778471701123843
  - 0.38203606007367163
  - 0.3873102920378625
  - 0.3767311082915361
  - 0.3887966657062092
  train_level4__average_precision_micro:
  - 0.3844773926935817
  - 0.37691835006840285
  - 0.38889818380075747
  - 0.3765507184594665
  - 0.3886223404209366
  train_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_micro_oob:
  - 0.3831306002655639
  - 0.37617050598869145
  - 0.3857115762500254
  - 0.37390804538774525
  - 0.38570195004735025
  train_level4__average_precision_samples:
  - 0.39059257799816477
  - 0.3799537133578213
  - 0.39468287390859524
  - 0.3801897591286406
  - 0.3931685354936604
  train_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_samples_oob:
  - 0.38951159093712123
  - 0.3787117516838893
  - 0.39181105477175954
  - 0.3778073328445747
  - 0.3908673485255276
  train_level4__average_precision_weighted:
  - 0.5051060394664918
  - 0.5131773255249297
  - 0.5181060422003567
  - 0.5050979701543773
  - 0.5195811068600837
  train_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__average_precision_weighted_oob:
  - 0.5012723832085173
  - 0.5085978779007517
  - 0.5128021821060893
  - 0.500946842715671
  - 0.5124099208630422
  train_level4__f1_macro:
  - 0.49667858967807865
  - 0.4982304270888135
  - 0.49346245792067134
  - 0.49468789900985344
  - 0.49910640969907744
  train_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_macro_oob:
  - 0.49397766260310977
  - 0.4948586732985796
  - 0.4902912621359223
  - 0.4917005950516755
  - 0.49492827126503414
  train_level4__f1_micro:
  - 0.4966785896780787
  - 0.49823042708881343
  - 0.49346245792067134
  - 0.49468789900985327
  - 0.49910640969907744
  train_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_micro_oob:
  - 0.4939776626031097
  - 0.4948586732985796
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.494928271265034
  train_level4__f1_samples:
  - 0.4966785896780787
  - 0.4982304270888134
  - 0.4934624579206713
  - 0.4946878990098533
  - 0.4991064096990774
  train_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_samples_oob:
  - 0.4939776626031097
  - 0.4948586732985795
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.4949282712650341
  train_level4__f1_weighted:
  - 0.5556432431333194
  - 0.5601798190540583
  - 0.5514033161539977
  - 0.5499570494301089
  - 0.5562163370036756
  train_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__f1_weighted_oob:
  - 0.5516709697889789
  - 0.5549246997649633
  - 0.5465304036577182
  - 0.5456658284549891
  - 0.5515011416844533
  train_level4__fn_macro:
  - -0.014526607781589894
  - -0.013965278109904824
  - -0.012928721276284335
  - -0.01356332361656508
  - -0.014055933922619907
  train_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_macro_oob:
  - -0.015889237657249918
  - -0.01528050121957052
  - -0.014270381031370443
  - -0.014767881664217396
  - -0.015287639472540209
  train_level4__fn_micro:
  - -0.014526607781589897
  - -0.013965278109904826
  - -0.012928721276284335
  - -0.013563323616565082
  - -0.01405593392261991
  train_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_micro_oob:
  - -0.01588923765724992
  - -0.01528050121957052
  - -0.014270381031370445
  - -0.014767881664217398
  - -0.015287639472540212
  train_level4__fn_samples:
  - -0.014526607781589894
  - -0.013965278109904824
  - -0.012928721276284333
  - -0.013563323616565082
  - -0.01405593392261991
  train_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_samples_oob:
  - -0.015889237657249918
  - -0.015280501219570518
  - -0.014270381031370443
  - -0.014767881664217395
  - -0.01528763947254021
  train_level4__fn_weighted:
  - -0.01657008431825428
  - -0.01635848304839177
  - -0.014810703878505676
  - -0.01525454893718118
  - -0.015237442113130786
  train_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fn_weighted_oob:
  - -0.018354165868223034
  - -0.018275701085031713
  - -0.016576062366584668
  - -0.01670711956523129
  - -0.01664008301291683
  train_level4__fp_macro:
  - -0.48879480254033136
  - -0.48780429480128173
  - -0.49360882080304436
  - -0.49174877737358164
  - -0.48683765637830256
  train_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_macro_oob:
  - -0.4901330997396403
  - -0.48986082548185
  - -0.4954383568327072
  - -0.49353152328410693
  - -0.48978408926242567
  train_level4__fp_micro:
  - -0.4887948025403314
  - -0.48780429480128173
  - -0.49360882080304436
  - -0.49174877737358164
  - -0.4868376563783027
  train_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_micro_oob:
  - -0.49013309973964037
  - -0.48986082548184995
  - -0.4954383568327072
  - -0.49353152328410704
  - -0.4897840892624257
  train_level4__fp_samples:
  - -0.4887948025403314
  - -0.4878042948012818
  - -0.49360882080304436
  - -0.4917487773735817
  - -0.4868376563783026
  train_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_samples_oob:
  - -0.49013309973964037
  - -0.4898608254818499
  - -0.4954383568327072
  - -0.49353152328410704
  - -0.48978408926242567
  train_level4__fp_weighted:
  - -0.427786672548426
  - -0.42346169789754984
  - -0.43378597996749646
  - -0.4347884016327099
  - -0.4285462208831938
  train_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__fp_weighted_oob:
  - -0.42997486434279814
  - -0.42679959915000487
  - -0.43689353397569713
  - -0.43762705197977964
  - -0.43185877530262984
  train_level4__jaccard_macro:
  - 0.3459795609110665
  - 0.3485558011265265
  - 0.34409906708574095
  - 0.34469046689541183
  - 0.34895315226475554
  train_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_macro_oob:
  - 0.34342417267228503
  - 0.34535474152527545
  - 0.3410054919511632
  - 0.34188116932399404
  - 0.3451606127982163
  train_level4__jaccard_micro:
  - 0.33038749150237934
  - 0.33176223308546043
  - 0.32754740199808935
  - 0.32862812880097303
  - 0.3325395037492357
  train_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_micro_oob:
  - 0.3280015510639329
  - 0.3287788757904102
  - 0.3247588424437299
  - 0.32599667774086377
  - 0.3288403215712704
  train_level4__jaccard_samples:
  - 0.33714994382643476
  - 0.33934791084884386
  - 0.33493389634974347
  - 0.3362415914340264
  - 0.3406597304206738
  train_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_samples_oob:
  - 0.3345939054233848
  - 0.33634026360419184
  - 0.3321452931560344
  - 0.3336384889297665
  - 0.3370164802264728
  train_level4__jaccard_weighted:
  - 0.39963122498721787
  - 0.40497592953364864
  - 0.39623468962987907
  - 0.39472147948185554
  - 0.40028313596885695
  train_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__jaccard_weighted_oob:
  - 0.39565916822885916
  - 0.3996199841756318
  - 0.3913620131293966
  - 0.39055652646885264
  - 0.3958882926152965
  train_level4__label_ranking_average_precision_score:
  - 0.39059257799816477
  - 0.3799537133578211
  - 0.394682873908595
  - 0.3801897591286407
  - 0.3931685354936605
  train_level4__label_ranking_average_precision_score_oob:
  - 0.3895115909371214
  - 0.37871175168388904
  - 0.39181105477175926
  - 0.37780733284457463
  - 0.3908673485255279
  train_level4__matthews_corrcoef_macro:
  - 0.23524896803923026
  - 0.24156594325511843
  - 0.2366465154007759
  - 0.23268126346318146
  - 0.2349008022213244
  train_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_macro_oob:
  - 0.22636937670095986
  - 0.23289672440392462
  - 0.22706270856349764
  - 0.22263065222648518
  - 0.22416837621711613
  train_level4__matthews_corrcoef_micro:
  - 0.27922232431333593
  - 0.282580129704618
  - 0.2816493736606941
  - 0.28056248255618277
  - 0.2830518023129669
  train_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_micro_oob:
  - 0.27216441146298537
  - 0.27505348397575863
  - 0.27417607964042573
  - 0.2737362063582213
  - 0.2750523785213442
  train_level4__matthews_corrcoef_samples:
  - 0.27880773859873326
  - 0.2815938888866525
  - 0.2819086199489856
  - 0.280981670991756
  - 0.2812375788972612
  train_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_samples_oob:
  - 0.27165867523055376
  - 0.27365883596950696
  - 0.27409504584724653
  - 0.2739225015520076
  - 0.27290792581045775
  train_level4__matthews_corrcoef_weighted:
  - 0.24970749405614537
  - 0.26305633344266127
  - 0.2483104318374797
  - 0.24590138352906216
  - 0.24609762649195224
  train_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.23722875544702865
  - 0.25006616166187606
  - 0.23496007140526
  - 0.23229598589054298
  - 0.23221839130387723
  train_level4__ndcg:
  - 0.7242837998141399
  - 0.7166155278917122
  - 0.725953310433829
  - 0.7175867368672081
  - 0.7215637491695939
  train_level4__ndcg_oob:
  - 0.7241209396268192
  - 0.7163296148050957
  - 0.7242335801722604
  - 0.7162968164054356
  - 0.7203127898852215
  train_level4__neg_coverage_error:
  - -75.17543859649123
  - -75.82758620689656
  - -75.32914572864321
  - -75.40942928039702
  - -74.92537313432835
  train_level4__neg_coverage_error_oob:
  - -77.84461152882206
  - -78.48029556650246
  - -77.82412060301507
  - -78.37717121588089
  - -77.77363184079601
  train_level4__neg_hamming_loss_macro:
  - -0.5033214103219213
  - -0.5017695729111865
  - -0.5065375420793287
  - -0.5053121009901467
  - -0.5008935903009225
  train_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_macro_oob:
  - -0.5060223373968903
  - -0.5051413267014204
  - -0.5097087378640778
  - -0.5082994049483245
  - -0.5050717287349659
  train_level4__neg_hamming_loss_micro:
  - -0.5033214103219213
  - -0.5017695729111866
  - -0.5065375420793287
  - -0.5053121009901467
  - -0.5008935903009226
  train_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_micro_oob:
  - -0.5060223373968903
  - -0.5051413267014204
  - -0.5097087378640777
  - -0.5082994049483245
  - -0.505071728734966
  train_level4__neg_hamming_loss_samples:
  - -0.5033214103219212
  - -0.5017695729111865
  - -0.5065375420793287
  - -0.5053121009901467
  - -0.5008935903009226
  train_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_samples_oob:
  - -0.5060223373968903
  - -0.5051413267014204
  - -0.5097087378640777
  - -0.5082994049483244
  - -0.5050717287349659
  train_level4__neg_hamming_loss_weighted:
  - -0.4443567568666805
  - -0.4398201809459416
  - -0.4485966838460022
  - -0.450042950569891
  - -0.4437836629963244
  train_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.4483290302110211
  - -0.44507530023503666
  - -0.45346959634228173
  - -0.454334171545011
  - -0.4484988583155467
  train_level4__neg_label_ranking_loss:
  - -0.33391461001956785
  - -0.34018669445218785
  - -0.32229423061883344
  - -0.3474532732723675
  - -0.3192440539317117
  train_level4__neg_label_ranking_loss_oob:
  - -0.34301542646976496
  - -0.34955069867418254
  - -0.33074990769778306
  - -0.35621642479784305
  - -0.32781888636210144
  train_level4__precision_macro:
  - 0.49667858967807865
  - 0.4982304270888135
  - 0.49346245792067134
  - 0.49468789900985344
  - 0.49910640969907744
  train_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_macro_oob:
  - 0.49397766260310977
  - 0.4948586732985796
  - 0.4902912621359223
  - 0.4917005950516755
  - 0.49492827126503414
  train_level4__precision_micro:
  - 0.4966785896780787
  - 0.49823042708881343
  - 0.49346245792067134
  - 0.49468789900985327
  - 0.49910640969907744
  train_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_micro_oob:
  - 0.4939776626031097
  - 0.4948586732985796
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.494928271265034
  train_level4__precision_samples:
  - 0.4966785896780787
  - 0.4982304270888134
  - 0.4934624579206713
  - 0.4946878990098533
  - 0.4991064096990774
  train_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_samples_oob:
  - 0.4939776626031097
  - 0.4948586732985795
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.4949282712650341
  train_level4__precision_weighted:
  - 0.5556432431333194
  - 0.5601798190540583
  - 0.5514033161539977
  - 0.5499570494301089
  - 0.5562163370036756
  train_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__precision_weighted_oob:
  - 0.5516709697889789
  - 0.5549246997649633
  - 0.5465304036577182
  - 0.5456658284549891
  - 0.5515011416844533
  train_level4__recall_macro:
  - 0.49667858967807865
  - 0.4982304270888135
  - 0.49346245792067134
  - 0.49468789900985344
  - 0.49910640969907744
  train_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_macro_oob:
  - 0.49397766260310977
  - 0.4948586732985796
  - 0.4902912621359223
  - 0.4917005950516755
  - 0.49492827126503414
  train_level4__recall_micro:
  - 0.4966785896780787
  - 0.49823042708881343
  - 0.49346245792067134
  - 0.49468789900985327
  - 0.49910640969907744
  train_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_micro_oob:
  - 0.4939776626031097
  - 0.4948586732985796
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.494928271265034
  train_level4__recall_samples:
  - 0.4966785896780787
  - 0.4982304270888134
  - 0.4934624579206713
  - 0.4946878990098533
  - 0.4991064096990774
  train_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_samples_oob:
  - 0.4939776626031097
  - 0.4948586732985795
  - 0.49029126213592233
  - 0.4917005950516755
  - 0.4949282712650341
  train_level4__recall_weighted:
  - 0.5556432431333194
  - 0.5601798190540583
  - 0.5514033161539977
  - 0.5499570494301089
  - 0.5562163370036756
  train_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__recall_weighted_oob:
  - 0.5516709697889789
  - 0.5549246997649633
  - 0.5465304036577182
  - 0.5456658284549891
  - 0.5515011416844533
  train_level4__roc_auc_macro:
  - 0.7214267127149354
  - 0.7227472983737794
  - 0.7265869779742223
  - 0.7180282366599936
  - 0.7274474089344642
  train_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_macro_oob:
  - 0.7134752655472976
  - 0.7156233129938886
  - 0.7184254110865719
  - 0.7095542270217525
  - 0.7176316192102571
  train_level4__roc_auc_micro:
  - 0.7319773635712755
  - 0.7259656876903325
  - 0.7333172922940077
  - 0.7242671238830427
  - 0.7330308406361172
  train_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_micro_oob:
  - 0.728356703101424
  - 0.7228074990846897
  - 0.7291692750573036
  - 0.7200162405017396
  - 0.728427801330642
  train_level4__roc_auc_samples:
  - 0.7226589206161764
  - 0.713102253228648
  - 0.7221340474799003
  - 0.7109373297887862
  - 0.7203061945357222
  train_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_samples_oob:
  - 0.7195895507084186
  - 0.710193124531543
  - 0.718619867779593
  - 0.7069857465870962
  - 0.7160169672180726
  train_level4__roc_auc_weighted:
  - 0.7133465893102986
  - 0.7175095847143838
  - 0.7213047071092902
  - 0.7133818015909394
  - 0.7192312686416186
  train_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__roc_auc_weighted_oob:
  - 0.705678535488771
  - 0.7103587857908895
  - 0.7135102948998745
  - 0.7059926404260676
  - 0.7091399048641046
  train_level4__tn_macro:
  - 0.27729517969681483
  - 0.27803816538332776
  - 0.27203981070400546
  - 0.2744946878990098
  - 0.2792590445829107
  train_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_macro_oob:
  - 0.27595688249750583
  - 0.27598163470275955
  - 0.27021027467434255
  - 0.2727119419884844
  - 0.2763126116987876
  train_level4__tn_micro:
  - 0.27729517969681483
  - 0.27803816538332776
  - 0.27203981070400546
  - 0.2744946878990098
  - 0.2792590445829107
  train_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_micro_oob:
  - 0.2759568824975059
  - 0.2759816347027596
  - 0.2702102746743426
  - 0.2727119419884844
  - 0.2763126116987876
  train_level4__tn_samples:
  - 0.27729517969681483
  - 0.2780381653833277
  - 0.2720398107040054
  - 0.2744946878990098
  - 0.2792590445829106
  train_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_samples_oob:
  - 0.27595688249750583
  - 0.27598163470275955
  - 0.2702102746743425
  - 0.27271194198848436
  - 0.27631261169878757
  train_level4__tn_weighted:
  - 0.2245510270005608
  - 0.22972759506101287
  - 0.21926406258418146
  - 0.21978595553446034
  - 0.22399515073060094
  train_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tn_weighted_oob:
  - 0.22236283520618877
  - 0.22638969380855792
  - 0.21615650857598076
  - 0.21694730518739053
  - 0.2206825963111649
  train_level4__tp_macro:
  - 0.21938340998126377
  - 0.22019226170548573
  - 0.22142264721666588
  - 0.2201932111108435
  - 0.2198473651161668
  train_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_macro_oob:
  - 0.21802078010560375
  - 0.21887703859582003
  - 0.22008098746157975
  - 0.2189886530631912
  - 0.21861565956624646
  train_level4__tp_micro:
  - 0.21938340998126385
  - 0.22019226170548567
  - 0.22142264721666585
  - 0.22019321111084345
  - 0.21984736511616673
  train_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_micro_oob:
  - 0.21802078010560383
  - 0.21887703859581997
  - 0.22008098746157975
  - 0.21898865306319112
  - 0.21861565956624643
  train_level4__tp_samples:
  - 0.21938340998126382
  - 0.22019226170548561
  - 0.2214226472166658
  - 0.2201932111108434
  - 0.21984736511616668
  train_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_samples_oob:
  - 0.21802078010560375
  - 0.21887703859581994
  - 0.22008098746157967
  - 0.21898865306319107
  - 0.21861565956624635
  train_level4__tp_weighted:
  - 0.33109221613275874
  - 0.33045222399304547
  - 0.3321392535698164
  - 0.33017109389564864
  - 0.33222118627307445
  train_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level4__tp_weighted_oob:
  - 0.32930813458279007
  - 0.32853500595640556
  - 0.3303738950817374
  - 0.3287185232675986
  - 0.3308185453732884
  train_level5__average_precision_macro:
  - 0.38541549275320214
  - 0.3844106102796485
  - 0.38851377655420327
  - 0.3838586667607758
  - 0.3912379247289192
  train_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_macro_oob:
  - 0.3799065838722306
  - 0.3797432261915876
  - 0.38396234117738526
  - 0.3783988299292676
  - 0.3871975636284396
  train_level5__average_precision_micro:
  - 0.38713775494776337
  - 0.38111323060780194
  - 0.3865832272172217
  - 0.3773916104339545
  - 0.3862254117884744
  train_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_micro_oob:
  - 0.3841954912937535
  - 0.3780545530595507
  - 0.38345931092607854
  - 0.37371678060814034
  - 0.3848732527863428
  train_level5__average_precision_samples:
  - 0.3928897364129868
  - 0.3822782239972734
  - 0.3925508857632317
  - 0.380292925126471
  - 0.3908660828962638
  train_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_samples_oob:
  - 0.38970540198955633
  - 0.37956174697195183
  - 0.38981179299296687
  - 0.3763931283322528
  - 0.38982936148517733
  train_level5__average_precision_weighted:
  - 0.5092830118244152
  - 0.5125995682389157
  - 0.513449153636188
  - 0.508099387049137
  - 0.5150975598809236
  train_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__average_precision_weighted_oob:
  - 0.502730000033849
  - 0.5070949929423265
  - 0.5087089153270697
  - 0.5022407574381292
  - 0.510609484586152
  train_level5__f1_macro:
  - 0.4968732510888873
  - 0.49801520876177724
  - 0.49299897545982335
  - 0.495049266424149
  - 0.49871999227165154
  train_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_macro_oob:
  - 0.49414799133756726
  - 0.494165192022574
  - 0.4894130848416842
  - 0.49261605916789125
  - 0.4943969473023233
  train_level5__f1_micro:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_micro_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.4926160591678913
  - 0.4943969473023233
  train_level5__f1_samples:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_samples_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.49261605916789125
  - 0.49439694730232336
  train_level5__f1_weighted:
  - 0.5558682412887519
  - 0.5599421162143019
  - 0.5505912512494815
  - 0.5499636985210119
  - 0.5562602578229144
  train_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__f1_weighted_oob:
  - 0.5515906691726715
  - 0.5544419995009497
  - 0.545953196815764
  - 0.5464529785242036
  - 0.5512055109070035
  train_level5__fn_macro:
  - -0.01435627904713239
  - -0.014204409584389495
  - -0.01280675220764014
  - -0.013780144065142495
  - -0.013790271941264549
  train_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_macro_oob:
  - -0.015572912864685986
  - -0.015567458988952126
  - -0.014002049080353221
  - -0.01467151702040521
  - -0.015094430758827219
  train_level5__fn_micro:
  - -0.014356279047132395
  - -0.014204409584389498
  - -0.012806752207640142
  - -0.013780144065142498
  - -0.01379027194126455
  train_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_micro_oob:
  - -0.015572912864685987
  - -0.015567458988952126
  - -0.014002049080353223
  - -0.014671517020405212
  - -0.015094430758827224
  train_level5__fn_samples:
  - -0.014356279047132391
  - -0.014204409584389498
  - -0.01280675220764014
  - -0.013780144065142497
  - -0.01379027194126455
  train_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_samples_oob:
  - -0.015572912864685984
  - -0.015567458988952124
  - -0.014002049080353223
  - -0.01467151702040521
  - -0.015094430758827222
  train_level5__fn_weighted:
  - -0.016353950516570213
  - -0.01654084766090344
  - -0.014645414017103318
  - -0.015466296909016653
  - -0.014941297641888646
  train_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fn_weighted_oob:
  - -0.01795318421926031
  - -0.018533275379117163
  - -0.01613668425399612
  - -0.01641967425080729
  - -0.016331866737556412
  train_level5__fp_macro:
  - -0.4887704698639804
  - -0.4877803816538333
  - -0.4941942723325365
  - -0.4911705895107085
  - -0.4874897357870841
  train_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_macro_oob:
  - -0.49027909579774676
  - -0.490267348988474
  - -0.4965848660779626
  - -0.49271242381170344
  - -0.4905086219388494
  train_level5__fp_micro:
  - -0.4887704698639803
  - -0.48778038165383325
  - -0.4941942723325365
  - -0.4911705895107085
  - -0.487489735787084
  train_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_micro_oob:
  - -0.4902790957977468
  - -0.49026734898847385
  - -0.49658486607796265
  - -0.4927124238117035
  - -0.4905086219388494
  train_level5__fp_samples:
  - -0.4887704698639803
  - -0.48778038165383325
  - -0.4941942723325365
  - -0.4911705895107085
  - -0.487489735787084
  train_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_samples_oob:
  - -0.4902790957977468
  - -0.49026734898847385
  - -0.4965848660779626
  - -0.4927124238117035
  - -0.4905086219388494
  train_level5__fp_weighted:
  - -0.4277778081946779
  - -0.42351703612479485
  - -0.4347633347334151
  - -0.4345700045699712
  - -0.4287984445351971
  train_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__fp_weighted_oob:
  - -0.43045614660806814
  - -0.4270247251199331
  - -0.43791011893023984
  - -0.437127347224989
  - -0.4324626223554402
  train_level5__jaccard_macro:
  - 0.3461187813359981
  - 0.3484010066245557
  - 0.34342618952241916
  - 0.34496339775833745
  - 0.3486008974479441
  train_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_macro_oob:
  - 0.3435350824150546
  - 0.3447643179515932
  - 0.33999002633972564
  - 0.34279430502387664
  - 0.34476499393725935
  train_level5__jaccard_micro:
  - 0.3305597824327387
  - 0.3315714058270976
  - 0.32713911101039206
  - 0.32894715779026396
  - 0.33219651877352724
  train_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_micro_oob:
  - 0.3281517629189154
  - 0.3281669339854854
  - 0.3239886960032297
  - 0.3268019817804059
  - 0.32837137678253475
  train_level5__jaccard_samples:
  - 0.33738133030019063
  - 0.3391297188503363
  - 0.3346946809853498
  - 0.33665112607446257
  - 0.3402954628393266
  train_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_samples_oob:
  - 0.33482209988551304
  - 0.3357088143949472
  - 0.3314888978260733
  - 0.33442100273542646
  - 0.33645291864139637
  train_level5__jaccard_weighted:
  - 0.39982891028881207
  - 0.40481276946075284
  - 0.39523238954133744
  - 0.3945956631393375
  - 0.4003490920410774
  train_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__jaccard_weighted_oob:
  - 0.3955445005025761
  - 0.3992623480712947
  - 0.39059544065868723
  - 0.3913918108427369
  - 0.3956435396634792
  train_level5__label_ranking_average_precision_score:
  - 0.39288973641298663
  - 0.3822782239972735
  - 0.3925508857632316
  - 0.3802929251264709
  - 0.3908660828962643
  train_level5__label_ranking_average_precision_score_oob:
  - 0.38970540198955644
  - 0.3795617469719525
  - 0.3898117929929671
  - 0.37639312833225275
  - 0.38982936148517733
  train_level5__matthews_corrcoef_macro:
  - 0.23598506458258428
  - 0.24024705365621932
  - 0.23695049227889894
  - 0.23192499794425286
  - 0.2361952873043706
  train_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_macro_oob:
  - 0.2270515878742296
  - 0.23104312332028146
  - 0.22727159071415376
  - 0.22405963138499171
  - 0.2237983327800305
  train_level5__matthews_corrcoef_micro:
  - 0.27997116073536255
  - 0.2815836111905176
  - 0.28163089792980484
  - 0.28017116522052454
  - 0.2835766197890127
  train_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_micro_oob:
  - 0.2733736598198718
  - 0.27344958964004706
  - 0.27425768712186743
  - 0.2749155969404042
  - 0.27519634440815277
  train_level5__matthews_corrcoef_samples:
  - 0.2795881111219004
  - 0.28049711600468485
  - 0.2815642424672759
  - 0.2802611169371998
  - 0.28139022856602186
  train_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_samples_oob:
  - 0.272733711611714
  - 0.27181730695077744
  - 0.2737714049885816
  - 0.27490326396824777
  - 0.2725658908642794
  train_level5__matthews_corrcoef_weighted:
  - 0.24990780147060587
  - 0.2624241277712864
  - 0.24790025248803196
  - 0.24491014455842341
  - 0.2480704429994019
  train_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.2372518434049478
  - 0.2488511246400468
  - 0.2351326915150094
  - 0.23509998622979725
  - 0.23205343818800167
  train_level5__ndcg:
  - 0.7265847583705833
  - 0.719586533631724
  - 0.725643456746057
  - 0.7179007122231175
  - 0.718656685765844
  train_level5__ndcg_oob:
  - 0.7250005721417012
  - 0.7182908548972966
  - 0.7240135789845461
  - 0.7153577446942905
  - 0.7190976650225107
  train_level5__neg_coverage_error:
  - -75.23308270676692
  - -75.83497536945812
  - -75.4572864321608
  - -75.49875930521092
  - -74.93532338308458
  train_level5__neg_coverage_error_oob:
  - -77.9298245614035
  - -78.56403940886699
  - -77.98241206030151
  - -78.38213399503722
  - -77.79850746268657
  train_level5__neg_hamming_loss_macro:
  - -0.5031267489111126
  - -0.5019847912382228
  - -0.5070010245401766
  - -0.504950733575851
  - -0.5012800077283485
  train_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_macro_oob:
  - -0.5058520086624327
  - -0.5058348079774261
  - -0.5105869151583158
  - -0.5073839408321087
  - -0.5056030526976766
  train_level5__neg_hamming_loss_micro:
  - -0.5031267489111128
  - -0.5019847912382228
  - -0.5070010245401766
  - -0.5049507335758511
  - -0.5012800077283486
  train_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_micro_oob:
  - -0.5058520086624327
  - -0.505834807977426
  - -0.5105869151583159
  - -0.5073839408321087
  - -0.5056030526976767
  train_level5__neg_hamming_loss_samples:
  - -0.5031267489111128
  - -0.5019847912382228
  - -0.5070010245401766
  - -0.5049507335758511
  - -0.5012800077283486
  train_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_samples_oob:
  - -0.5058520086624327
  - -0.505834807977426
  - -0.5105869151583159
  - -0.5073839408321087
  - -0.5056030526976766
  train_level5__neg_hamming_loss_weighted:
  - -0.4441317587112481
  - -0.44005788378569816
  - -0.4494087487505185
  - -0.45003630147898804
  - -0.4437397421770856
  train_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.44840933082732837
  - -0.44555800049905037
  - -0.454046803184236
  - -0.4535470214757965
  - -0.44879448909299663
  train_level5__neg_label_ranking_loss:
  - -0.32749763051778646
  - -0.34461981360553073
  - -0.33116527236139415
  - -0.3453630251475911
  - -0.32277567437927124
  train_level5__neg_label_ranking_loss_oob:
  - -0.338654517406357
  - -0.3543359131553339
  - -0.338381994567239
  - -0.35631074656485306
  - -0.33120738917013653
  train_level5__precision_macro:
  - 0.4968732510888873
  - 0.49801520876177724
  - 0.49299897545982335
  - 0.495049266424149
  - 0.49871999227165154
  train_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_macro_oob:
  - 0.49414799133756726
  - 0.494165192022574
  - 0.4894130848416842
  - 0.49261605916789125
  - 0.4943969473023233
  train_level5__precision_micro:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_micro_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.4926160591678913
  - 0.4943969473023233
  train_level5__precision_samples:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_samples_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.49261605916789125
  - 0.49439694730232336
  train_level5__precision_weighted:
  - 0.5558682412887519
  - 0.5599421162143019
  - 0.5505912512494815
  - 0.5499636985210119
  - 0.5562602578229144
  train_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__precision_weighted_oob:
  - 0.5515906691726715
  - 0.5544419995009497
  - 0.545953196815764
  - 0.5464529785242036
  - 0.5512055109070035
  train_level5__recall_macro:
  - 0.4968732510888873
  - 0.49801520876177724
  - 0.49299897545982335
  - 0.495049266424149
  - 0.49871999227165154
  train_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_macro_oob:
  - 0.49414799133756726
  - 0.494165192022574
  - 0.4894130848416842
  - 0.49261605916789125
  - 0.4943969473023233
  train_level5__recall_micro:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_micro_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.4926160591678913
  - 0.4943969473023233
  train_level5__recall_samples:
  - 0.49687325108888725
  - 0.49801520876177724
  - 0.4929989754598234
  - 0.495049266424149
  - 0.4987199922716514
  train_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_samples_oob:
  - 0.4941479913375672
  - 0.49416519202257403
  - 0.48941308484168417
  - 0.49261605916789125
  - 0.49439694730232336
  train_level5__recall_weighted:
  - 0.5558682412887519
  - 0.5599421162143019
  - 0.5505912512494815
  - 0.5499636985210119
  - 0.5562602578229144
  train_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__recall_weighted_oob:
  - 0.5515906691726715
  - 0.5544419995009497
  - 0.545953196815764
  - 0.5464529785242036
  - 0.5512055109070035
  train_level5__roc_auc_macro:
  - 0.7221564634103321
  - 0.723636453505278
  - 0.7239639937818044
  - 0.718769580670318
  - 0.7257339171190674
  train_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_macro_oob:
  - 0.7133890620888979
  - 0.7159791754052681
  - 0.7158674580819838
  - 0.7095680231879873
  - 0.7174663677595906
  train_level5__roc_auc_micro:
  - 0.7330708966147579
  - 0.7275102003646752
  - 0.731640337205534
  - 0.7242666977838936
  - 0.7320536872389445
  train_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_micro_oob:
  - 0.7287059630122537
  - 0.7231888576208914
  - 0.7273545796981007
  - 0.7195759763912946
  - 0.7283017198038453
  train_level5__roc_auc_samples:
  - 0.7241394299606918
  - 0.7132807644476719
  - 0.7200539165597541
  - 0.7101911236587494
  - 0.7195115074659093
  train_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_samples_oob:
  - 0.7199774189866719
  - 0.7091531592514644
  - 0.7165337782464093
  - 0.7055914112939778
  - 0.7156379795747034
  train_level5__roc_auc_weighted:
  - 0.7136763366544976
  - 0.718847438833328
  - 0.719095037006508
  - 0.7142439165388461
  - 0.7174418671807088
  train_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__roc_auc_weighted_oob:
  - 0.7047832397854069
  - 0.7108040813982675
  - 0.7112485277473919
  - 0.7055429513778467
  - 0.7095857542437102
  train_level5__tn_macro:
  - 0.2773195123731659
  - 0.2780620785307762
  - 0.2714543591745133
  - 0.27507287576188294
  - 0.27860696517412936
  train_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_macro_oob:
  - 0.27581088643939944
  - 0.2755751111961356
  - 0.26906376542908716
  - 0.273531041460888
  - 0.2755880790223639
  train_level5__tn_micro:
  - 0.27731951237316593
  - 0.27806207853077625
  - 0.2714543591745133
  - 0.27507287576188294
  - 0.27860696517412936
  train_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_micro_oob:
  - 0.2758108864393995
  - 0.27557511119613565
  - 0.26906376542908716
  - 0.273531041460888
  - 0.27558807902236393
  train_level5__tn_samples:
  - 0.2773195123731659
  - 0.2780620785307762
  - 0.2714543591745133
  - 0.27507287576188294
  - 0.2786069651741293
  train_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_samples_oob:
  - 0.27581088643939944
  - 0.2755751111961356
  - 0.2690637654290871
  - 0.27353104146088797
  - 0.2755880790223639
  train_level5__tn_weighted:
  - 0.22455989135430904
  - 0.22967225683376802
  - 0.21828670781826273
  - 0.22000435259719883
  - 0.2237429270785977
  train_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tn_weighted_oob:
  - 0.2218815529409188
  - 0.22616456783862968
  - 0.21513992362143808
  - 0.21744700994218108
  - 0.22007874925835455
  train_level5__tp_macro:
  - 0.21955373871572126
  - 0.21995313023100105
  - 0.22154461628531008
  - 0.219976390662266
  - 0.22011302709752212
  train_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_macro_oob:
  - 0.21833710489816768
  - 0.21859008082643844
  - 0.22034931941259697
  - 0.21908501770700337
  - 0.21880886827995946
  train_level5__tp_micro:
  - 0.21955373871572134
  - 0.219953130231001
  - 0.22154461628531005
  - 0.219976390662266
  - 0.2201130270975221
  train_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_micro_oob:
  - 0.21833710489816774
  - 0.21859008082643838
  - 0.22034931941259697
  - 0.2190850177070033
  - 0.21880886827995943
  train_level5__tp_samples:
  - 0.21955373871572129
  - 0.21995313023100094
  - 0.22154461628530997
  - 0.21997639066226596
  - 0.22011302709752203
  train_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_samples_oob:
  - 0.2183371048981677
  - 0.21859008082643835
  - 0.2203493194125969
  - 0.21908501770700323
  - 0.2188088682799594
  train_level5__tp_weighted:
  - 0.33130834993444286
  - 0.33026985938053377
  - 0.33230454343121874
  - 0.32995934592381315
  - 0.3325173307443166
  train_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level5__tp_weighted_oob:
  - 0.3297091162317528
  - 0.3282774316623201
  - 0.33081327319432596
  - 0.3290059685820226
  - 0.33112676164864885
  train_level6__average_precision_macro:
  - 0.380508514088904
  - 0.38246408169066676
  - 0.38560374615266485
  - 0.379732552508394
  - 0.3889025187970881
  train_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_macro_oob:
  - 0.3764383487708537
  - 0.3785773166276473
  - 0.3805220516920847
  - 0.37385159821125236
  - 0.3823496908602281
  train_level6__average_precision_micro:
  - 0.3838529338663826
  - 0.3783193763350784
  - 0.382089441351648
  - 0.37326649893857144
  - 0.3844399439139101
  train_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_micro_oob:
  - 0.38150413866144833
  - 0.3756365056998837
  - 0.37941130422231695
  - 0.37008795549657914
  - 0.3817556165850842
  train_level6__average_precision_samples:
  - 0.38937676066131865
  - 0.3799906502213309
  - 0.38643736160457715
  - 0.3763202927575614
  - 0.3887205377399348
  train_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_samples_oob:
  - 0.38704668580538215
  - 0.37727911018812726
  - 0.38439727615531927
  - 0.37360623357844064
  - 0.3864870652045386
  train_level6__average_precision_weighted:
  - 0.5041903919250059
  - 0.5094607387083787
  - 0.5115578614047882
  - 0.5026743324477259
  - 0.5117932569269628
  train_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__average_precision_weighted_oob:
  - 0.4994627174632118
  - 0.5052918939121673
  - 0.5052307662107456
  - 0.4965908212004776
  - 0.5057034609754467
  train_level6__f1_macro:
  - 0.4973842372922598
  - 0.4983739059735041
  - 0.4926818558813486
  - 0.4952419957117733
  - 0.49862338791479505
  train_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_macro_oob:
  - 0.49407499330851407
  - 0.4954086756898943
  - 0.4899985363711763
  - 0.4930978823869523
  - 0.4951697821571754
  train_level6__f1_micro:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.49524199571177335
  - 0.49862338791479494
  train_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_micro_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.4899985363711763
  - 0.49309788238695224
  - 0.4951697821571753
  train_level6__f1_samples:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.4952419957117733
  - 0.498623387914795
  train_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_samples_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.48999853637117624
  - 0.4930978823869522
  - 0.4951697821571753
  train_level6__f1_weighted:
  - 0.5561959616611487
  - 0.5603159007856016
  - 0.5508106787711848
  - 0.5500519268426103
  - 0.5558721621628563
  train_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__f1_weighted_oob:
  - 0.5514806468996791
  - 0.5554076515663736
  - 0.5471743018203331
  - 0.5469966695726605
  - 0.5518715149086781
  train_level6__fn_macro:
  - -0.014380611723483462
  - -0.014132670142044095
  - -0.012733570766453628
  - -0.013731961743236402
  - -0.014055933922619909
  train_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_macro_oob:
  - -0.015402584130228478
  - -0.015376153809364388
  - -0.01390447382543787
  - -0.014743790503264352
  - -0.014997826401970728
  train_level6__fn_micro:
  - -0.014380611723483466
  - -0.014132670142044095
  - -0.012733570766453628
  - -0.013731961743236407
  - -0.01405593392261991
  train_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_micro_oob:
  - -0.015402584130228485
  - -0.015376153809364388
  - -0.01390447382543787
  - -0.014743790503264352
  - -0.014997826401970728
  train_level6__fn_samples:
  - -0.014380611723483466
  - -0.014132670142044095
  - -0.012733570766453626
  - -0.013731961743236406
  - -0.014055933922619909
  train_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_samples_oob:
  - -0.015402584130228483
  - -0.015376153809364386
  - -0.013904473825437868
  - -0.01474379050326435
  - -0.014997826401970726
  train_level6__fn_weighted:
  - -0.01641652242538104
  - -0.016494313242538392
  - -0.014562507551811312
  - -0.015420520475491835
  - -0.015146518311899462
  train_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fn_weighted_oob:
  - -0.01771880027750641
  - -0.018311419395344343
  - -0.016066854518245438
  - -0.016709676907886304
  - -0.01630464096656624
  train_level6__fp_macro:
  - -0.48823515098425674
  - -0.4874934238844517
  - -0.49458457335219785
  - -0.49102604254499027
  - -0.48732067816258506
  train_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_macro_oob:
  - -0.49052242256125755
  - -0.4892151705007413
  - -0.49609698980338585
  - -0.4921583271097834
  - -0.48983239144085383
  train_level6__fp_micro:
  - -0.48823515098425674
  - -0.48749342388445166
  - -0.4945845733521979
  - -0.4910260425449902
  - -0.4873206781625851
  train_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_micro_oob:
  - -0.4905224225612575
  - -0.4892151705007413
  - -0.49609698980338585
  - -0.4921583271097834
  - -0.489832391440854
  train_level6__fp_samples:
  - -0.48823515098425674
  - -0.4874934238844516
  - -0.4945845733521979
  - -0.4910260425449902
  - -0.4873206781625852
  train_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_samples_oob:
  - -0.49052242256125755
  - -0.48921517050074126
  - -0.4960969898033859
  - -0.4921583271097834
  - -0.48983239144085394
  train_level6__fp_weighted:
  - -0.4273875159134703
  - -0.4231897859718601
  - -0.4346268136770037
  - -0.43452755268189797
  - -0.42898131952524415
  train_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__fp_weighted_oob:
  - -0.4308005528228144
  - -0.42628092903828196
  - -0.4367588436614215
  - -0.4362936535194534
  - -0.4318238441247557
  train_level6__jaccard_macro:
  - 0.34660375850995195
  - 0.3487348778971691
  - 0.3432808228024448
  - 0.3451295434274451
  - 0.348493799135413
  train_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_macro_oob:
  - 0.34346754901081605
  - 0.34581722183165187
  - 0.3407811629932481
  - 0.3432224620494941
  - 0.3454579335067847
  train_level6__jaccard_micro:
  - 0.33101225851375643
  - 0.3318894816466279
  - 0.32685989869074783
  - 0.3291173692384048
  - 0.33211080011581895
  train_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_micro_oob:
  - 0.3280873822488649
  - 0.32926461005419666
  - 0.32450202743089773
  - 0.32722621902478016
  - 0.3290535877642074
  train_level6__jaccard_samples:
  - 0.33774141996125373
  - 0.33943012113244997
  - 0.33429917401291126
  - 0.3368974118914107
  - 0.3402275102619127
  train_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_samples_oob:
  - 0.33466928561503934
  - 0.33677774194458665
  - 0.3319510075334063
  - 0.33493966761224614
  - 0.3371531426048134
  train_level6__jaccard_weighted:
  - 0.4001671567404021
  - 0.40517327075881715
  - 0.3955687036160976
  - 0.3946779697207186
  - 0.3999583161015323
  train_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__jaccard_weighted_oob:
  - 0.39545610081063176
  - 0.40011726350493065
  - 0.39198931066358234
  - 0.3918810973996737
  - 0.3962530591836327
  train_level6__label_ranking_average_precision_score:
  - 0.38937676066131854
  - 0.37999065022133083
  - 0.38643736160457703
  - 0.37632029275756107
  - 0.388720537739935
  train_level6__label_ranking_average_precision_score_oob:
  - 0.38704668580538204
  - 0.3772791101881271
  - 0.38439727615531927
  - 0.3736062335784411
  - 0.38648706520453796
  train_level6__matthews_corrcoef_macro:
  - 0.23612849056534221
  - 0.24130465670125337
  - 0.23692882182501254
  - 0.2323282514056665
  - 0.23370091152807757
  train_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_macro_oob:
  - 0.22759070698355308
  - 0.23326629357718925
  - 0.22823931837057518
  - 0.2249398939979413
  - 0.22545746548506443
  train_level6__matthews_corrcoef_micro:
  - 0.28036709502152135
  - 0.2821568107348725
  - 0.28158400259058586
  - 0.2805120137405792
  - 0.2826018811780584
  train_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_micro_oob:
  - 0.2738707315633954
  - 0.27525263690415813
  - 0.27513369260598575
  - 0.27512479713543636
  - 0.2762419840011283
  train_level6__matthews_corrcoef_samples:
  - 0.27991637922276164
  - 0.2808119210365019
  - 0.28182221680247993
  - 0.2805538623382306
  - 0.2803273578976219
  train_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_samples_oob:
  - 0.2732442764742866
  - 0.2734341847090665
  - 0.2750659094542209
  - 0.2748516563643678
  - 0.27353944410937003
  train_level6__matthews_corrcoef_weighted:
  - 0.2500360094167776
  - 0.263852645000588
  - 0.24881184359071118
  - 0.24551834507444872
  - 0.24481742673706655
  train_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.23749181786613016
  - 0.2511044241844425
  - 0.236069227965431
  - 0.23571461573735272
  - 0.23362780025853688
  train_level6__ndcg:
  - 0.7232953240585964
  - 0.7183942620677151
  - 0.7196315577229413
  - 0.7142687450926485
  - 0.7183016000744935
  train_level6__ndcg_oob:
  - 0.7226438373384148
  - 0.7167665794167458
  - 0.7189647876835312
  - 0.7129341529260284
  - 0.7178706263878839
  train_level6__neg_coverage_error:
  - -75.21052631578948
  - -75.8423645320197
  - -75.37688442211055
  - -75.39205955334988
  - -74.92288557213931
  train_level6__neg_coverage_error_oob:
  - -77.98245614035088
  - -78.56403940886699
  - -77.8894472361809
  - -78.42679900744417
  - -77.79353233830845
  train_level6__neg_hamming_loss_macro:
  - -0.5026157627077402
  - -0.5016260940264958
  - -0.5073181441186514
  - -0.5047580042882267
  - -0.501376612085205
  train_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_macro_oob:
  - -0.505925006691486
  - -0.5045913243101058
  - -0.5100014636288237
  - -0.5069021176130477
  - -0.5048302178428247
  train_level6__neg_hamming_loss_micro:
  - -0.5026157627077402
  - -0.5016260940264957
  - -0.5073181441186515
  - -0.5047580042882267
  - -0.501376612085205
  train_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_micro_oob:
  - -0.505925006691486
  - -0.5045913243101057
  - -0.5100014636288237
  - -0.5069021176130478
  - -0.5048302178428247
  train_level6__neg_hamming_loss_samples:
  - -0.5026157627077402
  - -0.5016260940264957
  - -0.5073181441186515
  - -0.5047580042882267
  - -0.501376612085205
  train_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_samples_oob:
  - -0.505925006691486
  - -0.5045913243101057
  - -0.5100014636288237
  - -0.5069021176130478
  - -0.5048302178428247
  train_level6__neg_hamming_loss_weighted:
  - -0.44380403833885124
  - -0.43968409921439844
  - -0.44918932122881505
  - -0.4499480731573897
  - -0.4441278378371437
  train_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.44851935310032076
  - -0.4445923484336263
  - -0.4528256981796669
  - -0.45300333042733953
  - -0.4481284850913219
  train_level6__neg_label_ranking_loss:
  - -0.3341524271269374
  - -0.345669734175656
  - -0.3322457464490696
  - -0.34773406686326824
  - -0.3271172669564387
  train_level6__neg_label_ranking_loss_oob:
  - -0.34420973803046345
  - -0.35536649523635283
  - -0.34118124232941294
  - -0.35884240985457067
  - -0.3354607347192123
  train_level6__precision_macro:
  - 0.4973842372922598
  - 0.4983739059735041
  - 0.4926818558813486
  - 0.4952419957117733
  - 0.49862338791479505
  train_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_macro_oob:
  - 0.49407499330851407
  - 0.4954086756898943
  - 0.4899985363711763
  - 0.4930978823869523
  - 0.4951697821571754
  train_level6__precision_micro:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.49524199571177335
  - 0.49862338791479494
  train_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_micro_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.4899985363711763
  - 0.49309788238695224
  - 0.4951697821571753
  train_level6__precision_samples:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.4952419957117733
  - 0.498623387914795
  train_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_samples_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.48999853637117624
  - 0.4930978823869522
  - 0.4951697821571753
  train_level6__precision_weighted:
  - 0.5561959616611487
  - 0.5603159007856016
  - 0.5508106787711848
  - 0.5500519268426103
  - 0.5558721621628563
  train_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__precision_weighted_oob:
  - 0.5514806468996791
  - 0.5554076515663736
  - 0.5471743018203331
  - 0.5469966695726605
  - 0.5518715149086781
  train_level6__recall_macro:
  - 0.4973842372922598
  - 0.4983739059735041
  - 0.4926818558813486
  - 0.4952419957117733
  - 0.49862338791479505
  train_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_macro_oob:
  - 0.49407499330851407
  - 0.4954086756898943
  - 0.4899985363711763
  - 0.4930978823869523
  - 0.4951697821571754
  train_level6__recall_micro:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.49524199571177335
  - 0.49862338791479494
  train_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_micro_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.4899985363711763
  - 0.49309788238695224
  - 0.4951697821571753
  train_level6__recall_samples:
  - 0.4973842372922598
  - 0.4983739059735042
  - 0.4926818558813485
  - 0.4952419957117733
  - 0.498623387914795
  train_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_samples_oob:
  - 0.494074993308514
  - 0.49540867568989433
  - 0.48999853637117624
  - 0.4930978823869522
  - 0.4951697821571753
  train_level6__recall_weighted:
  - 0.5561959616611487
  - 0.5603159007856016
  - 0.5508106787711848
  - 0.5500519268426103
  - 0.5558721621628563
  train_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__recall_weighted_oob:
  - 0.5514806468996791
  - 0.5554076515663736
  - 0.5471743018203331
  - 0.5469966695726605
  - 0.5518715149086781
  train_level6__roc_auc_macro:
  - 0.7202729467912723
  - 0.7229652893159114
  - 0.7231210206515766
  - 0.7157902231630556
  - 0.725255366842831
  train_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_macro_oob:
  - 0.712109810701163
  - 0.7150061680323078
  - 0.7144390074713652
  - 0.7063801505970035
  - 0.7158143515913606
  train_level6__roc_auc_micro:
  - 0.7313831322227371
  - 0.726074661393888
  - 0.7297750075763201
  - 0.7218024303127155
  - 0.7311875918291671
  train_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_micro_oob:
  - 0.7273575727100484
  - 0.7218814553861262
  - 0.7255800471845202
  - 0.7169751595342757
  - 0.7268261367660935
  train_level6__roc_auc_samples:
  - 0.7221563042503502
  - 0.7127520779624458
  - 0.7181944311204478
  - 0.7088382153257987
  - 0.7188741091899215
  train_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_samples_oob:
  - 0.7181246399465392
  - 0.7089881047120863
  - 0.7147082599640342
  - 0.7042595963770525
  - 0.7146093312771198
  train_level6__roc_auc_weighted:
  - 0.7128734567187522
  - 0.7168869079449595
  - 0.7186223041772193
  - 0.7111031020578092
  - 0.7159215678949917
  train_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__roc_auc_weighted_oob:
  - 0.7045485375707607
  - 0.7096117852030371
  - 0.7094668634946235
  - 0.7024401226854518
  - 0.7072627506418714
  train_level6__tn_macro:
  - 0.2778548312528895
  - 0.2783490363001578
  - 0.27106405815485185
  - 0.2752174227276012
  - 0.27877602279862823
  train_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_macro_oob:
  - 0.27556755967588875
  - 0.2766272896838682
  - 0.2695516417036639
  - 0.27408513816280805
  - 0.27626430952035935
  train_level6__tn_micro:
  - 0.2778548312528895
  - 0.27834903630015784
  - 0.2710640581548519
  - 0.27521742272760125
  - 0.27877602279862823
  train_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_micro_oob:
  - 0.27556755967588875
  - 0.2766272896838682
  - 0.26955164170366397
  - 0.27408513816280805
  - 0.27626430952035935
  train_level6__tn_samples:
  - 0.27785483125288946
  - 0.2783490363001578
  - 0.27106405815485185
  - 0.2752174227276012
  - 0.2787760227986282
  train_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_samples_oob:
  - 0.2755675596758887
  - 0.2766272896838682
  - 0.2695516417036639
  - 0.274085138162808
  - 0.2762643095203593
  train_level6__tn_weighted:
  - 0.22495018363551658
  - 0.2299995069867027
  - 0.21842322887467416
  - 0.2200468044852721
  - 0.22356005208855054
  train_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tn_weighted_oob:
  - 0.22153714672617247
  - 0.22690836392028074
  - 0.2162911988902564
  - 0.21828070364771684
  - 0.22071752748903903
  train_level6__tp_macro:
  - 0.21952940603937024
  - 0.22002486967334645
  - 0.22161779772649656
  - 0.22002457298417213
  - 0.2198473651161668
  train_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_macro_oob:
  - 0.21850743363262515
  - 0.21878138600602615
  - 0.22044689466751236
  - 0.21901274422414418
  - 0.21890547263681595
  train_level6__tp_micro:
  - 0.21952940603937027
  - 0.22002486967334642
  - 0.22161779772649656
  - 0.2200245729841721
  - 0.21984736511616673
  train_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_micro_oob:
  - 0.21850743363262526
  - 0.21878138600602612
  - 0.22044689466751233
  - 0.21901274422414416
  - 0.21890547263681592
  train_level6__tp_samples:
  - 0.21952940603937024
  - 0.22002486967334636
  - 0.22161779772649653
  - 0.22002457298417202
  - 0.21984736511616668
  train_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_samples_oob:
  - 0.21850743363262518
  - 0.21878138600602604
  - 0.22044689466751227
  - 0.2190127442241441
  - 0.21890547263681584
  train_level6__tp_weighted:
  - 0.33124577802563193
  - 0.3303163937988988
  - 0.33238744989651076
  - 0.33000512235733803
  - 0.3323121100743059
  train_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level6__tp_weighted_oob:
  - 0.32994350017350665
  - 0.32849928764609293
  - 0.33088310293007667
  - 0.32871596592494357
  - 0.33115398741963903
  train_level7__average_precision_macro:
  - 0.3776117823728652
  - 0.3835062014041362
  - 0.3846007953494952
  - 0.3793942334788998
  - 0.3878947306374099
  train_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_macro_oob:
  - 0.3724768027922909
  - 0.37744815588546743
  - 0.38000182096996915
  - 0.3757280081091881
  - 0.38208576494550367
  train_level7__average_precision_micro:
  - 0.38344621176827975
  - 0.3773501386413517
  - 0.3822589834937383
  - 0.37224541687353707
  - 0.38479777017137107
  train_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_micro_oob:
  - 0.3801679819344961
  - 0.3738265153274235
  - 0.3795226523325376
  - 0.3706582118901373
  - 0.38161009189730216
  train_level7__average_precision_samples:
  - 0.3881556122972337
  - 0.3806054673062584
  - 0.3867897826956465
  - 0.37587273067764987
  - 0.39048755416644537
  train_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_samples_oob:
  - 0.38514444517404867
  - 0.3774511506539371
  - 0.384048548492469
  - 0.3736064417671354
  - 0.38791007197256333
  train_level7__average_precision_weighted:
  - 0.5016068140921545
  - 0.5088982984795587
  - 0.5094974910875023
  - 0.5038538032872008
  - 0.511653019647911
  train_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__average_precision_weighted_oob:
  - 0.49533676697829604
  - 0.5030353574401418
  - 0.5041946862029414
  - 0.5007494913373767
  - 0.5048249002105115
  train_level7__f1_macro:
  - 0.49774922743752575
  - 0.4984934717107465
  - 0.49270624969507726
  - 0.495603363126069
  - 0.49900980534222095
  train_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_macro_oob:
  - 0.49480497359904624
  - 0.4957673729016213
  - 0.49014489925354926
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__f1_micro:
  - 0.49774922743752587
  - 0.4984934717107466
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_micro_oob:
  - 0.4948049735990462
  - 0.4957673729016213
  - 0.4901448992535493
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__f1_samples:
  - 0.49774922743752587
  - 0.49849347171074654
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_samples_oob:
  - 0.4948049735990461
  - 0.49576737290162126
  - 0.49014489925354937
  - 0.4936278879279191
  - 0.4959667681012413
  train_level7__f1_weighted:
  - 0.5566866297127401
  - 0.5604150065198493
  - 0.5504989295389199
  - 0.5508252672614874
  - 0.5562145390754025
  train_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__f1_weighted_oob:
  - 0.5526760310742527
  - 0.556356702163624
  - 0.5472872847635702
  - 0.5477500627188286
  - 0.5528208210367882
  train_level7__fn_macro:
  - -0.014258948341728105
  - -0.014443541058874168
  - -0.012904327462555498
  - -0.01351514129465899
  - -0.013621214316765684
  train_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_macro_oob:
  - -0.015499914835632768
  - -0.015543545841503657
  - -0.014270381031370445
  - -0.014526970054686937
  - -0.014925373134328356
  train_level7__fn_micro:
  - -0.014258948341728106
  - -0.014443541058874168
  - -0.012904327462555496
  - -0.01351514129465899
  - -0.013621214316765686
  train_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_micro_oob:
  - -0.015499914835632771
  - -0.015543545841503659
  - -0.014270381031370445
  - -0.014526970054686936
  - -0.014925373134328358
  train_level7__fn_samples:
  - -0.014258948341728105
  - -0.014443541058874167
  - -0.012904327462555494
  - -0.013515141294658986
  - -0.013621214316765684
  train_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_samples_oob:
  - -0.01549991483563277
  - -0.015543545841503656
  - -0.014270381031370443
  - -0.014526970054686934
  - -0.014925373134328356
  train_level7__fn_weighted:
  - -0.016275996346843388
  - -0.016907840722495893
  - -0.014721259048443005
  - -0.01498168047589078
  - -0.014697549937457782
  train_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fn_weighted_oob:
  - -0.01782882255049879
  - -0.018470391029975206
  - -0.016386711322826267
  - -0.016288226838339376
  - -0.016226302663245467
  train_level7__fp_macro:
  - -0.487991824220746
  - -0.4870629872303793
  - -0.49438942284236725
  - -0.490881495579272
  - -0.4873689803410134
  train_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_macro_oob:
  - -0.489695111565321
  - -0.48868908125687516
  - -0.4955847197150802
  - -0.49184514201739377
  - -0.48910785876443014
  train_level7__fp_micro:
  - -0.48799182422074605
  - -0.4870629872303793
  - -0.4943894228423672
  - -0.49088149557927196
  - -0.4873689803410134
  train_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_micro_oob:
  - -0.4896951115653211
  - -0.48868908125687505
  - -0.4955847197150803
  - -0.4918451420173938
  - -0.4891078587644303
  train_level7__fp_samples:
  - -0.487991824220746
  - -0.48706298723037933
  - -0.49438942284236714
  - -0.4908814955792719
  - -0.48736898034101334
  train_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_samples_oob:
  - -0.48969511156532103
  - -0.48868908125687505
  - -0.4955847197150803
  - -0.4918451420173938
  - -0.48910785876443025
  train_level7__fp_weighted:
  - -0.42703737394041646
  - -0.4226771527576549
  - -0.4347798114126372
  - -0.4341930522626217
  - -0.42908791098713966
  train_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__fp_weighted_oob:
  - -0.4294951463752484
  - -0.42517290680640074
  - -0.4363260039136036
  - -0.43596171044283205
  - -0.4309528762999664
  train_level7__jaccard_macro:
  - 0.34693110524569315
  - 0.3487355457891563
  - 0.3431840697304975
  - 0.345544041061783
  - 0.3488906388604915
  train_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_macro_oob:
  - 0.3442477308940371
  - 0.34623622725935566
  - 0.3407936676743759
  - 0.34365758143720704
  - 0.3461787292907551
  train_level7__jaccard_micro:
  - 0.33133564417376654
  - 0.33199554069119286
  - 0.3268813723903544
  - 0.329436633251129
  - 0.3324537409493162
  train_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_micro_oob:
  - 0.3287314699558674
  - 0.329581584636907
  - 0.3246304224897003
  - 0.3276931934493347
  - 0.3297578521420772
  train_level7__jaccard_samples:
  - 0.3379696295149762
  - 0.33957427419948155
  - 0.33433973128861033
  - 0.33714014069942444
  - 0.3404798195055755
  train_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_samples_oob:
  - 0.3353177139339758
  - 0.3370497272105107
  - 0.3320316353055177
  - 0.33532794546747036
  - 0.33783660139934096
  train_level7__jaccard_weighted:
  - 0.40062132900052616
  - 0.4051667890742253
  - 0.39510641624785653
  - 0.395522109748509
  - 0.4002841312790878
  train_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__jaccard_weighted_oob:
  - 0.39672908556295494
  - 0.40114105503112724
  - 0.39199621355505204
  - 0.3925548194132565
  - 0.3971426730896815
  train_level7__label_ranking_average_precision_score:
  - 0.38815561229723344
  - 0.3806054673062582
  - 0.3867897826956469
  - 0.37587273067764987
  - 0.39048755416644537
  train_level7__label_ranking_average_precision_score_oob:
  - 0.38514444517404856
  - 0.37745115065393686
  - 0.3840485484924689
  - 0.3736064417671356
  - 0.38791007197256283
  train_level7__matthews_corrcoef_macro:
  - 0.23697900618260856
  - 0.24092365388605058
  - 0.2359920129197222
  - 0.23324824271028907
  - 0.23547401911065366
  train_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_macro_oob:
  - 0.22818205622489357
  - 0.2331204299626178
  - 0.22729275808334157
  - 0.22629078177039957
  - 0.22614994914625963
  train_level7__matthews_corrcoef_micro:
  - 0.28111252523917546
  - 0.2812355187267187
  - 0.28102961519771996
  - 0.28157510304860134
  - 0.2844097275067738
  train_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_micro_oob:
  - 0.27423316465983194
  - 0.2750351198425361
  - 0.27403908605923377
  - 0.2763452536725551
  - 0.2772292813173078
  train_level7__matthews_corrcoef_samples:
  - 0.28043818958251737
  - 0.2797637802138968
  - 0.2807596631637976
  - 0.281373258317769
  - 0.28232841790136465
  train_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_samples_oob:
  - 0.2733329514165607
  - 0.27301558519343727
  - 0.27337353725810337
  - 0.2759709172490977
  - 0.274430491088271
  train_level7__matthews_corrcoef_weighted:
  - 0.25096587196308984
  - 0.26342483216202467
  - 0.24716949250838874
  - 0.247438253136599
  - 0.2462777098589536
  train_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.23915633962658814
  - 0.25205860344461156
  - 0.23626178528154698
  - 0.2376021292857884
  - 0.23434542439477155
  train_level7__ndcg:
  - 0.7231310204601351
  - 0.7182307236759335
  - 0.7213343791265763
  - 0.7140975549475367
  - 0.7191283087573276
  train_level7__ndcg_oob:
  - 0.7213150647431414
  - 0.7165037671763835
  - 0.7197875218561485
  - 0.7131947114329481
  - 0.7181753617828874
  train_level7__neg_coverage_error:
  - -75.32581453634086
  - -75.93596059113301
  - -75.40954773869346
  - -75.42183622828784
  - -74.91293532338308
  train_level7__neg_coverage_error_oob:
  - -77.97744360902256
  - -78.79064039408867
  - -78.03266331658291
  - -78.33250620347394
  - -77.91542288557214
  train_level7__neg_hamming_loss_macro:
  - -0.5022507725624742
  - -0.5015065282892536
  - -0.5072937503049227
  - -0.5043966368739309
  - -0.500990194657779
  train_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_macro_oob:
  - -0.5051950264009537
  - -0.5042326270983787
  - -0.5098551007464507
  - -0.5063721120720807
  - -0.5040332318987586
  train_level7__neg_hamming_loss_micro:
  - -0.5022507725624742
  - -0.5015065282892535
  - -0.5072937503049226
  - -0.504396636873931
  - -0.500990194657779
  train_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_micro_oob:
  - -0.5051950264009538
  - -0.5042326270983787
  - -0.5098551007464507
  - -0.5063721120720808
  - -0.5040332318987586
  train_level7__neg_hamming_loss_samples:
  - -0.5022507725624741
  - -0.5015065282892535
  - -0.5072937503049227
  - -0.504396636873931
  - -0.500990194657779
  train_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_samples_oob:
  - -0.5051950264009538
  - -0.5042326270983787
  - -0.5098551007464507
  - -0.5063721120720808
  - -0.5040332318987587
  train_level7__neg_hamming_loss_weighted:
  - -0.44331337028725987
  - -0.43958499348015073
  - -0.4495010704610801
  - -0.44917473273851255
  - -0.4437854609245975
  train_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.44732396892574733
  - -0.44364329783637596
  - -0.45271271523642975
  - -0.4522499372811714
  - -0.44717917896321185
  train_level7__neg_label_ranking_loss:
  - -0.33858786568204713
  - -0.34824179987403603
  - -0.3409834810238927
  - -0.34875449325394464
  - -0.3254698386609156
  train_level7__neg_label_ranking_loss_oob:
  - -0.34937114077162423
  - -0.3578705392517122
  - -0.3487559155741892
  - -0.3598869029707117
  - -0.3350289717116857
  train_level7__precision_macro:
  - 0.49774922743752575
  - 0.4984934717107465
  - 0.49270624969507726
  - 0.495603363126069
  - 0.49900980534222095
  train_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_macro_oob:
  - 0.49480497359904624
  - 0.4957673729016213
  - 0.49014489925354926
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__precision_micro:
  - 0.49774922743752587
  - 0.4984934717107466
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_micro_oob:
  - 0.4948049735990462
  - 0.4957673729016213
  - 0.4901448992535493
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__precision_samples:
  - 0.49774922743752587
  - 0.49849347171074654
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_samples_oob:
  - 0.4948049735990461
  - 0.49576737290162126
  - 0.49014489925354937
  - 0.4936278879279191
  - 0.4959667681012413
  train_level7__precision_weighted:
  - 0.5566866297127401
  - 0.5604150065198493
  - 0.5504989295389199
  - 0.5508252672614874
  - 0.5562145390754025
  train_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__precision_weighted_oob:
  - 0.5526760310742527
  - 0.556356702163624
  - 0.5472872847635702
  - 0.5477500627188286
  - 0.5528208210367882
  train_level7__recall_macro:
  - 0.49774922743752575
  - 0.4984934717107465
  - 0.49270624969507726
  - 0.495603363126069
  - 0.49900980534222095
  train_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_macro_oob:
  - 0.49480497359904624
  - 0.4957673729016213
  - 0.49014489925354926
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__recall_micro:
  - 0.49774922743752587
  - 0.4984934717107466
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_micro_oob:
  - 0.4948049735990462
  - 0.4957673729016213
  - 0.4901448992535493
  - 0.49362788792791923
  - 0.49596676810124135
  train_level7__recall_samples:
  - 0.49774922743752587
  - 0.49849347171074654
  - 0.4927062496950773
  - 0.49560336312606906
  - 0.49900980534222095
  train_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_samples_oob:
  - 0.4948049735990461
  - 0.49576737290162126
  - 0.49014489925354937
  - 0.4936278879279191
  - 0.4959667681012413
  train_level7__recall_weighted:
  - 0.5566866297127401
  - 0.5604150065198493
  - 0.5504989295389199
  - 0.5508252672614874
  - 0.5562145390754025
  train_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__recall_weighted_oob:
  - 0.5526760310742527
  - 0.556356702163624
  - 0.5472872847635702
  - 0.5477500627188286
  - 0.5528208210367882
  train_level7__roc_auc_macro:
  - 0.7204771636689378
  - 0.7219785293544497
  - 0.7224193196679182
  - 0.7156626200765163
  - 0.7244539990507934
  train_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_macro_oob:
  - 0.7119294209760648
  - 0.7130157098889596
  - 0.7138774344292359
  - 0.7070839910345778
  - 0.7151879608082116
  train_level7__roc_auc_micro:
  - 0.7312070245155013
  - 0.7253604808914449
  - 0.7293616159713037
  - 0.7208262404026512
  - 0.7309928554452485
  train_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_micro_oob:
  - 0.7267971636231445
  - 0.720663825556972
  - 0.7251324273701258
  - 0.7170688948664605
  - 0.726266966846673
  train_level7__roc_auc_samples:
  - 0.7214844283979884
  - 0.7122516368456951
  - 0.7182349484276127
  - 0.7074707076458036
  - 0.7194572916414684
  train_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_samples_oob:
  - 0.7171900471611178
  - 0.7080489846921394
  - 0.7143325387000222
  - 0.703689341950742
  - 0.714653074385702
  train_level7__roc_auc_weighted:
  - 0.7128024634521962
  - 0.7155366068859419
  - 0.7176402544546033
  - 0.7119559610917384
  - 0.7158859925364295
  train_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__roc_auc_weighted_oob:
  - 0.7035931913397517
  - 0.7074696449377242
  - 0.7086679119986868
  - 0.7044131572168811
  - 0.7066514147356726
  train_level7__tn_macro:
  - 0.2780981580164002
  - 0.2787794729542302
  - 0.2712592086646826
  - 0.2753619696933195
  - 0.2787277206202
  train_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_macro_oob:
  - 0.2763948706718252
  - 0.27715337892773445
  - 0.2700639117919695
  - 0.27439832325519764
  - 0.2769888421967831
  train_level7__tn_micro:
  - 0.2780981580164002
  - 0.2787794729542302
  - 0.2712592086646826
  - 0.2753619696933195
  - 0.27872772062019996
  train_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_micro_oob:
  - 0.2763948706718252
  - 0.27715337892773445
  - 0.27006391179196954
  - 0.27439832325519764
  - 0.27698884219678305
  train_level7__tn_samples:
  - 0.27809815801640014
  - 0.27877947295423017
  - 0.2712592086646826
  - 0.27536196969331944
  - 0.2787277206201999
  train_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_samples_oob:
  - 0.27639487067182517
  - 0.27715337892773445
  - 0.27006391179196954
  - 0.2743983232551976
  - 0.27698884219678305
  train_level7__tn_weighted:
  - 0.22530032560857047
  - 0.23051214020090796
  - 0.2182702311390406
  - 0.2203813049045485
  - 0.223453460626655
  train_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tn_weighted_oob:
  - 0.22284255317373847
  - 0.228016386152162
  - 0.21672403863807427
  - 0.21861264672433814
  - 0.22158849531382832
  train_level7__tp_macro:
  - 0.21965106942112556
  - 0.2197139987565164
  - 0.22144704103039473
  - 0.22024139343274957
  - 0.220282084722021
  train_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_macro_oob:
  - 0.2184101029272209
  - 0.2186139939738869
  - 0.22008098746157972
  - 0.21922956467272162
  - 0.21897792590445836
  train_level7__tp_micro:
  - 0.21965106942112564
  - 0.21971399875651634
  - 0.2214470410303947
  - 0.2202413934327495
  - 0.22028208472202096
  train_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_micro_oob:
  - 0.21841010292722096
  - 0.21861399397388684
  - 0.22008098746157975
  - 0.2192295646727216
  - 0.2189779259044583
  train_level7__tp_samples:
  - 0.21965106942112558
  - 0.21971399875651626
  - 0.22144704103039461
  - 0.22024139343274945
  - 0.2202820847220209
  train_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_samples_oob:
  - 0.21841010292722093
  - 0.21861399397388678
  - 0.22008098746157967
  - 0.2192295646727215
  - 0.21897792590445822
  train_level7__tp_weighted:
  - 0.33138630410416964
  - 0.3299028663189414
  - 0.3322286983998791
  - 0.33044396235693907
  - 0.3327610784487475
  train_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level7__tp_weighted_oob:
  - 0.32983347790051426
  - 0.3283403160114621
  - 0.3305632461254958
  - 0.32913741599449053
  - 0.33123232572295974
  train_level8__average_precision_macro:
  - 0.38046117290554465
  - 0.380294137022928
  - 0.3832376519244306
  - 0.379405576912869
  - 0.38322732999556425
  train_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_macro_oob:
  - 0.37411198405335305
  - 0.37571426680985204
  - 0.37983785115409
  - 0.37293602174441737
  - 0.3779479188572901
  train_level8__average_precision_micro:
  - 0.3859575062491962
  - 0.37678277254781817
  - 0.38066832355018987
  - 0.3732675514530749
  - 0.38306607747841986
  train_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_micro_oob:
  - 0.3820468982065721
  - 0.3741735106939778
  - 0.3793972122094442
  - 0.3695572570307258
  - 0.3802170744283766
  train_level8__average_precision_samples:
  - 0.39169740557603366
  - 0.3794338167820932
  - 0.3884421734667015
  - 0.37602917838594135
  - 0.38962529101550164
  train_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_samples_oob:
  - 0.38793322622098186
  - 0.37656038355061044
  - 0.3859861333883134
  - 0.3724104139510883
  - 0.38699523202887615
  train_level8__average_precision_weighted:
  - 0.5044532197236595
  - 0.5074868804473738
  - 0.5095087296811411
  - 0.5029473119257931
  - 0.5069283191286975
  train_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__average_precision_weighted_oob:
  - 0.497874638093302
  - 0.5023254991890062
  - 0.5047590162106411
  - 0.4958146293637251
  - 0.5015215027542326
  train_level8__f1_macro:
  - 0.49847920772805804
  - 0.49873260318523116
  - 0.49282821876372146
  - 0.49598882170131786
  - 0.49879244553929386
  train_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_macro_oob:
  - 0.4954376231841741
  - 0.4959347649337605
  - 0.49073035078304145
  - 0.4943024404346046
  - 0.4956528039414578
  train_level8__f1_micro:
  - 0.498479207728058
  - 0.4987326031852312
  - 0.4928282187637215
  - 0.4959888217013178
  - 0.4987924455392938
  train_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_micro_oob:
  - 0.495437623184174
  - 0.4959347649337606
  - 0.49073035078304145
  - 0.49430244043460453
  - 0.4956528039414578
  train_level8__f1_samples:
  - 0.49847920772805804
  - 0.4987326031852312
  - 0.49282821876372146
  - 0.49598882170131775
  - 0.4987924455392938
  train_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_samples_oob:
  - 0.49543762318417406
  - 0.4959347649337605
  - 0.4907303507830414
  - 0.4943024404346046
  - 0.4956528039414577
  train_level8__f1_weighted:
  - 0.5573879565239949
  - 0.5607374774622491
  - 0.5505671900671255
  - 0.5512497861422205
  - 0.5561647107775526
  train_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__f1_weighted_oob:
  - 0.5533846579415355
  - 0.5565315206542386
  - 0.5475242351028591
  - 0.5483180485225081
  - 0.5523060998569362
  train_level8__fn_macro:
  - -0.014039954254568455
  - -0.014037017552250227
  - -0.012831146021368981
  - -0.013370594328940708
  - -0.013741969762836303
  train_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_macro_oob:
  - -0.015110592014015623
  - -0.01528050121957052
  - -0.014075230521539738
  - -0.014382423088968655
  - -0.01499782640197073
  train_level8__fn_micro:
  - -0.01403995425456846
  - -0.014037017552250227
  - -0.012831146021368981
  - -0.013370594328940711
  - -0.013741969762836304
  train_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_micro_oob:
  - -0.015110592014015621
  - -0.01528050121957052
  - -0.014075230521539738
  - -0.014382423088968657
  - -0.014997826401970728
  train_level8__fn_samples:
  - -0.014039954254568459
  - -0.014037017552250227
  - -0.01283114602136898
  - -0.013370594328940711
  - -0.0137419697628363
  train_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_samples_oob:
  - -0.015110592014015621
  - -0.015280501219570518
  - -0.014075230521539734
  - -0.014382423088968654
  - -0.014997826401970726
  train_level8__fn_weighted:
  - -0.015849203785496195
  - -0.016406275153739654
  - -0.0146511677781015
  - -0.014725434741857994
  - -0.014869894204763486
  train_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fn_weighted_oob:
  - -0.017346497420081985
  - -0.01811572330081458
  - -0.016193960329387126
  - -0.0161485959293754
  - -0.016437173964971224
  train_level8__fp_macro:
  - -0.48748083801737346
  - -0.48723037926251866
  - -0.4943406352149095
  - -0.4906405839697414
  - -0.4874655846978698
  train_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_macro_oob:
  - -0.4894517848018103
  - -0.488784733846669
  - -0.49519441869541886
  - -0.4913151364764267
  - -0.4893493696565715
  train_level8__fp_micro:
  - -0.4874808380173735
  - -0.48723037926251855
  - -0.4943406352149095
  - -0.49064058396974153
  - -0.4874655846978699
  train_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_micro_oob:
  - -0.48945178480181034
  - -0.4887847338466689
  - -0.49519441869541886
  - -0.4913151364764268
  - -0.4893493696565715
  train_level8__fp_samples:
  - -0.4874808380173735
  - -0.48723037926251855
  - -0.49434063521490956
  - -0.4906405839697415
  - -0.48746558469786994
  train_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_samples_oob:
  - -0.4894517848018103
  - -0.48878473384666893
  - -0.49519441869541886
  - -0.4913151364764268
  - -0.48934936965657155
  train_level8__fp_weighted:
  - -0.4267628396905089
  - -0.42285624738401106
  - -0.43478164215477305
  - -0.4340247791159215
  - -0.4289653950176839
  train_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__fp_weighted_oob:
  - -0.4292688446383826
  - -0.42535275604494677
  - -0.43628180456775395
  - -0.4355333555481165
  - -0.4312567261780925
  train_level8__jaccard_macro:
  - 0.3476010838098589
  - 0.34900947137198507
  - 0.3431777386137504
  - 0.34592513471472164
  - 0.3486626290844449
  train_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_macro_oob:
  - 0.3448692860361529
  - 0.3463877117202546
  - 0.34118897314927293
  - 0.34437000159002484
  - 0.34583670267277067
  train_level8__jaccard_micro:
  - 0.331982887145913
  - 0.332207709461612
  - 0.3269887513150441
  - 0.32977735063270863
  - 0.3322608150066764
  train_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_micro_oob:
  - 0.3292901848527485
  - 0.329729557848546
  - 0.32514425174960804
  - 0.328288
  - 0.32948032557915524
  train_level8__jaccard_samples:
  - 0.33864700339122156
  - 0.3397345841895403
  - 0.33443321928485964
  - 0.3375198635887352
  - 0.34028150997570605
  train_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_samples_oob:
  - 0.3357795538153739
  - 0.33715653274128954
  - 0.33256423061397833
  - 0.3359059125956779
  - 0.33752701066651936
  train_level8__jaccard_weighted:
  - 0.4012573197043559
  - 0.40554135823824516
  - 0.3951194928190633
  - 0.3959687741989318
  - 0.40023101813223344
  train_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__jaccard_weighted_oob:
  - 0.3974205366527115
  - 0.40130782142677024
  - 0.3921361658726628
  - 0.39316924095899397
  - 0.3966004408938374
  train_level8__label_ranking_average_precision_score:
  - 0.3916974055760338
  - 0.3794338167820929
  - 0.3884421734667019
  - 0.3760291783859415
  - 0.38962529101550125
  train_level8__label_ranking_average_precision_score_oob:
  - 0.387933226220982
  - 0.37656038355061044
  - 0.3859861333883133
  - 0.3724104139510884
  - 0.3869952320288762
  train_level8__matthews_corrcoef_macro:
  - 0.2381022709506483
  - 0.24212686614808435
  - 0.23624338821948257
  - 0.2341728731151001
  - 0.23457417713523054
  train_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_macro_oob:
  - 0.23028224188536967
  - 0.23428566093088707
  - 0.2277020167435683
  - 0.22710814039829746
  - 0.22466031236169964
  train_level8__matthews_corrcoef_micro:
  - 0.28252190024525115
  - 0.2828093714972243
  - 0.2813900310901032
  - 0.28241812809823774
  - 0.2838050161346509
  train_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_micro_oob:
  - 0.2761192671627309
  - 0.27606365799679655
  - 0.2752428271387887
  - 0.2774587206348068
  - 0.2766944615536208
  train_level8__matthews_corrcoef_samples:
  - 0.2819587582201066
  - 0.28162724514439025
  - 0.2812549632016968
  - 0.2822170590007406
  - 0.2817388514070374
  train_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_samples_oob:
  - 0.27550337991881296
  - 0.2742100439582274
  - 0.274685972379207
  - 0.277297194392488
  - 0.2740913297321421
  train_level8__matthews_corrcoef_weighted:
  - 0.25271483070518946
  - 0.2643124456469182
  - 0.2477396734936243
  - 0.24916717302880648
  - 0.24452360009738014
  train_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.24157175629623256
  - 0.25300587097159055
  - 0.23548098264879053
  - 0.23828722796871582
  - 0.23098526397500785
  train_level8__ndcg:
  - 0.725186158656653
  - 0.7170778044713861
  - 0.7206718832787768
  - 0.7145289221642684
  - 0.7197372237242803
  train_level8__ndcg_oob:
  - 0.7231036870886679
  - 0.715828145359187
  - 0.7203615881848806
  - 0.7124548437145863
  - 0.7184337826480054
  train_level8__neg_coverage_error:
  - -75.33333333333333
  - -75.83004926108374
  - -75.46984924623115
  - -75.31761786600497
  - -74.91542288557214
  train_level8__neg_coverage_error_oob:
  - -78.12781954887218
  - -78.56403940886699
  - -78.03517587939699
  - -78.3498759305211
  - -77.99004975124379
  train_level8__neg_hamming_loss_macro:
  - -0.501520792271942
  - -0.5012673968147688
  - -0.5071717812362785
  - -0.5040111782986821
  - -0.5012075544607062
  train_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_macro_oob:
  - -0.5045623768158258
  - -0.5040652350662395
  - -0.5092696492169585
  - -0.5056975595653954
  - -0.5043471960585423
  train_level8__neg_hamming_loss_micro:
  - -0.501520792271942
  - -0.5012673968147687
  - -0.5071717812362785
  - -0.5040111782986822
  - -0.5012075544607062
  train_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_micro_oob:
  - -0.5045623768158259
  - -0.5040652350662395
  - -0.5092696492169586
  - -0.5056975595653954
  - -0.5043471960585423
  train_level8__neg_hamming_loss_samples:
  - -0.501520792271942
  - -0.5012673968147687
  - -0.5071717812362785
  - -0.5040111782986822
  - -0.5012075544607062
  train_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_samples_oob:
  - -0.5045623768158259
  - -0.5040652350662395
  - -0.5092696492169585
  - -0.5056975595653954
  - -0.5043471960585422
  train_level8__neg_hamming_loss_weighted:
  - -0.4426120434760051
  - -0.4392625225377509
  - -0.44943280993287443
  - -0.4487502138577794
  - -0.44383528922244747
  train_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.4466153420584646
  - -0.44346847934576133
  - -0.4524757648971409
  - -0.45168195147749196
  - -0.44769390014306376
  train_level8__neg_label_ranking_loss:
  - -0.3394548431235245
  - -0.34559267598515564
  - -0.33340580796924885
  - -0.3552417169036109
  - -0.3290553803885098
  train_level8__neg_label_ranking_loss_oob:
  - -0.3504724612402085
  - -0.3568579211073128
  - -0.3423745019912481
  - -0.36641531761662594
  - -0.33814899113362284
  train_level8__precision_macro:
  - 0.49847920772805804
  - 0.49873260318523116
  - 0.49282821876372146
  - 0.49598882170131786
  - 0.49879244553929386
  train_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_macro_oob:
  - 0.4954376231841741
  - 0.4959347649337605
  - 0.49073035078304145
  - 0.4943024404346046
  - 0.4956528039414578
  train_level8__precision_micro:
  - 0.498479207728058
  - 0.4987326031852312
  - 0.4928282187637215
  - 0.4959888217013178
  - 0.4987924455392938
  train_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_micro_oob:
  - 0.495437623184174
  - 0.4959347649337606
  - 0.49073035078304145
  - 0.49430244043460453
  - 0.4956528039414578
  train_level8__precision_samples:
  - 0.49847920772805804
  - 0.4987326031852312
  - 0.49282821876372146
  - 0.49598882170131775
  - 0.4987924455392938
  train_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_samples_oob:
  - 0.49543762318417406
  - 0.4959347649337605
  - 0.4907303507830414
  - 0.4943024404346046
  - 0.4956528039414577
  train_level8__precision_weighted:
  - 0.5573879565239949
  - 0.5607374774622491
  - 0.5505671900671255
  - 0.5512497861422205
  - 0.5561647107775526
  train_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__precision_weighted_oob:
  - 0.5533846579415355
  - 0.5565315206542386
  - 0.5475242351028591
  - 0.5483180485225081
  - 0.5523060998569362
  train_level8__recall_macro:
  - 0.49847920772805804
  - 0.49873260318523116
  - 0.49282821876372146
  - 0.49598882170131786
  - 0.49879244553929386
  train_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_macro_oob:
  - 0.4954376231841741
  - 0.4959347649337605
  - 0.49073035078304145
  - 0.4943024404346046
  - 0.4956528039414578
  train_level8__recall_micro:
  - 0.498479207728058
  - 0.4987326031852312
  - 0.4928282187637215
  - 0.4959888217013178
  - 0.4987924455392938
  train_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_micro_oob:
  - 0.495437623184174
  - 0.4959347649337606
  - 0.49073035078304145
  - 0.49430244043460453
  - 0.4956528039414578
  train_level8__recall_samples:
  - 0.49847920772805804
  - 0.4987326031852312
  - 0.49282821876372146
  - 0.49598882170131775
  - 0.4987924455392938
  train_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_samples_oob:
  - 0.49543762318417406
  - 0.4959347649337605
  - 0.4907303507830414
  - 0.4943024404346046
  - 0.4956528039414577
  train_level8__recall_weighted:
  - 0.5573879565239949
  - 0.5607374774622491
  - 0.5505671900671255
  - 0.5512497861422205
  - 0.5561647107775526
  train_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__recall_weighted_oob:
  - 0.5533846579415355
  - 0.5565315206542386
  - 0.5475242351028591
  - 0.5483180485225081
  - 0.5523060998569362
  train_level8__roc_auc_macro:
  - 0.7215128907080902
  - 0.7215194768865657
  - 0.7214307550195962
  - 0.7153744329930943
  - 0.722782688875327
  train_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_macro_oob:
  - 0.7120587450649066
  - 0.7136010527905675
  - 0.713821669093774
  - 0.7059779169917471
  - 0.7132714514168007
  train_level8__roc_auc_micro:
  - 0.732351934421904
  - 0.7251597848372993
  - 0.7288150772619166
  - 0.721676317925802
  - 0.7300391121434873
  train_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_micro_oob:
  - 0.7275426113578594
  - 0.7210842993835891
  - 0.7253732319928503
  - 0.7167396255339582
  - 0.7255818195610585
  train_level8__roc_auc_samples:
  - 0.7232486785385883
  - 0.7121061807883093
  - 0.7185813937567823
  - 0.708013504797098
  - 0.7182447515947734
  train_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_samples_oob:
  - 0.7186998251143956
  - 0.708106578485283
  - 0.7151713443798469
  - 0.7031701747045592
  - 0.7135517057580848
  train_level8__roc_auc_weighted:
  - 0.7128478333158816
  - 0.716421493632431
  - 0.717297397893547
  - 0.7110265590346557
  - 0.7146300223966231
  train_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__roc_auc_weighted_oob:
  - 0.7037270361768586
  - 0.7090992412978423
  - 0.7094419794738418
  - 0.7020855667594881
  - 0.7061558169373802
  train_level8__tn_macro:
  - 0.27860914421977273
  - 0.27861208092209094
  - 0.2713079962921403
  - 0.27560288130285
  - 0.27863111626334347
  train_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_macro_oob:
  - 0.2766381974353359
  - 0.2770577263379406
  - 0.27045421281163096
  - 0.2749283287961647
  - 0.27674733130464185
  train_level8__tn_micro:
  - 0.27860914421977273
  - 0.27861208092209094
  - 0.2713079962921403
  - 0.27560288130285
  - 0.27863111626334347
  train_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_micro_oob:
  - 0.2766381974353359
  - 0.2770577263379406
  - 0.27045421281163096
  - 0.2749283287961647
  - 0.27674733130464185
  train_level8__tn_samples:
  - 0.2786091442197727
  - 0.27861208092209094
  - 0.27130799629214025
  - 0.27560288130284993
  - 0.2786311162633434
  train_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_samples_oob:
  - 0.27663819743533585
  - 0.2770577263379405
  - 0.2704542128116309
  - 0.27492832879616463
  - 0.2767473313046418
  train_level8__tn_weighted:
  - 0.22557485985847792
  - 0.23033304557455167
  - 0.21826840039690487
  - 0.22054957805124856
  - 0.22357597659611078
  train_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tn_weighted_oob:
  - 0.22306885491060427
  - 0.227836536913616
  - 0.21676823798392403
  - 0.21904100161905365
  - 0.2212846454357022
  train_level8__tp_macro:
  - 0.21987006350828522
  - 0.2201205222631403
  - 0.22152022247158124
  - 0.22038594039846787
  - 0.2201613292759504
  train_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_macro_oob:
  - 0.218799425748838
  - 0.21887703859582003
  - 0.22027613797141046
  - 0.2193741116384399
  - 0.21890547263681595
  train_level8__tp_micro:
  - 0.21987006350828528
  - 0.22012052226314027
  - 0.2215202224715812
  - 0.2203859403984678
  - 0.22016132927595033
  train_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_micro_oob:
  - 0.21879942574883812
  - 0.21887703859581997
  - 0.22027613797141046
  - 0.21937411163843987
  - 0.21890547263681592
  train_level8__tp_samples:
  - 0.2198700635082852
  - 0.22012052226314022
  - 0.22152022247158115
  - 0.22038594039846773
  - 0.22016132927595025
  train_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_samples_oob:
  - 0.21879942574883807
  - 0.21887703859581992
  - 0.22027613797141035
  - 0.21937411163843978
  - 0.2189054726368159
  train_level8__tp_weighted:
  - 0.33181309666551684
  - 0.33040443188769764
  - 0.33229878967022053
  - 0.33070020809097184
  - 0.3325887341814418
  train_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level8__tp_weighted_oob:
  - 0.3303158030309311
  - 0.3286949837406227
  - 0.33075599711893494
  - 0.32927704690345444
  - 0.33102145442123404
  train_level9__average_precision_macro:
  - 0.3776783455958645
  - 0.385433111437716
  - 0.38720367961116725
  - 0.37881921030833093
  - 0.38559820154754504
  train_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_macro_oob:
  - 0.37401962547517426
  - 0.3801196771466394
  - 0.3822710540228972
  - 0.374384965812398
  - 0.3798614578859569
  train_level9__average_precision_micro:
  - 0.3851044291089511
  - 0.3780810319260742
  - 0.3854136188083388
  - 0.37293213118803703
  - 0.38026746827195457
  train_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_micro_oob:
  - 0.3826832898304855
  - 0.37511085632139246
  - 0.38207308044373617
  - 0.37056454704214514
  - 0.37868892921441855
  train_level9__average_precision_samples:
  - 0.3882967206998635
  - 0.37967140761808665
  - 0.39084414717123006
  - 0.37682360739629817
  - 0.3886292976226522
  train_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_samples_oob:
  - 0.38633914106276196
  - 0.3765897651076902
  - 0.38808909806417075
  - 0.3745584200792441
  - 0.3859582046985857
  train_level9__average_precision_weighted:
  - 0.5016168073655725
  - 0.5124610575395476
  - 0.5123349025553039
  - 0.502585370090234
  - 0.5085208931688967
  train_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__average_precision_weighted_oob:
  - 0.4975663859582698
  - 0.5068887428070907
  - 0.5069945613295422
  - 0.4981334240477757
  - 0.5021685114302453
  train_level9__f1_macro:
  - 0.4977005620848237
  - 0.4989717346597158
  - 0.4928770063911791
  - 0.49589245705750556
  - 0.49915471187750576
  train_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_macro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.4935556144450601
  - 0.4963773366178816
  train_level9__f1_micro:
  - 0.4977005620848237
  - 0.4989717346597159
  - 0.4928770063911792
  - 0.4958924570575056
  - 0.49915471187750565
  train_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_micro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__f1_samples:
  - 0.49770056208482366
  - 0.4989717346597159
  - 0.49287700639117915
  - 0.4958924570575056
  - 0.4991547118775057
  train_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_samples_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.49085231985168565
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__f1_weighted:
  - 0.5569478674320252
  - 0.5610888752052544
  - 0.5507651717523814
  - 0.5512753595687707
  - 0.5564965569673573
  train_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__f1_weighted_oob:
  - 0.5529234508303422
  - 0.5574705097556264
  - 0.5479306598570034
  - 0.5476633688028235
  - 0.553323470412522
  train_level9__fn_macro:
  - -0.013966956225515244
  - -0.014060930699698692
  - -0.01285553983509782
  - -0.013346503167987665
  - -0.013814423030478673
  train_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_macro_oob:
  - -0.015426916806579554
  - -0.015304414367018985
  - -0.014026442894082062
  - -0.014334240767062563
  - -0.014804617688257738
  train_level9__fn_micro:
  - -0.013966956225515244
  - -0.014060930699698694
  - -0.01285553983509782
  - -0.013346503167987665
  - -0.013814423030478674
  train_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_micro_oob:
  - -0.015426916806579555
  - -0.015304414367018987
  - -0.01402644289408206
  - -0.014334240767062564
  - -0.01480461768825774
  train_level9__fn_samples:
  - -0.013966956225515244
  - -0.014060930699698692
  - -0.012855539835097816
  - -0.013346503167987665
  - -0.013814423030478673
  train_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_samples_oob:
  - -0.015426916806579555
  - -0.015304414367018985
  - -0.01402644289408206
  - -0.014334240767062564
  - -0.014804617688257736
  train_level9__fn_weighted:
  - -0.01588101117247503
  - -0.01654336303486912
  - -0.014661367627143734
  - -0.014691933553077264
  - -0.01497211926942469
  train_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fn_weighted_oob:
  - -0.01786740856093213
  - -0.018105661804951864
  - -0.01606580837988213
  - -0.016109724321019134
  - -0.016107896244127843
  train_level9__fp_macro:
  - -0.48833248168966104
  - -0.4869673346405855
  - -0.494267453773723
  - -0.49076103977450664
  - -0.4870308650920156
  train_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_macro_oob:
  - -0.4898654402997786
  - -0.4881390788655603
  - -0.49512123725423235
  - -0.49211014478787724
  - -0.4888180456938607
  train_level9__fp_micro:
  - -0.48833248168966104
  - -0.4869673346405854
  - -0.494267453773723
  - -0.49076103977450675
  - -0.48703086509201565
  train_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_micro_oob:
  - -0.4898654402997786
  - -0.4881390788655603
  - -0.49512123725423235
  - -0.49211014478787735
  - -0.4888180456938608
  train_level9__fp_samples:
  - -0.4883324816896611
  - -0.48696733464058534
  - -0.49426745377372294
  - -0.4907610397745068
  - -0.48703086509201565
  train_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_samples_oob:
  - -0.4898654402997786
  - -0.4881390788655603
  - -0.4951212372542323
  - -0.4921101447878774
  - -0.4888180456938608
  train_level9__fp_weighted:
  - -0.4271711213954995
  - -0.42236776175987634
  - -0.4345734606204751
  - -0.43403270687815204
  - -0.42853132376321795
  train_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__fp_weighted_oob:
  - -0.4292091406087256
  - -0.42442382843942167
  - -0.43600353176311446
  - -0.4362269068761573
  - -0.4305686333433504
  train_level9__jaccard_macro:
  - 0.3469290043962613
  - 0.34921781749387837
  - 0.34335419293067926
  - 0.3458373251817298
  - 0.3490016038209345
  train_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_macro_oob:
  - 0.3442479947440484
  - 0.34692122031063455
  - 0.34144665335130275
  - 0.34367086643677003
  - 0.3464869249086897
  train_level9__jaccard_micro:
  - 0.33129251700680273
  - 0.33241994583399714
  - 0.3270317077513232
  - 0.32969215491559084
  - 0.3325823892893924
  train_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_micro_oob:
  - 0.32864555550167307
  - 0.3302794611187988
  - 0.32525134969126823
  - 0.32762949577009803
  - 0.33012094636919964
  train_level9__jaccard_samples:
  - 0.3379201849491793
  - 0.33988691637580387
  - 0.33446748377732144
  - 0.33743774279074645
  - 0.34062733557707153
  train_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_samples_oob:
  - 0.33519205283462544
  - 0.3377691012923667
  - 0.33264069863686707
  - 0.33531738070621947
  - 0.3381062813745957
  train_level9__jaccard_weighted:
  - 0.4008618489431515
  - 0.4058763423573657
  - 0.3953772876117143
  - 0.3959557146325115
  - 0.4005589179599459
  train_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__jaccard_weighted_oob:
  - 0.396978290441359
  - 0.40225611381732634
  - 0.39262936401547943
  - 0.3925157760905271
  - 0.3975441608352789
  train_level9__label_ranking_average_precision_score:
  - 0.3882967206998638
  - 0.3796714076180865
  - 0.39084414717123017
  - 0.37682360739629817
  - 0.3886292976226521
  train_level9__label_ranking_average_precision_score_oob:
  - 0.38633914106276207
  - 0.37658976510768993
  - 0.38808909806417125
  - 0.3745584200792441
  - 0.3859582046985859
  train_level9__matthews_corrcoef_macro:
  - 0.237761083838873
  - 0.24266129043853718
  - 0.23633955494102765
  - 0.23445203674701745
  - 0.23514108412071266
  train_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_macro_oob:
  - 0.2285452280084047
  - 0.23510070104063965
  - 0.2284998045832289
  - 0.22725855400692352
  - 0.22705829080795661
  train_level9__matthews_corrcoef_micro:
  - 0.28203987272334324
  - 0.2829527418460797
  - 0.28135291223965286
  - 0.2824095205090307
  - 0.2839005512796
  train_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_micro_oob:
  - 0.2743839937324309
  - 0.2765679811492773
  - 0.2755208965109144
  - 0.2769225682338268
  - 0.278014901046359
  train_level9__matthews_corrcoef_samples:
  - 0.2815898052651838
  - 0.2817526332528293
  - 0.281200162360044
  - 0.2823387744704949
  - 0.28189875176563595
  train_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_samples_oob:
  - 0.2737264082882269
  - 0.2748455346810416
  - 0.2747028264196927
  - 0.27671492415896476
  - 0.27546623795859115
  train_level9__matthews_corrcoef_weighted:
  - 0.2523983809390631
  - 0.2647254119052944
  - 0.2482698703737845
  - 0.24949475270307112
  - 0.24597923937728128
  train_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.23935287059282043
  - 0.25484826635018537
  - 0.23714558264188598
  - 0.23893728731793942
  - 0.2348778923527646
  train_level9__ndcg:
  - 0.7235262049603309
  - 0.7176227302058525
  - 0.7242919530357486
  - 0.7153373559497348
  - 0.7180000447997734
  train_level9__ndcg_oob:
  - 0.722854650963769
  - 0.7161190843248626
  - 0.7226046658079361
  - 0.7144840933248244
  - 0.7169664951928366
  train_level9__neg_coverage_error:
  - -75.32581453634086
  - -75.91625615763547
  - -75.4572864321608
  - -75.42431761786601
  - -74.96019900497512
  train_level9__neg_coverage_error_oob:
  - -78.03258145363408
  - -78.60344827586206
  - -78.0251256281407
  - -78.3349875930521
  - -77.8905472636816
  train_level9__neg_hamming_loss_macro:
  - -0.5022994379151762
  - -0.5010282653402842
  - -0.5071229936088208
  - -0.5041075429424944
  - -0.5008452881224943
  train_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_macro_oob:
  - -0.5052923571063581
  - -0.5034434932325794
  - -0.5091476801483145
  - -0.50644438555494
  - -0.5036226633821185
  train_level9__neg_hamming_loss_micro:
  - -0.5022994379151763
  - -0.5010282653402841
  - -0.5071229936088208
  - -0.5041075429424944
  - -0.5008452881224943
  train_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_micro_oob:
  - -0.5052923571063581
  - -0.5034434932325793
  - -0.5091476801483144
  - -0.5064443855549399
  - -0.5036226633821186
  train_level9__neg_hamming_loss_samples:
  - -0.5022994379151763
  - -0.5010282653402841
  - -0.5071229936088208
  - -0.5041075429424944
  - -0.5008452881224943
  train_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_samples_oob:
  - -0.505292357106358
  - -0.5034434932325792
  - -0.5091476801483144
  - -0.5064443855549399
  - -0.5036226633821185
  train_level9__neg_hamming_loss_weighted:
  - -0.4430521325679747
  - -0.43891112479474564
  - -0.4492348282476187
  - -0.4487246404312293
  - -0.4435034430326427
  train_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.44707654916965767
  - -0.44252949024437366
  - -0.45206934014299666
  - -0.4523366311971765
  - -0.4466765295874782
  train_level9__neg_label_ranking_loss:
  - -0.34606432084904964
  - -0.3478041373862525
  - -0.3340850178687337
  - -0.35194095690586674
  - -0.32296945786246767
  train_level9__neg_label_ranking_loss_oob:
  - -0.3552691901984695
  - -0.3578467570509744
  - -0.3434138956842739
  - -0.3609170829021172
  - -0.3338843780617417
  train_level9__precision_macro:
  - 0.4977005620848237
  - 0.4989717346597158
  - 0.4928770063911791
  - 0.49589245705750556
  - 0.49915471187750576
  train_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_macro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.4935556144450601
  - 0.4963773366178816
  train_level9__precision_micro:
  - 0.4977005620848237
  - 0.4989717346597159
  - 0.4928770063911792
  - 0.4958924570575056
  - 0.49915471187750565
  train_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_micro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__precision_samples:
  - 0.49770056208482366
  - 0.4989717346597159
  - 0.49287700639117915
  - 0.4958924570575056
  - 0.4991547118775057
  train_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_samples_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.49085231985168565
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__precision_weighted:
  - 0.5569478674320252
  - 0.5610888752052544
  - 0.5507651717523814
  - 0.5512753595687707
  - 0.5564965569673573
  train_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__precision_weighted_oob:
  - 0.5529234508303422
  - 0.5574705097556264
  - 0.5479306598570034
  - 0.5476633688028235
  - 0.553323470412522
  train_level9__recall_macro:
  - 0.4977005620848237
  - 0.4989717346597158
  - 0.4928770063911791
  - 0.49589245705750556
  - 0.49915471187750576
  train_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_macro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.4935556144450601
  - 0.4963773366178816
  train_level9__recall_micro:
  - 0.4977005620848237
  - 0.4989717346597159
  - 0.4928770063911792
  - 0.4958924570575056
  - 0.49915471187750565
  train_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_micro_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.4908523198516856
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__recall_samples:
  - 0.49770056208482366
  - 0.4989717346597159
  - 0.49287700639117915
  - 0.4958924570575056
  - 0.4991547118775057
  train_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_samples_oob:
  - 0.4947076428936419
  - 0.49655650676742075
  - 0.49085231985168565
  - 0.49355561444506013
  - 0.49637733661788147
  train_level9__recall_weighted:
  - 0.5569478674320252
  - 0.5610888752052544
  - 0.5507651717523814
  - 0.5512753595687707
  - 0.5564965569673573
  train_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__recall_weighted_oob:
  - 0.5529234508303422
  - 0.5574705097556264
  - 0.5479306598570034
  - 0.5476633688028235
  - 0.553323470412522
  train_level9__roc_auc_macro:
  - 0.7199838938970275
  - 0.7224121308404814
  - 0.7235627794232556
  - 0.7161340479576036
  - 0.7236787431428483
  train_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_macro_oob:
  - 0.71121560972059
  - 0.7142567321846857
  - 0.7152112299274579
  - 0.7065874206712357
  - 0.7141835158264366
  train_level9__roc_auc_micro:
  - 0.7319825675044631
  - 0.7258157603590262
  - 0.7309586748378776
  - 0.7210222881350623
  - 0.7291658475547411
  train_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_micro_oob:
  - 0.7278677696238403
  - 0.7214968809553839
  - 0.7266579572052136
  - 0.7168946608182403
  - 0.7252226526460203
  train_level9__roc_auc_samples:
  - 0.7213600299893713
  - 0.7117812155434848
  - 0.720085842282431
  - 0.7078814228868376
  - 0.7178497810501195
  train_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_samples_oob:
  - 0.7176871699204975
  - 0.7076722158152626
  - 0.7162635208452308
  - 0.7040609698983212
  - 0.713067836253475
  train_level9__roc_auc_weighted:
  - 0.7121884358747044
  - 0.7176194162160026
  - 0.7189391573623028
  - 0.7115942067232262
  - 0.7144975892631767
  train_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__roc_auc_weighted_oob:
  - 0.7039884583453655
  - 0.7098446744611405
  - 0.7105064676610207
  - 0.7036189669233753
  - 0.7056042579245226
  train_level9__tn_macro:
  - 0.2777575005474852
  - 0.2788751255440241
  - 0.2713811777333268
  - 0.2754824254980847
  - 0.2790658358691977
  train_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_macro_oob:
  - 0.2762245419373676
  - 0.27770338131904926
  - 0.27052739425281747
  - 0.27413332048471417
  - 0.27727865526735257
  train_level9__tn_micro:
  - 0.2777575005474852
  - 0.2788751255440241
  - 0.2713811777333268
  - 0.27548242549808477
  - 0.2790658358691977
  train_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_micro_oob:
  - 0.2762245419373677
  - 0.2777033813190492
  - 0.27052739425281747
  - 0.27413332048471417
  - 0.27727865526735257
  train_level9__tn_samples:
  - 0.27775750054748516
  - 0.27887512554402405
  - 0.27138117773332676
  - 0.2754824254980847
  - 0.2790658358691977
  train_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_samples_oob:
  - 0.2762245419373676
  - 0.2777033813190491
  - 0.2705273942528174
  - 0.2741333204847141
  - 0.2772786552673525
  train_level9__tn_weighted:
  - 0.22516657815348728
  - 0.23082153119868634
  - 0.21847658193120278
  - 0.22054165028901804
  - 0.22401004785057677
  train_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tn_weighted_oob:
  - 0.2231285589402613
  - 0.22876546451914098
  - 0.21704651078856343
  - 0.21834745029101277
  - 0.22197273827044434
  train_level9__tp_macro:
  - 0.21994306153733842
  - 0.22009660911569187
  - 0.22149582865785233
  - 0.2204100315594209
  - 0.220088876008308
  train_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_macro_oob:
  - 0.2184831009562741
  - 0.21885312544837157
  - 0.2203249255988681
  - 0.21942229396034602
  - 0.21909868135052893
  train_level9__tp_micro:
  - 0.2199430615373385
  - 0.22009660911569182
  - 0.22149582865785236
  - 0.22041003155942085
  - 0.22008887600830798
  train_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_micro_oob:
  - 0.21848310095627418
  - 0.21885312544837152
  - 0.22032492559886813
  - 0.21942229396034596
  - 0.2190986813505289
  train_level9__tp_samples:
  - 0.21994306153733842
  - 0.22009660911569176
  - 0.2214958286578523
  - 0.22041003155942074
  - 0.2200888760083079
  train_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_samples_oob:
  - 0.2184831009562741
  - 0.21885312544837146
  - 0.2203249255988681
  - 0.21942229396034588
  - 0.21909868135052882
  train_level9__tp_weighted:
  - 0.33178128927853806
  - 0.33026734400656815
  - 0.33228858982117837
  - 0.3307337092797526
  - 0.3324865091167806
  train_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level9__tp_weighted_oob:
  - 0.329794891890081
  - 0.32870504523648536
  - 0.33088414906844
  - 0.32931591851181075
  - 0.33135073214207744
start: 2023-12-31 02:42:50.736008
wrapper: null
