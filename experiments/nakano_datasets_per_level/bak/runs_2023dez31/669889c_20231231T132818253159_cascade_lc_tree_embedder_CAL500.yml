active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            YGZmZmZm9r+AmZmZmZnZv2BmZmZmZva/QDMzMzMz4z/QzMzMzMwEQA==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJv8CZmZmZmek/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb/MzMzMzMwcwNDMzMzMzPw/NDMzMzMzE0CgmZmZmZnpPw==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+AmZmZmZnJv4CZmZmZmcm/gJmZmZmZyb+AmZmZmZnJvw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJP4CZmZmZmem/AJqZmZmZyT8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T9AMzMzMzPjPzAzMzMzMwPAYGZmZmZm9r+gmZmZmZn5Pw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMFMCYmZmZmZkBwGhmZmZmZg5ANDMzMzMzE0AwMzMzMzPzvw==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb8wMzMzMzPzvzQzMzMzMxdAzMzMzMzMHMBoZmZmZmYGQA==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz47/OzMzMzMwgQDIzMzMzMyHAODMzMzMzA0CQmZmZmZn5vw==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0BkZmZmZmYWwJyZmZmZmRlAIDMzMzMz47/IzMzMzMwMwA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAADwPwAAAAAAABjAAAAAAAAA8D8AAAAAAAAQQA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAAAAAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPw==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8CYmZmZmZkRwEAzMzMzM+M/aGZmZmZmFkBAMzMzMzPjPw==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUBkZmZmZmYWwJCZmZmZmfm/nJmZmZmZEUCQmZmZmZn5vw==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZm9j84MzMzMzMLQJCZmZmZmfm/ODMzMzMzA0BkZmZmZmYWwA==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAAAAAAAAAABBAAAAAAAAACMAAAAAAAAAAwA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAYQAAAAAAAAPC/AAAAAAAACEAAAAAAAAAQwA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkAwMzMzMzPzv4CZmZmZmcm/zMzMzMzMEMBoZmZmZmYGQA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzF8AwMzMzMzMTwICZmZmZmem/0MzMzMzMGEDQzMzMzMwUQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUDIzMzMzMwEwJyZmZmZmRVAMjMzMzMzIcBwZmZmZmb2Pw==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBMCYmZmZmZkZQDQzMzMzMyXAmJmZmZmZFUBgZmZmZmb2Pw==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b/OzMzMzMwcQMCZmZmZmck/ZGZmZmZmDsBkZmZmZmYGwA==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAQwAAAAAAAAAAAAAAAAAAAGEAAAAAAAAAAwA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D+QmZmZmZkJwODMzMzMzPw/kJmZmZmZCcBwZmZmZmYGQA==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMDMzMzMzMwMwGhmZmZmZvY/NDMzMzMzA0A0MzMzMzMDQA==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAQAAAAAAAAAAAAAAAAAAAEMAAAAAAAADwPw==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b/QzMzMzMwMQDAzMzMzMwvAYGZmZmZm9r+gmZmZmZn5Pw==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAIwAAAAAAAAAAAAAAAAAAAAMAAAAAAAAAIQA==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAAAjAAAAAAAAA8D8AAAAAAAAAQA==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBEAwMzMzMzMDwDAzMzMzMwPAQDMzMzMz4z+gmZmZmZn5Pw==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz8z9gZmZmZmYGwNDMzMzMzBhAMDMzMzMzF8BAMzMzMzPzPw==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+gmZmZmZnpP4CZmZmZmcm/MDMzMzMz87+gmZmZmZnpPw==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L8wMzMzMzMTwACamZmZmck/0MzMzMzMGEAAmpmZmZnJPw==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAQQAAAAAAAAPC/AAAAAAAAFMAAAAAAAADwPw==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcDIzMzMzMwQwJCZmZmZmQHAODMzMzMzH0DAmZmZmZnpPw==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAAwAAAAAAAAAjAAAAAAAAAEMAAAAAAAAAYQA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAUwAAAAAAAACBAAAAAAAAACEAAAAAAAAAAwA==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+gmZmZmZnZPzAzMzMzM+O/oJmZmZmZ2T+gmZmZmZnZPw==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T+YmZmZmZkRwKCZmZmZmfk/mJmZmZmZEcBoZmZmZmYWQA==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz4z+QmZmZmZnZv5CZmZmZmdm/MjMzMzMzA8DOzMzMzMwEQA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmBsCQmZmZmZnpvzgzMzMzM/M/nJmZmZmZCUCQmZmZmZnpvw==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAPC/AAAAAAAAAAAAAAAAAADwPw==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j9mZmZmZmYSwDQzMzMzMwNAmJmZmZmZ+b80MzMzMzMDQA==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0A0MzMzMzMDQKCZmZmZmdk/MzMzMzMzIcA0MzMzMzMDQA==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzM/L80MzMzMzPzP8zMzMzMzPy/mpmZmZmZCUCYmZmZmZnpvw==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUBgZmZmZmYOwDAzMzMzMxPAoJmZmZmZAUCgmZmZmZkJQA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+gmZmZmZn5P4CZmZmZmdm/oJmZmZmZ+T8wMzMzMzMDwA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b9oZmZmZmb2P5iZmZmZmfm/mpmZmZmZEUDMzMzMzMwEwA==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBEAwMzMzMzMDwKCZmZmZmfk/oJmZmZmZ+T8wMzMzMzMLwA==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJv8jMzMzMzBTAcGZmZmZmBkBwZmZmZmYGQA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D+YmZmZmZkJwGhmZmZmZg5AmJmZmZmZAcCAmZmZmZnJvw==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAAQAAAAAAAAPA/AAAAAAAAAAAAAAAAAADwPw==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/QzMzMzMz8PzAzMzMzM/O/aGZmZmZmBkDMzMzMzMwUwA==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAQwAAAAAAAABTAAAAAAAAAEEAAAAAAAAAAAA==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGMAAAAAAAAAAwAAAAAAAAABAAAAAAAAACEAAAAAAAAAIQA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBkBAMzMzMzPzv6CZmZmZmQHAYGZmZmZmBkCgmZmZmZkBwA==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+gmZmZmZnpP4CZmZmZmcm/mJmZmZmZAcCgmZmZmZnpPw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMCamZmZmZkRQDAzMzMzM+O/mJmZmZmZ+b+gmZmZmZnZPw==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEMCYmZmZmZkBwGhmZmZmZgZAoJmZmZmZ6T9oZmZmZmYGQA==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+AmZmZmZnJv6CZmZmZmek/gJmZmZmZyb8wMzMzMzPzvw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAHEAAAAAAAAAcwAAAAAAAAPA/AAAAAAAAEMAAAAAAAAAIQA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDsDMzMzMzMwQQJiZmZmZmQlAgJmZmZmZyT9oZmZmZmYOwA==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmBsCgmZmZmZnJP5qZmZmZmQlANDMzMzMz8z/MzMzMzMz8vw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIEAAAAAAAAAgwAAAAAAAAPC/AAAAAAAAAMAAAAAAAAAIQA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAgwAAAAAAAAAAAAAAAAAAAFEAAAAAAAAAUQA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAADwPwAAAAAAAADAAAAAAAAACEAAAAAAAADwvw==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGEAAAAAAAAAIwAAAAAAAAAjAAAAAAAAACMAAAAAAAAAIQA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmFsA4MzMzMzMDQDgzMzMzMwNAyMzMzMzMDMCcmZmZmZkRQA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMFECYmZmZmZkpwNDMzMzMzBRAoJmZmZmZCUCAmZmZmZnpvw==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC8DQzMzMzMwEQGBmZmZmZva/YGZmZmZm9r/QzMzMzMwMQA==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzF0BkZmZmZmYqwODMzMzMzPw/ODMzMzMzE0DAmZmZmZnpPw==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAQQAAAAAAAABDAAAAAAAAA8D8AAAAAAAAAAA==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZFUA0MzMzMzMpwJiZmZmZmRFAMDMzMzMzA0CAmZmZmZnZPw==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+gmZmZmZn5P0AzMzMzM+M/oJmZmZmZ+T8wMzMzMzMLwA==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZFUAwMzMzMzMhwAAzMzMzM+O/gJmZmZmZ+b+gmZmZmZkVQA==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87/MzMzMzMwQwNDMzMzMzPw/NDMzMzMzF0CYmZmZmZkBwA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcBoZmZmZmYOQJiZmZmZmQHAMDMzMzMz879oZmZmZmYGQA==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ADMzMzMz87/AzMzMzMwYwIBmZmZmZg5AAJiZmZmZyb+AZmZmZmYOQA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+gmZmZmZn5P0AzMzMzM+M/MDMzMzMzA8BAMzMzMzPjPw==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8wMzMzMzMbwKCZmZmZmQlAoJmZmZmZAUBAMzMzMzPzPw==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAAwAAAAAAAAAhAAAAAAAAACMAAAAAAAAAUQA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUBkZmZmZmYWwJyZmZmZmRFAIDMzMzMz47/IzMzMzMwEwA==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkCYmZmZmZkBwDAzMzMzM/O/aGZmZmZmBkCYmZmZmZkJwA==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBECYmZmZmZkVwICZmZmZmdm/gJmZmZmZ2b/QzMzMzMwMQA==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmDsDQzMzMzMwYQEAzMzMzM/M/oJmZmZmZAUAwMzMzMzMXwA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZEUBmZmZmZmYWwGhmZmZmZvY/NDMzMzMzA0DMzMzMzMwEwA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZEcCgmZmZmZnZv8zMzMzMzARAaGZmZmZm9r/MzMzMzMwMQA==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUAwMzMzMzMTwICZmZmZmem/0MzMzMzMGEBgZmZmZmYOwA==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ6b84MzMzMzPzP8CZmZmZmck/yMzMzMzM/L84MzMzMzPzPw==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmBkCYmZmZmZkBwNDMzMzMzPw/MDMzMzMz878wMzMzMzPzvw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz4z9kZmZmZmb2v5yZmZmZmfk/kJmZmZmZ2b+QmZmZmZnZvw==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j+gmZmZmZnZP6CZmZmZmdk/mJmZmZmZ+b8wMzMzMzPjvw==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAwAAAAAAAAABAAAAAAAAAAAAAAAAAAADwPw==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAUQAAAAAAAAADAAAAAAAAAAAAAAAAAAAAAwA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAAAjAAAAAAAAAFEAAAAAAAAAAwA==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47/MzMzMzMwEwKCZmZmZmdk/NDMzMzMzC0AwMzMzMzPjvw==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+gmZmZmZnZP8zMzMzMzATAmpmZmZmZEUCYmZmZmZn5vw==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0A0MzMzMzMDQDAzMzMzM+O/ZmZmZmZmEsCgmZmZmZnZPw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b/MzMzMzMwEwJqZmZmZmRVANDMzMzMzC0BmZmZmZmYSwA==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAADwvwAAAAAAAPA/AAAAAAAACEAAAAAAAADwPw==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47/MzMzMzMwEwMzMzMzMzAzAmpmZmZmZEUA0MzMzMzMDQA==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZAUBmZmZmZmYGwGZmZmZmZgbAoJmZmZmZyT+amZmZmZkJQA==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAQAAAAAAAABTAAAAAAAAAAMAAAAAAAADwPw==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          AJqZmZmZ2T/AzMzMzMwMwEAzMzMzMwNAADMzMzMz47+AZmZmZmb2Pw==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 13:33:39.220855
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - xt_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - xt
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.ExtraTreesRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.8
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    - - rf_embedder
                      - call: sklearn.pipeline.Pipeline
                        params:
                          memory: null
                          steps:
                          - - rf
                            - call: deep_forest.tree_embedder.ForestEmbedder
                              params:
                                estimator:
                                  call: sklearn.ensemble._forest.RandomForestRegressor
                                  params:
                                    bootstrap: true
                                    ccp_alpha: 0.0
                                    criterion: squared_error
                                    max_depth: null
                                    max_features: sqrt
                                    max_leaf_nodes: null
                                    max_samples: 0.5
                                    min_impurity_decrease: 0.0
                                    min_samples_leaf: 5
                                    min_samples_split: 2
                                    min_weight_fraction_leaf: 0.0
                                    monotonic_cst: null
                                    n_estimators: 150
                                    n_jobs: 14
                                    oob_score: false
                                    random_state: 0
                                    verbose: true
                                    warm_start: false
                                max_node_size: 0.95
                                max_pvalue: 1.0
                                method: path
                                node_weights: log_node_size
                          - - densifier
                            - call: nakano_datasets_v2.estimators.Densifier
                              params: {}
                          - - pca
                            - call: sklearn.decomposition._pca.PCA
                              params:
                                copy: true
                                iterated_power: auto
                                n_components: 0.8
                                n_oversamples: 10
                                power_iteration_normalizer: auto
                                random_state: 0
                                svd_solver: auto
                                tol: 0.0
                                whiten: false
                          verbose: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_tree_embedder
  params: {}
hash: 669889cb0406777e77e1c990a402af4407237aa7355a04fade7d560c3058ffe2
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/669889c_20231231T132818253159_cascade_lc_tree_embedder_CAL500.yml
results:
  fit_time:
  - 301.1050775051117
  - 301.2306785583496
  - 304.8613631725311
  - 308.3269462585449
  - 311.9194824695587
  fitted_params:
    estimator.level1.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 206
    - 202
    - 207
    - 204
    - 205
    estimator.level1.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 202
    - 199
    - 202
    - 199
    - 202
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level10.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 214
    - 219
    - 225
    - 201
    - 221
    estimator.level10.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 236
    - 231
    - 237
    - 230
    - 237
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level2.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 217
    - 221
    - 205
    - 226
    estimator.level2.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 235
    - 229
    - 233
    - 232
    - 238
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level3.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 218
    - 221
    - 225
    - 206
    - 225
    estimator.level3.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 235
    - 231
    - 236
    - 233
    - 239
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level4.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 214
    - 222
    - 226
    - 203
    - 225
    estimator.level4.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 236
    - 232
    - 235
    - 231
    - 238
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level5.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 214
    - 220
    - 224
    - 202
    - 225
    estimator.level5.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 235
    - 232
    - 237
    - 231
    - 238
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level6.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 215
    - 220
    - 225
    - 200
    - 220
    estimator.level6.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 234
    - 232
    - 235
    - 231
    - 238
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level7.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 213
    - 220
    - 223
    - 201
    - 223
    estimator.level7.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 234
    - 231
    - 235
    - 231
    - 237
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level8.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 213
    - 218
    - 224
    - 199
    - 223
    estimator.level8.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 235
    - 231
    - 234
    - 230
    - 237
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
    estimator.level9.alternating_forests.column_transformer_.transformers_.rf_embedder.pca.n_components_:
    - 213
    - 219
    - 225
    - 199
    - 221
    estimator.level9.alternating_forests.column_transformer_.transformers_.xt_embedder.pca.n_components_:
    - 235
    - 230
    - 236
    - 229
    - 236
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.025594246395633763
      - 0.19796937558565464
      - 0.08693949728432486
      - 0.06273857292592991
      - 0.17990661267502955
      - 0.09249883932492627
      - 0.09281151315912553
      - 0.06190605480378207
      - 0.09161906669719169
      - 0.05825905245548103
      - 0.11139207374806452
      - 0.09702938936809906
      - 0.041137516996892
      - 0.07291323159917358
      - 0.09252913603720056
      - 0.08153101743218022
      - 0.07494222912947446
      - 0.0723226446225873
      - 0.09265318015318014
      - 0.05751877915444989
      - 0.11463820411614528
      - 0.042593754683531077
      - 0.13637965202634544
      - 0.11312232590641681
      - 0.0379859670892587
      - 0.07433482554932858
      - 0.06678198039584178
      - 0.09651290678518401
      - 0.04263096983514453
      - 0.03123501955919538
      - 0.1274102767219914
      - 0.06444822403362446
      - 0.12056154895828808
      - 0.04330732098589242
      - 0.12641068667789923
      - 0.05962050515621945
      - 0.04747558798039567
      - 0.016894800275482093
      - 0.025534839969238624
      - 0.022130248739159628
      - 0.029020754560920764
      - 0.0180197810978744
      - 0.026238930822264153
      - 0.04819890358683461
      - 0.020942696192696193
      - 0.08458792315679065
      - 0.03225838014799053
      - 0.02014552354925425
      - 0.09362470043936627
      - 0.10019072263329837
      - 0.03072188619092258
      - 0.16305727101181644
      - 0.07711074038321228
      - 0.04435973521213581
      - 0.049544658037601594
      - 0.2068846373533873
      - 0.05040014809751652
      - 0.014370932355626233
      - 0.02193718699601053
      - 0.05700586450586449
      - 0.10088939593015678
      - 0.04170367147171271
      - 0.01832046661215537
      - 0.12545831693558965
      - 0.07426146064336916
      - 0.08357801099736582
      - 0.07946512104675368
      - 0.05401672809123606
      - 0.1371387070025684
      - 0.05651257201118172
      - 0.10262049392333043
      - 0.02851896997658243
      - 0.10275508634883633
      - 0.045381751185322616
      - 0.17756575823802712
      - 0.045901363535665374
      - 0.054170976082740796
      - 0.2660348558446385
      - 0.17157989885931063
      - 0.19463533882138528
      - 0.08995521225661722
      - 0.05370961148342697
      - 0.024263311093668236
      - 0.044961356273246864
      - 0.14683092241660012
      - 0.039807075312394455
      - 0.0199284411240933
      - 0.08490205384535282
      - 0.03176595276161715
      - 0.01680543068043068
      - 0.021218007581643945
      - 0.023122134777233377
      - 0.019228529995856725
      - 0.054468940810295546
      - 0.01857224753566217
      - 0.042238432152314466
      - 0.03360284070660865
      - 0.017166180903804666
      - 0.025176157176157177
      - 0.01984747975601634
      - 0.01867883022774327
      - 0.024032482763685768
      - 0.026297593965863196
    - - 0.0328941945735424
      - 0.19759001566066775
      - 0.08839462508817347
      - 0.058967279533402715
      - 0.18440951757446117
      - 0.09134969689989972
      - 0.0963341575410541
      - 0.06504266269371592
      - 0.09924708990643052
      - 0.057990815153594055
      - 0.11137853586339863
      - 0.09292838871490555
      - 0.04025961018148518
      - 0.06666959934005388
      - 0.08819649648597017
      - 0.07841468821582456
      - 0.08553297011630345
      - 0.06087543608728444
      - 0.09734691992235095
      - 0.05151517647966512
      - 0.11717347148381631
      - 0.05214564081751581
      - 0.13482848673066067
      - 0.11350107044797986
      - 0.039169371496957706
      - 0.07111022267784803
      - 0.07380726189319939
      - 0.09407336273087163
      - 0.03809455050027366
      - 0.03221041733246305
      - 0.12828237522115069
      - 0.06521874560989177
      - 0.12408669054387998
      - 0.0498036291360155
      - 0.1374562170975348
      - 0.06073002500823545
      - 0.0575870152574698
      - 0.0164003419201188
      - 0.02832159858021927
      - 0.021777592525440446
      - 0.03159334948691324
      - 0.02045249197670928
      - 0.0161161215327882
      - 0.04181988744518967
      - 0.021226264266036993
      - 0.07869894202168845
      - 0.034954811270600745
      - 0.018667980764754958
      - 0.08931322997165242
      - 0.10137601775198674
      - 0.023611566169037437
      - 0.17533556800798183
      - 0.07605859079105004
      - 0.03710431621824027
      - 0.05136019791192205
      - 0.2020324684473036
      - 0.05097672030811566
      - 0.02188896807799247
      - 0.018326681998557
      - 0.05615290115955403
      - 0.09413579781771336
      - 0.04961184999063786
      - 0.018875960398237624
      - 0.1171237465776502
      - 0.0764127442578621
      - 0.08223994798068873
      - 0.0817612180249543
      - 0.0669460223239293
      - 0.13345387218366114
      - 0.06826446098395406
      - 0.08689523266479049
      - 0.03298917635652329
      - 0.09051701832271136
      - 0.04870315470964821
      - 0.16670980794692133
      - 0.04514116620094881
      - 0.06266752085717603
      - 0.2599281681482768
      - 0.16689594168252703
      - 0.19339152277982063
      - 0.09253096032616884
      - 0.051608842896721685
      - 0.02336211655408084
      - 0.038388449373297856
      - 0.1489207597957598
      - 0.032394204556350205
      - 0.030724022619627017
      - 0.0768274139241881
      - 0.03235988241906802
      - 0.017948695120284706
      - 0.02133189334640228
      - 0.017588369574350882
      - 0.01737471218962091
      - 0.0586933621933622
      - 0.024142127713556283
      - 0.03916808161313656
      - 0.03641348431476686
      - 0.02350195156317605
      - 0.0248243528814181
      - 0.02598664298098203
      - 0.019246399858644757
      - 0.02026065437358092
      - 0.023322156566837414
    - - 0.028435391237115373
      - 0.18771528097370788
      - 0.09282790441309186
      - 0.06610158916105209
      - 0.16898534214323685
      - 0.08896192859428154
      - 0.09586612692862691
      - 0.06980816856108005
      - 0.08472013811843719
      - 0.06738838167605152
      - 0.10510359256440761
      - 0.10281180886019595
      - 0.04187995349189881
      - 0.06758910807206261
      - 0.08908767736892739
      - 0.08306275470561184
      - 0.08026240033815793
      - 0.0675041625041625
      - 0.09023560383450495
      - 0.055677405927405936
      - 0.09989113831062768
      - 0.0472845518678852
      - 0.14266509178698256
      - 0.1092214510635563
      - 0.04467119055187237
      - 0.07211867080288133
      - 0.07141366735624086
      - 0.09569569624514679
      - 0.03397688620902907
      - 0.03220780760594462
      - 0.1333625947465233
      - 0.06110854275747893
      - 0.12498497044749599
      - 0.04364146639200518
      - 0.14199490857049352
      - 0.06111169013439978
      - 0.05986188748089048
      - 0.022049424341091008
      - 0.027765517252116775
      - 0.02138896410874433
      - 0.03234364493959678
      - 0.016082831600072976
      - 0.018632756132756136
      - 0.040594432057060925
      - 0.016585497835497835
      - 0.08172602663104626
      - 0.03570494348524651
      - 0.0175938958757762
      - 0.08544297963940821
      - 0.08980038070041257
      - 0.026312536775056714
      - 0.16544325092119208
      - 0.07057826333141384
      - 0.0339610200405655
      - 0.051408345088120366
      - 0.20002845869781347
      - 0.050871589581267
      - 0.017357871215629837
      - 0.025838833883388337
      - 0.06400191367614966
      - 0.10150065538465089
      - 0.0559451911724639
      - 0.02295830185845025
      - 0.11940155018459617
      - 0.08173974901502991
      - 0.07647738858993637
      - 0.07625974089042271
      - 0.06847034306273438
      - 0.1474164385749751
      - 0.05703474187206112
      - 0.09898031847671553
      - 0.029200945559816525
      - 0.10430341263674595
      - 0.04717320722755505
      - 0.17012138100847773
      - 0.04822142769511191
      - 0.05922719812985158
      - 0.2633622922988059
      - 0.167978792041292
      - 0.19731369335187296
      - 0.10153312744976561
      - 0.05442515373092609
      - 0.025302520547085764
      - 0.03942819245849549
      - 0.1471666462891414
      - 0.03690070362710504
      - 0.02912763183410505
      - 0.08086353844675856
      - 0.03268326821805424
      - 0.020388837353123065
      - 0.017282335011926848
      - 0.02129822603960535
      - 0.01973232705991327
      - 0.05738927437297002
      - 0.012253205817035602
      - 0.04116046552485431
      - 0.02984918450343982
      - 0.02192838466009001
      - 0.03179937878213741
      - 0.02128318819179803
      - 0.015795444869125888
      - 0.01970229180703732
      - 0.01823622166364102
    - - 0.026756883388033274
      - 0.19651115979389222
      - 0.0953404799335032
      - 0.059724978534797746
      - 0.172446978469887
      - 0.08980863979312503
      - 0.09756312281822485
      - 0.05990007783211255
      - 0.09682422020969977
      - 0.061244688474369605
      - 0.11142142601092492
      - 0.09441971608638275
      - 0.049252420559238744
      - 0.07535096107230495
      - 0.08626682430036087
      - 0.0786032515372275
      - 0.08592559656953597
      - 0.06195730836819946
      - 0.10427602834517725
      - 0.04654441856326896
      - 0.11648239015886072
      - 0.04394408398314649
      - 0.1412871004334419
      - 0.10732546510507035
      - 0.041044493879545424
      - 0.07162766658000341
      - 0.07052780667408899
      - 0.09536116709602441
      - 0.03710600774484839
      - 0.03513708513708514
      - 0.13378595202048807
      - 0.06222883019758019
      - 0.1296053092604129
      - 0.04162978687978687
      - 0.1350117019018403
      - 0.05235354922854922
      - 0.05631102667619521
      - 0.016295131222340057
      - 0.023965494863932367
      - 0.01643672459405218
      - 0.037347652347652346
      - 0.01654676722644219
      - 0.019084915373977874
      - 0.03539367040787495
      - 0.018947385032549866
      - 0.08463684541136694
      - 0.03288915762599973
      - 0.01867358185292968
      - 0.08864615020516137
      - 0.09960594960594961
      - 0.02294286063620113
      - 0.16923113455877564
      - 0.06831158340304681
      - 0.04400019172746446
      - 0.053677871835766576
      - 0.2069485908148698
      - 0.046424094224055135
      - 0.019686742214693093
      - 0.02255188567832577
      - 0.0590276156115687
      - 0.09500743408638143
      - 0.049888334853994194
      - 0.020702613159509713
      - 0.11545147823556912
      - 0.08632059550426896
      - 0.08337279946554658
      - 0.073077433422261
      - 0.06474337148494452
      - 0.14309975738547162
      - 0.05478160371874034
      - 0.10117576569189471
      - 0.032459403313995154
      - 0.10268476369825151
      - 0.04906522008084509
      - 0.16580765639589168
      - 0.051335210822968554
      - 0.06156321642337428
      - 0.2720502811794946
      - 0.16992964585049222
      - 0.19484349267512532
      - 0.09509795759795758
      - 0.05293466241046887
      - 0.028474822580962227
      - 0.04012916401530263
      - 0.14911394711943463
      - 0.03785533988265081
      - 0.021050501304283847
      - 0.08725405404095393
      - 0.03086340742590743
      - 0.020138003411991415
      - 0.02156970541279052
      - 0.020580229955229956
      - 0.018597118461248896
      - 0.05923802899609351
      - 0.019343590352571292
      - 0.04217457100979828
      - 0.037744662744662746
      - 0.01812021312021312
      - 0.0298371219423851
      - 0.027172842254363998
      - 0.02699519356145862
      - 0.02117721688034188
      - 0.021120649445117528
    - - 0.028589564195624802
      - 0.19639884381263692
      - 0.09106383596742035
      - 0.06375703890396764
      - 0.1759261422611443
      - 0.08954341341389532
      - 0.09181643272552359
      - 0.06730046315082891
      - 0.08166887518859077
      - 0.0569402585554271
      - 0.1092940874055425
      - 0.0969913519020662
      - 0.042040940742178554
      - 0.06930829907963351
      - 0.09301195104947638
      - 0.07897040663050353
      - 0.0719798896886895
      - 0.07201830972756193
      - 0.10092063334987862
      - 0.05362213419144113
      - 0.11727919680876667
      - 0.040312398723807645
      - 0.1402728444395111
      - 0.11233243880302704
      - 0.040054324606211396
      - 0.07222950795461874
      - 0.0681045438147711
      - 0.09651711113907405
      - 0.037675579914590904
      - 0.03574578929842087
      - 0.13383815384925085
      - 0.06317283270919152
      - 0.12286034398188547
      - 0.044242988194601096
      - 0.12743842331910513
      - 0.06477498884492931
      - 0.045669962425281575
      - 0.019028855882304158
      - 0.03918878795985537
      - 0.015916700710515146
      - 0.037835741359953615
      - 0.018143199393199395
      - 0.021139178282035424
      - 0.04152513084012277
      - 0.02072887430030287
      - 0.08126063331378848
      - 0.029511850252921683
      - 0.016583642806468894
      - 0.08791527810254832
      - 0.10065218872037053
      - 0.02444761033470711
      - 0.16141371383718325
      - 0.07165842364706
      - 0.035853024210920084
      - 0.0564108486364584
      - 0.20263180632498806
      - 0.05248723212640738
      - 0.015029716286846077
      - 0.023502507593416686
      - 0.059915511862790774
      - 0.10220469185986426
      - 0.04705449940598456
      - 0.018642316017316016
      - 0.11986225008203027
      - 0.07802924945994873
      - 0.08199259148457008
      - 0.07707941663140022
      - 0.0700374682873359
      - 0.13749584839090356
      - 0.057610634820939546
      - 0.09951472262149179
      - 0.03301228404101075
      - 0.10186530915407876
      - 0.04038327312947496
      - 0.1780915871277317
      - 0.04785372488229897
      - 0.059483770198055924
      - 0.2646376331788197
      - 0.16951612113376813
      - 0.19086706252403923
      - 0.09630074533052987
      - 0.04767896441324433
      - 0.019888784223023353
      - 0.04071080292990406
      - 0.1447503454400006
      - 0.03580581833132854
      - 0.02525414996804423
      - 0.0763571556408635
      - 0.029475759375870703
      - 0.023962290288856256
      - 0.019051082233265217
      - 0.02149884259259259
      - 0.018468552922334434
      - 0.05818807261114954
      - 0.017699115420942914
      - 0.03846752219128531
      - 0.028398534488792544
      - 0.026599818006068005
      - 0.021689319485078414
      - 0.023554001597390288
      - 0.021260027253942063
      - 0.025911580787954414
      - 0.026220606213090022
  score_time:
  - 8.170634746551514
  - 8.190736055374146
  - 8.268506526947021
  - 8.2676682472229
  - 8.471945762634277
  test_level0__average_precision_macro:
  - 0.3058433906365013
  - 0.31545178727610484
  - 0.29906053975493935
  - 0.29425008502727285
  - 0.3214673697797739
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.4925855870386707
  - 0.5031570161463907
  - 0.49833420946598755
  - 0.47549470792147397
  - 0.5046227844003229
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.5254601111365677
  - 0.5341261550195898
  - 0.5294694909289495
  - 0.5096559411689007
  - 0.5389590344234418
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.41532200209421644
  - 0.43589621898783615
  - 0.4187270126532955
  - 0.40396922596190576
  - 0.4430007805281345
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7675728155339804
  - 0.7612957430918597
  - 0.7612443035466614
  - 0.7725656060751704
  - 0.767284495439835
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7675728155339806
  - 0.7612957430918595
  - 0.7612443035466614
  - 0.7725656060751707
  - 0.7672844954398352
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7675728155339805
  - 0.7612957430918594
  - 0.7612443035466613
  - 0.7725656060751706
  - 0.7672844954398351
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.6522639933166248
  - 0.6412224361481302
  - 0.6438225082564146
  - 0.6576500422654268
  - 0.6505510222324382
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.2324271844660194
  - -0.2387042569081404
  - -0.23875569645333863
  - -0.2274343939248294
  - -0.2327155045601647
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.23242718446601943
  - -0.2387042569081404
  - -0.2387556964533386
  - -0.22743439392482936
  - -0.23271550456016477
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.2324271844660194
  - -0.23870425690814034
  - -0.23875569645333858
  - -0.22743439392482936
  - -0.2327155045601647
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.3477360066833752
  - -0.35877756385186965
  - -0.3561774917435854
  - -0.34234995773457316
  - -0.3494489777675619
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6480701889791989
  - 0.6412670153486609
  - 0.6408536797252297
  - 0.6545135814614792
  - 0.6482037803548129
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.6228139278399244
  - 0.6145903986736001
  - 0.6145233525271913
  - 0.6294149894275197
  - 0.6224343675417661
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6258671488513246
  - 0.6172472250029764
  - 0.6171628262475357
  - 0.6316676008986591
  - 0.6252840204734098
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5141508160042816
  - 0.5028344667912169
  - 0.5042418908105942
  - 0.5190596838783731
  - 0.5117008224702797
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5254601111365674
  - 0.53412615501959
  - 0.5294694909289493
  - 0.5096559411689006
  - 0.5389590344234417
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8232397292357788
  - 0.8260190989835863
  - 0.8260121774497827
  - 0.814584489678127
  - 0.8269843407776118
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -90.32
  - -89.58653846153847
  - -90.72448979591837
  - -89.95049504950495
  - -89.60606060606061
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.2324271844660194
  - -0.2387042569081404
  - -0.23875569645333863
  - -0.2274343939248294
  - -0.2327155045601647
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.23242718446601943
  - -0.2387042569081404
  - -0.2387556964533386
  - -0.22743439392482936
  - -0.23271550456016477
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.2324271844660194
  - -0.23870425690814034
  - -0.23875569645333858
  - -0.22743439392482936
  - -0.2327155045601647
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.3477360066833752
  - -0.35877756385186965
  - -0.3561774917435854
  - -0.34234995773457316
  - -0.3494489777675619
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.2570033752244823
  - -0.2526627032668707
  - -0.2571624465970953
  - -0.26284492007169685
  - -0.24664783112101676
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7675728155339804
  - 0.7612957430918597
  - 0.7612443035466614
  - 0.7725656060751704
  - 0.767284495439835
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7675728155339806
  - 0.7612957430918595
  - 0.7612443035466614
  - 0.7725656060751707
  - 0.7672844954398352
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7675728155339805
  - 0.7612957430918594
  - 0.7612443035466613
  - 0.7725656060751706
  - 0.7672844954398351
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.6522639933166248
  - 0.6412224361481302
  - 0.6438225082564146
  - 0.6576500422654268
  - 0.6505510222324382
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7675728155339804
  - 0.7612957430918597
  - 0.7612443035466614
  - 0.7725656060751704
  - 0.767284495439835
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7675728155339806
  - 0.7612957430918595
  - 0.7612443035466614
  - 0.7725656060751707
  - 0.7672844954398352
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7675728155339805
  - 0.7612957430918594
  - 0.7612443035466613
  - 0.7725656060751706
  - 0.7672844954398351
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.6522639933166248
  - 0.6412224361481302
  - 0.6438225082564146
  - 0.6576500422654268
  - 0.6505510222324382
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5697464713711908
  - 0.5690528882418843
  - 0.5476875873338601
  - 0.5509773887309252
  - 0.5668436337100671
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7405551149143623
  - 0.7431832933817725
  - 0.7404538395242797
  - 0.7352285830190904
  - 0.7483157703785861
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7429966247755178
  - 0.7473372967331292
  - 0.7428375534029045
  - 0.7371550799283032
  - 0.7533521688789832
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5669999293616015
  - 0.5667479865350028
  - 0.5540279377362151
  - 0.5425029533042023
  - 0.5746694227459965
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7675728155339804
  - 0.7612957430918597
  - 0.7612443035466614
  - 0.7725656060751704
  - 0.767284495439835
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7675728155339806
  - 0.7612957430918595
  - 0.7612443035466614
  - 0.7725656060751707
  - 0.7672844954398352
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7675728155339805
  - 0.7612957430918594
  - 0.7612443035466613
  - 0.7725656060751706
  - 0.7672844954398351
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.6522639933166248
  - 0.6412224361481302
  - 0.6438225082564146
  - 0.6576500422654268
  - 0.6505510222324382
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.24582255954604496
  - 0.26114462904219576
  - 0.2520647619559148
  - 0.23542251490649438
  - 0.2443652184156815
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.20764901102302233
  - 0.22997349542163228
  - 0.2284542783746186
  - 0.2053084661019213
  - 0.2160115123757101
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.21210287017355206
  - 0.23298442299081135
  - 0.23143472070943064
  - 0.20753748682888698
  - 0.2196975561610185
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.3634126468366716
  - 0.3881459694488277
  - 0.3693435379101048
  - 0.3476222696735967
  - 0.36307357043951777
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.21210287017355203
  - 0.23298442299081132
  - 0.23143472070943072
  - 0.20753748682888698
  - 0.2196975561610185
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6003900354884552
  - 0.6227293908426268
  - 0.6217878300748935
  - 0.6010641693600824
  - 0.6088921357788183
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -98.63
  - -97.29807692307692
  - -98.81632653061224
  - -100.02970297029702
  - -98.07070707070707
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.7976375541778528
  - -0.7417254224560459
  - -0.7436559142106343
  - -0.811619663371619
  - -0.7969601856294564
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5077897715628767
  - 0.521877945532538
  - 0.5080499415957194
  - 0.5040030021585117
  - 0.5053195334700012
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.44039049263262714
  - 0.4850189439216279
  - 0.4780028987322906
  - 0.4413905477950614
  - 0.460633085056235
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.43523595919761976
  - 0.4855127906827498
  - 0.4778772145240773
  - 0.4399977172807991
  - 0.4562753268630422
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5093611876171262
  - 0.5300461328419253
  - 0.5080906727555757
  - 0.49324270589961344
  - 0.5107396320719862
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.24915734741898962
  - 0.2633185578939728
  - 0.260967810174423
  - 0.2442871205734237
  - 0.2517918410366649
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.22579299230127642
  - 0.24546352729634974
  - 0.25715638375032324
  - 0.2234283816129926
  - 0.2395763687402873
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.2309926472272434
  - 0.24935031339151234
  - 0.2617994097599059
  - 0.22645980089926365
  - 0.24460101004571388
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.3630195212745542
  - 0.3847377241514716
  - 0.37385286476345525
  - 0.35550913130292333
  - 0.36705871537757584
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.23099264722724328
  - 0.24935031339151242
  - 0.2617994097599058
  - 0.22645980089926362
  - 0.24460101004571397
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.6172218352980827
  - 0.6370591171281098
  - 0.6476922235727244
  - 0.6185006668127576
  - 0.6294398506453993
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -98.43
  - -97.0673076923077
  - -99.06122448979592
  - -100.0990099009901
  - -98.02020202020202
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.687253732387975
  - -0.6638148340598311
  - -0.6177007393755243
  - -0.6914712324268726
  - -0.6683351444949268
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5145957917770035
  - 0.5276001467147301
  - 0.5168785821766944
  - 0.5073425053383596
  - 0.5130519580575837
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.48287350786951355
  - 0.5139576694888126
  - 0.5282709018686239
  - 0.48104831826513283
  - 0.513905801204243
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.47723198680280726
  - 0.5147586320994145
  - 0.5289237465155628
  - 0.4792362939042246
  - 0.5097648834740587
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5106396011594583
  - 0.5263682979232013
  - 0.5126721724186261
  - 0.5015624603827399
  - 0.5157084762855505
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.24671127308788915
  - 0.26396960346007275
  - 0.25298653904655005
  - 0.23726177637241633
  - 0.2459683336785936
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.20756217700313867
  - 0.22988688618870196
  - 0.22890315131373445
  - 0.2052826783122985
  - 0.21548914458276214
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.21205245481554091
  - 0.23287086409162475
  - 0.23185029978080632
  - 0.20755132670639434
  - 0.21909731444890027
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.36301082057046224
  - 0.3905913511622063
  - 0.37027157744484407
  - 0.35032770763948634
  - 0.3665952546238045
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.21205245481554091
  - 0.23287086409162486
  - 0.2318502997808063
  - 0.20755132670639434
  - 0.2190973144489003
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6002572094254688
  - 0.6226931537293521
  - 0.6221201650233354
  - 0.6010676750375135
  - 0.6084282562990267
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -98.48
  - -97.36538461538461
  - -98.55102040816327
  - -100.34653465346534
  - -98.16161616161617
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.796842701685557
  - -0.7424841718683569
  - -0.743094737331963
  - -0.8117739216554102
  - -0.7954742466219809
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5060466496680746
  - 0.5232534982695334
  - 0.5108088779762299
  - 0.5053255420613847
  - 0.5098945993174077
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.4402757621349098
  - 0.48448451935958253
  - 0.47922630091951596
  - 0.4411002589355591
  - 0.4594365926058064
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.4351666640206881
  - 0.4848457302613815
  - 0.4788887834113591
  - 0.4396171423430406
  - 0.4550781531660464
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5079158427531467
  - 0.5292212981381269
  - 0.5113126386264355
  - 0.4976596172876076
  - 0.5149791012036564
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.24843773804672903
  - 0.26456403724324606
  - 0.2547512147409718
  - 0.23308090013279678
  - 0.24266124810726714
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.2075624511975407
  - 0.22985294883300472
  - 0.22878418291115127
  - 0.20469811747161992
  - 0.21571276668684627
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.21203190840786956
  - 0.2327932398477967
  - 0.23166966632713396
  - 0.2069008138441999
  - 0.21953274983308457
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.3674683398808024
  - 0.39240387679163163
  - 0.3721815914453013
  - 0.3461635101822917
  - 0.3650809083175932
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.21203190840786956
  - 0.23279323984779673
  - 0.2316696663271339
  - 0.20690081384419995
  - 0.2195327498330845
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.6002175480447295
  - 0.6226373198147619
  - 0.622007774255231
  - 0.6005055880442036
  - 0.6085710566148348
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -98.85
  - -97.4326923076923
  - -99.11224489795919
  - -99.89108910891089
  - -98.12121212121212
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.7962503478601203
  - -0.7426480349540588
  - -0.743574962988293
  - -0.8112027430634385
  - -0.7957645814242433
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5102638178312932
  - 0.5219354437255721
  - 0.5095081588803341
  - 0.5055464619095361
  - 0.5078202522695835
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.44047172594611583
  - 0.48449897817198884
  - 0.4788095271523952
  - 0.4397476811336748
  - 0.459809740761136
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.43532093721011966
  - 0.48459017818473693
  - 0.4782725815613529
  - 0.43826227762413944
  - 0.4552719723161949
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.5147598374750368
  - 0.5304144754513058
  - 0.5099045796029386
  - 0.499161391041662
  - 0.5156116447628111
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.24467098340463153
  - 0.2611588856878862
  - 0.25505373807401394
  - 0.23628466876918702
  - 0.25119616847186543
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.20790837318616945
  - 0.22982028460866616
  - 0.22862987857496575
  - 0.20437036056121877
  - 0.21651314322739168
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.21238166739526204
  - 0.23288034780823155
  - 0.2316420203704894
  - 0.2066323892144417
  - 0.22000302807827382
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.36247161885029455
  - 0.38696141589057204
  - 0.3710278883323952
  - 0.35170397398968356
  - 0.3720721537259716
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.21238166739526207
  - 0.23288034780823155
  - 0.23164202037048937
  - 0.2066323892144416
  - 0.22000302807827393
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6005867173951756
  - 0.6226678837333792
  - 0.6218477598961786
  - 0.6001053571993656
  - 0.6092136124882571
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -98.65
  - -97.35576923076923
  - -98.60204081632654
  - -100.14851485148515
  - -98.07070707070707
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.796663049125392
  - -0.7423229076259641
  - -0.7438465978547038
  - -0.8115219116660984
  - -0.7964163475826727
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5106936823556463
  - 0.520176278910767
  - 0.5155103497955034
  - 0.5017973393562363
  - 0.5089485496806004
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.44128368923827405
  - 0.4843627584153045
  - 0.4787059817133625
  - 0.4390486213856013
  - 0.46212850537359185
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.43634677566202335
  - 0.4849153055128315
  - 0.47831785745503724
  - 0.4376598268245455
  - 0.45761679480010825
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5112407629968807
  - 0.5238962201957214
  - 0.5135520007594773
  - 0.4969834409193476
  - 0.5165048097895235
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.24737967823509516
  - 0.2638665720975497
  - 0.25283607319810164
  - 0.23641791646034788
  - 0.24414438164062674
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.20769448387163414
  - 0.2298025894308633
  - 0.2288332056993511
  - 0.20459807199935226
  - 0.2159282474972879
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.21206609191243986
  - 0.23281574049278458
  - 0.2317793394992862
  - 0.2067518740591156
  - 0.219634507122477
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.3661993595215244
  - 0.38823088860892835
  - 0.3700753473278245
  - 0.3511409519699345
  - 0.3655315037194151
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.21206609191243986
  - 0.2328157404927846
  - 0.23177933949928628
  - 0.2067518740591156
  - 0.219634507122477
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.600301672689922
  - 0.6226365609009631
  - 0.6220052554031957
  - 0.6002850779212733
  - 0.6086869950854698
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -98.51
  - -97.17307692307692
  - -99.05102040816327
  - -100.02970297029702
  - -98.14141414141415
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.7967436376129536
  - -0.7425259675818098
  - -0.7433852055151101
  - -0.8113275777446662
  - -0.7942185998634747
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5140343104682105
  - 0.5234304891892986
  - 0.5114176892251658
  - 0.5049811471131335
  - 0.5071902981387142
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.44075111570984127
  - 0.4843253525324621
  - 0.4791709506848309
  - 0.4397063465243325
  - 0.46071460349345955
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.43540839445881196
  - 0.4847488258245442
  - 0.4787926618087219
  - 0.4380687352638962
  - 0.4561972330287446
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5167626294179416
  - 0.5277296048318323
  - 0.5112103021590177
  - 0.5007087863779064
  - 0.5140908953796125
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.24929036554181067
  - 0.26758197387236626
  - 0.2530984520630235
  - 0.23830506897287376
  - 0.24274072658250065
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.20793931404685503
  - 0.2299887373685761
  - 0.2288868883027464
  - 0.20531365523043335
  - 0.21597255602551732
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.21237159177492845
  - 0.2329270007146523
  - 0.23181557584792936
  - 0.20752497469511022
  - 0.21959370796107794
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.36900950020204226
  - 0.39140067051582683
  - 0.37109907284682114
  - 0.3534890879792367
  - 0.36257366614897824
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.21237159177492831
  - 0.2329270007146522
  - 0.23181557584792936
  - 0.20752497469511022
  - 0.21959370796107794
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6006042998246222
  - 0.6226811348146565
  - 0.6220798219633286
  - 0.6009933064589287
  - 0.6089700020790841
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -98.44
  - -97.22115384615384
  - -98.71428571428571
  - -99.82178217821782
  - -98.17171717171718
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.7965589634942587
  - -0.742042640742574
  - -0.7427129238410213
  - -0.8118646840533377
  - -0.7963471955045256
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5117513482610548
  - 0.5273329733073207
  - 0.5104493584764191
  - 0.5097092585410073
  - 0.5064702993732296
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.4413320329663014
  - 0.4851572018193646
  - 0.47909877937882456
  - 0.4416679787512762
  - 0.46055022009708746
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.4360645006485114
  - 0.4852358978675817
  - 0.4786299535404571
  - 0.44024507265459456
  - 0.45641698530707303
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5154188946822638
  - 0.5320125324466449
  - 0.5105329559507581
  - 0.5052289939054074
  - 0.5095044550813176
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.2520644679293662
  - 0.2608623003647248
  - 0.2522477337669071
  - 0.23485046830727174
  - 0.24341803307817142
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.20769950812138877
  - 0.22977872029768562
  - 0.22888294982873358
  - 0.20526897622483004
  - 0.21589615348705374
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.2121624732388768
  - 0.2328261753870954
  - 0.2318941735477032
  - 0.20749338948185025
  - 0.21953398971450816
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.37250486273720357
  - 0.3860992366416092
  - 0.37033016793843765
  - 0.3507603094666227
  - 0.36473634487042106
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.2121624732388768
  - 0.23282617538709552
  - 0.23189417354770325
  - 0.20749338948185028
  - 0.21953398971450808
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.6002981775254687
  - 0.6226487334380592
  - 0.6221036847668395
  - 0.6010101573070421
  - 0.6087631793953258
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -98.45
  - -97.26923076923077
  - -98.81632653061224
  - -100.17821782178218
  - -97.93939393939394
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.796276060450444
  - -0.7424954633408564
  - -0.7423117703148443
  - -0.8119443909137298
  - -0.7948454250857129
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5110385850425071
  - 0.5196108598792732
  - 0.5108840342404567
  - 0.5054572245475419
  - 0.5088480569733177
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.44089395425489264
  - 0.4841821311618099
  - 0.4792236819084113
  - 0.4412745637226644
  - 0.46049541665481725
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.4356431195914085
  - 0.4847427497979393
  - 0.4791429332437798
  - 0.4396628962252061
  - 0.4560977697011342
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5137240847242143
  - 0.5263779438769055
  - 0.5129000753032105
  - 0.5012355746538246
  - 0.5157914978176906
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.24897226335857364
  - 0.2587332675581753
  - 0.2530597222133874
  - 0.23626853541575368
  - 0.24417294057804295
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.20766148111349741
  - 0.22976087533805245
  - 0.22890676809738458
  - 0.20472332551319014
  - 0.21618687073408874
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.21205777095993286
  - 0.23277627164244516
  - 0.23182498832283943
  - 0.20696772188057547
  - 0.21986290682419474
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.3667795782928913
  - 0.38492434016099486
  - 0.3713999034435402
  - 0.3497395764141037
  - 0.36444177869778344
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.21205777095993283
  - 0.23277627164244516
  - 0.23182498832283935
  - 0.20696772188057547
  - 0.21986290682419476
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6003282538200798
  - 0.6226444416595509
  - 0.62211895060888
  - 0.6005429481909128
  - 0.6089550003970288
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -98.78
  - -97.4423076923077
  - -99.0
  - -100.20792079207921
  - -98.08080808080808
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.7973774085416423
  - -0.7430313523865636
  - -0.7437816638256043
  - -0.8136628679704864
  - -0.7975206274381276
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5094042566936048
  - 0.5182322744478784
  - 0.508780961899738
  - 0.5052011751541245
  - 0.5082441379257095
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.44069920564122167
  - 0.48393230302505696
  - 0.47887724343951227
  - 0.43983971111630693
  - 0.46116582298989056
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.4352599026777135
  - 0.4843088421042134
  - 0.4783704341045118
  - 0.4384184367738002
  - 0.45667637411734424
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5119955605681311
  - 0.5252479718298143
  - 0.5093949249143817
  - 0.49907798958987
  - 0.5129124823522018
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.24407493444852732
  - 0.2637477014010501
  - 0.24599709996321592
  - 0.23409811043375103
  - 0.2430393815696942
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.20745811763562355
  - 0.22984072378874876
  - 0.22852607869057648
  - 0.20455474231931708
  - 0.21606835671425706
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.2119955550304893
  - 0.2328777992367888
  - 0.23153028367603143
  - 0.20677166534411803
  - 0.2197069041808335
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.3622229968899003
  - 0.38751923201799054
  - 0.36312824896349755
  - 0.3474670135583023
  - 0.36341766468387265
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.14305069396488806
  - 0.14801091519175236
  - 0.14759608518017991
  - 0.1393995848571863
  - 0.14326345981880773
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.13149511150170273
  - 0.13552764085440186
  - 0.13556080548993138
  - 0.12830802603036875
  - 0.1316797070084901
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.13255048870416106
  - 0.1364663887053711
  - 0.13648687722860453
  - 0.12907283880268022
  - 0.1326656403812211
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.23092911264690635
  - 0.24011961168091614
  - 0.2363774969367106
  - 0.22584436286501178
  - 0.23123261674874193
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.21199555503048947
  - 0.23287779923678886
  - 0.23153028367603143
  - 0.206771665344118
  - 0.2197069041808334
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.60020609975583
  - 0.6227127295926628
  - 0.6219206316257395
  - 0.6003714481485812
  - 0.6088460980834159
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -98.93
  - -97.38461538461539
  - -98.87755102040816
  - -100.33663366336634
  - -98.01010101010101
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.7675728155339804
  - -0.7612957430918597
  - -0.7612443035466614
  - -0.7725656060751704
  - -0.767284495439835
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.7675728155339806
  - -0.7612957430918595
  - -0.7612443035466614
  - -0.7725656060751707
  - -0.7672844954398352
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.7675728155339805
  - -0.7612957430918594
  - -0.7612443035466613
  - -0.7725656060751706
  - -0.7672844954398351
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.6522639933166248
  - -0.6412224361481302
  - -0.6438225082564146
  - -0.6576500422654268
  - -0.6505510222324382
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.7968060738440081
  - -0.742552010951166
  - -0.7448181982692277
  - -0.8148211766786967
  - -0.7942887581212379
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5089255475562179
  - 0.5201139402275854
  - 0.5062416949756303
  - 0.5031587318213369
  - 0.5093486228244047
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.4399225887469327
  - 0.48429691447025003
  - 0.47772128753825915
  - 0.439102629838266
  - 0.4612770457007387
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.43501980374796645
  - 0.4848325232578637
  - 0.47756910697703037
  - 0.4375080097259033
  - 0.45692841512463694
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5094413917325324
  - 0.5249747861955183
  - 0.5051692177961888
  - 0.4974042969436609
  - 0.5145649695203628
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.2324271844660194
  - 0.2387042569081404
  - 0.23875569645333863
  - 0.2274343939248294
  - 0.2327155045601647
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.23242718446601943
  - 0.2387042569081404
  - 0.2387556964533386
  - 0.22743439392482936
  - 0.23271550456016477
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.2324271844660194
  - 0.23870425690814034
  - 0.23875569645333858
  - 0.22743439392482936
  - 0.2327155045601647
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.3477360066833752
  - 0.35877756385186965
  - 0.3561774917435854
  - 0.34234995773457316
  - 0.3494489777675619
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.5730811984802276
  - 0.5658491320755823
  - 0.5738859111903967
  - 0.5703983113885552
  - 0.566113077171042
  train_level0__average_precision_macro_masked:
  - 0.24523899378999414
  - 0.24233706458172916
  - 0.25097917704678374
  - 0.24701818936830242
  - 0.23869434776927878
  train_level0__average_precision_macro_oob:
  - 0.2667718984890723
  - 0.26517394033451186
  - 0.26974315080548744
  - 0.2724188812258145
  - 0.26078855910251314
  train_level0__average_precision_micro:
  - 0.6261819215380389
  - 0.6216417653431701
  - 0.6274405515379573
  - 0.6267006944062037
  - 0.6229146669086847
  train_level0__average_precision_micro_masked:
  - 0.42806111480977327
  - 0.425131271982797
  - 0.42925038943412896
  - 0.43033603405286613
  - 0.4254738733502425
  train_level0__average_precision_micro_oob:
  - 0.4903434572182274
  - 0.4870293520083694
  - 0.4895907616168517
  - 0.49451893314762374
  - 0.4868397693803559
  train_level0__average_precision_samples:
  - 0.6434470505520131
  - 0.6379996421824838
  - 0.6425539627158569
  - 0.6425566311839974
  - 0.6358208201987406
  train_level0__average_precision_samples_masked:
  - 0.47746072905122117
  - 0.46966024935303247
  - 0.47779777466285134
  - 0.4759986250725754
  - 0.469182578831956
  train_level0__average_precision_samples_oob:
  - 0.5260194311800065
  - 0.520312763689202
  - 0.5241827047064005
  - 0.5287288958570615
  - 0.5194135863151054
  train_level0__average_precision_weighted:
  - 0.6496199401847297
  - 0.6459946703309963
  - 0.6513793521298754
  - 0.6484404018347572
  - 0.6449684028065906
  train_level0__average_precision_weighted_masked:
  - 0.3486917883413853
  - 0.3509407021246543
  - 0.355715490318017
  - 0.35369815891932493
  - 0.3442677707126013
  train_level0__average_precision_weighted_oob:
  - 0.3816961493312692
  - 0.38229379007131575
  - 0.3850555014628802
  - 0.3908401043414112
  - 0.37641816965567026
  train_level0__f1_macro:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__f1_macro_masked:
  - 0.8170050513327435
  - 0.8184411720624812
  - 0.8182531112463574
  - 0.81580843349988
  - 0.8171390813319128
  train_level0__f1_macro_oob:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__f1_micro:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__f1_micro_masked:
  - 0.8245545584601378
  - 0.8258974291641501
  - 0.8257113295395758
  - 0.8234388857008712
  - 0.8246497145822522
  train_level0__f1_micro_oob:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__f1_samples:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__f1_samples_masked:
  - 0.8244115475296873
  - 0.8256965990295021
  - 0.825503244588075
  - 0.8231972656305474
  - 0.8244081521463956
  train_level0__f1_samples_oob:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__f1_weighted:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__f1_weighted_masked:
  - 0.7166371179006432
  - 0.7185449109925119
  - 0.7182022906644027
  - 0.7150399040463621
  - 0.7171362967539634
  train_level0__f1_weighted_oob:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__fn_macro:
  - -0.23441047191228326
  - -0.23279016441430453
  - -0.23286551956166493
  - -0.23567295353848383
  - -0.23433472259028154
  train_level0__fn_macro_masked:
  - -0.1829949486672564
  - -0.18155882793751882
  - -0.18174688875364242
  - -0.18419156650012
  - -0.18286091866808707
  train_level0__fn_macro_oob:
  - -0.23441047191228326
  - -0.23279016441430453
  - -0.23286551956166493
  - -0.23567295353848383
  - -0.23433472259028154
  train_level0__fn_micro:
  - -0.23441047191228323
  - -0.23279016441430453
  - -0.2328655195616649
  - -0.2356729535384839
  - -0.23433472259028162
  train_level0__fn_micro_masked:
  - -0.17544544153986213
  - -0.1741025708358499
  - -0.1742886704604242
  - -0.1765611142991288
  - -0.1753502854177478
  train_level0__fn_micro_oob:
  - -0.23441047191228323
  - -0.23279016441430453
  - -0.2328655195616649
  - -0.2356729535384839
  - -0.23433472259028162
  train_level0__fn_samples:
  - -0.23441047191228317
  - -0.23279016441430447
  - -0.23286551956166482
  - -0.2356729535384838
  - -0.23433472259028157
  train_level0__fn_samples_masked:
  - -0.17558845247031268
  - -0.17430340097049793
  - -0.17449675541192497
  - -0.1768027343694526
  - -0.17559184785360443
  train_level0__fn_samples_oob:
  - -0.23441047191228317
  - -0.23279016441430447
  - -0.23286551956166482
  - -0.2356729535384838
  - -0.23433472259028157
  train_level0__fn_weighted:
  - -0.34746830446982074
  - -0.3453832612712519
  - -0.3454653669701335
  - -0.34916766026171475
  - -0.3468004054101283
  train_level0__fn_weighted_masked:
  - -0.28336288209935684
  - -0.2814550890074879
  - -0.2817977093355973
  - -0.28496009595363786
  - -0.2828637032460365
  train_level0__fn_weighted_oob:
  - -0.34746830446982074
  - -0.3453832612712519
  - -0.3454653669701335
  - -0.34916766026171475
  - -0.3468004054101283
  train_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__jaccard_macro:
  - 0.64513302592101
  - 0.6470500486321379
  - 0.6469172874526542
  - 0.6436103018112573
  - 0.6450496210834301
  train_level0__jaccard_macro_masked:
  - 0.7121404475268214
  - 0.7139667026521401
  - 0.7137156464705667
  - 0.7105834696714857
  - 0.7122029689766849
  train_level0__jaccard_macro_oob:
  - 0.64513302592101
  - 0.6470500486321379
  - 0.6469172874526542
  - 0.6436103018112573
  - 0.6450496210834301
  train_level0__jaccard_micro:
  - 0.6202066051025199
  - 0.6223361101767022
  - 0.6222369498265174
  - 0.6185512471344319
  - 0.6203060348192677
  train_level0__jaccard_micro_masked:
  - 0.7014826289001992
  - 0.7034286864529982
  - 0.7031587294594476
  - 0.6998691999024542
  - 0.7016203805907546
  train_level0__jaccard_micro_oob:
  - 0.6202066051025199
  - 0.6223361101767022
  - 0.6222369498265174
  - 0.6185512471344319
  - 0.6203060348192677
  train_level0__jaccard_samples:
  - 0.6228288907716423
  - 0.6250507979271936
  - 0.624955376245233
  - 0.6213603523305936
  - 0.6229796797728662
  train_level0__jaccard_samples_masked:
  - 0.7038577145518069
  - 0.7057528830038229
  - 0.7053411523000732
  - 0.7020786131569574
  - 0.7036332138190132
  train_level0__jaccard_samples_oob:
  - 0.6228288907716423
  - 0.6250507979271936
  - 0.624955376245233
  - 0.6213603523305936
  - 0.6229796797728662
  train_level0__jaccard_weighted:
  - 0.513869969989147
  - 0.5161720953970599
  - 0.5162515825098195
  - 0.5122214612995313
  - 0.5147152542868204
  train_level0__jaccard_weighted_masked:
  - 0.587218930087527
  - 0.5895557447265387
  - 0.589418608315301
  - 0.5855700152517102
  - 0.5880916861864612
  train_level0__jaccard_weighted_oob:
  - 0.513869969989147
  - 0.5161720953970599
  - 0.5162515825098195
  - 0.5122214612995313
  - 0.5147152542868204
  train_level0__label_ranking_average_precision_score:
  - 0.6434470505520126
  - 0.6379996421824835
  - 0.6425539627158572
  - 0.6425566311839982
  - 0.6358208201987409
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5260194311800064
  - 0.5203127636892025
  - 0.5241827047064004
  - 0.5287288958570615
  - 0.519413586315105
  train_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__ndcg:
  - 0.881350659607343
  - 0.8795979005827732
  - 0.8799563644684475
  - 0.8817345418390278
  - 0.877623391774538
  train_level0__ndcg_oob:
  - 0.8227408779974221
  - 0.8196517284562125
  - 0.8217223758213021
  - 0.8244517527183188
  - 0.8194040624105133
  train_level0__neg_coverage_error:
  - -83.1542288557214
  - -84.05025125628141
  - -83.73762376237623
  - -84.67331670822942
  - -85.08684863523573
  train_level0__neg_coverage_error_oob:
  - -90.30099502487562
  - -89.13316582914572
  - -89.75742574257426
  - -89.9426433915212
  - -90.92555831265508
  train_level0__neg_hamming_loss_macro:
  - -0.23441047191228326
  - -0.23279016441430453
  - -0.23286551956166493
  - -0.23567295353848383
  - -0.23433472259028154
  train_level0__neg_hamming_loss_macro_masked:
  - -0.1829949486672564
  - -0.18155882793751882
  - -0.18174688875364242
  - -0.18419156650012
  - -0.18286091866808707
  train_level0__neg_hamming_loss_macro_oob:
  - -0.23441047191228326
  - -0.23279016441430453
  - -0.23286551956166493
  - -0.23567295353848383
  - -0.23433472259028154
  train_level0__neg_hamming_loss_micro:
  - -0.23441047191228323
  - -0.23279016441430453
  - -0.2328655195616649
  - -0.2356729535384839
  - -0.23433472259028162
  train_level0__neg_hamming_loss_micro_masked:
  - -0.17544544153986213
  - -0.1741025708358499
  - -0.1742886704604242
  - -0.1765611142991288
  - -0.1753502854177478
  train_level0__neg_hamming_loss_micro_oob:
  - -0.23441047191228323
  - -0.23279016441430453
  - -0.2328655195616649
  - -0.2356729535384839
  - -0.23433472259028162
  train_level0__neg_hamming_loss_samples:
  - -0.23441047191228317
  - -0.23279016441430447
  - -0.23286551956166482
  - -0.2356729535384838
  - -0.23433472259028157
  train_level0__neg_hamming_loss_samples_masked:
  - -0.17558845247031268
  - -0.17430340097049793
  - -0.17449675541192497
  - -0.1768027343694526
  - -0.17559184785360443
  train_level0__neg_hamming_loss_samples_oob:
  - -0.23441047191228317
  - -0.23279016441430447
  - -0.23286551956166482
  - -0.2356729535384838
  - -0.23433472259028157
  train_level0__neg_hamming_loss_weighted:
  - -0.34746830446982074
  - -0.3453832612712519
  - -0.3454653669701335
  - -0.34916766026171475
  - -0.3468004054101283
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.28336288209935684
  - -0.2814550890074879
  - -0.2817977093355973
  - -0.28496009595363786
  - -0.2828637032460365
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.34746830446982074
  - -0.3453832612712519
  - -0.3454653669701335
  - -0.34916766026171475
  - -0.3468004054101283
  train_level0__neg_label_ranking_loss:
  - -0.18220535428609774
  - -0.18529789532828406
  - -0.1828650050893005
  - -0.18400780177720172
  - -0.1882324438328571
  train_level0__neg_label_ranking_loss_oob:
  - -0.2555106321879837
  - -0.25934424371062786
  - -0.25679451674792053
  - -0.2559027981587204
  - -0.26194940665696714
  train_level0__precision_macro:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__precision_macro_masked:
  - 0.8170050513327435
  - 0.8184411720624812
  - 0.8182531112463574
  - 0.81580843349988
  - 0.8171390813319128
  train_level0__precision_macro_oob:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__precision_micro:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__precision_micro_masked:
  - 0.8245545584601378
  - 0.8258974291641501
  - 0.8257113295395758
  - 0.8234388857008712
  - 0.8246497145822522
  train_level0__precision_micro_oob:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__precision_samples:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__precision_samples_masked:
  - 0.8244115475296873
  - 0.8256965990295021
  - 0.825503244588075
  - 0.8231972656305474
  - 0.8244081521463956
  train_level0__precision_samples_oob:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__precision_weighted:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__precision_weighted_masked:
  - 0.7166371179006432
  - 0.7185449109925119
  - 0.7182022906644027
  - 0.7150399040463621
  - 0.7171362967539634
  train_level0__precision_weighted_oob:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__recall_macro:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__recall_macro_masked:
  - 0.8170050513327435
  - 0.8184411720624812
  - 0.8182531112463574
  - 0.81580843349988
  - 0.8171390813319128
  train_level0__recall_macro_oob:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__recall_micro:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__recall_micro_masked:
  - 0.8245545584601378
  - 0.8258974291641501
  - 0.8257113295395758
  - 0.8234388857008712
  - 0.8246497145822522
  train_level0__recall_micro_oob:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__recall_samples:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__recall_samples_masked:
  - 0.8244115475296873
  - 0.8256965990295021
  - 0.825503244588075
  - 0.8231972656305474
  - 0.8244081521463956
  train_level0__recall_samples_oob:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__recall_weighted:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__recall_weighted_masked:
  - 0.7166371179006432
  - 0.7185449109925119
  - 0.7182022906644027
  - 0.7150399040463621
  - 0.7171362967539634
  train_level0__recall_weighted_oob:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__roc_auc_macro:
  - 0.7155365567852738
  - 0.7112246416748019
  - 0.7174499645893299
  - 0.7125710153727778
  - 0.7024436162206744
  train_level0__roc_auc_macro_masked:
  - 0.5907768534600742
  - 0.5850300138859036
  - 0.5942345925397563
  - 0.5877762096351788
  - 0.5722816456873818
  train_level0__roc_auc_macro_oob:
  - 0.5393656287212095
  - 0.5349300059942506
  - 0.544976507516488
  - 0.5427255942763126
  - 0.5242694269012366
  train_level0__roc_auc_micro:
  - 0.8153792704242913
  - 0.8126006322055183
  - 0.8160758399165562
  - 0.8141031595009274
  - 0.8113185806641248
  train_level0__roc_auc_micro_masked:
  - 0.7565534652377155
  - 0.7523946944594749
  - 0.7564700226838539
  - 0.7550305813460801
  - 0.7507585920910709
  train_level0__roc_auc_micro_oob:
  - 0.7407964113387862
  - 0.7370905781982622
  - 0.7403589884243773
  - 0.7404063942356759
  - 0.7350332603128785
  train_level0__roc_auc_samples:
  - 0.8177946457139023
  - 0.814702104671716
  - 0.8171349949106994
  - 0.8159921982227983
  - 0.8117675561671429
  train_level0__roc_auc_samples_masked:
  - 0.7608654237208073
  - 0.756042384114663
  - 0.760649553914729
  - 0.7586179397155868
  - 0.7531073649076033
  train_level0__roc_auc_samples_oob:
  - 0.7444893678120162
  - 0.7406557562893722
  - 0.7432054832520796
  - 0.7440972018412797
  - 0.7380505933430328
  train_level0__roc_auc_weighted:
  - 0.7088834925203703
  - 0.7074567419512795
  - 0.7125234629215451
  - 0.7084962906259523
  - 0.7009286015286598
  train_level0__roc_auc_weighted_masked:
  - 0.5843050092318722
  - 0.5833605554682844
  - 0.5905455166723474
  - 0.5853379543265294
  - 0.5735837967680107
  train_level0__roc_auc_weighted_oob:
  - 0.5415837110639243
  - 0.5378660421107233
  - 0.5459774215168387
  - 0.5476411585104011
  - 0.5311315459406183
  train_level0__tn_macro:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__tn_macro_masked:
  - 0.8170050513327435
  - 0.8184411720624812
  - 0.8182531112463574
  - 0.81580843349988
  - 0.8171390813319128
  train_level0__tn_macro_oob:
  - 0.7655895280877171
  - 0.7672098355856956
  - 0.7671344804383353
  - 0.764327046461516
  - 0.765665277409718
  train_level0__tn_micro:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__tn_micro_masked:
  - 0.8245545584601378
  - 0.8258974291641501
  - 0.8257113295395758
  - 0.8234388857008712
  - 0.8246497145822522
  train_level0__tn_micro_oob:
  - 0.7655895280877167
  - 0.7672098355856954
  - 0.7671344804383351
  - 0.7643270464615161
  - 0.7656652774097183
  train_level0__tn_samples:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__tn_samples_masked:
  - 0.8244115475296873
  - 0.8256965990295021
  - 0.825503244588075
  - 0.8231972656305474
  - 0.8244081521463956
  train_level0__tn_samples_oob:
  - 0.7655895280877167
  - 0.7672098355856956
  - 0.767134480438335
  - 0.7643270464615161
  - 0.7656652774097182
  train_level0__tn_weighted:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__tn_weighted_masked:
  - 0.7166371179006432
  - 0.7185449109925119
  - 0.7182022906644027
  - 0.7150399040463621
  - 0.7171362967539634
  train_level0__tn_weighted_oob:
  - 0.6525316955301795
  - 0.6546167387287479
  - 0.6545346330298665
  - 0.6508323397382851
  - 0.6531995945898716
  train_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__average_precision_macro:
  - 0.24719655595474618
  - 0.2470546331401186
  - 0.24522807503995342
  - 0.24279904120198356
  - 0.24203792485397882
  train_level10__average_precision_macro_masked:
  - 0.19415368486656842
  - 0.1933630010598615
  - 0.19232860006174596
  - 0.1901109367453772
  - 0.18998419448019968
  train_level10__average_precision_macro_oob:
  - 0.24458302393748368
  - 0.2470590035831357
  - 0.24533580484089426
  - 0.24351986576131923
  - 0.24206501875810815
  train_level10__average_precision_micro:
  - 0.21079289701933016
  - 0.22728827148363737
  - 0.22433118327326493
  - 0.21417796834349273
  - 0.21697919884504105
  train_level10__average_precision_micro_masked:
  - 0.15647451945977126
  - 0.16958543674953394
  - 0.16731683305450926
  - 0.15920651715699657
  - 0.16138374068891487
  train_level10__average_precision_micro_oob:
  - 0.21103906039541062
  - 0.22723031574290253
  - 0.22438429349455183
  - 0.214261048484631
  - 0.21714122075219397
  train_level10__average_precision_samples:
  - 0.21521484416024286
  - 0.2302984891235436
  - 0.22772522430145187
  - 0.2165291663031661
  - 0.22079450200001716
  train_level10__average_precision_samples_masked:
  - 0.16154125793200724
  - 0.17318014432813505
  - 0.171337364033573
  - 0.16241339968546714
  - 0.16585854699025585
  train_level10__average_precision_samples_oob:
  - 0.21548859228478007
  - 0.2302382549953561
  - 0.2277512068603236
  - 0.21657701448598518
  - 0.2209189566020568
  train_level10__average_precision_weighted:
  - 0.3634895434250544
  - 0.3625860095206581
  - 0.3599390970412188
  - 0.35898827475401235
  - 0.3571006642380607
  train_level10__average_precision_weighted_masked:
  - 0.29800043813457083
  - 0.2971412294220559
  - 0.29420836535456585
  - 0.2932694548153778
  - 0.29233009476457394
  train_level10__average_precision_weighted_oob:
  - 0.3604874130716868
  - 0.361552960368241
  - 0.3602498729607848
  - 0.36028554402320945
  - 0.3571285952803136
  train_level10__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level10__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level10__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level10__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level10__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level10__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level10__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level10__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level10__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level10__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level10__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level10__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level10__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level10__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level10__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level10__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level10__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level10__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level10__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level10__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level10__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level10__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level10__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level10__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level10__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level10__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level10__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level10__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level10__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level10__label_ranking_average_precision_score:
  - 0.2152148441602431
  - 0.23029848912354364
  - 0.22772522430145187
  - 0.21652916630316602
  - 0.22079450200001713
  train_level10__label_ranking_average_precision_score_oob:
  - 0.21548859228478012
  - 0.23023825499535597
  - 0.22775120686032344
  - 0.216577014485985
  - 0.22091895660205674
  train_level10__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__ndcg:
  - 0.6044584135655731
  - 0.6196560427799348
  - 0.6173184966909182
  - 0.6090340268407831
  - 0.6105685164336099
  train_level10__ndcg_oob:
  - 0.6047470987092084
  - 0.6196186062461827
  - 0.6174050367912315
  - 0.6090851343424699
  - 0.6107409018521897
  train_level10__neg_coverage_error:
  - -98.32089552238806
  - -97.38693467336684
  - -98.56683168316832
  - -99.97256857855362
  - -97.97022332506204
  train_level10__neg_coverage_error_oob:
  - -98.17412935323384
  - -97.42713567839196
  - -98.80940594059406
  - -99.91271820448878
  - -98.0
  train_level10__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level10__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level10__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level10__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level10__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level10__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level10__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level10__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level10__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level10__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level10__neg_label_ranking_loss:
  - -0.7939803382768931
  - -0.7377202432099061
  - -0.7398484936692546
  - -0.8057740002502247
  - -0.7937220010461384
  train_level10__neg_label_ranking_loss_oob:
  - -0.7947887711354616
  - -0.7379575361506343
  - -0.7410697784377712
  - -0.8068107481303715
  - -0.7948087263353719
  train_level10__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level10__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level10__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level10__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level10__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level10__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level10__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level10__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level10__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__roc_auc_macro:
  - 0.5174303218041131
  - 0.5203743708685186
  - 0.5178392394180619
  - 0.5084577928340738
  - 0.5088625878016696
  train_level10__roc_auc_macro_masked:
  - 0.5146051063596668
  - 0.5159123983223086
  - 0.5147762032426084
  - 0.5067027040868062
  - 0.506723533225453
  train_level10__roc_auc_macro_oob:
  - 0.5137548304242762
  - 0.518393485570549
  - 0.5146260064936121
  - 0.5081504857886127
  - 0.5083209106071976
  train_level10__roc_auc_micro:
  - 0.4443691550512512
  - 0.4920717610680404
  - 0.482288762553254
  - 0.44529497624228864
  - 0.4593246455754528
  train_level10__roc_auc_micro_masked:
  - 0.44375637520958394
  - 0.4914637761831435
  - 0.4816599679029895
  - 0.4445673456770045
  - 0.45895269171422687
  train_level10__roc_auc_micro_oob:
  - 0.44476980481681955
  - 0.49188322709797627
  - 0.48209090863830945
  - 0.4455132404958366
  - 0.4596911307024867
  train_level10__roc_auc_samples:
  - 0.4401295050266545
  - 0.49222843214437545
  - 0.4817199910160062
  - 0.4433303867211408
  - 0.4561392282145723
  train_level10__roc_auc_samples_masked:
  - 0.439479734048986
  - 0.4909364962836796
  - 0.48167529232334694
  - 0.44312154215707084
  - 0.455643383465991
  train_level10__roc_auc_samples_oob:
  - 0.4407077302028286
  - 0.49203640216965167
  - 0.48143903265831045
  - 0.44341606174257625
  - 0.45666262443120853
  train_level10__roc_auc_weighted:
  - 0.5190035267451699
  - 0.5226343908816823
  - 0.5183823312816097
  - 0.5125201163255836
  - 0.5103159933854825
  train_level10__roc_auc_weighted_masked:
  - 0.5162375814820065
  - 0.5186982365009
  - 0.5152823314518271
  - 0.5096654433568775
  - 0.508169364619268
  train_level10__roc_auc_weighted_oob:
  - 0.5149017354105921
  - 0.5207905293856262
  - 0.5158876163460474
  - 0.5128506395431411
  - 0.5100323319395701
  train_level10__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level10__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level10__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level10__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level10__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level10__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level10__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level10__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level10__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__average_precision_macro:
  - 0.252461604382617
  - 0.2564621131346689
  - 0.2539898883491954
  - 0.25243892247940003
  - 0.24680792245994138
  train_level1__average_precision_macro_masked:
  - 0.19617597802274975
  - 0.2010400997721256
  - 0.19711178972525376
  - 0.19671874106741827
  - 0.19110199115161544
  train_level1__average_precision_macro_oob:
  - 0.24975830060055854
  - 0.2549885846066343
  - 0.25302758968539807
  - 0.2508661653092199
  - 0.24295186348098713
  train_level1__average_precision_micro:
  - 0.23197491085210395
  - 0.24291897845168578
  - 0.25357586177746283
  - 0.23742296079915087
  - 0.24236451347263072
  train_level1__average_precision_micro_masked:
  - 0.1733883058146903
  - 0.18216356408382448
  - 0.19094488593461761
  - 0.17770163831345837
  - 0.18154554600097145
  train_level1__average_precision_micro_oob:
  - 0.23174849460330493
  - 0.24226657305416355
  - 0.25293086183051383
  - 0.23667535027266176
  - 0.24175122421446832
  train_level1__average_precision_samples:
  - 0.23780737083687434
  - 0.2468711936000989
  - 0.2586747389389828
  - 0.240950356966099
  - 0.24726618530867422
  train_level1__average_precision_samples_masked:
  - 0.18013820033411193
  - 0.1868124217790432
  - 0.1970752362167549
  - 0.18245178964916364
  - 0.18740235827422497
  train_level1__average_precision_samples_oob:
  - 0.2376244144563088
  - 0.2462054495722649
  - 0.2579414687673729
  - 0.2401109581920942
  - 0.2465626356253291
  train_level1__average_precision_weighted:
  - 0.3671548756897058
  - 0.37184043806467804
  - 0.36617850287607523
  - 0.36534800726011707
  - 0.3592932775227493
  train_level1__average_precision_weighted_masked:
  - 0.29844059501247344
  - 0.3036631853491032
  - 0.29838272500382246
  - 0.2970967460758857
  - 0.2919329075293864
  train_level1__average_precision_weighted_oob:
  - 0.3636804377914959
  - 0.3716544676921153
  - 0.3648268172032563
  - 0.3629532280814618
  - 0.35487234223691233
  train_level1__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level1__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level1__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level1__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level1__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level1__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level1__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level1__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level1__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level1__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level1__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level1__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level1__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level1__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level1__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level1__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level1__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level1__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level1__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level1__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level1__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level1__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level1__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level1__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level1__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level1__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level1__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level1__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level1__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level1__label_ranking_average_precision_score:
  - 0.23780737083687417
  - 0.24687119360009888
  - 0.2586747389389827
  - 0.24095035696609907
  - 0.24726618530867406
  train_level1__label_ranking_average_precision_score_oob:
  - 0.2376244144563086
  - 0.24620544957226506
  - 0.25794146876737295
  - 0.24011095819209402
  - 0.24656263562532899
  train_level1__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__ndcg:
  - 0.624255505154705
  - 0.633919729375539
  - 0.6435602253494909
  - 0.6304852752857123
  - 0.6327391346552766
  train_level1__ndcg_oob:
  - 0.6240836168469615
  - 0.6333343645311382
  - 0.6429978936326142
  - 0.6297568768178384
  - 0.6322134712174244
  train_level1__neg_coverage_error:
  - -98.30597014925372
  - -97.06281407035176
  - -98.44554455445545
  - -99.76059850374065
  - -97.712158808933
  train_level1__neg_coverage_error_oob:
  - -98.2089552238806
  - -97.11809045226131
  - -98.67574257425743
  - -99.85785536159601
  - -97.79652605459057
  train_level1__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level1__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level1__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level1__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level1__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level1__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level1__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level1__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level1__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level1__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level1__neg_label_ranking_loss:
  - -0.6781773743963867
  - -0.655497587711925
  - -0.610625456623139
  - -0.6759662444355546
  - -0.6654244490116333
  train_level1__neg_label_ranking_loss_oob:
  - -0.6807002278791591
  - -0.6585610244483507
  - -0.6151231875543748
  - -0.6813308789898895
  - -0.6695880046807339
  train_level1__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level1__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level1__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level1__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level1__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level1__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level1__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level1__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level1__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__roc_auc_macro:
  - 0.5221490895763061
  - 0.5280183616796061
  - 0.5292274865077421
  - 0.5214196871643996
  - 0.5198088076354987
  train_level1__roc_auc_macro_masked:
  - 0.5161181725740438
  - 0.5195233890692997
  - 0.5195345159616825
  - 0.5121373927764105
  - 0.5104031213927449
  train_level1__roc_auc_macro_oob:
  - 0.5189181625934922
  - 0.5253199531243414
  - 0.5261507890014817
  - 0.5208730750196167
  - 0.5140429957180823
  train_level1__roc_auc_micro:
  - 0.4918735963510164
  - 0.5219343528021396
  - 0.5344077886184002
  - 0.49456644009632433
  - 0.5160195274224644
  train_level1__roc_auc_micro_masked:
  - 0.4910707335495624
  - 0.5210064874791704
  - 0.5332586498639112
  - 0.49314900015635216
  - 0.5148903806784191
  train_level1__roc_auc_micro_oob:
  - 0.4914213378046426
  - 0.5208717126954466
  - 0.5332411792055829
  - 0.4933048560491746
  - 0.514745515573068
  train_level1__roc_auc_samples:
  - 0.4880806220807557
  - 0.5221673108688067
  - 0.5343222674846042
  - 0.49290562739711635
  - 0.5134036395291768
  train_level1__roc_auc_samples_masked:
  - 0.48745530253470293
  - 0.5206795097685574
  - 0.5341619914106549
  - 0.4920470572312449
  - 0.5122257367776
  train_level1__roc_auc_samples_oob:
  - 0.48799719222689525
  - 0.5211531343036702
  - 0.5330755645105626
  - 0.49145827621436805
  - 0.5120950499353404
  train_level1__roc_auc_weighted:
  - 0.5212078901741148
  - 0.5290575558522931
  - 0.5259965641454618
  - 0.5209661572525105
  - 0.5161666114774248
  train_level1__roc_auc_weighted_masked:
  - 0.514871440648769
  - 0.5225852619507931
  - 0.5195119860622839
  - 0.5135130117466377
  - 0.5100427842260208
  train_level1__roc_auc_weighted_oob:
  - 0.51853689352456
  - 0.5282128804753058
  - 0.5231199845949746
  - 0.5179883190316612
  - 0.5105217566042769
  train_level1__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level1__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level1__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level1__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level1__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level1__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level1__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level1__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level1__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level1__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__average_precision_macro:
  - 0.24682919044034404
  - 0.2453291716428619
  - 0.24731361067122162
  - 0.24272817390373777
  - 0.24432374740353058
  train_level2__average_precision_macro_masked:
  - 0.19187831183710718
  - 0.1918777597595682
  - 0.19327006427716012
  - 0.1890109775811361
  - 0.19234939916678545
  train_level2__average_precision_macro_oob:
  - 0.24283437435691677
  - 0.2442993289361085
  - 0.24469946656117286
  - 0.2431289028858725
  - 0.24240951184496415
  train_level2__average_precision_micro:
  - 0.21085304936478236
  - 0.22726162830425808
  - 0.22436963226351353
  - 0.2141180797685699
  - 0.21694259828136594
  train_level2__average_precision_micro_masked:
  - 0.15652611669910738
  - 0.16954872351228994
  - 0.1673328752627098
  - 0.15911114089145512
  - 0.16133240191110618
  train_level2__average_precision_micro_oob:
  - 0.21091207603365225
  - 0.22721481885996345
  - 0.22423962542364662
  - 0.21418685435456303
  - 0.21708368955896432
  train_level2__average_precision_samples:
  - 0.2152759045368696
  - 0.2302866357001103
  - 0.22777206102761205
  - 0.21644414664071188
  - 0.2208323999239472
  train_level2__average_precision_samples_masked:
  - 0.16159649602522289
  - 0.1731671878729477
  - 0.17136262565379717
  - 0.162298413096089
  - 0.16585528337060812
  train_level2__average_precision_samples_oob:
  - 0.21539463797912364
  - 0.23023390426435333
  - 0.22761827631349146
  - 0.21653140915936162
  - 0.22090017028796233
  train_level2__average_precision_weighted:
  - 0.36249621666398396
  - 0.3623916424942351
  - 0.36135789331693785
  - 0.35796836051126174
  - 0.36026951493650794
  train_level2__average_precision_weighted_masked:
  - 0.294885352343309
  - 0.29582910815459246
  - 0.29513212288471924
  - 0.29158275602527683
  - 0.295891802828363
  train_level2__average_precision_weighted_oob:
  - 0.35731548015606646
  - 0.36040752595491743
  - 0.3591288315548986
  - 0.35904757691928474
  - 0.35774133157066174
  train_level2__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level2__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level2__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level2__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level2__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level2__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level2__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level2__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level2__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level2__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level2__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level2__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level2__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level2__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level2__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level2__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level2__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level2__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level2__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level2__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level2__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level2__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level2__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level2__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level2__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level2__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level2__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level2__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level2__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level2__label_ranking_average_precision_score:
  - 0.21527590453686968
  - 0.23028663570011035
  - 0.2277720610276119
  - 0.21644414664071177
  - 0.22083239992394701
  train_level2__label_ranking_average_precision_score_oob:
  - 0.21539463797912364
  - 0.23023390426435345
  - 0.22761827631349146
  - 0.21653140915936162
  - 0.22090017028796247
  train_level2__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__ndcg:
  - 0.6044984166709335
  - 0.6196473370868336
  - 0.6173019035519253
  - 0.6089906629138686
  - 0.6105741500786388
  train_level2__ndcg_oob:
  - 0.6046522505977288
  - 0.6196334010680514
  - 0.6172145165371854
  - 0.6090780699486453
  - 0.6106673941447792
  train_level2__neg_coverage_error:
  - -98.30099502487562
  - -97.47989949748744
  - -98.61386138613861
  - -99.96009975062344
  - -97.90818858560795
  train_level2__neg_coverage_error_oob:
  - -98.2363184079602
  - -97.56030150753769
  - -98.84653465346534
  - -99.86533665835411
  - -98.00248138957816
  train_level2__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level2__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level2__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level2__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level2__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level2__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level2__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level2__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level2__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level2__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level2__neg_label_ranking_loss:
  - -0.7937733596336538
  - -0.7378372780689832
  - -0.7392522556636247
  - -0.8058190497197435
  - -0.7930457682158851
  train_level2__neg_label_ranking_loss_oob:
  - -0.794600061361664
  - -0.7381453868373595
  - -0.7406476613357218
  - -0.8067632121055519
  - -0.7945913872145943
  train_level2__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level2__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level2__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level2__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level2__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level2__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level2__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level2__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level2__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__roc_auc_macro:
  - 0.5174600982053134
  - 0.5147092789520614
  - 0.5207562511013868
  - 0.5097642235895573
  - 0.5127408306626664
  train_level2__roc_auc_macro_masked:
  - 0.5136324479420608
  - 0.5112984183368696
  - 0.5163355604506297
  - 0.5055937521342518
  - 0.5111988005728512
  train_level2__roc_auc_macro_oob:
  - 0.5125818563954005
  - 0.5127421491008513
  - 0.5171840848953909
  - 0.5096778237091123
  - 0.5096245610560349
  train_level2__roc_auc_micro:
  - 0.44459130454283374
  - 0.4919391582427023
  - 0.48260723911076064
  - 0.4451720478205002
  - 0.45937341418717254
  train_level2__roc_auc_micro_masked:
  - 0.443922531703587
  - 0.49125082791766916
  - 0.4818788804723982
  - 0.4442714692484709
  - 0.45897925809276785
  train_level2__roc_auc_micro_oob:
  - 0.4445086294145675
  - 0.4917230935018708
  - 0.48204999848379126
  - 0.4453723145720839
  - 0.45966938999082474
  train_level2__roc_auc_samples:
  - 0.4403323217057801
  - 0.4921113972852983
  - 0.4819797782745623
  - 0.44327153118338386
  - 0.4566060461054064
  train_level2__roc_auc_samples_masked:
  - 0.43963897691236875
  - 0.4907638126219104
  - 0.48181043260303374
  - 0.44282255359296885
  - 0.4560532026902803
  train_level2__roc_auc_samples_oob:
  - 0.4406899893750291
  - 0.491880495911332
  - 0.48133559560181616
  - 0.4435690273102372
  - 0.45674383350267117
  train_level2__roc_auc_weighted:
  - 0.5197400483687938
  - 0.5197089726779843
  - 0.5218646426848867
  - 0.5113847222692722
  - 0.5161255990877183
  train_level2__roc_auc_weighted_masked:
  - 0.5152429213984338
  - 0.5157420055997171
  - 0.5177590952034556
  - 0.5068624361998324
  - 0.5151517377805597
  train_level2__roc_auc_weighted_oob:
  - 0.5137158764190152
  - 0.5171272542468007
  - 0.5179966544212429
  - 0.5113716589656532
  - 0.51256930364555
  train_level2__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level2__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level2__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level2__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level2__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level2__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level2__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level2__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level2__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level2__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__average_precision_macro:
  - 0.24817893744428035
  - 0.2485787813082769
  - 0.24732143280244032
  - 0.24403755679726336
  - 0.24098952238881877
  train_level3__average_precision_macro_masked:
  - 0.19479366771733916
  - 0.194291199874335
  - 0.19234023472957076
  - 0.19106257497962612
  - 0.18938282261813427
  train_level3__average_precision_macro_oob:
  - 0.246708227012115
  - 0.2477555970286544
  - 0.24520873270962396
  - 0.24322796225615367
  - 0.24120796493679822
  train_level3__average_precision_micro:
  - 0.21082850780601015
  - 0.22735539224074225
  - 0.22433561935972865
  - 0.21416868015661983
  - 0.21668860684752045
  train_level3__average_precision_micro_masked:
  - 0.15644616443249526
  - 0.16962401396679005
  - 0.1673334761999602
  - 0.1591502530763887
  - 0.16108524803246416
  train_level3__average_precision_micro_oob:
  - 0.21114842518458177
  - 0.22733826674355173
  - 0.2243051859508379
  - 0.21435569391523568
  - 0.21700433733533542
  train_level3__average_precision_samples:
  - 0.21527179303813035
  - 0.23035243892882093
  - 0.22773786277999128
  - 0.21650620104191245
  - 0.22058556046014077
  train_level3__average_precision_samples_masked:
  - 0.1615279486526421
  - 0.1732140955046767
  - 0.1713487269154019
  - 0.16232540184847863
  - 0.16563118144330652
  train_level3__average_precision_samples_oob:
  - 0.21566160689065286
  - 0.23029571688721734
  - 0.2276975503740766
  - 0.21669966032955015
  - 0.22080763455400113
  train_level3__average_precision_weighted:
  - 0.3643808983333376
  - 0.36554420024187095
  - 0.3608831356327487
  - 0.3598286830717824
  - 0.3555099536966532
  train_level3__average_precision_weighted_masked:
  - 0.29883097692916855
  - 0.29863867431702384
  - 0.2933712178974994
  - 0.29514534283235605
  - 0.2919521210635503
  train_level3__average_precision_weighted_oob:
  - 0.36363151482115735
  - 0.3648833365862339
  - 0.35875193762495233
  - 0.359004098715716
  - 0.35559549013054115
  train_level3__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level3__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level3__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level3__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level3__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level3__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level3__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level3__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level3__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level3__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level3__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level3__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level3__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level3__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level3__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level3__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level3__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level3__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level3__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level3__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level3__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level3__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level3__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level3__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level3__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level3__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level3__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level3__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level3__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level3__label_ranking_average_precision_score:
  - 0.2152717930381303
  - 0.2303524389288208
  - 0.22773786277999122
  - 0.2165062010419123
  - 0.22058556046014072
  train_level3__label_ranking_average_precision_score_oob:
  - 0.21566160689065286
  - 0.2302957168872174
  - 0.22769755037407668
  - 0.2166996603295501
  - 0.22080763455400104
  train_level3__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__ndcg:
  - 0.6044854394471063
  - 0.6196709581650989
  - 0.617316208918493
  - 0.6090199300590042
  - 0.6103486529683289
  train_level3__ndcg_oob:
  - 0.6048270801738167
  - 0.6196420879698976
  - 0.6173165234617135
  - 0.6092363795958177
  - 0.6106376696534148
  train_level3__neg_coverage_error:
  - -98.23383084577114
  - -97.45226130653266
  - -98.4480198019802
  - -100.04738154613466
  - -97.92803970223325
  train_level3__neg_coverage_error_oob:
  - -98.1592039800995
  - -97.40954773869346
  - -98.70544554455445
  - -100.0423940149626
  - -97.9925558312655
  train_level3__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level3__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level3__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level3__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level3__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level3__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level3__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level3__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level3__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level3__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level3__neg_label_ranking_loss:
  - -0.7936915233119783
  - -0.7375564867373533
  - -0.7399533085956628
  - -0.8057848575580935
  - -0.7935253117862554
  train_level3__neg_label_ranking_loss_oob:
  - -0.7942306216375988
  - -0.737799590597278
  - -0.7412402048314614
  - -0.8066188632095058
  - -0.7949255799949098
  train_level3__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level3__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level3__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level3__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level3__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level3__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level3__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level3__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level3__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__roc_auc_macro:
  - 0.5168726570828133
  - 0.5212269381974225
  - 0.5176584659016154
  - 0.5107453918163152
  - 0.510313606253463
  train_level3__roc_auc_macro_masked:
  - 0.5139209311415182
  - 0.5170543187994954
  - 0.5125428202836504
  - 0.5086961493910912
  - 0.5077975331705351
  train_level3__roc_auc_macro_oob:
  - 0.5150001603097889
  - 0.5203476140706831
  - 0.5152896620402048
  - 0.5098381603949067
  - 0.5081943475603096
  train_level3__roc_auc_micro:
  - 0.4445219695645023
  - 0.4923760388896942
  - 0.4822976318889781
  - 0.44535703760382206
  - 0.45862485246900575
  train_level3__roc_auc_micro_masked:
  - 0.4437575327441988
  - 0.49167683474971935
  - 0.48159777080929805
  - 0.4445843117984047
  - 0.4580838556704244
  train_level3__roc_auc_micro_oob:
  - 0.4451987323201168
  - 0.4923261299969544
  - 0.4819805034317072
  - 0.4457622083803464
  - 0.45934433060756363
  train_level3__roc_auc_samples:
  - 0.4403205655405536
  - 0.4924013534083375
  - 0.4816459671855505
  - 0.44345412550736824
  - 0.45574226900430115
  train_level3__roc_auc_samples_masked:
  - 0.43947843147399296
  - 0.4909993261846077
  - 0.4814205416191195
  - 0.4430077850475153
  - 0.4550511692148985
  train_level3__roc_auc_samples_oob:
  - 0.4411935402111138
  - 0.49216741433982225
  - 0.48127249364391445
  - 0.44402544236463104
  - 0.45637869042408036
  train_level3__roc_auc_weighted:
  - 0.5189221776882992
  - 0.5254130170374327
  - 0.5172245156144796
  - 0.514547774891202
  - 0.5114536421720486
  train_level3__roc_auc_weighted_masked:
  - 0.5156238881265386
  - 0.5210575489457074
  - 0.5122800974058025
  - 0.5131956212168098
  - 0.5101012912020819
  train_level3__roc_auc_weighted_oob:
  - 0.5164498901949577
  - 0.5248643039514221
  - 0.5150273409423928
  - 0.5133949094843779
  - 0.5096978008366827
  train_level3__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level3__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level3__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level3__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level3__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level3__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level3__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level3__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level3__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level3__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__average_precision_macro:
  - 0.24799241554310805
  - 0.2487354915212646
  - 0.24658893804937454
  - 0.24436032978750072
  - 0.2409597092939667
  train_level4__average_precision_macro_masked:
  - 0.19421980226467614
  - 0.19380958294489203
  - 0.19204455088754765
  - 0.19149289185667584
  - 0.18724496569477705
  train_level4__average_precision_macro_oob:
  - 0.2463710308487744
  - 0.24809663694868792
  - 0.24474165123055525
  - 0.2428017529428209
  - 0.23995046311871546
  train_level4__average_precision_micro:
  - 0.21095065250711365
  - 0.22734073632892537
  - 0.22447629981060985
  - 0.21423792690658647
  - 0.21684550792605797
  train_level4__average_precision_micro_masked:
  - 0.15654799592005914
  - 0.16959036069169225
  - 0.16734119928273156
  - 0.15925154477072295
  - 0.16118351086467064
  train_level4__average_precision_micro_oob:
  - 0.2111532204417224
  - 0.2273505402298715
  - 0.2244105923614963
  - 0.21434342477461374
  - 0.21690100690685113
  train_level4__average_precision_samples:
  - 0.21536300725029991
  - 0.23032578720667884
  - 0.2278910251733884
  - 0.21656937968328174
  - 0.22072827281108345
  train_level4__average_precision_samples_masked:
  - 0.161581376550485
  - 0.17317651749394505
  - 0.17139511937132187
  - 0.16242644627187514
  - 0.1657421752449203
  train_level4__average_precision_samples_oob:
  - 0.2156054162280169
  - 0.23032049957057696
  - 0.22779792625571943
  - 0.21666513250910502
  - 0.22076393233119085
  train_level4__average_precision_weighted:
  - 0.36471860126243066
  - 0.3656157613843421
  - 0.36133736923968507
  - 0.3587692817678524
  - 0.3551267592941377
  train_level4__average_precision_weighted_masked:
  - 0.29855119251146445
  - 0.2989825393119576
  - 0.2947438226509725
  - 0.2931467908674379
  - 0.2883545334594631
  train_level4__average_precision_weighted_oob:
  - 0.36208314575641326
  - 0.36547323492642725
  - 0.35885329561232276
  - 0.3563713774985387
  - 0.35401752008946347
  train_level4__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level4__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level4__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level4__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level4__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level4__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level4__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level4__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level4__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level4__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level4__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level4__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level4__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level4__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level4__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level4__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level4__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level4__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level4__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level4__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level4__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level4__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level4__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level4__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level4__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level4__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level4__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level4__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level4__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level4__label_ranking_average_precision_score:
  - 0.21536300725029997
  - 0.23032578720667887
  - 0.2278910251733882
  - 0.21656937968328174
  - 0.2207282728110835
  train_level4__label_ranking_average_precision_score_oob:
  - 0.21560541622801704
  - 0.230320499570577
  - 0.22779792625571935
  - 0.21666513250910488
  - 0.220763932331191
  train_level4__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__ndcg:
  - 0.6045622648322437
  - 0.6196777926170779
  - 0.6174019010980979
  - 0.6091160346672141
  - 0.610513943436495
  train_level4__ndcg_oob:
  - 0.6047902915931064
  - 0.6196753488788983
  - 0.6173691857931346
  - 0.6092504077600798
  - 0.6105720104828906
  train_level4__neg_coverage_error:
  - -98.32338308457712
  - -97.37688442211055
  - -98.45792079207921
  - -100.05236907730674
  - -97.93796526054591
  train_level4__neg_coverage_error_oob:
  - -98.18656716417911
  - -97.35678391959799
  - -98.70049504950495
  - -100.07231920199501
  - -97.98759305210918
  train_level4__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level4__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level4__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level4__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level4__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level4__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level4__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level4__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level4__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level4__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level4__neg_label_ranking_loss:
  - -0.793407763852223
  - -0.7377117780843138
  - -0.7398988880471559
  - -0.805989762775133
  - -0.7936385218598798
  train_level4__neg_label_ranking_loss_oob:
  - -0.794151721387416
  - -0.7376786981844028
  - -0.7410196383209097
  - -0.8074771826100472
  - -0.795195126624534
  train_level4__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level4__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level4__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level4__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level4__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level4__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level4__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level4__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level4__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__roc_auc_macro:
  - 0.5186527021634258
  - 0.5219151333875276
  - 0.5179606790363719
  - 0.5104053548310283
  - 0.5073059950172628
  train_level4__roc_auc_macro_masked:
  - 0.5144394314731134
  - 0.5162048925899787
  - 0.5121523402647143
  - 0.5078637383726586
  - 0.5036524981364646
  train_level4__roc_auc_macro_oob:
  - 0.5154095196100649
  - 0.5204426271918324
  - 0.5152126899826948
  - 0.5086534506374519
  - 0.5058995003449875
  train_level4__roc_auc_micro:
  - 0.4450073859156358
  - 0.49225918221256454
  - 0.48272280071994367
  - 0.4454300836083139
  - 0.4588812479501025
  train_level4__roc_auc_micro_masked:
  - 0.44421313836864795
  - 0.49148554866141697
  - 0.4817910941423726
  - 0.44469235587808675
  - 0.458180134349333
  train_level4__roc_auc_micro_oob:
  - 0.4453587247408185
  - 0.492331412586456
  - 0.48230960476481344
  - 0.4455878306310004
  - 0.4589801033315549
  train_level4__roc_auc_samples:
  - 0.44076939486692396
  - 0.49228139968914847
  - 0.4820611417343386
  - 0.4435276970337509
  - 0.4559693139361385
  train_level4__roc_auc_samples_masked:
  - 0.43979451681542014
  - 0.49078201339129135
  - 0.48167340981917656
  - 0.443146273438957
  - 0.4551548788919234
  train_level4__roc_auc_samples_oob:
  - 0.4413119959299771
  - 0.49232537883414335
  - 0.481560716110988
  - 0.44365242941702576
  - 0.4560898541320333
  train_level4__roc_auc_weighted:
  - 0.5220457357167789
  - 0.5247498143078047
  - 0.5188873579516097
  - 0.5133337526788379
  - 0.5085901581101626
  train_level4__roc_auc_weighted_masked:
  - 0.5186117668103493
  - 0.5199676954961016
  - 0.5140112407861767
  - 0.5098738586002646
  - 0.5047737245627966
  train_level4__roc_auc_weighted_oob:
  - 0.5175404655984482
  - 0.5243709985889825
  - 0.5162378650984616
  - 0.5101053887376136
  - 0.507456728983544
  train_level4__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level4__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level4__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level4__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level4__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level4__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level4__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level4__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level4__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level4__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__average_precision_macro:
  - 0.2474928113345687
  - 0.2461537022906109
  - 0.248300703013894
  - 0.24210482853467696
  - 0.2439879065492873
  train_level5__average_precision_macro_masked:
  - 0.19377646944301694
  - 0.19142388067170588
  - 0.1941821919068679
  - 0.18954579599992075
  - 0.1912671131675019
  train_level5__average_precision_macro_oob:
  - 0.24703251170980475
  - 0.24753566336739022
  - 0.2464447663838862
  - 0.24142874793197094
  - 0.24223140167348783
  train_level5__average_precision_micro:
  - 0.21087553546966975
  - 0.22726473948058667
  - 0.22444431818217278
  - 0.214302318355512
  - 0.21698105092756348
  train_level5__average_precision_micro_masked:
  - 0.15650951873478577
  - 0.16954589625584257
  - 0.16739806024794915
  - 0.15928869162619114
  - 0.16136642115390193
  train_level5__average_precision_micro_oob:
  - 0.21124583556008736
  - 0.22726698089651667
  - 0.22437424481294738
  - 0.21431648775594025
  - 0.21712429532261424
  train_level5__average_precision_samples:
  - 0.21527809354065053
  - 0.23025700633637924
  - 0.22783680726354383
  - 0.21665351081358233
  - 0.22083604589561773
  train_level5__average_precision_samples_masked:
  - 0.16155408216596706
  - 0.17312762160468326
  - 0.17143473825764002
  - 0.16248527998750983
  - 0.16585801109091053
  train_level5__average_precision_samples_oob:
  - 0.21568828113732727
  - 0.2302096633557545
  - 0.22775764345929736
  - 0.21666439629578718
  - 0.22090089269102425
  train_level5__average_precision_weighted:
  - 0.3636092729818619
  - 0.3617380457397666
  - 0.3623379837671881
  - 0.3571735577242873
  - 0.3591607166929568
  train_level5__average_precision_weighted_masked:
  - 0.29790312520323675
  - 0.2948233720005771
  - 0.29565091350542944
  - 0.2919753983996916
  - 0.294584748390732
  train_level5__average_precision_weighted_oob:
  - 0.3629185110173296
  - 0.3632366483879621
  - 0.3606072437982407
  - 0.3559724340758129
  - 0.35593127179756395
  train_level5__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level5__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level5__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level5__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level5__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level5__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level5__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level5__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level5__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level5__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level5__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level5__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level5__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level5__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level5__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level5__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level5__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level5__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level5__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level5__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level5__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level5__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level5__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level5__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level5__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level5__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level5__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level5__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level5__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level5__label_ranking_average_precision_score:
  - 0.21527809354065053
  - 0.23025700633637933
  - 0.22783680726354372
  - 0.21665351081358228
  - 0.22083604589561792
  train_level5__label_ranking_average_precision_score_oob:
  - 0.2156882811373273
  - 0.23020966335575438
  - 0.22775764345929736
  - 0.21666439629578693
  - 0.2209008926910244
  train_level5__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__ndcg:
  - 0.6045088018388554
  - 0.6196373454698986
  - 0.6173748999868097
  - 0.6091650043877236
  - 0.6105857975837199
  train_level5__ndcg_oob:
  - 0.6049458069316856
  - 0.6196209606750355
  - 0.617357128217836
  - 0.609183998577837
  - 0.6107371489430354
  train_level5__neg_coverage_error:
  - -98.31840796019901
  - -97.45477386934674
  - -98.56683168316832
  - -99.98753117206982
  - -98.01488833746899
  train_level5__neg_coverage_error_oob:
  - -98.08208955223881
  - -97.55025125628141
  - -98.81188118811882
  - -100.07481296758105
  - -98.06203473945409
  train_level5__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level5__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level5__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level5__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level5__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level5__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level5__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level5__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level5__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level5__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level5__neg_label_ranking_loss:
  - -0.7937464292509833
  - -0.7378991890035765
  - -0.7397571003732563
  - -0.805605218740367
  - -0.7931476798788212
  train_level5__neg_label_ranking_loss_oob:
  - -0.794322120944903
  - -0.7380297118741455
  - -0.7406739065084474
  - -0.8067322685908211
  - -0.7947147240125402
  train_level5__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level5__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level5__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level5__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level5__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level5__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level5__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level5__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level5__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__roc_auc_macro:
  - 0.5162010507186541
  - 0.5176140715811746
  - 0.5202605282774722
  - 0.509527457751984
  - 0.5108970081569512
  train_level5__roc_auc_macro_masked:
  - 0.5126013568641364
  - 0.5124744224593029
  - 0.5160608857137972
  - 0.5071069054890792
  - 0.508714334365543
  train_level5__roc_auc_macro_oob:
  - 0.5148009684242029
  - 0.5175279810556508
  - 0.5180172123341138
  - 0.5092715045614709
  - 0.5082070067518946
  train_level5__roc_auc_micro:
  - 0.4446283007486346
  - 0.49196911124151604
  - 0.48271090058332977
  - 0.44557848286418156
  - 0.4594462185611309
  train_level5__roc_auc_micro_masked:
  - 0.44393007789389505
  - 0.49123673575304216
  - 0.4819950316154456
  - 0.44482305421061635
  - 0.4590345465163879
  train_level5__roc_auc_micro_oob:
  - 0.4454340643304314
  - 0.4920007184854812
  - 0.4823588718476519
  - 0.4455537865361087
  - 0.45965937845941696
  train_level5__roc_auc_samples:
  - 0.440302707372589
  - 0.49204948635070495
  - 0.482052429135631
  - 0.44371997983201156
  - 0.4565412093128637
  train_level5__roc_auc_samples_masked:
  - 0.43944937278423124
  - 0.49063003783290743
  - 0.48200805091170057
  - 0.4433487564750391
  - 0.45600306886929615
  train_level5__roc_auc_samples_oob:
  - 0.44142244802977065
  - 0.4919298627252198
  - 0.48167199144762535
  - 0.4436546587420788
  - 0.45667933245357095
  train_level5__roc_auc_weighted:
  - 0.5182107318629091
  - 0.5209601842570559
  - 0.5205543483219341
  - 0.5123984816484183
  - 0.5126641391169745
  train_level5__roc_auc_weighted_masked:
  - 0.5152546840748083
  - 0.5158826673626135
  - 0.5165288532121741
  - 0.5095039773915679
  - 0.5111854994920592
  train_level5__roc_auc_weighted_oob:
  - 0.5172924344868067
  - 0.5210427602818298
  - 0.5183215513252749
  - 0.5104775450449786
  - 0.5086093554995046
  train_level5__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level5__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level5__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level5__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level5__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level5__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level5__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level5__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level5__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level5__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__average_precision_macro:
  - 0.246744821630213
  - 0.24763213003262638
  - 0.24554618265328446
  - 0.2426077165820577
  - 0.24213027164149944
  train_level6__average_precision_macro_masked:
  - 0.1931633351871504
  - 0.19360256770037293
  - 0.19241778466424977
  - 0.1913318277862612
  - 0.18851460241350362
  train_level6__average_precision_macro_oob:
  - 0.24629112184170054
  - 0.24719510619080554
  - 0.24409733878729337
  - 0.24192910206858476
  - 0.24066230041651135
  train_level6__average_precision_micro:
  - 0.2108297352673945
  - 0.22729800347066742
  - 0.22438507115276132
  - 0.2141330031651253
  - 0.21683684283065677
  train_level6__average_precision_micro_masked:
  - 0.15651441266535387
  - 0.16956628625460862
  - 0.16731748855955275
  - 0.1591702816218455
  - 0.16120956681688436
  train_level6__average_precision_micro_oob:
  - 0.21116670613557814
  - 0.2273572751082365
  - 0.22437241015940704
  - 0.2142827056349793
  - 0.21704329572987402
  train_level6__average_precision_samples:
  - 0.21522379424577273
  - 0.23031108585546364
  - 0.2277655677482259
  - 0.21650412599623944
  - 0.22070748295951093
  train_level6__average_precision_samples_masked:
  - 0.1615584819472792
  - 0.17317233640567703
  - 0.1713374587640573
  - 0.1623877961685375
  - 0.16573016432770116
  train_level6__average_precision_samples_oob:
  - 0.2155771398601626
  - 0.23033636360246934
  - 0.22769883159663815
  - 0.21663452578040604
  - 0.2208809156252376
  train_level6__average_precision_weighted:
  - 0.3602269782605023
  - 0.365059362728898
  - 0.35942580922788386
  - 0.3581322260453149
  - 0.3557549911765879
  train_level6__average_precision_weighted_masked:
  - 0.2936133047025356
  - 0.2986030946541796
  - 0.2939300035040442
  - 0.29461335979549
  - 0.28995987024878933
  train_level6__average_precision_weighted_oob:
  - 0.35922527863939446
  - 0.3647330403487598
  - 0.3584566422871523
  - 0.3579545906532779
  - 0.3544243278614348
  train_level6__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level6__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level6__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level6__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level6__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level6__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level6__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level6__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level6__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level6__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level6__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level6__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level6__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level6__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level6__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level6__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level6__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level6__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level6__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level6__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level6__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level6__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level6__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level6__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level6__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level6__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level6__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level6__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level6__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level6__label_ranking_average_precision_score:
  - 0.2152237942457728
  - 0.23031108585546392
  - 0.22776556774822598
  - 0.21650412599623972
  - 0.22070748295951106
  train_level6__label_ranking_average_precision_score_oob:
  - 0.21557713986016272
  - 0.23033636360246929
  - 0.2276988315966384
  - 0.216634525780406
  - 0.2208809156252375
  train_level6__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__ndcg:
  - 0.6044851724600253
  - 0.6196597089057424
  - 0.6173313374430538
  - 0.6090130642929779
  - 0.6104460433978725
  train_level6__ndcg_oob:
  - 0.6048879456993357
  - 0.6196975905724622
  - 0.617355367740161
  - 0.6091944423057745
  - 0.6106687796370828
  train_level6__neg_coverage_error:
  - -98.47014925373135
  - -97.2462311557789
  - -98.56188118811882
  - -99.81296758104739
  - -97.91811414392059
  train_level6__neg_coverage_error_oob:
  - -98.33830845771145
  - -97.36180904522612
  - -98.90841584158416
  - -99.85785536159601
  - -97.98759305210918
  train_level6__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level6__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level6__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level6__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level6__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level6__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level6__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level6__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level6__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level6__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level6__neg_label_ranking_loss:
  - -0.7940171793977179
  - -0.7376578446674656
  - -0.7398086415525947
  - -0.8056068309266571
  - -0.793451047728953
  train_level6__neg_label_ranking_loss_oob:
  - -0.7946955653079397
  - -0.737759989553165
  - -0.7410402581310465
  - -0.8067332470977788
  - -0.7948602750477696
  train_level6__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level6__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level6__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level6__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level6__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level6__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level6__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level6__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level6__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__roc_auc_macro:
  - 0.5181605843142779
  - 0.518045448704764
  - 0.5182635986370199
  - 0.5086807677820242
  - 0.5106288458516042
  train_level6__roc_auc_macro_masked:
  - 0.5148475267059222
  - 0.513562481267875
  - 0.5147852573490684
  - 0.5080048198880124
  - 0.5066444156456034
  train_level6__roc_auc_macro_oob:
  - 0.5149583933046403
  - 0.5186016229799925
  - 0.5157585968272294
  - 0.5066663438086824
  - 0.5079836115628521
  train_level6__roc_auc_micro:
  - 0.4445329094949887
  - 0.49211705373387743
  - 0.48248095250749556
  - 0.44522774716841085
  - 0.4590640869793568
  train_level6__roc_auc_micro_masked:
  - 0.44394735439032995
  - 0.49135788712581363
  - 0.4817029660956194
  - 0.44459776349223024
  - 0.45844896412447567
  train_level6__roc_auc_micro_oob:
  - 0.44521323276570934
  - 0.4923354240893004
  - 0.4822082790294635
  - 0.4454778263714128
  - 0.45944356607138775
  train_level6__roc_auc_samples:
  - 0.4402631847924955
  - 0.49229834106479264
  - 0.48181406671994365
  - 0.44350376898354804
  - 0.45604228915716427
  train_level6__roc_auc_samples_masked:
  - 0.4395926925279781
  - 0.4908854094881734
  - 0.4817062636863798
  - 0.4433480458991621
  - 0.4553490422675257
  train_level6__roc_auc_samples_oob:
  - 0.4412843938396844
  - 0.49239889679856935
  - 0.48139298815565706
  - 0.44373507393201894
  - 0.45647686866655024
  train_level6__roc_auc_weighted:
  - 0.5172942416674033
  - 0.5224539694751225
  - 0.5184244027925035
  - 0.5138419349688454
  - 0.5114893375769898
  train_level6__roc_auc_weighted_masked:
  - 0.5138177824527375
  - 0.5176385945414511
  - 0.5150654876813926
  - 0.5125957592667242
  - 0.507423898367842
  train_level6__roc_auc_weighted_oob:
  - 0.5137675823860297
  - 0.5237339525899513
  - 0.5163525431330865
  - 0.5106032872934332
  - 0.5084420504320482
  train_level6__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level6__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level6__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level6__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level6__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level6__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level6__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level6__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level6__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level6__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__average_precision_macro:
  - 0.2470680530605622
  - 0.24740277079061992
  - 0.24538622548285682
  - 0.24370790388646174
  - 0.24267857909191348
  train_level7__average_precision_macro_masked:
  - 0.1944042052289964
  - 0.19348040612291317
  - 0.19092574872626392
  - 0.1903316462243075
  - 0.19068338272095442
  train_level7__average_precision_macro_oob:
  - 0.246157378937616
  - 0.2485885384695862
  - 0.24354938108645766
  - 0.243740113379222
  - 0.2409044601120003
  train_level7__average_precision_micro:
  - 0.21085768219764878
  - 0.2272774993341905
  - 0.22442395968123943
  - 0.21412792133019531
  - 0.21672426314102755
  train_level7__average_precision_micro_masked:
  - 0.1565418535334635
  - 0.16957355305543761
  - 0.1673031733531719
  - 0.15913426590296714
  - 0.1611444415998599
  train_level7__average_precision_micro_oob:
  - 0.2110981520070046
  - 0.22730030158708006
  - 0.22422223679628536
  - 0.21417445770134708
  - 0.21676083199368726
  train_level7__average_precision_samples:
  - 0.2152845624765158
  - 0.23026952037991974
  - 0.2278177682770536
  - 0.21646824876217366
  - 0.22059925426380483
  train_level7__average_precision_samples_masked:
  - 0.16160419493843392
  - 0.17315205618920843
  - 0.1713106032089956
  - 0.162317996843498
  - 0.16566407410497988
  train_level7__average_precision_samples_oob:
  - 0.21554413003720732
  - 0.23027406488106175
  - 0.22759376723874908
  - 0.21647168878556997
  - 0.2206067417998329
  train_level7__average_precision_weighted:
  - 0.36235870076317306
  - 0.36373712874202413
  - 0.3594099127346858
  - 0.3586162103464389
  - 0.3588818911967464
  train_level7__average_precision_weighted_masked:
  - 0.29728272395428545
  - 0.2978488862343466
  - 0.2918795456302797
  - 0.2918925761380417
  - 0.2947798065424238
  train_level7__average_precision_weighted_oob:
  - 0.3609753372234282
  - 0.3648523314805595
  - 0.35759437807951855
  - 0.35799757487274925
  - 0.3566316660727616
  train_level7__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level7__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level7__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level7__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level7__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level7__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level7__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level7__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level7__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level7__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level7__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level7__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level7__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level7__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level7__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level7__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level7__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level7__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level7__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level7__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level7__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level7__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level7__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level7__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level7__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level7__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level7__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level7__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level7__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level7__label_ranking_average_precision_score:
  - 0.21528456247651595
  - 0.23026952037991974
  - 0.22781776827705372
  - 0.2164682487621736
  - 0.22059925426380483
  train_level7__label_ranking_average_precision_score_oob:
  - 0.21554413003720732
  - 0.23027406488106175
  - 0.227593767238749
  - 0.21647168878557008
  - 0.22060674179983272
  train_level7__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__ndcg:
  - 0.604543444496238
  - 0.6196465960723856
  - 0.6173876181755825
  - 0.608972004824468
  - 0.6103449877354625
  train_level7__ndcg_oob:
  - 0.6048132920750178
  - 0.6196452235618929
  - 0.617248823052618
  - 0.6090136180230186
  - 0.6103909254265015
  train_level7__neg_coverage_error:
  - -98.35074626865672
  - -97.46231155778895
  - -98.58415841584159
  - -99.89775561097257
  - -97.95285359801488
  train_level7__neg_coverage_error_oob:
  - -98.09701492537313
  - -97.42964824120602
  - -98.88118811881188
  - -99.98503740648378
  - -97.98759305210918
  train_level7__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level7__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level7__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level7__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level7__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level7__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level7__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level7__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level7__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level7__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level7__neg_label_ranking_loss:
  - -0.7941029935092093
  - -0.7378387634702321
  - -0.7399044860779113
  - -0.8055165382446364
  - -0.7936838052813774
  train_level7__neg_label_ranking_loss_oob:
  - -0.794752730346166
  - -0.7378150538765851
  - -0.7415641451202115
  - -0.807176761554361
  - -0.7954316891921244
  train_level7__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level7__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level7__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level7__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level7__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level7__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level7__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level7__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level7__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__roc_auc_macro:
  - 0.5150930401167527
  - 0.5173286744460072
  - 0.5175002910620863
  - 0.5104827920439283
  - 0.5092235198276175
  train_level7__roc_auc_macro_masked:
  - 0.5126382751015892
  - 0.5126827303211378
  - 0.5136232323122871
  - 0.5079977751662107
  - 0.5063285645126835
  train_level7__roc_auc_macro_oob:
  - 0.5139615606005482
  - 0.5184334927066646
  - 0.5141830076895091
  - 0.5103330901034309
  - 0.5067096404441865
  train_level7__roc_auc_micro:
  - 0.44443266905052714
  - 0.4920032223429461
  - 0.48248283402868797
  - 0.44536069535487677
  - 0.4587644122464105
  train_level7__roc_auc_micro_masked:
  - 0.44393207025650505
  - 0.491371207182731
  - 0.48158741237569486
  - 0.4444744075523299
  - 0.4582886463194465
  train_level7__roc_auc_micro_oob:
  - 0.44493487231222545
  - 0.4921286051295268
  - 0.48176194955079166
  - 0.44542878354466053
  - 0.45874101372865944
  train_level7__roc_auc_samples:
  - 0.4401940555389539
  - 0.4921099118840493
  - 0.48181164920079506
  - 0.4434587553905958
  - 0.4557692392440091
  train_level7__roc_auc_samples_masked:
  - 0.4394714491847428
  - 0.49084030800811995
  - 0.4814186443025922
  - 0.4429456491813865
  - 0.4550571581478445
  train_level7__roc_auc_samples_oob:
  - 0.44087616889893655
  - 0.4921452179214537
  - 0.48096517326674926
  - 0.4433162410583061
  - 0.45573047629474134
  train_level7__roc_auc_weighted:
  - 0.5162799777801123
  - 0.5216751978014762
  - 0.5177001201920787
  - 0.5136975731281459
  - 0.5116606058805406
  train_level7__roc_auc_weighted_masked:
  - 0.5135708117024295
  - 0.5180877269030424
  - 0.5138236044900015
  - 0.5102140429996846
  - 0.5092316747793995
  train_level7__roc_auc_weighted_oob:
  - 0.5147046252468452
  - 0.5221892162143486
  - 0.5141754094763102
  - 0.5127482912154316
  - 0.5081628333205126
  train_level7__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level7__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level7__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level7__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level7__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level7__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level7__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level7__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level7__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level7__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__average_precision_macro:
  - 0.24898177412690597
  - 0.24763648674293942
  - 0.2469196075181661
  - 0.24128558845579934
  - 0.24112266890047002
  train_level8__average_precision_macro_masked:
  - 0.1953571112795608
  - 0.19310569672852626
  - 0.19366770024539678
  - 0.18937730113400197
  - 0.18985120391690652
  train_level8__average_precision_macro_oob:
  - 0.24690525366797889
  - 0.24692357146893343
  - 0.24451880129841386
  - 0.24133687257667855
  - 0.2411730054763802
  train_level8__average_precision_micro:
  - 0.21093594861508522
  - 0.2272803819950085
  - 0.22440517495935014
  - 0.21416473899155297
  - 0.21688403273644433
  train_level8__average_precision_micro_masked:
  - 0.1565330268202582
  - 0.1695886361831596
  - 0.16733946325419086
  - 0.15915169324519987
  - 0.16131701388329459
  train_level8__average_precision_micro_oob:
  - 0.21122314281698285
  - 0.2272843087779291
  - 0.224370496985211
  - 0.21420321644498377
  - 0.21694742085971003
  train_level8__average_precision_samples:
  - 0.2153201568352933
  - 0.2302759645513195
  - 0.2278092454104136
  - 0.21654320013137113
  - 0.22074304107549997
  train_level8__average_precision_samples_masked:
  - 0.16154812402656352
  - 0.17318017721017057
  - 0.17138892542354958
  - 0.16238019052117378
  - 0.16580222891136137
  train_level8__average_precision_samples_oob:
  - 0.215632679424991
  - 0.2302709064658664
  - 0.2277490749145636
  - 0.21656557867682122
  - 0.22072785287035748
  train_level8__average_precision_weighted:
  - 0.3665005880221698
  - 0.36148037628861585
  - 0.36081220002926384
  - 0.3564957493144858
  - 0.35479976253430545
  train_level8__average_precision_weighted_masked:
  - 0.30028928766838564
  - 0.295279376911844
  - 0.2948493647643842
  - 0.29214785240648067
  - 0.291330981662625
  train_level8__average_precision_weighted_oob:
  - 0.3640980375578505
  - 0.3612213040584859
  - 0.35821290629633673
  - 0.3571618253188594
  - 0.3549955303418954
  train_level8__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level8__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level8__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level8__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level8__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level8__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level8__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level8__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level8__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level8__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level8__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level8__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level8__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level8__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level8__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level8__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level8__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level8__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level8__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10893488726931033
  train_level8__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level8__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level8__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09610079349279031
  train_level8__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level8__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level8__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09688862925838053
  train_level8__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level8__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level8__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.18087639790883067
  train_level8__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level8__label_ranking_average_precision_score:
  - 0.21532015683529349
  - 0.2302759645513196
  - 0.22780924541041372
  - 0.21654320013137104
  - 0.22074304107549989
  train_level8__label_ranking_average_precision_score_oob:
  - 0.2156326794249911
  - 0.23027090646586623
  - 0.22774907491456373
  - 0.21656557867682108
  - 0.22072785287035768
  train_level8__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__ndcg:
  - 0.6045843571416444
  - 0.6196438158136848
  - 0.6173429050984912
  - 0.609051940102314
  - 0.6104985563659122
  train_level8__ndcg_oob:
  - 0.6049275863668244
  - 0.6196599435581617
  - 0.6173522924434117
  - 0.6090873374876139
  - 0.6105790122180214
  train_level8__neg_coverage_error:
  - -98.33333333333333
  - -97.47989949748744
  - -98.48267326732673
  - -99.83291770573567
  - -97.95533498759305
  train_level8__neg_coverage_error_oob:
  - -98.11442786069652
  - -97.53015075376885
  - -98.77227722772277
  - -99.84538653366583
  - -97.9652605459057
  train_level8__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level8__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171390813319128
  train_level8__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level8__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level8__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246497145822522
  train_level8__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level8__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level8__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8244081521463956
  train_level8__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level8__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171362967539634
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level8__neg_label_ranking_loss:
  - -0.7936806882495497
  - -0.7378553715720642
  - -0.7396931500890838
  - -0.805684071658178
  - -0.7937345785568007
  train_level8__neg_label_ranking_loss_oob:
  - -0.7941258450958387
  - -0.7379040385575866
  - -0.741129741213122
  - -0.8068172855632225
  - -0.7955734802085088
  train_level8__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level8__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level8__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level8__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level8__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level8__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level8__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level8__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level8__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__roc_auc_macro:
  - 0.5173081934954549
  - 0.5201464833817283
  - 0.5189504948065903
  - 0.5082686254218606
  - 0.5083171754160356
  train_level8__roc_auc_macro_masked:
  - 0.5139181820373732
  - 0.5165187686472512
  - 0.5147542613159076
  - 0.5059130391732183
  - 0.5080088168542175
  train_level8__roc_auc_macro_oob:
  - 0.514802127153788
  - 0.5195633994448715
  - 0.5155671477019884
  - 0.5089785472873551
  - 0.5081598481452386
  train_level8__roc_auc_micro:
  - 0.44484455450821986
  - 0.4920299701376598
  - 0.4825022844964787
  - 0.44526676697625883
  - 0.45908975628710746
  train_level8__roc_auc_micro_masked:
  - 0.4440577785156897
  - 0.49146690297958284
  - 0.48176966362186363
  - 0.4444332733068168
  - 0.4588079640806918
  train_level8__roc_auc_micro_oob:
  - 0.44543983005731275
  - 0.49201956655158685
  - 0.4821319270934461
  - 0.4453709136273961
  - 0.4592314073262427
  train_level8__roc_auc_samples:
  - 0.4405774017499463
  - 0.4920933037822174
  - 0.4818426151297157
  - 0.44358637595016276
  - 0.4561336433627131
  train_level8__roc_auc_samples_masked:
  - 0.4396300499440738
  - 0.49086635621079794
  - 0.4817512745117735
  - 0.44311963708045354
  - 0.45570213058421005
  train_level8__roc_auc_samples_oob:
  - 0.4414610043086082
  - 0.49211118700376144
  - 0.4813948333074515
  - 0.4436607027250689
  - 0.45632431067832957
  train_level8__roc_auc_weighted:
  - 0.5201159399939157
  - 0.5215184833035202
  - 0.5188130903875007
  - 0.5121546334805024
  - 0.5090549980917558
  train_level8__roc_auc_weighted_masked:
  - 0.516508322450525
  - 0.5188506046749111
  - 0.5151298507900958
  - 0.5099518457509294
  - 0.5087686967442857
  train_level8__roc_auc_weighted_oob:
  - 0.5176310986740155
  - 0.5212450600333068
  - 0.5154445642195481
  - 0.5138993056689413
  - 0.5087377585489365
  train_level8__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level8__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level8__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level8__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level8__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level8__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level8__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level8__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level8__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level8__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level9__average_precision_macro:
  - 0.2480511526821502
  - 0.2466361533199718
  - 0.24566841138533077
  - 0.24163067904577726
  - 0.24243714933318378
  train_level9__average_precision_macro_masked:
  - 0.19519463217391145
  - 0.19212815089953184
  - 0.19207383954793084
  - 0.18952050281494234
  - 0.18957505165196617
  train_level9__average_precision_macro_oob:
  - 0.24518926215562462
  - 0.24726084820656327
  - 0.2455281419086516
  - 0.24212074590120328
  - 0.24111954705314725
  train_level9__average_precision_micro:
  - 0.21093238813676282
  - 0.2272953651373145
  - 0.22440992212382446
  - 0.21408115497981556
  - 0.21679658211989128
  train_level9__average_precision_micro_masked:
  - 0.1565774900925408
  - 0.16957434472828145
  - 0.16731547453881945
  - 0.15914133567614752
  - 0.1611716951910393
  train_level9__average_precision_micro_oob:
  - 0.21121480357501846
  - 0.22730687043742914
  - 0.22419415955632294
  - 0.21434536201066035
  - 0.21697767827192124
  train_level9__average_precision_samples:
  - 0.21532774749189476
  - 0.23032323087580892
  - 0.2278160341642458
  - 0.21645481057061547
  - 0.22065972845575083
  train_level9__average_precision_samples_masked:
  - 0.16161351338402813
  - 0.1732033216435061
  - 0.17133452627702248
  - 0.16236634642067102
  - 0.16569152823509856
  train_level9__average_precision_samples_oob:
  - 0.21568994304214248
  - 0.23029994561966982
  - 0.22763387011898326
  - 0.21668188178090214
  - 0.22076707930630637
  train_level9__average_precision_weighted:
  - 0.36594750189568526
  - 0.3638195357998049
  - 0.3593804744757154
  - 0.3568985193453371
  - 0.35763362484210065
  train_level9__average_precision_weighted_masked:
  - 0.30011771599301923
  - 0.2972322068482811
  - 0.29341140527240656
  - 0.29222502265462
  - 0.29208107416634455
  train_level9__average_precision_weighted_oob:
  - 0.3612992378316311
  - 0.3633691779910586
  - 0.35864521637430014
  - 0.356622231408122
  - 0.35504795179944026
  train_level9__f1_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.2343588137512346
  train_level9__f1_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.1828854977512873
  train_level9__f1_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level9__f1_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23435881375123468
  train_level9__f1_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.17537623248572912
  train_level9__f1_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level9__f1_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.2343588137512346
  train_level9__f1_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17561716815542244
  train_level9__f1_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level9__f1_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468070380953377
  train_level9__f1_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.28287044630911035
  train_level9__f1_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level9__fn_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fn_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level9__fp_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.7656411862487651
  train_level9__fp_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171145022487125
  train_level9__fp_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level9__fp_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656411862487653
  train_level9__fp_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246237675142709
  train_level9__fp_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level9__fp_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656411862487653
  train_level9__fp_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8243828318445776
  train_level9__fp_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level9__fp_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531929619046621
  train_level9__fp_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171295536908895
  train_level9__fp_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level9__jaccard_macro:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14409326771565137
  train_level9__jaccard_macro_masked:
  - 0.10899667801462888
  - 0.10800697639396332
  - 0.10819923666742291
  - 0.10984803347189767
  - 0.10894777327112586
  train_level9__jaccard_macro_oob:
  - 0.14415820836991533
  - 0.14297227086194447
  - 0.14306083291170177
  - 0.1451126764165557
  - 0.14408038920158264
  train_level9__jaccard_micro:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13273297857825078
  train_level9__jaccard_micro_masked:
  - 0.09615795851450566
  - 0.0953517804751769
  - 0.09546343260321329
  - 0.09682864376957959
  - 0.09611638059754554
  train_level9__jaccard_micro_oob:
  - 0.13276612042787186
  - 0.1317275174270136
  - 0.13177577719150324
  - 0.13357668240201998
  - 0.13271752329753994
  train_level9__jaccard_samples:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336620572084553
  train_level9__jaccard_samples_masked:
  - 0.09694822757622473
  - 0.09617776935285023
  - 0.0962641893418457
  - 0.09767779699383178
  - 0.09690406607540966
  train_level9__jaccard_samples_oob:
  - 0.13367779480242148
  - 0.13266587426037924
  - 0.13271734755590667
  - 0.13455652284767788
  - 0.1336467096358527
  train_level9__jaccard_weighted:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.229700857345293
  train_level9__jaccard_weighted_masked:
  - 0.18085428569458
  - 0.17946986116643057
  - 0.18010457419025652
  - 0.18222437493670568
  - 0.1808799330741704
  train_level9__jaccard_weighted_oob:
  - 0.2299638936255338
  - 0.22833600999990605
  - 0.22869914945752995
  - 0.23147501007458376
  - 0.2296973116826348
  train_level9__label_ranking_average_precision_score:
  - 0.2153277474918949
  - 0.23032323087580892
  - 0.2278160341642459
  - 0.2164548105706158
  - 0.22065972845575077
  train_level9__label_ranking_average_precision_score_oob:
  - 0.2156899430421424
  - 0.23029994561967
  - 0.22763387011898314
  - 0.21668188178090236
  - 0.2207670793063065
  train_level9__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.00012716445890151778
  train_level9__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.00010687601243731601
  train_level9__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0027153945515117515
  train_level9__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.002348920192376136
  train_level9__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0001317388270964074
  train_level9__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.00011950892662554632
  train_level9__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 3.501042674393591e-05
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.932052782757974e-05
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__ndcg:
  - 0.6045479232042117
  - 0.6196646940928698
  - 0.6173712688749184
  - 0.6089700576573086
  - 0.610432108462661
  train_level9__ndcg_oob:
  - 0.6048774079474571
  - 0.6196472773675133
  - 0.6172269693218467
  - 0.6092198593809017
  - 0.6105754881022811
  train_level9__neg_coverage_error:
  - -98.42039800995025
  - -97.37939698492463
  - -98.68564356435644
  - -99.90523690773067
  - -97.93052109181141
  train_level9__neg_coverage_error_oob:
  - -98.16915422885572
  - -97.40954773869346
  - -98.86633663366337
  - -99.87032418952619
  - -97.93548387096774
  train_level9__neg_hamming_loss_macro:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.7656411862487651
  train_level9__neg_hamming_loss_macro_masked:
  - -0.8170050513327435
  - -0.8184411720624812
  - -0.8182531112463574
  - -0.81580843349988
  - -0.8171145022487125
  train_level9__neg_hamming_loss_macro_oob:
  - -0.7655895280877171
  - -0.7672098355856956
  - -0.7671344804383353
  - -0.764327046461516
  - -0.765665277409718
  train_level9__neg_hamming_loss_micro:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656411862487653
  train_level9__neg_hamming_loss_micro_masked:
  - -0.8245545584601378
  - -0.8258974291641501
  - -0.8257113295395758
  - -0.8234388857008712
  - -0.8246237675142709
  train_level9__neg_hamming_loss_micro_oob:
  - -0.7655895280877167
  - -0.7672098355856954
  - -0.7671344804383351
  - -0.7643270464615161
  - -0.7656652774097183
  train_level9__neg_hamming_loss_samples:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656411862487653
  train_level9__neg_hamming_loss_samples_masked:
  - -0.8244115475296873
  - -0.8256965990295021
  - -0.825503244588075
  - -0.8231972656305474
  - -0.8243828318445776
  train_level9__neg_hamming_loss_samples_oob:
  - -0.7655895280877167
  - -0.7672098355856956
  - -0.767134480438335
  - -0.7643270464615161
  - -0.7656652774097182
  train_level9__neg_hamming_loss_weighted:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531929619046621
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.7166371179006432
  - -0.7185449109925119
  - -0.7182022906644027
  - -0.7150399040463621
  - -0.7171295536908895
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.6525316955301795
  - -0.6546167387287479
  - -0.6545346330298665
  - -0.6508323397382851
  - -0.6531995945898716
  train_level9__neg_label_ranking_loss:
  - -0.7936401835307684
  - -0.7376196530629803
  - -0.7398228986594982
  - -0.8059805618295476
  - -0.7935043847409515
  train_level9__neg_label_ranking_loss_oob:
  - -0.7941980301871171
  - -0.7376902067617566
  - -0.7411960784350159
  - -0.8071508832128292
  - -0.7950291755940803
  train_level9__precision_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.2343588137512346
  train_level9__precision_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.1828854977512873
  train_level9__precision_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level9__precision_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23435881375123468
  train_level9__precision_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.17537623248572912
  train_level9__precision_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level9__precision_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.2343588137512346
  train_level9__precision_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17561716815542244
  train_level9__precision_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level9__precision_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468070380953377
  train_level9__precision_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.28287044630911035
  train_level9__precision_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level9__recall_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.2343588137512346
  train_level9__recall_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.1828854977512873
  train_level9__recall_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level9__recall_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23435881375123468
  train_level9__recall_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.17537623248572912
  train_level9__recall_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level9__recall_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.2343588137512346
  train_level9__recall_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17561716815542244
  train_level9__recall_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level9__recall_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468070380953377
  train_level9__recall_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.28287044630911035
  train_level9__recall_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level9__roc_auc_macro:
  - 0.5180124622802238
  - 0.5174332677001355
  - 0.518175596217585
  - 0.5069400295149528
  - 0.5092346271328168
  train_level9__roc_auc_macro_masked:
  - 0.5162034533421799
  - 0.5117178037394937
  - 0.5146201384333596
  - 0.505620358165766
  - 0.5069239164321423
  train_level9__roc_auc_macro_oob:
  - 0.515224995712722
  - 0.5188260861265632
  - 0.5161010185810919
  - 0.5067931552936373
  - 0.5079526271340105
  train_level9__roc_auc_micro:
  - 0.44488120945059195
  - 0.49210540904746425
  - 0.4824787864951262
  - 0.44502330036235227
  - 0.4589291771458611
  train_level9__roc_auc_micro_masked:
  - 0.44430435209630686
  - 0.4914022377599707
  - 0.48168723550311643
  - 0.4444080709769861
  - 0.458360113881768
  train_level9__roc_auc_micro_oob:
  - 0.44543632479438067
  - 0.4922067894532379
  - 0.4817867277624401
  - 0.4456089082587417
  - 0.4592558005276475
  train_level9__roc_auc_samples:
  - 0.44048659767960496
  - 0.49234126298193387
  - 0.48179448769097927
  - 0.4431889575459624
  - 0.45596273942794197
  train_level9__roc_auc_samples_masked:
  - 0.43978751593315624
  - 0.4910243998703934
  - 0.48161739559732203
  - 0.4429767051277612
  - 0.45526549231162095
  train_level9__roc_auc_samples_oob:
  - 0.44136093883240723
  - 0.4923032013868153
  - 0.4812217331461623
  - 0.4437041974512935
  - 0.45620967609269564
  train_level9__roc_auc_weighted:
  - 0.5230310771958518
  - 0.5221250835957312
  - 0.5181974495925586
  - 0.5098347329526433
  - 0.5105213593905628
  train_level9__roc_auc_weighted_masked:
  - 0.5205288516076978
  - 0.5179637488655985
  - 0.5151995250485174
  - 0.5078964271357362
  - 0.5080162957962829
  train_level9__roc_auc_weighted_oob:
  - 0.519062552531528
  - 0.5239789506510462
  - 0.5148762062170501
  - 0.5092605447080462
  - 0.5083397854882659
  train_level9__tn_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.409116095304633e-05
  train_level9__tn_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.4579083200196634e-05
  train_level9__tn_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.409116095304633e-05
  train_level9__tn_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.5947067981318112e-05
  train_level9__tn_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.4091160953046325e-05
  train_level9__tn_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 2.532030181799767e-05
  train_level9__tn_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tn_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 6.632685209443617e-06
  train_level9__tn_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 6.743063073862763e-06
  train_level9__tn_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level9__tp_macro:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level9__tp_macro_masked:
  - 0.1829949486672564
  - 0.18155882793751882
  - 0.18174688875364242
  - 0.18419156650012
  - 0.18286091866808707
  train_level9__tp_macro_oob:
  - 0.23441047191228326
  - 0.23279016441430453
  - 0.23286551956166493
  - 0.23567295353848383
  - 0.23433472259028154
  train_level9__tp_micro:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level9__tp_micro_masked:
  - 0.17544544153986213
  - 0.1741025708358499
  - 0.1742886704604242
  - 0.1765611142991288
  - 0.1753502854177478
  train_level9__tp_micro_oob:
  - 0.23441047191228323
  - 0.23279016441430453
  - 0.2328655195616649
  - 0.2356729535384839
  - 0.23433472259028162
  train_level9__tp_samples:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level9__tp_samples_masked:
  - 0.17558845247031268
  - 0.17430340097049793
  - 0.17449675541192497
  - 0.1768027343694526
  - 0.17559184785360443
  train_level9__tp_samples_oob:
  - 0.23441047191228317
  - 0.23279016441430447
  - 0.23286551956166482
  - 0.2356729535384838
  - 0.23433472259028157
  train_level9__tp_weighted:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
  train_level9__tp_weighted_masked:
  - 0.28336288209935684
  - 0.2814550890074879
  - 0.2817977093355973
  - 0.28496009595363786
  - 0.2828637032460365
  train_level9__tp_weighted_oob:
  - 0.34746830446982074
  - 0.3453832612712519
  - 0.3454653669701335
  - 0.34916766026171475
  - 0.3468004054101283
start: 2023-12-31 13:28:18.253159
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
