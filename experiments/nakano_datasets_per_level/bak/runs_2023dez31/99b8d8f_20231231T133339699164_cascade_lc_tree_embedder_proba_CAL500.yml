active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            YGZmZmZm9r/QzMzMzMwEQDAzMzMzMwPA0MzMzMzMBEBgZmZmZmb2vw==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJv8CZmZmZmek/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkA0MzMzMzMTQKCZmZmZmek/0MzMzMzM/D9mZmZmZmYmwA==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcCYmZmZmZkJwNDMzMzMzPw/0MzMzMzM/D9oZmZmZmYGQA==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/gJmZmZmZ6b8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b9AMzMzMzPjP4CZmZmZmdm/QDMzMzMz4z+AmZmZmZnZvw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcCamZmZmZkpQMzMzMzMzBjANDMzMzMzE0BmZmZmZmYiwA==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMFMDQzMzMzMz8P5iZmZmZmQHANDMzMzMzE0CgmZmZmZnpPw==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUDOzMzMzMwsQDIzMzMzMyfAyMzMzMzMBMBkZmZmZmYSwA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ2T+cmZmZmZkZQMjMzMzMzAzAcGZmZmZm9j9kZmZmZmYSwA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAgQAAAAAAAACjAAAAAAAAAAMAAAAAAAADwPw==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9oZmZmZmYSQMzMzMzMzCLAaGZmZmZmEkCgmZmZmZn5Pw==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b+cmZmZmZkVQCAzMzMzM+O/ODMzMzMzC0BkZmZmZmYawA==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMDMBwZmZmZmb2P8CZmZmZmdk/cGZmZmZm9j/AmZmZmZnZPw==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAUQAAAAAAAAAjAAAAAAAAAAEAAAAAAAAAIwA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAoQAAAAAAAACbAAAAAAAAA8D8AAAAAAAAIwA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcCYmZmZmZkBwICZmZmZmcm/aGZmZmZmBkDQzMzMzMz8Pw==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L9oZmZmZmYuQDAzMzMzMxPAQDMzMzMz8z+YmZmZmZkjwA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMBMA4MzMzMzMDQGRmZmZmZhbAODMzMzMzA0A4MzMzMzMLQA==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA0DMzMzMzMwsQGhmZmZmZh7A0MzMzMzMBMBoZmZmZmYawA==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmBsCQmZmZmZnpv87MzMzMzBRAyMzMzMzM/L/AmZmZmZnJPw==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAsQAAAAAAAACLAAAAAAAAAAAAAAAAAAAAUwA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T+QmZmZmZkBwACZmZmZmcm/wJmZmZmZ6T/AmZmZmZnpPw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0BoZmZmZmb2P2ZmZmZmZh7ANDMzMzMzC0CgmZmZmZnZPw==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwvwAAAAAAABxAAAAAAAAAEMAAAAAAAAAAAA==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z9oZmZmZmYaQJiZmZmZmRHAQDMzMzMz4z8wMzMzMzMLwA==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAADwPwAAAAAAAABAAAAAAAAAFMAAAAAAAAAAAA==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAAPC/AAAAAAAAAEAAAAAAAADwvw==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T+gmZmZmZn5P4CZmZmZmdm/MDMzMzMzA8CAmZmZmZnZvw==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L9oZmZmZmYmQGBmZmZmZg7AQDMzMzMz8z8wMzMzMzMbwA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D8wMzMzMzPzv9DMzMzMzPw/mJmZmZmZCcCgmZmZmZnpPw==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L9oZmZmZmYuQDAzMzMzMx/AoJmZmZmZCUCYmZmZmZkhwA==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFMAAAAAAAAAQwAAAAAAAABxAAAAAAAAAAMAAAAAAAAAQQA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T/OzMzMzMwwQDIzMzMzMzHAwJmZmZmZ6T8gMzMzMzPzvw==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAIQAAAAAAAACDAAAAAAAAAFEAAAAAAAAAAwA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAQQAAAAAAAABBAAAAAAAAA8D8AAAAAAAAUwA==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T80MzMzMzMLQGZmZmZmZhLANDMzMzMzC0DMzMzMzMwEwA==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r/QzMzMzMwMQNDMzMzMzARAgJmZmZmZ2b+YmZmZmZkRwA==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz4z+cmZmZmZn5P5yZmZmZmfk/MjMzMzMzA8BkZmZmZmb2vw==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zszMzMzMHEDOzMzMzMwQQJmZmZmZmSXAMjMzMzMzG8DOzMzMzMwYQA==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAPC/AAAAAAAAAAAAAAAAAADwPw==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j+YmZmZmZn5vzQzMzMzMwNAzMzMzMzMBMCgmZmZmZnZPw==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz479oZmZmZmb2P2ZmZmZmZhLAaGZmZmZm9j80MzMzMzMDQA==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ6b+YmZmZmZnpvzQzMzMzM/M/MzMzMzMzE8DNzMzMzMwUQA==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzE8DQzMzMzMwcQMDMzMzMzPy/oJmZmZmZAUBgZmZmZmYGwA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9AMzMzMzPjP0AzMzMzM+M/0MzMzMzMBEAwMzMzMzMDwA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0A0MzMzMzMDQGZmZmZmZhrAzMzMzMzMBMCamZmZmZkRQA==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b9gZmZmZmb2v0AzMzMzM+M/QDMzMzMz4z9AMzMzMzPjPw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMGMAgMzMzMzPzv8CZmZmZmek/wJmZmZmZ6T84MzMzMzMXQA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T9oZmZmZmYGQMzMzMzMzBDAoJmZmZmZ6T+AmZmZmZnJvw==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcA0MzMzMzMTQDAzMzMzM/O/oJmZmZmZ6T8wMzMzMzPzvw==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAQAAAAAAAABDAAAAAAAAAGEAAAAAAAAAgwA==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAgQAAAAAAAABDAAAAAAAAAAAAAAAAAAAAQwA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMGMDAzMzMzMz8P4CZmZmZmek/wMzMzMzM/D/AzMzMzMz8Pw==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T9oZmZmZmYOQGhmZmZmZg5AzMzMzMzMFMCYmZmZmZkJwA==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j80MzMzMzMLQMzMzMzMzATAzMzMzMzMDMBoZmZmZmb2Pw==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkBoZmZmZmYGQMzMzMzMzBjAmJmZmZmZAcDQzMzMzMz8Pw==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+AmZmZmZnJv6CZmZmZmek/oJmZmZmZ6T8wMzMzMzPzvw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAwAAAAAAAAAAAAAAAAAAACEAAAAAAAAAUwA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMGEDMzMzMzMwcQJqZmZmZmSHA0MzMzMzM/L9oZmZmZmYGwA==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zczMzMzMEECamZmZmZkBQGZmZmZmZg7AzMzMzMzM/L+YmZmZmZnpvw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAgQAAAAAAAACbAAAAAAAAA8D8AAAAAAAAUQA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAgQAAAAAAAAADAAAAAAAAAGMAAAAAAAADwvw==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAwAAAAAAAAAAAAAAAAAAACMAAAAAAAAAYQA==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAgQAAAAAAAABTAAAAAAAAAEMAAAAAAAADwPw==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZm9j+QmZmZmZn5v2RmZmZmZhbAODMzMzMzC0A4MzMzMzMDQA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz8z9oZmZmZmYuQDAzMzMzMx/AMDMzMzMzF8BgZmZmZmYGwA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b/QzMzMzMwMQDAzMzMzMwvAYGZmZmZm9r+gmZmZmZn5Pw==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz87/AmZmZmZnpPyAzMzMzM/O/4MzMzMzM/D8AmZmZmZnJvw==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAAAAAAAAAAADAAAAAAAAAGEAAAAAAAAAgwA==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZFUAwMzMzMzMLQGhmZmZmZhbAQDMzMzMz47/QzMzMzMwEwA==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8BoZmZmZmYSQJiZmZmZmRXAgJmZmZmZ2b/QzMzMzMwMQA==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzMBMCAZmZmZmb2P4CZmZmZmfm/gGZmZmZm9j+AZmZmZmb2Pw==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+AmZmZmZnJv6CZmZmZmek/oJmZmZmZ6T+YmZmZmZkBwA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzH0BoZmZmZmYGQGZmZmZmZirANDMzMzMzF0CYmZmZmZkJwA==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJiZmZmZyb+gmZmZmZkrQGBmZmZmZiDAAM3MzMzM/D/AzMzMzMwcwA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmFkCAmZmZmZnZv2hmZmZmZhpAMDMzMzMzA8DMzMzMzMwiwA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzF8BoZmZmZmYoQDAzMzMzMx/A0MzMzMzMFEBgZmZmZmYOwA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAYQAAAAAAAABzAAAAAAAAACMAAAAAAAAAQQA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZGUAyMzMzMzMjwJCZmZmZmfm/nJmZmZmZFUAgMzMzMzPjvw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcA0MzMzMzMXQMzMzMzMzBDA0MzMzMzM/D+AmZmZmZnJvw==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMDEBoZmZmZmYSQJiZmZmZmRXAYGZmZmZm9r9gZmZmZmb2vw==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT9oZmZmZmYmQMDMzMzMzPy/oJmZmZmZAUCYmZmZmZknwA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0CYmZmZmZn5v8zMzMzMzATAaGZmZmZm9j+gmZmZmZnZPw==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2b+YmZmZmZn5P6CZmZmZmdm/mJmZmZmZ+T80MzMzMzMDwA==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmDsDQzMzMzMwcQGBmZmZmZgbAoJmZmZmZCUBgZmZmZmYOwA==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZyT/IzMzMzMz8v8CZmZmZmck/yMzMzMzM/L+cmZmZmZkJQA==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEMCAmZmZmZnJv2hmZmZmZgZA0MzMzMzM/D+AmZmZmZnJvw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZm9r84MzMzMzPjP2RmZmZmZva/nJmZmZmZ+T84MzMzMzPjPw==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b9oZmZmZmb2P8zMzMzMzAzAaGZmZmZm9j80MzMzMzMDQA==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAIQAAAAAAAAADAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwPwAAAAAAAAAAAAAAAAAAFMAAAAAAAAAYQA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8D8AAAAAAADwPw==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMA0MzMzMzMDQDAzMzMzM+O/mpmZmZmZEUDMzMzMzMwEwA==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b/MzMzMzMwEwDAzMzMzM+O/NDMzMzMzC0BoZmZmZmb2Pw==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+amZmZmZkRQMzMzMzMzAzAaGZmZmZm9j+YmZmZmZn5vw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T9oZmZmZmb2P6CZmZmZmdk/mJmZmZmZ+b8wMzMzMzPjvw==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAIQAAAAAAAACDAAAAAAAAAGMAAAAAAAAAYQA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMBoZmZmZmb2P2hmZmZmZvY/mJmZmZmZ+b80MzMzMzMDQA==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmBsCYmZmZmZnpv5qZmZmZmQlAmpmZmZmZAUDMzMzMzMz8vw==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAQAAAAAAAABDAAAAAAAAA8L8AAAAAAAAIQA==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          AJqZmZmZ2T/QzMzMzMwsQGBmZmZmZh7AgJmZmZmZ+b9gZmZmZmYWwA==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 13:39:27.031179
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder_proba
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.7
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - xt
                      - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                        params:
                          estimator:
                            call: deep_forest.tree_embedder.ForestEmbedder
                            params:
                              estimator:
                                call: sklearn.ensemble._forest.ExtraTreesRegressor
                                params:
                                  bootstrap: true
                                  ccp_alpha: 0.0
                                  criterion: squared_error
                                  max_depth: null
                                  max_features: sqrt
                                  max_leaf_nodes: null
                                  max_samples: 0.5
                                  min_impurity_decrease: 0.0
                                  min_samples_leaf: 5
                                  min_samples_split: 2
                                  min_weight_fraction_leaf: 0.0
                                  monotonic_cst: null
                                  n_estimators: 150
                                  n_jobs: 14
                                  oob_score: false
                                  random_state: 0
                                  verbose: true
                                  warm_start: false
                              max_node_size: 0.8
                              max_pvalue: 1.0
                              method: path
                              node_weights: log_node_size
                          method: predict
                          post_transformer:
                            call: sklearn.pipeline.Pipeline
                            params:
                              memory: null
                              steps:
                              - - densifier
                                - call: nakano_datasets_v2.estimators.Densifier
                                  params: {}
                              - - pca
                                - call: sklearn.decomposition._pca.PCA
                                  params:
                                    copy: true
                                    iterated_power: auto
                                    n_components: 0.8
                                    n_oversamples: 10
                                    power_iteration_normalizer: auto
                                    random_state: 0
                                    svd_solver: auto
                                    tol: 0.0
                                    whiten: false
                              verbose: false
                    - - rf
                      - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                        params:
                          estimator:
                            call: deep_forest.tree_embedder.ForestEmbedder
                            params:
                              estimator:
                                call: sklearn.ensemble._forest.RandomForestRegressor
                                params:
                                  bootstrap: true
                                  ccp_alpha: 0.0
                                  criterion: squared_error
                                  max_depth: null
                                  max_features: sqrt
                                  max_leaf_nodes: null
                                  max_samples: 0.5
                                  min_impurity_decrease: 0.0
                                  min_samples_leaf: 5
                                  min_samples_split: 2
                                  min_weight_fraction_leaf: 0.0
                                  monotonic_cst: null
                                  n_estimators: 150
                                  n_jobs: 14
                                  oob_score: false
                                  random_state: 0
                                  verbose: true
                                  warm_start: false
                              max_node_size: 0.95
                              max_pvalue: 1.0
                              method: path
                              node_weights: log_node_size
                          method: predict
                          post_transformer:
                            call: sklearn.pipeline.Pipeline
                            params:
                              memory: null
                              steps:
                              - - densifier
                                - call: nakano_datasets_v2.estimators.Densifier
                                  params: {}
                              - - pca
                                - call: sklearn.decomposition._pca.PCA
                                  params:
                                    copy: true
                                    iterated_power: auto
                                    n_components: 0.8
                                    n_oversamples: 10
                                    power_iteration_normalizer: auto
                                    random_state: 0
                                    svd_solver: auto
                                    tol: 0.0
                                    whiten: false
                              verbose: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_tree_embedder_proba
  params: {}
hash: 99b8d8f64409a286507767831d005b8e101aa766a07e7d03a67f29a318ae665f
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/99b8d8f_20231231T133339699164_cascade_lc_tree_embedder_proba_CAL500.yml
results:
  fit_time:
  - 327.56154918670654
  - 329.855571269989
  - 331.8184676170349
  - 330.44241166114807
  - 335.9990966320038
  fitted_params:
    estimator.level1.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 203
    - 213
    - 201
    - 204
    - 201
    estimator.level1.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 201
    - 209
    - 196
    - 201
    - 197
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level10.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 37
    - 34
    - 39
    - 30
    - 34
    estimator.level10.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 35
    - 34
    - 35
    - 31
    - 31
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level2.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 201
    - 212
    - 200
    - 202
    - 199
    estimator.level2.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 211
    - 223
    - 210
    - 212
    - 209
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level3.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 128
    - 137
    - 135
    - 128
    - 125
    estimator.level3.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 139
    - 146
    - 147
    - 139
    - 142
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level4.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 81
    - 80
    - 85
    - 68
    - 79
    estimator.level4.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 83
    - 82
    - 86
    - 69
    - 73
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level5.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 58
    - 55
    - 56
    - 46
    - 51
    estimator.level5.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 66
    - 60
    - 63
    - 51
    - 56
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level6.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 53
    - 47
    - 51
    - 41
    - 48
    estimator.level6.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 49
    - 47
    - 48
    - 45
    - 44
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level7.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 42
    - 43
    - 41
    - 37
    - 38
    estimator.level7.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 49
    - 42
    - 47
    - 36
    - 43
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level8.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 42
    - 38
    - 44
    - 33
    - 39
    estimator.level8.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 40
    - 38
    - 39
    - 35
    - 35
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
    estimator.level9.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 36
    - 36
    - 36
    - 32
    - 33
    estimator.level9.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 41
    - 37
    - 43
    - 32
    - 36
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.045767557777560086
      - 0.25944542405385773
      - 0.16530409739172625
      - 0.10510740802407467
      - 0.2769788109157045
      - 0.16203723621972047
      - 0.16732086559672768
      - 0.10222943156616623
      - 0.11394061958847038
      - 0.10883554386145544
      - 0.19911177837314198
      - 0.13615029548764487
      - 0.05564978188539044
      - 0.12601626417914294
      - 0.1327313029347913
      - 0.16440530369101797
      - 0.13823554917304914
      - 0.10346287385057829
      - 0.14396548842571566
      - 0.07855085181304693
      - 0.14522900044680348
      - 0.06876772502291605
      - 0.21247500253280754
      - 0.1699984218923613
      - 0.05565314802156907
      - 0.09685451876463114
      - 0.12332654860744749
      - 0.15959064576085852
      - 0.0526271336548106
      - 0.04930888708361235
      - 0.2267901959151959
      - 0.09083190663843237
      - 0.2127868863162981
      - 0.0722084980237154
      - 0.1956708569208569
      - 0.09272506904859845
      - 0.06678023622468067
      - 0.022467949577082702
      - 0.04226654500802228
      - 0.01904945989104405
      - 0.05469809520038789
      - 0.016241966607593132
      - 0.021759124146764598
      - 0.0495403955336991
      - 0.02931569092283378
      - 0.1256538492359312
      - 0.04507717537889952
      - 0.03380453815847074
      - 0.14167682515896804
      - 0.12260472679584815
      - 0.027453878260329877
      - 0.2647670155620523
      - 0.09673489539560967
      - 0.05398320500361316
      - 0.08549191847013816
      - 0.3143696904266757
      - 0.06196260635915809
      - 0.022502526713053028
      - 0.03564174773852193
      - 0.08182516399845946
      - 0.17300294805226654
      - 0.060914502387215075
      - 0.025832960819373862
      - 0.19062059151287977
      - 0.1170080666048408
      - 0.13457405050146987
      - 0.149055456982463
      - 0.1017649303731778
      - 0.21437794145857406
      - 0.1062253359667153
      - 0.12699888763718548
      - 0.049624286698150326
      - 0.17538403589874174
      - 0.06996703752679456
      - 0.25252404045507487
      - 0.06594798879281638
      - 0.08104028793683965
      - 0.38437350801808623
      - 0.20236463145116987
      - 0.2557887107392058
      - 0.13693071634248102
      - 0.08420841005705972
      - 0.028438925132701652
      - 0.08784082927228087
      - 0.20740122363712582
      - 0.060559634724381264
      - 0.029161645914223232
      - 0.09260284035564935
      - 0.0490645640032962
      - 0.011667031470402257
      - 0.018306551213177716
      - 0.04258343400785261
      - 0.03595723273142628
      - 0.08171985218688516
      - 0.017625824031964075
      - 0.05194690061711339
      - 0.038174648536192575
      - 0.02628760991395697
      - 0.028348740823106372
      - 0.03996861380023276
      - 0.015462330789832234
      - 0.016592946192530593
      - 0.02094590034411265
    - - 0.03209222190703672
      - 0.25198170639746725
      - 0.12588786944050098
      - 0.11513737209759936
      - 0.29235379700416986
      - 0.12302027030981111
      - 0.1811708699463801
      - 0.10822078506289033
      - 0.1302466929622102
      - 0.12806503851540615
      - 0.17129981841969955
      - 0.10873435427006854
      - 0.07277743300470574
      - 0.13768381523027384
      - 0.1425988830388936
      - 0.15586063723623533
      - 0.17474593745900563
      - 0.12844224974372032
      - 0.15359170283739246
      - 0.06935467697595155
      - 0.18790134525082688
      - 0.0668267788856024
      - 0.21235518228054256
      - 0.14178525239380502
      - 0.06061055490403316
      - 0.1338077215824469
      - 0.11532640131541232
      - 0.13284600237725233
      - 0.06135227048553243
      - 0.049619185433792165
      - 0.2811827722542008
      - 0.09765495675821763
      - 0.21253369646226783
      - 0.058314243228036335
      - 0.22997603665953512
      - 0.0763708728270584
      - 0.07700346841913108
      - 0.026360192837465567
      - 0.049730512932760124
      - 0.021584167643950252
      - 0.04536871174802209
      - 0.03463209977023854
      - 0.01631898825080643
      - 0.047532346122128206
      - 0.02053793428793429
      - 0.13108682843531327
      - 0.06254165364990105
      - 0.016929212762546095
      - 0.11004561917483266
      - 0.16630931737639054
      - 0.03485112583123947
      - 0.24289053791652826
      - 0.09330485795367324
      - 0.05490355732702672
      - 0.07260461953170287
      - 0.24546602315019245
      - 0.0795772315168867
      - 0.020650939969121786
      - 0.038884495134495135
      - 0.0903638870159087
      - 0.15855286439963862
      - 0.07442429217309518
      - 0.031192880990485956
      - 0.21012338779107065
      - 0.14155534420685933
      - 0.10885193925924264
      - 0.10750223224487927
      - 0.09977026542740546
      - 0.20990736728719384
      - 0.11108030714989477
      - 0.13105130011062016
      - 0.036083442268771165
      - 0.19323655103066867
      - 0.07851031818423122
      - 0.24685787552166857
      - 0.06860633328024632
      - 0.0768027147537457
      - 0.3992970440551086
      - 0.2590462330381684
      - 0.30773443745704976
      - 0.12116367428867428
      - 0.0738660093063502
      - 0.030151515151515155
      - 0.06107357779706264
      - 0.25456135552198167
      - 0.04720467704338672
      - 0.01682027340272021
      - 0.10898095787191531
      - 0.030809714976381644
      - 0.023527675074066827
      - 0.02202157745636007
      - 0.041470060512916476
      - 0.031421853878851866
      - 0.06701163841783053
      - 0.023104084924737096
      - 0.04054825768574426
      - 0.03594384373796139
      - 0.03696975410210704
      - 0.03348942749932385
      - 0.033190329206812724
      - 0.026471343044924604
      - 0.022020070572702152
      - 0.03766214977152477
    - - 0.05903172981824667
      - 0.25825294234385143
      - 0.14098469548876366
      - 0.11248942856085711
      - 0.2858915316793917
      - 0.1433025074731628
      - 0.17281498860439076
      - 0.09275227933957417
      - 0.1616690562523896
      - 0.1259595360447633
      - 0.13875184390113088
      - 0.11993226926737562
      - 0.05367921904066482
      - 0.11437355222740342
      - 0.12782537796571203
      - 0.13765656981761995
      - 0.09070180185311763
      - 0.11428668553668553
      - 0.12171084301186341
      - 0.08219158292687703
      - 0.1692568952512134
      - 0.07695295757870518
      - 0.23138113303929625
      - 0.14929587136219788
      - 0.055587844849483786
      - 0.10783797882012167
      - 0.09342908552533197
      - 0.18240516910303
      - 0.057729874968105485
      - 0.05521571384316483
      - 0.2221229248389834
      - 0.12677376675038238
      - 0.1948687362632301
      - 0.07984332229615249
      - 0.1973679838237162
      - 0.06699698730377135
      - 0.09210282471152034
      - 0.029972337275708062
      - 0.033367992551666024
      - 0.03205214923964924
      - 0.04298084631417965
      - 0.01437711593961594
      - 0.030627232962397794
      - 0.0493853663808527
      - 0.02153968253968254
      - 0.10242060128423763
      - 0.052556370134495135
      - 0.01950438560557608
      - 0.11871206773550522
      - 0.15221123526350508
      - 0.03509167212434
      - 0.22806834577749546
      - 0.09454567416336913
      - 0.06029738052209963
      - 0.0827559955307208
      - 0.3466291472801889
      - 0.073765969882335
      - 0.02195165945165945
      - 0.03437919676044236
      - 0.08499282506875164
      - 0.1997233788267781
      - 0.05779976889527452
      - 0.018494524367508237
      - 0.1463846076603808
      - 0.11713999084128954
      - 0.13442246697197185
      - 0.0963714877194069
      - 0.09261530899987835
      - 0.2055176860102622
      - 0.07945174318915116
      - 0.13242145785249232
      - 0.044825600124513164
      - 0.17108673295214133
      - 0.0648607189181786
      - 0.26550234940180584
      - 0.07405557892399997
      - 0.06946451081990174
      - 0.419825749851523
      - 0.23802909527341337
      - 0.2871354128098788
      - 0.14371775635980177
      - 0.0668262611661125
      - 0.03258744361228833
      - 0.0728997701859544
      - 0.21631242434813858
      - 0.04980370359158238
      - 0.04183515148705022
      - 0.08861411836955317
      - 0.057474365171409504
      - 0.02144026608312323
      - 0.029582896052428455
      - 0.040109659361721894
      - 0.02591107290953186
      - 0.0768576830366603
      - 0.020733271896062593
      - 0.06125344658360963
      - 0.03212749145993891
      - 0.024929527836504577
      - 0.03051518844383501
      - 0.02090327160183591
      - 0.030199780746312258
      - 0.023082984912332037
      - 0.02876843835177168
    - - 0.05352441300717163
      - 0.2675704214766714
      - 0.16033729637390381
      - 0.10210110065373222
      - 0.26629009218294925
      - 0.12823616688920503
      - 0.14595531501019307
      - 0.11704272055736048
      - 0.1363849584060711
      - 0.11064109900316796
      - 0.16870315219371818
      - 0.15101582445332445
      - 0.04973637473637473
      - 0.14280312393423802
      - 0.1566122752608142
      - 0.13946519489282647
      - 0.14493746993746986
      - 0.1123792961592319
      - 0.1566731514099935
      - 0.08605508720304639
      - 0.18023833999957595
      - 0.06572400556875693
      - 0.251961746322396
      - 0.18666234559091702
      - 0.06799228815968796
      - 0.12152413939435032
      - 0.10478077478077479
      - 0.15864270366821384
      - 0.05269476420044602
      - 0.06366218406303795
      - 0.21131999046984368
      - 0.08900436034272241
      - 0.22685939721654008
      - 0.07702704004480707
      - 0.2042952843939686
      - 0.08853924291897775
      - 0.07717995528601587
      - 0.03131841503053624
      - 0.03361550719804124
      - 0.023984522229741186
      - 0.03600919045740778
      - 0.016545167049199307
      - 0.03289276352463166
      - 0.06305377093375432
      - 0.018743518839564564
      - 0.10855972615347612
      - 0.043781388364721695
      - 0.01585154186898373
      - 0.12339510744683158
      - 0.10489926739926736
      - 0.025356737489090432
      - 0.23498733409447692
      - 0.10104991663738273
      - 0.05665135373223985
      - 0.08271216913942603
      - 0.3191098848041892
      - 0.054928181652319566
      - 0.018872573133936768
      - 0.03347367016921472
      - 0.07313556054472396
      - 0.18307214465751048
      - 0.059424868432221375
      - 0.026290116133866136
      - 0.19848941708697804
      - 0.09844190709575326
      - 0.13190265038734497
      - 0.1048022079443078
      - 0.12163663210174838
      - 0.247614680121982
      - 0.10855868612511126
      - 0.1460554837262864
      - 0.0487104908979909
      - 0.17576675407925405
      - 0.07020989865817454
      - 0.23946649538404852
      - 0.07007442849548112
      - 0.08719955547909712
      - 0.4234447144104402
      - 0.23735206221161276
      - 0.257168456215442
      - 0.1231043853115163
      - 0.07456090064508432
      - 0.03519786338771022
      - 0.05496222024332789
      - 0.2062674516575378
      - 0.05870852999130152
      - 0.03314587544238707
      - 0.12463278864794014
      - 0.03828029255325173
      - 0.018028117325870133
      - 0.026610903871542167
      - 0.038057797465692204
      - 0.0234781071902284
      - 0.07889223016770704
      - 0.023074176104479135
      - 0.05995218481013935
      - 0.03974674018791666
      - 0.026008479660165056
      - 0.02203006014887203
      - 0.025832323674509577
      - 0.04522139792026156
      - 0.024493071743071745
      - 0.02238221830999941
    - - 0.05049023453055278
      - 0.23627231146926525
      - 0.13280747612859678
      - 0.08315938360581218
      - 0.29400139905147227
      - 0.17130420275705496
      - 0.16302759740259734
      - 0.12552857960752695
      - 0.12464037551935345
      - 0.11488839443384899
      - 0.160428376494614
      - 0.15543916780618905
      - 0.05804954228004652
      - 0.09356400465951027
      - 0.13762638112725803
      - 0.1263361629156005
      - 0.09962409140127973
      - 0.11454782867231568
      - 0.13965223225704593
      - 0.09930414173574674
      - 0.17081760831760828
      - 0.06674997910952968
      - 0.22617360343975446
      - 0.17804442833854595
      - 0.062024018293368136
      - 0.1200178089883972
      - 0.1034850547041481
      - 0.15765466972363523
      - 0.04788191642388348
      - 0.044578710286382245
      - 0.22663156432342407
      - 0.10085424451989627
      - 0.1760902292152292
      - 0.09849685231090508
      - 0.19945423105934468
      - 0.09104863565760386
      - 0.07588830583336079
      - 0.01826471773840195
      - 0.035471627138293806
      - 0.024257661656385297
      - 0.06710992003287262
      - 0.020438537491238168
      - 0.03163538605114692
      - 0.051115852691880834
      - 0.030592160648340423
      - 0.09955608286485307
      - 0.0466843174684935
      - 0.018419001177621866
      - 0.11687871307436522
      - 0.17355201811220328
      - 0.048333690575069886
      - 0.22553635764418734
      - 0.11319314062139293
      - 0.04196851541616152
      - 0.0700551473988974
      - 0.3226970212368314
      - 0.07065842950748279
      - 0.02801469039786797
      - 0.03774427775114589
      - 0.08390544015225138
      - 0.14850717048519244
      - 0.07508049102876688
      - 0.02080835830835831
      - 0.17636279135087785
      - 0.1357907074199209
      - 0.11183901651437719
      - 0.13198181972344558
      - 0.13096161444375728
      - 0.21344722127689159
      - 0.0966745205026455
      - 0.12410774181224547
      - 0.03344907534467974
      - 0.16467648579490685
      - 0.06832111395626611
      - 0.24148928503973202
      - 0.06236061807957232
      - 0.07044453773177177
      - 0.3502893543654413
      - 0.2187359237435004
      - 0.32023569557764076
      - 0.1700127092086486
      - 0.06599816301482321
      - 0.034452752634570816
      - 0.0650497840880384
      - 0.2860991242254712
      - 0.05227546801620876
      - 0.03517238073599681
      - 0.10215346057451319
      - 0.04555370932921954
      - 0.018164422196680262
      - 0.03022395885767979
      - 0.029952959577232367
      - 0.02235136317583126
      - 0.08678178874808087
      - 0.02487272978344407
      - 0.07277577148266805
      - 0.04579955678440527
      - 0.02250505640591847
      - 0.03187312703446424
      - 0.048258003502388624
      - 0.034283825661068856
      - 0.020835117263688693
      - 0.02569635751453933
  score_time:
  - 10.246814012527466
  - 9.892204761505127
  - 10.382633924484253
  - 10.406821966171265
  - 10.674226522445679
  test_level0__average_precision_macro:
  - 0.2998948759913915
  - 0.31586655883275444
  - 0.311433920467284
  - 0.30009627734626165
  - 0.29780051166597227
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.4991113784175619
  - 0.5017412000648418
  - 0.48555886555810834
  - 0.4891063138020344
  - 0.488513215897347
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.533384102513375
  - 0.5368353633751095
  - 0.5158059789854929
  - 0.5210343831180771
  - 0.5212288545575604
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.42002849803639314
  - 0.4445672453688382
  - 0.4184002701011385
  - 0.42310409750826344
  - 0.4098874310135743
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7645631067961165
  - 0.7657484759539401
  - 0.7580007191657677
  - 0.7727964972396725
  - 0.7690969041949074
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7645631067961165
  - 0.7657484759539399
  - 0.7580007191657677
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7645631067961165
  - 0.7657484759539398
  - 0.7580007191657676
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.6437649484536083
  - 0.6354777248529
  - 0.649200649386385
  - 0.6595652923926169
  - 0.6461235059462777
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.2354368932038835
  - -0.23425152404606
  - -0.2419992808342323
  - -0.22720350276032747
  - -0.23090309580509247
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.2354368932038835
  - -0.23425152404606006
  - -0.24199928083423228
  - -0.22720350276032744
  - -0.2309030958050925
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.23543689320388342
  - -0.23425152404606003
  - -0.24199928083423222
  - -0.22720350276032739
  - -0.23090309580509247
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.35623505154639173
  - -0.36452227514710006
  - -0.35079935061361517
  - -0.3404347076073831
  - -0.3538764940537223
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6455269635017824
  - 0.6485091350005548
  - 0.6349777219100688
  - 0.6545053956088126
  - 0.6520002072874433
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.618860510805501
  - 0.6204152565627001
  - 0.6103068905616676
  - 0.629721554331808
  - 0.6248232755413349
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.621549856517434
  - 0.6232441239311048
  - 0.612845034436718
  - 0.6323781412718534
  - 0.6275482503454684
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5055968148171709
  - 0.5004848588747395
  - 0.5083610035187192
  - 0.520639427622043
  - 0.5071248460276457
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.533384102513375
  - 0.5368353633751097
  - 0.5158059789854927
  - 0.5210343831180773
  - 0.5212288545575604
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8264671590161694
  - 0.8297920021273334
  - 0.8218943476905665
  - 0.8173819477855008
  - 0.8176424612880571
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -90.48
  - -90.87209302325581
  - -90.42592592592592
  - -89.93137254901961
  - -89.08490566037736
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.2354368932038835
  - -0.23425152404606
  - -0.2419992808342323
  - -0.22720350276032747
  - -0.23090309580509247
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.2354368932038835
  - -0.23425152404606006
  - -0.24199928083423228
  - -0.22720350276032744
  - -0.2309030958050925
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.23543689320388342
  - -0.23425152404606003
  - -0.24199928083423222
  - -0.22720350276032739
  - -0.23090309580509247
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.35623505154639173
  - -0.36452227514710006
  - -0.35079935061361517
  - -0.3404347076073831
  - -0.3538764940537223
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.2533386445328764
  - -0.25129337779965494
  - -0.2684330904097918
  - -0.25490199082912757
  - -0.25336288616498537
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7645631067961165
  - 0.7657484759539401
  - 0.7580007191657677
  - 0.7727964972396725
  - 0.7690969041949074
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7645631067961165
  - 0.7657484759539399
  - 0.7580007191657677
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7645631067961165
  - 0.7657484759539398
  - 0.7580007191657676
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.6437649484536083
  - 0.6354777248529
  - 0.649200649386385
  - 0.6595652923926169
  - 0.6461235059462777
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7645631067961165
  - 0.7657484759539401
  - 0.7580007191657677
  - 0.7727964972396725
  - 0.7690969041949074
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7645631067961165
  - 0.7657484759539399
  - 0.7580007191657677
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7645631067961165
  - 0.7657484759539398
  - 0.7580007191657676
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.6437649484536083
  - 0.6354777248529
  - 0.649200649386385
  - 0.6595652923926169
  - 0.6461235059462777
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.554234064381558
  - 0.5574974009682021
  - 0.5582134820555695
  - 0.5580900705913001
  - 0.5568324866982565
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7440043986254297
  - 0.7452431930286383
  - 0.7276619123779502
  - 0.7428389385725621
  - 0.7458069141918378
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7466613554671235
  - 0.748706622200345
  - 0.7315669095902082
  - 0.7450980091708725
  - 0.7466371138350146
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5566100998325755
  - 0.5552539954121191
  - 0.5513571042124694
  - 0.5706176820193983
  - 0.5450289241466859
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7645631067961165
  - 0.7657484759539401
  - 0.7580007191657677
  - 0.7727964972396725
  - 0.7690969041949074
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7645631067961165
  - 0.7657484759539399
  - 0.7580007191657677
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7645631067961165
  - 0.7657484759539398
  - 0.7580007191657676
  - 0.7727964972396726
  - 0.7690969041949075
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.6437649484536083
  - 0.6354777248529
  - 0.649200649386385
  - 0.6595652923926169
  - 0.6461235059462777
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.29466426622443476
  - 0.30727853880829126
  - 0.31690353296487295
  - 0.29127574515323196
  - 0.28611864403854487
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.22177490677960854
  - 0.21661660199595045
  - 0.23341308171775826
  - 0.21449954057237247
  - 0.21229111564505557
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.24435307171284879
  - 0.23380392601450983
  - 0.25288165774188964
  - 0.23241507864822158
  - 0.2326430240006175
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.4176994168616664
  - 0.44805253053911015
  - 0.43170426204791423
  - 0.4135390938217249
  - 0.4151487751377296
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.3607766990291263
  - 0.3653194852111086
  - 0.3691118302768789
  - 0.36312583285741484
  - 0.3531782377724858
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.36077669902912624
  - 0.36531948521110863
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.3531782377724858
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.3607766990291262
  - 0.3653194852111085
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.35317823777248586
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.4580536082474227
  - 0.46906696553656485
  - 0.4474230917395851
  - 0.45668120620682284
  - 0.4463450412759237
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.05087378640776699
  - -0.047414766312937465
  - -0.04297015462064006
  - -0.03940605368360937
  - -0.044971606521340905
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.05087378640776699
  - -0.04741476631293746
  - -0.04297015462064006
  - -0.03940605368360937
  - -0.044971606521340905
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.05087378640776699
  - -0.04741476631293746
  - -0.042970154620640064
  - -0.03940605368360937
  - -0.0449716065213409
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.08396288659793814
  - -0.07492294760437099
  - -0.06970241043420834
  - -0.06557168321874204
  - -0.07546795596236892
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.5883495145631067
  - -0.5872657484759539
  - -0.5879180151024811
  - -0.5974681134589759
  - -0.6018501557061733
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.5883495145631068
  - -0.5872657484759539
  - -0.5879180151024811
  - -0.5974681134589758
  - -0.6018501557061733
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.5883495145631068
  - -0.587265748475954
  - -0.5879180151024811
  - -0.5974681134589759
  - -0.6018501557061734
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.45798350515463915
  - -0.45601008685906425
  - -0.48287449782620673
  - -0.4777471105744351
  - -0.4781870027617072
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.23577817490900765
  - 0.23964922483326861
  - 0.23888833288374894
  - 0.2373337813836528
  - 0.22733053601609943
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.2200900260601753
  - 0.22348066298342542
  - 0.2263256531804652
  - 0.22184101878234574
  - 0.21446051167964406
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.22442185968516223
  - 0.2285475691138067
  - 0.23072614256165244
  - 0.22610085543708852
  - 0.21942058784344168
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.3095284871407994
  - 0.32306928875657376
  - 0.2998575487475011
  - 0.30881330537595125
  - 0.29957080400554825
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.24435307171284876
  - 0.23380392601450978
  - 0.25288165774188953
  - 0.23241507864822158
  - 0.2326430240006175
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.06623904033478711
  - 0.0626797743325446
  - 0.07635294704297009
  - 0.08895284310117113
  - 0.06206506200007181
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.014576564101423058
  - 0.03106608744993435
  - 0.048973167963141516
  - 0.05452717617038139
  - 0.02339021343446505
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.01289117252786049
  - 0.023847243376916828
  - 0.04359797818906453
  - 0.05099919238885621
  - 0.017177208775249656
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.08069906802576306
  - 0.08289049407406346
  - 0.08810746903421705
  - 0.10004290713853267
  - 0.06957178533319883
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6018258010448319
  - 0.5862488562128036
  - 0.6017330729972561
  - 0.5854040456973229
  - 0.5849691244524698
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -94.7
  - -95.66279069767442
  - -96.23148148148148
  - -93.90196078431373
  - -95.79245283018868
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.6392233009708737
  - -0.6346805147888914
  - -0.6308881697231212
  - -0.636874167142585
  - -0.6468217622275142
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.6392233009708738
  - -0.6346805147888914
  - -0.6308881697231212
  - -0.6368741671425852
  - -0.6468217622275142
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.6392233009708739
  - -0.6346805147888913
  - -0.6308881697231212
  - -0.6368741671425852
  - -0.6468217622275143
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5419463917525773
  - -0.5309330344634351
  - -0.552576908260415
  - -0.5433187937931772
  - -0.5536549587240763
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.5294415041098552
  - -0.5342434921594853
  - -0.5029863517398988
  - -0.5179499706982573
  - -0.5345370800796909
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.3607766990291263
  - 0.3653194852111086
  - 0.3691118302768789
  - 0.36312583285741484
  - 0.3531782377724858
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.36077669902912624
  - 0.36531948521110863
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.3531782377724858
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.3607766990291262
  - 0.3653194852111085
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.35317823777248586
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.4580536082474227
  - 0.46906696553656485
  - 0.4474230917395851
  - 0.45668120620682284
  - 0.4463450412759237
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.3607766990291263
  - 0.3653194852111086
  - 0.3691118302768789
  - 0.36312583285741484
  - 0.3531782377724858
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.36077669902912624
  - 0.36531948521110863
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.3531782377724858
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.3607766990291262
  - 0.3653194852111085
  - 0.3691118302768788
  - 0.3631258328574148
  - 0.35317823777248586
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.4580536082474227
  - 0.46906696553656485
  - 0.4474230917395851
  - 0.45668120620682284
  - 0.4463450412759237
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5668343502491794
  - 0.574813323125156
  - 0.578185940164483
  - 0.5762312583406118
  - 0.573255527952303
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.4898489150711831
  - 0.48882141569373466
  - 0.5106508919533879
  - 0.5020874297918587
  - 0.4846273557682928
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.4854604956109354
  - 0.473882721394404
  - 0.5022372306209231
  - 0.49158367216416354
  - 0.4730802736848786
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.562941831479927
  - 0.586914011570955
  - 0.5799894852120858
  - 0.5799586302005372
  - 0.5690398757048211
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.1762135922330097
  - 0.17848272747798594
  - 0.17008270406328663
  - 0.17532838378069673
  - 0.1672467484887342
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.1762135922330097
  - 0.178482727477986
  - 0.1700827040632866
  - 0.17532838378069673
  - 0.1672467484887342
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.1762135922330097
  - 0.178482727477986
  - 0.17008270406328657
  - 0.1753283837806967
  - 0.1672467484887342
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.18578144329896906
  - 0.1794676379938358
  - 0.1663261515601783
  - 0.18181818181818177
  - 0.16793650318457035
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.1845631067961165
  - 0.18683675773312264
  - 0.19902912621359226
  - 0.18779744907671814
  - 0.18593148928375158
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.1845631067961165
  - 0.1868367577331226
  - 0.19902912621359223
  - 0.18779744907671805
  - 0.1859314892837516
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.18456310679611648
  - 0.1868367577331226
  - 0.19902912621359217
  - 0.18779744907671805
  - 0.18593148928375156
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.27227216494845363
  - 0.28959932754272905
  - 0.28109694017940684
  - 0.2748630243886411
  - 0.2784085380913534
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.30694816633144806
  - 0.33677135637385397
  - 0.3214179422820039
  - 0.30124886417832214
  - 0.30413823230180986
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.21026893270964755
  - 0.21001881102322806
  - 0.2236520197546363
  - 0.20472329075856116
  - 0.21027886348191568
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.23719939879336394
  - 0.2334671323594219
  - 0.2503379241885765
  - 0.22981811554623818
  - 0.23408659223942796
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.4296944705777186
  - 0.46987254402692
  - 0.4304507962133741
  - 0.41991064580021437
  - 0.4253492156320087
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.3388349514563108
  - 0.34578911718220817
  - 0.34124415677813746
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.3388349514563107
  - 0.34578911718220817
  - 0.34124415677813735
  - 0.33285741481058445
  - 0.32350247298039936
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.33883495145631065
  - 0.34578911718220817
  - 0.34124415677813724
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.44663092783505154
  - 0.46525077052395625
  - 0.43097518023223813
  - 0.4308386111042658
  - 0.4237125130039743
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.03932038834951457
  - -0.040076766764506666
  - -0.0346997482919813
  - -0.034361317342470964
  - -0.035171276790620994
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.03932038834951456
  - -0.04007676676450666
  - -0.0346997482919813
  - -0.03436131734247097
  - -0.035171276790620994
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.03932038834951456
  - -0.04007676676450665
  - -0.034699748291981296
  - -0.034361317342470964
  - -0.03517127679062099
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.05811958762886598
  - -0.05738302045390866
  - -0.053591574486819664
  - -0.05444113129122617
  - -0.05966485297089354
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.6218446601941746
  - -0.6141341160532853
  - -0.6240560949298812
  - -0.6327812678469446
  - -0.6413262502289797
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.6218446601941747
  - -0.6141341160532852
  - -0.6240560949298813
  - -0.6327812678469446
  - -0.6413262502289797
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.6218446601941747
  - -0.6141341160532853
  - -0.6240560949298812
  - -0.6327812678469447
  - -0.6413262502289796
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.4952494845360825
  - -0.4773662090221351
  - -0.5154332452809424
  - -0.5147202576045081
  - -0.5166226340251321
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.22257348161223564
  - 0.2311192930500159
  - 0.2247561559170594
  - 0.21853724383953188
  - 0.20901963768072862
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.20397428404441847
  - 0.2090356923496895
  - 0.2057229568610449
  - 0.19965743648301457
  - 0.19296328671328672
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.2076971995632409
  - 0.21240567779887884
  - 0.20797613524764855
  - 0.20267774509784703
  - 0.19643318982734925
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.3068307731115928
  - 0.32647688454036994
  - 0.2930401057452736
  - 0.29208314881142017
  - 0.2859729987156014
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.2371993987933639
  - 0.23346713235942185
  - 0.2503379241885766
  - 0.22981811554623818
  - 0.23408659223942802
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.04873367328644502
  - 0.05911355581503358
  - 0.06337943166384742
  - 0.058708095568686
  - 0.04812872708949034
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.02161218128093477
  - 0.028954681675789837
  - 0.0381124637611338
  - 0.03306862351336035
  - 0.01575842573778378
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.021257559064222064
  - 0.020852872746978078
  - 0.03355728479688743
  - 0.029490910622963065
  - 0.014574434622435087
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.05748216916268309
  - 0.07042806907044272
  - 0.07658119406007861
  - 0.06589141671880577
  - 0.05828845518813362
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.5827551664776199
  - 0.5751524023498512
  - 0.593497992691647
  - 0.5732134332602611
  - 0.5754489360133894
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -95.3
  - -97.23255813953489
  - -97.12037037037037
  - -95.8529411764706
  - -98.74528301886792
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.6611650485436894
  - -0.6542108828177919
  - -0.6587558432218624
  - -0.6671425851894156
  - -0.6764975270196005
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.6611650485436893
  - -0.6542108828177918
  - -0.6587558432218626
  - -0.6671425851894156
  - -0.6764975270196006
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.6611650485436893
  - -0.6542108828177919
  - -0.6587558432218626
  - -0.6671425851894155
  - -0.6764975270196008
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.5533690721649484
  - -0.5347492294760438
  - -0.5690248197677619
  - -0.5691613888957342
  - -0.5762874869960257
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.5298073510561259
  - -0.5402718499307664
  - -0.5158482545525312
  - -0.5260461422696222
  - -0.5293232784473203
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.3388349514563108
  - 0.34578911718220817
  - 0.34124415677813746
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.3388349514563107
  - 0.34578911718220817
  - 0.34124415677813735
  - 0.33285741481058445
  - 0.32350247298039936
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.33883495145631065
  - 0.34578911718220817
  - 0.34124415677813724
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.44663092783505154
  - 0.46525077052395625
  - 0.43097518023223813
  - 0.4308386111042658
  - 0.4237125130039743
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.3388349514563108
  - 0.34578911718220817
  - 0.34124415677813746
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.3388349514563107
  - 0.34578911718220817
  - 0.34124415677813735
  - 0.33285741481058445
  - 0.32350247298039936
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.33883495145631065
  - 0.34578911718220817
  - 0.34124415677813724
  - 0.3328574148105844
  - 0.3235024729803993
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.44663092783505154
  - 0.46525077052395625
  - 0.43097518023223813
  - 0.4308386111042658
  - 0.4237125130039743
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5673275274613304
  - 0.5839890905152949
  - 0.5825225678856709
  - 0.5772407374760863
  - 0.5734614072153781
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.47384967435771563
  - 0.4731736499292171
  - 0.48906233259133114
  - 0.47804982783070826
  - 0.4795579228088912
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.4701926489438742
  - 0.4597364261361406
  - 0.48415174544746875
  - 0.47395385773037774
  - 0.4706767215526797
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5676781024356126
  - 0.592706329693734
  - 0.5753753886927168
  - 0.5763863155894194
  - 0.5706722805997183
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.14271844660194175
  - 0.15161435990065478
  - 0.13394462423588638
  - 0.14001522939272795
  - 0.12777065396592782
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.14271844660194175
  - 0.15161435990065478
  - 0.13394462423588638
  - 0.14001522939272795
  - 0.12777065396592782
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.14271844660194172
  - 0.15161435990065472
  - 0.13394462423588635
  - 0.14001522939272795
  - 0.1277706539659278
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.14851546391752576
  - 0.1581115158307649
  - 0.13376740410544274
  - 0.14484503478810878
  - 0.1295008719211454
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.19611650485436893
  - 0.19417475728155337
  - 0.20729953254225097
  - 0.19284218541785653
  - 0.19573181901447148
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.19611650485436893
  - 0.1941747572815534
  - 0.207299532542251
  - 0.19284218541785647
  - 0.1957318190144715
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.1961165048543689
  - 0.1941747572815534
  - 0.2072995325422509
  - 0.19284218541785642
  - 0.19573181901447145
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.29811546391752575
  - 0.3071392546931913
  - 0.2972077761267955
  - 0.28599357631615696
  - 0.29421164108282877
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.29592201247817046
  - 0.3220617047930124
  - 0.31432018993172534
  - 0.29824899937535654
  - 0.28884731806181413
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.2151616768416856
  - 0.2133269119912205
  - 0.22955160220220522
  - 0.21154631037819246
  - 0.2103110900205946
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.23711252650385398
  - 0.23112356520893765
  - 0.25110377317111354
  - 0.23047834928783792
  - 0.23173314081801807
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.42293044363189664
  - 0.4603076458187182
  - 0.428455581528068
  - 0.423009595518406
  - 0.4137622868843814
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.35398058252427195
  - 0.3570783472567171
  - 0.3595828838547286
  - 0.3528459927660384
  - 0.3437442755083347
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.35398058252427184
  - 0.3570783472567171
  - 0.35958288385472853
  - 0.35284599276603845
  - 0.34374427550833486
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.35398058252427184
  - 0.35707834725671705
  - 0.3595828838547285
  - 0.3528459927660384
  - 0.34374427550833475
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.4569814432989691
  - 0.4632277949005323
  - 0.44174783996477895
  - 0.4500357327681806
  - 0.43916011166578106
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.046504854368932036
  - -0.04188304357642809
  - -0.03811578568860122
  - -0.0367409099562155
  - -0.041399523722293455
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.046504854368932036
  - -0.04188304357642809
  - -0.038115785688601224
  - -0.0367409099562155
  - -0.04139952372229346
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.04650485436893204
  - -0.04188304357642808
  - -0.038115785688601224
  - -0.03674090995621549
  - -0.04139952372229346
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.07471340206185567
  - -0.0672065004202858
  - -0.06291962467668262
  - -0.0600023000402507
  - -0.06939818730213376
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.5995145631067961
  - -0.6010386091668547
  - -0.6023013304566702
  - -0.6104130972777461
  - -0.6148562007693718
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.5995145631067961
  - -0.6010386091668548
  - -0.6023013304566702
  - -0.6104130972777461
  - -0.6148562007693716
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.5995145631067961
  - -0.6010386091668548
  - -0.6023013304566702
  - -0.6104130972777461
  - -0.6148562007693716
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.4683051546391753
  - -0.46956570467918185
  - -0.49533253535853844
  - -0.4899619671915686
  - -0.4914417010320851
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.23171872032337387
  - 0.23427993863350055
  - 0.23213915328624454
  - 0.23026026942845734
  - 0.22082373786955853
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.2150524949864339
  - 0.21734350305778877
  - 0.21920210434020165
  - 0.21421554464027737
  - 0.20754299618426147
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.2190850534093504
  - 0.2218613313747925
  - 0.22328551632473898
  - 0.21833977023354798
  - 0.21233421701978875
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.3116321808012657
  - 0.31816470316989115
  - 0.29594220897439955
  - 0.3047876099630856
  - 0.2947911682753257
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.23711252650385398
  - 0.23112356520893765
  - 0.25110377317111365
  - 0.23047834928783795
  - 0.2317331408180181
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.0637228081582161
  - 0.06934518086554815
  - 0.07821787973637481
  - 0.08385085595469056
  - 0.057285608412024326
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.019059810908144584
  - 0.03797534458851768
  - 0.05190446733436443
  - 0.050801506102073915
  - 0.022578207448080964
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.019014467415239874
  - 0.029534126108561945
  - 0.04630986538832043
  - 0.048550321159856046
  - 0.014882188289896946
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.08106423011620013
  - 0.0727573846831836
  - 0.08838947867447196
  - 0.09466617441136953
  - 0.06315503220807281
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.590498931624582
  - 0.5820663535222398
  - 0.5955273665631464
  - 0.5807253314165567
  - 0.5821457701920603
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -94.9
  - -95.19767441860465
  - -96.04629629629629
  - -94.00980392156863
  - -95.87735849056604
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.6460194174757281
  - -0.642921652743283
  - -0.6404171161452713
  - -0.6471540072339615
  - -0.6562557244916651
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.6460194174757281
  - -0.642921652743283
  - -0.6404171161452715
  - -0.6471540072339615
  - -0.6562557244916651
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.6460194174757281
  - -0.6429216527432828
  - -0.6404171161452716
  - -0.6471540072339615
  - -0.6562557244916648
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.5430185567010309
  - -0.5367722050994675
  - -0.558252160035221
  - -0.5499642672318195
  - -0.5608398883342189
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.531982928081626
  - -0.5376699107606997
  - -0.5043996702469582
  - -0.5192936557270661
  - -0.5340245775884173
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.35398058252427195
  - 0.3570783472567171
  - 0.3595828838547286
  - 0.3528459927660384
  - 0.3437442755083347
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.35398058252427184
  - 0.3570783472567171
  - 0.35958288385472853
  - 0.35284599276603845
  - 0.34374427550833486
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.35398058252427184
  - 0.35707834725671705
  - 0.3595828838547285
  - 0.3528459927660384
  - 0.34374427550833475
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.4569814432989691
  - 0.4632277949005323
  - 0.44174783996477895
  - 0.4500357327681806
  - 0.43916011166578106
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.35398058252427195
  - 0.3570783472567171
  - 0.3595828838547286
  - 0.3528459927660384
  - 0.3437442755083347
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.35398058252427184
  - 0.3570783472567171
  - 0.35958288385472853
  - 0.35284599276603845
  - 0.34374427550833486
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.35398058252427184
  - 0.35707834725671705
  - 0.3595828838547285
  - 0.3528459927660384
  - 0.34374427550833475
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.4569814432989691
  - 0.4632277949005323
  - 0.44174783996477895
  - 0.4500357327681806
  - 0.43916011166578106
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5658931816043131
  - 0.5789315614942159
  - 0.5760976647401556
  - 0.5752209693710957
  - 0.5754418698003572
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.48124355424644083
  - 0.4841738293288146
  - 0.5056016041979751
  - 0.4967239253680059
  - 0.48222051594048365
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.47639401412124016
  - 0.46747943998690156
  - 0.49849800453319515
  - 0.48710586527891836
  - 0.47224303752965463
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5662479726549332
  - 0.5903623503878968
  - 0.5765832222720613
  - 0.5805567129195106
  - 0.5694384706349155
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.1650485436893204
  - 0.16470986678708513
  - 0.1556993887090974
  - 0.16238339996192652
  - 0.1542407034255358
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.1650485436893204
  - 0.16470986678708513
  - 0.15569938870909744
  - 0.16238339996192652
  - 0.1542407034255358
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.16504854368932037
  - 0.1647098667870851
  - 0.1556993887090974
  - 0.16238339996192647
  - 0.15424070342553584
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.175459793814433
  - 0.16591202017371812
  - 0.1538681140278466
  - 0.16960332520104815
  - 0.15468180491419245
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.18893203883495144
  - 0.19236848046963198
  - 0.20388349514563112
  - 0.190462592804112
  - 0.189503572082799
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.18893203883495147
  - 0.19236848046963198
  - 0.20388349514563106
  - 0.19046259280411193
  - 0.18950357208279905
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.18893203883495144
  - 0.19236848046963198
  - 0.203883495145631
  - 0.19046259280411187
  - 0.189503572082799
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.28152164948453606
  - 0.29731577472681425
  - 0.28787972593693256
  - 0.2804324075671324
  - 0.28447830675158853
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.2947358175823326
  - 0.3091100905551797
  - 0.3126832182054284
  - 0.29763330595404847
  - 0.2875562532940165
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.21877561242776902
  - 0.21397096421232292
  - 0.23161056841873418
  - 0.21436550508446814
  - 0.2114827239615643
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.24092506448345116
  - 0.2316560146834143
  - 0.2522246111937763
  - 0.2328420058883809
  - 0.23173416878291178
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.42190176981977295
  - 0.44899547435584763
  - 0.42720913205910227
  - 0.42212913566773047
  - 0.41599240818178823
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.35844660194174766
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701584
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.3584466019417476
  - 0.3615940392865207
  - 0.36641495864796836
  - 0.35760517799352753
  - 0.34869023630701595
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.35844660194174743
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701595
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.4607958762886597
  - 0.46670215746707755
  - 0.4479011887072807
  - 0.4525739914734222
  - 0.4417908437053282
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.04757281553398058
  - -0.04481824339580041
  - -0.04036317871269328
  - -0.038168665524462214
  - -0.044605239054771935
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.04757281553398058
  - -0.04481824339580041
  - -0.04036317871269328
  - -0.038168665524462214
  - -0.044605239054771935
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.047572815533980586
  - -0.0448182433958004
  - -0.04036317871269328
  - -0.03816866552446221
  - -0.044605239054771935
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.076
  - -0.0708041468198375
  - -0.06538233999229541
  - -0.0634770037047077
  - -0.0748505010739973
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.5939805825242718
  - -0.5935877173176789
  - -0.5932218626393383
  - -0.6042261564820103
  - -0.6067045246382121
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.5939805825242719
  - -0.5935877173176789
  - -0.5932218626393384
  - -0.6042261564820103
  - -0.6067045246382121
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.5939805825242718
  - -0.5935877173176789
  - -0.5932218626393384
  - -0.6042261564820104
  - -0.6067045246382121
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.4632041237113402
  - -0.46249369571308485
  - -0.48671647130042395
  - -0.48394900482187014
  - -0.48335865522067456
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.23519501665159795
  - 0.23716143211103738
  - 0.2374316774852971
  - 0.23364475189984044
  - 0.2241355510840394
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.21835817364561155
  - 0.22069868393853787
  - 0.22430112260620735
  - 0.21773399014778325
  - 0.21115979810305618
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.22240868788550483
  - 0.22535631629729735
  - 0.2283943986809426
  - 0.2218392153606341
  - 0.21607031766131785
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.31486104666887416
  - 0.32124747677898813
  - 0.301145081239441
  - 0.3060200912038498
  - 0.29622345484477114
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.24092506448345122
  - 0.23165601468341432
  - 0.2522246111937763
  - 0.23284200588838103
  - 0.23173416878291175
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.06473540145004053
  - 0.06773530090185831
  - 0.079371592618034
  - 0.08701278990627997
  - 0.0575637685925692
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.02162407332921575
  - 0.03442330855904083
  - 0.05366399455086234
  - 0.05187753021237598
  - 0.01869055288366715
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.021203811767834143
  - 0.02586681686369055
  - 0.04818106106902108
  - 0.05201710150770743
  - 0.011422413579327413
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0838378494318735
  - 0.08347778636680753
  - 0.09205934362396002
  - 0.09652561747446882
  - 0.06066712033213765
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.5975711059411425
  - 0.5821392146170637
  - 0.5996630459016743
  - 0.5867499311249642
  - 0.5840799482063174
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -94.53
  - -95.23255813953489
  - -96.10185185185185
  - -93.98039215686275
  - -95.75471698113208
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.6415533980582524
  - -0.6384059607134793
  - -0.6335850413520315
  - -0.6423948220064724
  - -0.6513097636929841
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.6415533980582524
  - -0.6384059607134793
  - -0.6335850413520316
  - -0.6423948220064725
  - -0.6513097636929841
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.6415533980582525
  - -0.6384059607134794
  - -0.6335850413520314
  - -0.6423948220064724
  - -0.6513097636929841
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.5392041237113402
  - -0.5332978425329223
  - -0.5520988112927193
  - -0.5474260085265779
  - -0.5582091562946718
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.5314614479366365
  - -0.5345884141431387
  - -0.5043290526108519
  - -0.5163572542914345
  - -0.5348891947197613
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.35844660194174766
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701584
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.3584466019417476
  - 0.3615940392865207
  - 0.36641495864796836
  - 0.35760517799352753
  - 0.34869023630701595
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.35844660194174743
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701595
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.4607958762886597
  - 0.46670215746707755
  - 0.4479011887072807
  - 0.4525739914734222
  - 0.4417908437053282
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.35844660194174766
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701584
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.3584466019417476
  - 0.3615940392865207
  - 0.36641495864796836
  - 0.35760517799352753
  - 0.34869023630701595
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.35844660194174743
  - 0.3615940392865206
  - 0.3664149586479684
  - 0.3576051779935275
  - 0.34869023630701595
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.4607958762886597
  - 0.46670215746707755
  - 0.4479011887072807
  - 0.4525739914734222
  - 0.4417908437053282
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5668007599555066
  - 0.575575167167401
  - 0.5775033571025097
  - 0.577292702325784
  - 0.5746526388437059
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.48553407298314516
  - 0.48618690596086256
  - 0.5087258684809302
  - 0.501653762247193
  - 0.483629804509336
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.48106546211679474
  - 0.47137155579904244
  - 0.5000896697085797
  - 0.49330872343755555
  - 0.472933814683993
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.5655093991574845
  - 0.5872989085547784
  - 0.5791553854062989
  - 0.5815979775024633
  - 0.5687340224569185
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.17058252427184462
  - 0.172160758636261
  - 0.16477885652642935
  - 0.16857034075766228
  - 0.16239237955669536
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.17058252427184467
  - 0.172160758636261
  - 0.16477885652642935
  - 0.16857034075766228
  - 0.16239237955669536
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.17058252427184464
  - 0.17216075863626096
  - 0.1647788565264293
  - 0.1685703407576622
  - 0.16239237955669536
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.18056082474226803
  - 0.17298402913981512
  - 0.16248417808596116
  - 0.17561628757074677
  - 0.162764850725603
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.18786407766990293
  - 0.18943328065025966
  - 0.201636102121539
  - 0.18903483723586528
  - 0.18629785675032054
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.1878640776699029
  - 0.18943328065025966
  - 0.201636102121539
  - 0.18903483723586523
  - 0.18629785675032057
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.18786407766990287
  - 0.18943328065025966
  - 0.20163610212153896
  - 0.1890348372358652
  - 0.1862978567503205
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.2802350515463917
  - 0.2937181283272625
  - 0.2854170106213198
  - 0.2769577039026754
  - 0.279025992979725
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.2914956449107317
  - 0.3128263879103008
  - 0.3110094252093098
  - 0.29804478381571564
  - 0.29028087125832525
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.21743352663774543
  - 0.2153209782301675
  - 0.2325146543381726
  - 0.21582065507559486
  - 0.21317478018164948
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.2403524350973635
  - 0.23339405547443973
  - 0.25318736626699095
  - 0.23369451036481198
  - 0.23405064702189243
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.4156144214735239
  - 0.45280377482342765
  - 0.4261213995567572
  - 0.4214794355318575
  - 0.41730708120698656
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.3591262135922331
  - 0.364642131406638
  - 0.3687522473930242
  - 0.35674852465257945
  - 0.35116321670635636
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.359126213592233
  - 0.3646421314066381
  - 0.3687522473930241
  - 0.3567485246525795
  - 0.3511632167063565
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.359126213592233
  - 0.36464213140663804
  - 0.3687522473930241
  - 0.35674852465257945
  - 0.3511632167063565
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.4587917525773196
  - 0.4681815634631549
  - 0.4489743272246986
  - 0.4514075424891364
  - 0.4439201275325006
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.04970873786407767
  - -0.04673741250846693
  - -0.040632865875584324
  - -0.039501237388159145
  - -0.04597911705440556
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.04970873786407767
  - -0.04673741250846692
  - -0.040632865875584324
  - -0.039501237388159145
  - -0.04597911705440557
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.049708737864077666
  - -0.04673741250846691
  - -0.04063286587558433
  - -0.039501237388159145
  - -0.04597911705440556
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.08059793814432989
  - -0.07338750350238163
  - -0.06578476693632711
  - -0.06530471426107101
  - -0.07736896858838585
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.5911650485436892
  - -0.5886204560848951
  - -0.5906148867313915
  - -0.6037502379592614
  - -0.602857666239238
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.5911650485436893
  - -0.588620456084895
  - -0.5906148867313916
  - -0.6037502379592614
  - -0.602857666239238
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.5911650485436892
  - -0.5886204560848951
  - -0.5906148867313915
  - -0.6037502379592614
  - -0.6028576662392379
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.4606103092783505
  - -0.45843093303446353
  - -0.4852409058389743
  - -0.48328774324979257
  - -0.47871090387911347
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.23518937571144166
  - 0.23921013362706592
  - 0.23878887263924392
  - 0.23253998176306237
  - 0.22587074314281835
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.21886278918407195
  - 0.2229739058401215
  - 0.2260553289981263
  - 0.2170991658943466
  - 0.21297633596267082
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.22305294901295836
  - 0.22782325726563063
  - 0.23036304539591293
  - 0.2212692816728149
  - 0.2178914786438269
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.3115194630852741
  - 0.32224185292691065
  - 0.3015252366722396
  - 0.30481827999636774
  - 0.2976162493897437
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.24035243509736343
  - 0.23339405547443978
  - 0.2531873662669909
  - 0.23369451036481198
  - 0.23405064702189252
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.061880443816198984
  - 0.06552015312446449
  - 0.0815535994226066
  - 0.08182655641442386
  - 0.0596550027414046
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.015958364055971064
  - 0.03230635703858963
  - 0.05584153232553689
  - 0.04629701753073576
  - 0.01754298871385162
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.014669089525682107
  - 0.024012993108356945
  - 0.049723505115818765
  - 0.04406793041522796
  - 0.011677046944718394
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.07918212747584454
  - 0.08080509395493458
  - 0.09312101445096299
  - 0.09232575664085695
  - 0.06472723757015421
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.5934119014504291
  - 0.5842669634851116
  - 0.6010686401988236
  - 0.5883090740827778
  - 0.5879324859355901
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -94.64
  - -95.09302325581395
  - -96.28703703703704
  - -94.12745098039215
  - -95.70754716981132
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.6408737864077669
  - -0.635357868593362
  - -0.631247752606976
  - -0.6432514753474204
  - -0.6488367832936434
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.640873786407767
  - -0.635357868593362
  - -0.6312477526069759
  - -0.6432514753474206
  - -0.6488367832936435
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.6408737864077669
  - -0.635357868593362
  - -0.6312477526069759
  - -0.6432514753474206
  - -0.6488367832936435
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.5412082474226804
  - -0.5318184365368451
  - -0.5510256727753013
  - -0.5485924575108635
  - -0.5560798724674995
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.5300554936307407
  - -0.5332603553086617
  - -0.5039416265634573
  - -0.5190591975271623
  - -0.5346131618306581
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.3591262135922331
  - 0.364642131406638
  - 0.3687522473930242
  - 0.35674852465257945
  - 0.35116321670635636
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.359126213592233
  - 0.3646421314066381
  - 0.3687522473930241
  - 0.3567485246525795
  - 0.3511632167063565
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.359126213592233
  - 0.36464213140663804
  - 0.3687522473930241
  - 0.35674852465257945
  - 0.3511632167063565
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.4587917525773196
  - 0.4681815634631549
  - 0.4489743272246986
  - 0.4514075424891364
  - 0.4439201275325006
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.3591262135922331
  - 0.364642131406638
  - 0.3687522473930242
  - 0.35674852465257945
  - 0.35116321670635636
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.359126213592233
  - 0.3646421314066381
  - 0.3687522473930241
  - 0.3567485246525795
  - 0.3511632167063565
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.359126213592233
  - 0.36464213140663804
  - 0.3687522473930241
  - 0.35674852465257945
  - 0.3511632167063565
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.4587917525773196
  - 0.4681815634631549
  - 0.4489743272246986
  - 0.4514075424891364
  - 0.4439201275325006
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5644486629367129
  - 0.5771654533108143
  - 0.5774767004369529
  - 0.5767535171515771
  - 0.5747159496553024
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.4851605825560465
  - 0.48811831137020434
  - 0.5097611589332085
  - 0.5021294059412531
  - 0.48471288243185023
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.4812041734193755
  - 0.4730894789904188
  - 0.5010244248836511
  - 0.4917526645501987
  - 0.4738522490584665
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5619079535102379
  - 0.5888699118662141
  - 0.578297135480296
  - 0.5805456396351855
  - 0.5690146615758938
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.17339805825242718
  - 0.17712801986904494
  - 0.16738583243437613
  - 0.16904625928041123
  - 0.16623923795566953
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.17339805825242718
  - 0.17712801986904494
  - 0.16738583243437613
  - 0.1690462592804112
  - 0.16623923795566953
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.17339805825242713
  - 0.17712801986904492
  - 0.16738583243437613
  - 0.16904625928041114
  - 0.16623923795566953
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.18315463917525773
  - 0.17704679181843652
  - 0.16395974354741072
  - 0.17627754914282429
  - 0.16741260206716413
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.18572815533980583
  - 0.18751411153759318
  - 0.201366414958648
  - 0.18770226537216833
  - 0.18492397875068692
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.18572815533980583
  - 0.18751411153759315
  - 0.20136641495864796
  - 0.18770226537216828
  - 0.18492397875068695
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.1857281553398058
  - 0.18751411153759312
  - 0.20136641495864788
  - 0.18770226537216825
  - 0.18492397875068692
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.2756371134020618
  - 0.2911347716447184
  - 0.28501458367728805
  - 0.2751299933463121
  - 0.27650752546533647
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.2950999846620097
  - 0.3123194353842455
  - 0.3122398486759812
  - 0.2942540211323531
  - 0.28916751705868937
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.2199916535904676
  - 0.21531606055944544
  - 0.23339414444731596
  - 0.21504788557424734
  - 0.21234559930898633
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.2424495104531304
  - 0.23276515757623434
  - 0.25332796213889514
  - 0.23318522162615954
  - 0.23320256775287906
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.42137212596689966
  - 0.4529506479432395
  - 0.4267438649210158
  - 0.41788773465154083
  - 0.41786580671115436
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.3583495145631069
  - 0.36610973131632424
  - 0.36893203883495157
  - 0.35912811726632404
  - 0.3515295841729253
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.3583495145631068
  - 0.36610973131632424
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.35834951456310676
  - 0.3661097313163241
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.4570103092783505
  - 0.469156626506024
  - 0.44814883605745404
  - 0.453514543647371
  - 0.4437629571972788
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.05019417475728155
  - -0.046285843305486574
  - -0.041531823085221145
  - -0.03931086997905958
  - -0.04643707638761678
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.05019417475728155
  - -0.04628584330548657
  - -0.041531823085221145
  - -0.03931086997905958
  - -0.04643707638761678
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.050194174757281565
  - -0.04628584330548656
  - -0.04153182308522115
  - -0.03931086997905958
  - -0.04643707638761678
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.08140618556701029
  - -0.07346035304006725
  - -0.06747014473611798
  - -0.0652718565432038
  - -0.07766834065547513
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.5914563106796116
  - -0.5876044253781891
  - -0.5895361380798273
  - -0.6015610127546165
  - -0.6020333394394578
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.5914563106796117
  - -0.5876044253781892
  - -0.5895361380798274
  - -0.6015610127546164
  - -0.6020333394394578
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.5914563106796116
  - -0.5876044253781892
  - -0.5895361380798274
  - -0.6015610127546164
  - -0.6020333394394578
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.46158350515463925
  - -0.4573830204539088
  - -0.4843810192064279
  - -0.4812135998094251
  - -0.478568702147246
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.23416976986082874
  - 0.24023871922809448
  - 0.23890396967738398
  - 0.2344382977850495
  - 0.2259950167317157
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.21828611981784848
  - 0.22407241069577835
  - 0.2261904761904762
  - 0.21886420326004988
  - 0.21324591621291256
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.22258853226747682
  - 0.2289288391477458
  - 0.23055266791967166
  - 0.22314565377070966
  - 0.218118458591119
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.3094630661892351
  - 0.32272986999486897
  - 0.30060509864442136
  - 0.30652422239927063
  - 0.2973832455049678
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.24244951045313046
  - 0.23276515757623434
  - 0.2533279621388952
  - 0.23318522162615957
  - 0.23320256775287912
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.0608166768655214
  - 0.06909839961586328
  - 0.07893329797780088
  - 0.08601927131203525
  - 0.05897663550337381
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.013464780758534441
  - 0.035581332261202143
  - 0.053237838814967964
  - 0.04990775402240551
  - 0.016567075443758263
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.011867042045452738
  - 0.027710206202563144
  - 0.048526347042086346
  - 0.04863729274171323
  - 0.009428673025662384
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.07676019253423713
  - 0.08399709981195998
  - 0.08912165048209376
  - 0.09791274040422383
  - 0.063666702721196
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.599186600106025
  - 0.5824856465707966
  - 0.6022785549120506
  - 0.5874340900233237
  - 0.58628359304027
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -94.45
  - -95.18604651162791
  - -96.10185185185185
  - -94.16666666666667
  - -95.88679245283019
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.6416504854368931
  - -0.6338902686836758
  - -0.6310679611650484
  - -0.6408718827336759
  - -0.6484704158270747
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.6416504854368932
  - -0.6338902686836758
  - -0.6310679611650486
  - -0.640871882733676
  - -0.6484704158270745
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.6416504854368931
  - -0.6338902686836758
  - -0.6310679611650485
  - -0.6408718827336759
  - -0.6484704158270745
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.5429896907216495
  - -0.5308433734939758
  - -0.5518511639425459
  - -0.5464854563526289
  - -0.5562370428027211
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.5294523596213216
  - -0.5319990111800482
  - -0.5030967726443063
  - -0.5184096310588668
  - -0.5349567844061883
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.3583495145631069
  - 0.36610973131632424
  - 0.36893203883495157
  - 0.35912811726632404
  - 0.3515295841729253
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.3583495145631068
  - 0.36610973131632424
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.35834951456310676
  - 0.3661097313163241
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.4570103092783505
  - 0.469156626506024
  - 0.44814883605745404
  - 0.453514543647371
  - 0.4437629571972788
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.3583495145631069
  - 0.36610973131632424
  - 0.36893203883495157
  - 0.35912811726632404
  - 0.3515295841729253
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.3583495145631068
  - 0.36610973131632424
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.35834951456310676
  - 0.3661097313163241
  - 0.36893203883495146
  - 0.359128117266324
  - 0.35152958417292546
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.4570103092783505
  - 0.469156626506024
  - 0.44814883605745404
  - 0.453514543647371
  - 0.4437629571972788
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5661920252088962
  - 0.57944615238176
  - 0.578150921134006
  - 0.5741746213963084
  - 0.5724404028923344
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.4877497758141057
  - 0.48887946300904633
  - 0.5107769330590886
  - 0.5017448352695424
  - 0.48441766073403086
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.4837358481086872
  - 0.4735789939950494
  - 0.5023712180143688
  - 0.4920243816769319
  - 0.47348170559362873
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5648296318965493
  - 0.5911863725570045
  - 0.5791378243881572
  - 0.579275425987986
  - 0.5692616569814314
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.17310679611650484
  - 0.17814405057575072
  - 0.1684645810859403
  - 0.17123548448505618
  - 0.1670635647554497
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.17310679611650484
  - 0.17814405057575072
  - 0.1684645810859403
  - 0.17123548448505616
  - 0.16706356475544973
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.17310679611650484
  - 0.17814405057575072
  - 0.16846458108594028
  - 0.1712354844850561
  - 0.1670635647554497
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.18218144329896907
  - 0.1780947043989913
  - 0.16481963017995707
  - 0.1783516925831916
  - 0.1675548037990315
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.18524271844660192
  - 0.1879656807405735
  - 0.20046745774901115
  - 0.18789263278126792
  - 0.18446601941747573
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.18524271844660195
  - 0.1879656807405735
  - 0.20046745774901115
  - 0.18789263278126786
  - 0.18446601941747573
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.18524271844660192
  - 0.1879656807405735
  - 0.2004674577490111
  - 0.18789263278126778
  - 0.18446601941747573
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.27482886597938144
  - 0.2910619221070328
  - 0.28332920587749716
  - 0.2751628510641793
  - 0.27620815339824717
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.29333459447982413
  - 0.30931962414779707
  - 0.3185738984605784
  - 0.2971397862669809
  - 0.2885812639351007
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.2219539894434788
  - 0.21662950040512302
  - 0.23313302169778333
  - 0.21620621333044637
  - 0.21284204701735246
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.24527376154877698
  - 0.23420144640444354
  - 0.2526151620344096
  - 0.2337133362550845
  - 0.23333929762713074
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.4196651464435816
  - 0.44944262788789907
  - 0.43391893652344854
  - 0.4211099244188134
  - 0.4168662376873344
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.35902912621359234
  - 0.36588394671483404
  - 0.3695613088816973
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.35902912621359223
  - 0.36588394671483404
  - 0.36956130888169725
  - 0.35760517799352753
  - 0.3511632167063565
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.3590291262135923
  - 0.365883946714834
  - 0.36956130888169725
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.4566845360824742
  - 0.46920706080134483
  - 0.4474884431236586
  - 0.45108307252519786
  - 0.443897674627469
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.05009708737864078
  - -0.047414766312937465
  - -0.041711614527148506
  - -0.039596421092708924
  - -0.04570434145447884
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.05009708737864078
  - -0.04741476631293746
  - -0.041711614527148506
  - -0.03959642109270893
  - -0.04570434145447884
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.050097087378640784
  - -0.04741476631293746
  - -0.04171161452714851
  - -0.03959642109270893
  - -0.045704341454478846
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.0816041237113402
  - -0.0752423648080695
  - -0.06816149358868527
  - -0.06598651190681552
  - -0.075905787610487
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.5908737864077669
  - -0.5867012869722283
  - -0.5887270765911542
  - -0.6027984009137636
  - -0.6031324418391647
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.590873786407767
  - -0.5867012869722285
  - -0.5887270765911543
  - -0.6027984009137636
  - -0.6031324418391647
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.5908737864077669
  - -0.5867012869722285
  - -0.5887270765911542
  - -0.6027984009137636
  - -0.6031324418391647
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.4617113402061855
  - -0.45555057439058566
  - -0.4843500632876563
  - -0.4829304155679867
  - -0.48019653776204413
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.2342789585016062
  - 0.2400472144607707
  - 0.23930649380950106
  - 0.23311082550897666
  - 0.22573775654597616
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.21879067565968524
  - 0.22390328151986183
  - 0.22666372608479904
  - 0.21773399014778325
  - 0.21297633596267082
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.22335308565751508
  - 0.22878787663925684
  - 0.23083277234265526
  - 0.22186345809599217
  - 0.21790230132907515
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.3085352888104639
  - 0.32273566829099953
  - 0.29981097163839043
  - 0.30422344470002183
  - 0.29772563884391884
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.2452737615487769
  - 0.2342014464044436
  - 0.25261516203440965
  - 0.23371333625508442
  - 0.23333929762713068
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.06228953542544137
  - 0.06520567012302533
  - 0.07989159698672514
  - 0.08295042436854949
  - 0.05814976956164856
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.014649755787766323
  - 0.03178458832483982
  - 0.053486756350240146
  - 0.04704852897580274
  - 0.018418693752811296
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.0127470388387994
  - 0.024048858778477913
  - 0.0481876158758478
  - 0.04521347103610951
  - 0.01261768747422661
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.07593888872607704
  - 0.08211471500475528
  - 0.08799921051813513
  - 0.09323225117343474
  - 0.06379029771900477
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6031952296339006
  - 0.5871323476323493
  - 0.6024582026698684
  - 0.5887075245628043
  - 0.5869779839796773
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -94.5
  - -95.30232558139535
  - -96.25925925925925
  - -94.09803921568627
  - -95.75471698113208
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.6409708737864077
  - -0.634116053285166
  - -0.6304386911183026
  - -0.6423948220064724
  - -0.6488367832936435
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.6409708737864077
  - -0.634116053285166
  - -0.6304386911183028
  - -0.6423948220064725
  - -0.6488367832936435
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.6409708737864076
  - -0.634116053285166
  - -0.6304386911183028
  - -0.6423948220064724
  - -0.6488367832936436
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5433154639175257
  - -0.530792939198655
  - -0.5525115568763415
  - -0.5489169274748021
  - -0.556102325372531
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.5287495789062069
  - -0.5347003912802144
  - -0.5025398948304473
  - -0.5176743123274458
  - -0.5354072729057455
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.35902912621359234
  - 0.36588394671483404
  - 0.3695613088816973
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.35902912621359223
  - 0.36588394671483404
  - 0.36956130888169725
  - 0.35760517799352753
  - 0.3511632167063565
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.3590291262135923
  - 0.365883946714834
  - 0.36956130888169725
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.4566845360824742
  - 0.46920706080134483
  - 0.4474884431236586
  - 0.45108307252519786
  - 0.443897674627469
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.35902912621359234
  - 0.36588394671483404
  - 0.3695613088816973
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.35902912621359223
  - 0.36588394671483404
  - 0.36956130888169725
  - 0.35760517799352753
  - 0.3511632167063565
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.3590291262135923
  - 0.365883946714834
  - 0.36956130888169725
  - 0.3576051779935275
  - 0.3511632167063564
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.4566845360824742
  - 0.46920706080134483
  - 0.4474884431236586
  - 0.45108307252519786
  - 0.443897674627469
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5662096863934377
  - 0.5732793016717322
  - 0.5786674051689776
  - 0.5776689609880984
  - 0.5727411003676692
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.4896776828669612
  - 0.48835145979761596
  - 0.5110254247950918
  - 0.5035398768001305
  - 0.4847334787451951
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.48578072650189236
  - 0.47313003095228096
  - 0.5025752271673499
  - 0.493563578246116
  - 0.4738396507091419
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5640390184555318
  - 0.5869779516710129
  - 0.5805417756745559
  - 0.5814787245173898
  - 0.5686426289193663
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.17368932038834953
  - 0.17904718898171143
  - 0.16927364257461347
  - 0.169998096325909
  - 0.1659644623557428
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.17368932038834953
  - 0.17904718898171146
  - 0.16927364257461344
  - 0.169998096325909
  - 0.1659644623557428
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.17368932038834944
  - 0.17904718898171143
  - 0.16927364257461341
  - 0.16999809632590895
  - 0.16596446235574283
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.1820536082474227
  - 0.17992715046231436
  - 0.16485058609872877
  - 0.17663487682463014
  - 0.16592696818423355
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.1853398058252427
  - 0.1868367577331226
  - 0.20028766630708378
  - 0.18760708166761855
  - 0.18519875435061364
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.18533980582524273
  - 0.1868367577331226
  - 0.20028766630708378
  - 0.1876070816676185
  - 0.18519875435061367
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.18533980582524268
  - 0.1868367577331226
  - 0.20028766630708375
  - 0.18760708166761847
  - 0.1851987543506136
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.2746309278350515
  - 0.28927991033903055
  - 0.2826378570249299
  - 0.27444819570056755
  - 0.27797070644323535
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.29309925828623495
  - 0.3057897659626535
  - 0.311663017717054
  - 0.2937130989445379
  - 0.2884086259850694
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.22238776998572374
  - 0.21537484051033495
  - 0.23352779332625595
  - 0.21599068014414302
  - 0.2118999706175515
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.24533552889941113
  - 0.23332518155231122
  - 0.2537898423185637
  - 0.23306762475068715
  - 0.23225301496587825
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.4185412510708868
  - 0.44623816537625965
  - 0.4283506656811331
  - 0.41584090253530936
  - 0.4153025560692197
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.3613592233009709
  - 0.367012869722285
  - 0.3695613088816973
  - 0.35969921949362266
  - 0.35226231910606337
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.36135922330097087
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.35226231910606337
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.3613592233009708
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.3522623191060633
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.4586762886597939
  - 0.47078733538806383
  - 0.44792870507952215
  - 0.452500061608221
  - 0.44606812211386615
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.050485436893203874
  - -0.04685030480921202
  - -0.041891405969075875
  - -0.04026270702455739
  - -0.04515479025462539
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.05048543689320388
  - -0.04685030480921201
  - -0.041891405969075875
  - -0.04026270702455739
  - -0.04515479025462539
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.05048543689320389
  - -0.046850304809212005
  - -0.041891405969075875
  - -0.0402627070245574
  - -0.04515479025462539
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.08270515463917524
  - -0.07389184645558983
  - -0.06841258048538879
  - -0.06752671743184079
  - -0.07469333073877542
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.5881553398058251
  - -0.586136825468503
  - -0.5885472851492268
  - -0.6000380734818199
  - -0.6025828906393113
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.5881553398058252
  - -0.5861368254685031
  - -0.5885472851492269
  - -0.6000380734818199
  - -0.6025828906393113
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.5881553398058252
  - -0.586136825468503
  - -0.5885472851492268
  - -0.60003807348182
  - -0.6025828906393114
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.45861855670103097
  - -0.4553208181563464
  - -0.483658714435089
  - -0.47997322095993816
  - -0.47923854714735836
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.23621581294754732
  - 0.24115005858025287
  - 0.23934069299407879
  - 0.23440473298375109
  - 0.22672916961675207
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.22052375873918711
  - 0.2247493950916004
  - 0.22666372608479904
  - 0.2192885742470841
  - 0.21378543635352973
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.22492159043576862
  - 0.22972626101703825
  - 0.23100361996234253
  - 0.22369134178302144
  - 0.21869313616992325
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.3101267719999222
  - 0.32483532928340364
  - 0.30025081979150564
  - 0.3051278130047792
  - 0.2997711989555119
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.2453355288994112
  - 0.2333251815523113
  - 0.2537898423185638
  - 0.23306762475068712
  - 0.23225301496587827
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.06657664715888431
  - 0.06763957141290915
  - 0.07956374780491605
  - 0.0854012611390445
  - 0.06083899613669506
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.016509184036020055
  - 0.03496887074902303
  - 0.052922852321701484
  - 0.04742435867472505
  - 0.02161111333947289
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.01474556506290476
  - 0.02724500605374751
  - 0.04616540965393025
  - 0.04305979985131522
  - 0.015542875250422326
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.0823705785277718
  - 0.08439213943054878
  - 0.08894962960366071
  - 0.09599169879546922
  - 0.0680789463554745
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.603266484266602
  - 0.5834422529700857
  - 0.6031185161027147
  - 0.5890107380383159
  - 0.5847863804117633
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -94.61
  - -95.37209302325581
  - -96.25
  - -94.15686274509804
  - -95.83018867924528
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.638640776699029
  - -0.632987130277715
  - -0.6304386911183029
  - -0.6403007805063772
  - -0.6477376808939365
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.6386407766990291
  - -0.632987130277715
  - -0.6304386911183028
  - -0.6403007805063773
  - -0.6477376808939366
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.6386407766990291
  - -0.6329871302777151
  - -0.6304386911183028
  - -0.6403007805063772
  - -0.6477376808939366
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.5413237113402062
  - -0.5292126646119361
  - -0.5520712949204778
  - -0.5474999383917789
  - -0.5539318778861338
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.5291897768048648
  - -0.5332532395753742
  - -0.5026138857346597
  - -0.5195042478002042
  - -0.5350031062520579
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.3613592233009709
  - 0.367012869722285
  - 0.3695613088816973
  - 0.35969921949362266
  - 0.35226231910606337
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.36135922330097087
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.35226231910606337
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.3613592233009708
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.3522623191060633
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.4586762886597939
  - 0.47078733538806383
  - 0.44792870507952215
  - 0.452500061608221
  - 0.44606812211386615
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.3613592233009709
  - 0.367012869722285
  - 0.3695613088816973
  - 0.35969921949362266
  - 0.35226231910606337
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.36135922330097087
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.35226231910606337
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.3613592233009708
  - 0.3670128697222849
  - 0.36956130888169725
  - 0.3596992194936227
  - 0.3522623191060633
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.4586762886597939
  - 0.47078733538806383
  - 0.44792870507952215
  - 0.452500061608221
  - 0.44606812211386615
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5681009248098157
  - 0.5757297830844671
  - 0.5776393017414605
  - 0.5765497008672626
  - 0.5730725349493925
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.49016260513827525
  - 0.48807248454232677
  - 0.511111464039913
  - 0.5026227224455991
  - 0.4839330568797898
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.48599502187338683
  - 0.47360685606190195
  - 0.5028277378805538
  - 0.4915862885468309
  - 0.47315537914824074
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5648502468153263
  - 0.5881539859342068
  - 0.5796702004936373
  - 0.5804863326234914
  - 0.5682602200084201
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.1764077669902913
  - 0.1796116504854369
  - 0.16945343401654084
  - 0.1727584237578527
  - 0.16651401355559625
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.17640776699029126
  - 0.1796116504854369
  - 0.1694534340165408
  - 0.17275842375785266
  - 0.16651401355559625
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.1764077669902912
  - 0.17961165048543687
  - 0.16945343401654078
  - 0.1727584237578526
  - 0.16651401355559625
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.18514639175257733
  - 0.18015690669655363
  - 0.16554193495129604
  - 0.1795920714326786
  - 0.16688495879891926
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.1849514563106796
  - 0.18740121923684808
  - 0.2001078748651564
  - 0.1869407957357701
  - 0.18574830555046712
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.1849514563106796
  - 0.18740121923684805
  - 0.2001078748651564
  - 0.18694079573577005
  - 0.18574830555046712
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.1849514563106796
  - 0.18740121923684802
  - 0.20010787486515635
  - 0.18694079573576997
  - 0.1857483055504671
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.27352989690721646
  - 0.29063042869151023
  - 0.2823867701282263
  - 0.2729079901755423
  - 0.2791831633149469
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.2987578384643567
  - 0.30760682319038735
  - 0.3185918480978267
  - 0.2969687787902435
  - 0.2885365999275775
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.2213828237078462
  - 0.21593698674412934
  - 0.23381853498675767
  - 0.21618750171518278
  - 0.21224943609432514
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.24339703287808664
  - 0.23334193322001703
  - 0.25308990678220883
  - 0.23374435207933242
  - 0.23183924368242556
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.42349544353398144
  - 0.44843746529778483
  - 0.4324957975656703
  - 0.4207351921620008
  - 0.41532560818337455
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.3607766990291263
  - 0.36723865432377517
  - 0.36794318590435104
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.36077669902912624
  - 0.3672386543237751
  - 0.36794318590435093
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.3607766990291261
  - 0.36723865432377506
  - 0.3679431859043509
  - 0.36027032172092144
  - 0.3518959516394944
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.45776082474226804
  - 0.47047352199495657
  - 0.44657352374662923
  - 0.453350255058035
  - 0.4449679297673131
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.05
  - -0.047414766312937465
  - -0.04261057173678533
  - -0.03969160479725871
  - -0.04506319838798315
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.05
  - -0.04741476631293746
  - -0.04261057173678533
  - -0.03969160479725871
  - -0.045063198387983144
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.05000000000000001
  - -0.04741476631293746
  - -0.042610571736785334
  - -0.039691604797258716
  - -0.04506319838798314
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.08204536082474226
  - -0.07574670776127768
  - -0.06940660943261238
  - -0.0658674026795469
  - -0.07494031269412407
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.5892233009708737
  - -0.5853465793632874
  - -0.5894462423588637
  - -0.60003807348182
  - -0.6030408499725225
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.5892233009708738
  - -0.5853465793632874
  - -0.5894462423588637
  - -0.6000380734818199
  - -0.6030408499725224
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.5892233009708738
  - -0.5853465793632875
  - -0.5894462423588638
  - -0.60003807348182
  - -0.6030408499725224
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.4601938144329897
  - -0.45377977024376587
  - -0.48401986682075854
  - -0.4807823422624182
  - -0.4800917575385628
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.23566782815751114
  - 0.24123399435370146
  - 0.2380473685371295
  - 0.23486161252052626
  - 0.22642293213468004
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.2200900260601753
  - 0.22491875821060636
  - 0.22544753511429358
  - 0.21971324084286295
  - 0.21351561631654997
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.22449578706571863
  - 0.2300266780420578
  - 0.2297425534806957
  - 0.22415228476317275
  - 0.21835897610920066
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.30919806848678155
  - 0.3239618162195671
  - 0.29910094976678125
  - 0.3059381977168118
  - 0.29871660691126406
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.24339703287808662
  - 0.23334193322001695
  - 0.25308990678220883
  - 0.23374435207933256
  - 0.2318392436824255
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.06664060637280526
  - 0.06788717789318403
  - 0.07625181523974471
  - 0.08502087771918605
  - 0.059988841462376145
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.01722469386719397
  - 0.0335041797450542
  - 0.048576258524066496
  - 0.05004580265235042
  - 0.021426419006345662
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.015630438787573822
  - 0.025673512927924625
  - 0.04310192509681606
  - 0.045355651560890324
  - 0.015956098229059197
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.08046775658755491
  - 0.08574918241999434
  - 0.08698416283947849
  - 0.09657613035789743
  - 0.06641574525835406
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6014936239482936
  - 0.585011317529588
  - 0.6028050287723046
  - 0.5888810086353472
  - 0.5842692698271763
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -94.49
  - -95.46511627906976
  - -96.32407407407408
  - -94.03921568627452
  - -95.9622641509434
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.6392233009708737
  - -0.6327613456762249
  - -0.632056814095649
  - -0.6397296782790786
  - -0.6481040483605056
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.6392233009708738
  - -0.6327613456762249
  - -0.6320568140956491
  - -0.6397296782790787
  - -0.6481040483605056
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.6392233009708739
  - -0.6327613456762249
  - -0.632056814095649
  - -0.6397296782790785
  - -0.6481040483605057
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.542239175257732
  - -0.5295264780050434
  - -0.5534264762533708
  - -0.546649744941965
  - -0.5550320702326869
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.5280111867591551
  - -0.5344348091157688
  - -0.5032638199618767
  - -0.5189223851053729
  - -0.5362116266160306
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.3607766990291263
  - 0.36723865432377517
  - 0.36794318590435104
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.36077669902912624
  - 0.3672386543237751
  - 0.36794318590435093
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.3607766990291261
  - 0.36723865432377506
  - 0.3679431859043509
  - 0.36027032172092144
  - 0.3518959516394944
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.45776082474226804
  - 0.47047352199495657
  - 0.44657352374662923
  - 0.453350255058035
  - 0.4449679297673131
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.3607766990291263
  - 0.36723865432377517
  - 0.36794318590435104
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.36077669902912624
  - 0.3672386543237751
  - 0.36794318590435093
  - 0.3602703217209214
  - 0.3518959516394944
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.3607766990291261
  - 0.36723865432377506
  - 0.3679431859043509
  - 0.36027032172092144
  - 0.3518959516394944
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.45776082474226804
  - 0.47047352199495657
  - 0.44657352374662923
  - 0.453350255058035
  - 0.4449679297673131
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5689911458467878
  - 0.5735389862531514
  - 0.5785711580679912
  - 0.5770845935025606
  - 0.5733856209861905
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.4899530420553101
  - 0.48787411476956033
  - 0.5110144330943325
  - 0.5029255079952568
  - 0.483958022823833
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.4851372108094784
  - 0.47277171501297877
  - 0.5023899425840594
  - 0.4920127336771897
  - 0.47226961355370933
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5657383379857654
  - 0.5863263800874042
  - 0.580445702997164
  - 0.5818692489945462
  - 0.5687978895590471
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.17533980582524275
  - 0.18040189659065253
  - 0.168554476806904
  - 0.1727584237578527
  - 0.16605605422238506
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.17533980582524272
  - 0.1804018965906525
  - 0.168554476806904
  - 0.17275842375785266
  - 0.16605605422238506
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.17533980582524272
  - 0.1804018965906525
  - 0.168554476806904
  - 0.1727584237578526
  - 0.16605605422238504
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.18357113402061853
  - 0.1816979546091342
  - 0.16518078256562654
  - 0.17878295013019868
  - 0.16603174840771484
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.18543689320388348
  - 0.18683675773312264
  - 0.19938870909744694
  - 0.18751189796306877
  - 0.18583989741710935
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.18543689320388348
  - 0.1868367577331226
  - 0.19938870909744696
  - 0.18751189796306872
  - 0.18583989741710935
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.18543689320388346
  - 0.1868367577331226
  - 0.1993887090974469
  - 0.1875118979630687
  - 0.18583989741710932
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.27418969072164945
  - 0.28877556738582233
  - 0.28139274118100277
  - 0.2745673049278362
  - 0.2789361813595983
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.3001535457422785
  - 0.30538422045047925
  - 0.3155858240475724
  - 0.29311966821663216
  - 0.28768183428121696
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.2202528078257926
  - 0.21609157917277455
  - 0.23340794130337705
  - 0.21541277623747945
  - 0.21228292180373726
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.24314767291175327
  - 0.23445257091332947
  - 0.25308947240169094
  - 0.23329148877632633
  - 0.23202444318441465
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.4244358170720526
  - 0.4443231860604402
  - 0.42868695255405836
  - 0.4159385583431707
  - 0.41633781667779746
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.3605825242718448
  - 0.36599683901557917
  - 0.3683027687882058
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.3605825242718447
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.36160289358461833
  - 0.3524455028393479
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.36058252427184456
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.4575628865979381
  - 0.46909498458952076
  - 0.44678333608497045
  - 0.45542029128366884
  - 0.44607560641554345
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.05058252427184467
  - -0.047866335515917825
  - -0.04252067601582165
  - -0.03931086997905958
  - -0.04515479025462539
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.05058252427184466
  - -0.04786633551591781
  - -0.04252067601582165
  - -0.03931086997905958
  - -0.04515479025462539
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.05058252427184467
  - -0.04786633551591781
  - -0.04252067601582166
  - -0.03931086997905958
  - -0.04515479025462539
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.08346391752577319
  - -0.07583076492014572
  - -0.0684572945902812
  - -0.06520203389273599
  - -0.07513116238689349
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.5888349514563105
  - -0.586136825468503
  - -0.5891765551959727
  - -0.5990862364363222
  - -0.6023997069060267
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.5888349514563107
  - -0.5861368254685031
  - -0.5891765551959727
  - -0.5990862364363221
  - -0.6023997069060267
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.5888349514563106
  - -0.586136825468503
  - -0.5891765551959727
  - -0.599086236436322
  - -0.6023997069060267
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.45897319587628865
  - -0.4550742504903335
  - -0.4847593693247484
  - -0.479377674823595
  - -0.478793231197563
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.23555228911426335
  - 0.24026129716744546
  - 0.23834281395401516
  - 0.23622548845532185
  - 0.22681963947573522
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.21994551699632833
  - 0.2239878402653033
  - 0.2257175913172828
  - 0.2207052808923488
  - 0.2139203913720258
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.22431027953216817
  - 0.22899175552936255
  - 0.23009867593756386
  - 0.22490734935435544
  - 0.21869567365607168
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.308969979057423
  - 0.3228341510027475
  - 0.29954096999623736
  - 0.3079214740088241
  - 0.2997510227641563
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.2431476729117533
  - 0.23445257091332955
  - 0.253089472401691
  - 0.23329148877632624
  - 0.23202444318441462
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.06548806446544399
  - 0.06346921982733632
  - 0.07421389275922198
  - 0.08741187722454163
  - 0.06216410926099541
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.015204806561078773
  - 0.03053151289920407
  - 0.04932406804581986
  - 0.05297227166390473
  - 0.021849913695737213
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.01395005316901674
  - 0.022826340952674624
  - 0.04335510149480934
  - 0.04916222924827732
  - 0.017066966722119607
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.07961573360038894
  - 0.07977016157477312
  - 0.08342748229523315
  - 0.09900903197325724
  - 0.06979506499752405
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.5984564711574488
  - 0.587078646501344
  - 0.6016408295026261
  - 0.5872988118836349
  - 0.5845716015497884
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -94.61
  - -95.52325581395348
  - -96.17592592592592
  - -93.87254901960785
  - -95.95283018867924
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.6394174757281553
  - -0.6340031609844209
  - -0.6316972312117942
  - -0.6383971064153816
  - -0.6475544971606523
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.6394174757281553
  - -0.6340031609844209
  - -0.6316972312117943
  - -0.6383971064153817
  - -0.6475544971606522
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.6394174757281553
  - -0.6340031609844208
  - -0.6316972312117942
  - -0.6383971064153816
  - -0.6475544971606519
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5424371134020618
  - -0.5309050154104792
  - -0.5532166639150295
  - -0.5445797087163311
  - -0.5539243935844566
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.5284263301986881
  - -0.5346740405934838
  - -0.5025995600198173
  - -0.5175873045807483
  - -0.5350233002963819
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.3605825242718448
  - 0.36599683901557917
  - 0.3683027687882058
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.3605825242718447
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.36160289358461833
  - 0.3524455028393479
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.36058252427184456
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.4575628865979381
  - 0.46909498458952076
  - 0.44678333608497045
  - 0.45542029128366884
  - 0.44607560641554345
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.3605825242718448
  - 0.36599683901557917
  - 0.3683027687882058
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.3605825242718447
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.36160289358461833
  - 0.3524455028393479
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.36058252427184456
  - 0.3659968390155791
  - 0.36830276878820567
  - 0.3616028935846183
  - 0.35244550283934784
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.4575628865979381
  - 0.46909498458952076
  - 0.44678333608497045
  - 0.45542029128366884
  - 0.44607560641554345
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5694866100451584
  - 0.57275275470615
  - 0.5795221329213146
  - 0.5768441361151745
  - 0.5738903175895272
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.48871603338242514
  - 0.487526825568528
  - 0.5111443510323652
  - 0.5028952965195709
  - 0.484470214400536
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.4839664716009134
  - 0.4731072273352309
  - 0.5026841191277471
  - 0.4928550175924625
  - 0.47298660931536873
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5667387979503883
  - 0.5853677679132895
  - 0.5811800907654381
  - 0.5806888144553395
  - 0.5688047930884682
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.17572815533980585
  - 0.1796116504854369
  - 0.16882416396979505
  - 0.17371026080335045
  - 0.16669719728888074
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.17572815533980582
  - 0.1796116504854369
  - 0.16882416396979505
  - 0.17371026080335047
  - 0.16669719728888074
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.17572815533980585
  - 0.17961165048543687
  - 0.16882416396979505
  - 0.1737102608033504
  - 0.16669719728888072
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.18479175257731958
  - 0.18040347436256657
  - 0.1644412800616367
  - 0.1801876175690217
  - 0.16733027474871456
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.1848543689320388
  - 0.18638518853014224
  - 0.19947860481841065
  - 0.18789263278126792
  - 0.18574830555046712
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.18485436893203883
  - 0.18638518853014224
  - 0.19947860481841065
  - 0.18789263278126786
  - 0.18574830555046712
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.18485436893203883
  - 0.1863851885301422
  - 0.19947860481841062
  - 0.1878926327812678
  - 0.18574830555046706
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.2727711340206186
  - 0.28869151022695433
  - 0.2823420560233339
  - 0.2752326737146471
  - 0.27874533166682885
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.5671602425719114
  - 0.5720522244462466
  - 0.5641315372576368
  - 0.5671398764175951
  - 0.5706002649809404
  train_level0__average_precision_macro_masked:
  - 0.24600840886959685
  - 0.2440806633345507
  - 0.23525876588357192
  - 0.24082464335408132
  - 0.24448351950806962
  train_level0__average_precision_macro_oob:
  - 0.26907861801449995
  - 0.2653378314701754
  - 0.25948332311342287
  - 0.2656211912048169
  - 0.2673189242147434
  train_level0__average_precision_micro:
  - 0.6241429181116964
  - 0.6240359533545172
  - 0.6232974611283559
  - 0.6236036538983034
  - 0.6243874210617634
  train_level0__average_precision_micro_masked:
  - 0.42623835480020006
  - 0.4266364618691023
  - 0.42711500144466696
  - 0.42517713013669167
  - 0.4277224610568854
  train_level0__average_precision_micro_oob:
  - 0.49011550452033903
  - 0.4867245951389777
  - 0.48841257841452546
  - 0.4894611938953999
  - 0.49114957676660287
  train_level0__average_precision_samples:
  - 0.638731852404454
  - 0.6388112464425958
  - 0.6389837571679673
  - 0.639742869092674
  - 0.6396748048321244
  train_level0__average_precision_samples_masked:
  - 0.470814987545087
  - 0.46873433040998064
  - 0.4718779290489328
  - 0.4714429861231237
  - 0.47186579274503615
  train_level0__average_precision_samples_oob:
  - 0.5223428269113266
  - 0.5206067456848358
  - 0.523018604340879
  - 0.5237906166930715
  - 0.5238452501395052
  train_level0__average_precision_weighted:
  - 0.6455871335153252
  - 0.6492404617786744
  - 0.6449049652119009
  - 0.6447014971263513
  - 0.6462743731999708
  train_level0__average_precision_weighted_masked:
  - 0.3521581958050587
  - 0.34903393349340384
  - 0.34288350832944686
  - 0.3448279632252517
  - 0.3490188120028284
  train_level0__average_precision_weighted_oob:
  - 0.3869300386311576
  - 0.37976605571587146
  - 0.3764711572549829
  - 0.38003028142691264
  - 0.38396955790057014
  train_level0__f1_macro:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__f1_macro_masked:
  - 0.817832341474411
  - 0.8174358457010852
  - 0.8189824915442285
  - 0.8157230435603467
  - 0.8168500241678105
  train_level0__f1_macro_oob:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__f1_micro:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__f1_micro_masked:
  - 0.8252535760728218
  - 0.8248642943305187
  - 0.8266553525496539
  - 0.8233617488625072
  - 0.8243264659270998
  train_level0__f1_micro_oob:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__f1_samples:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__f1_samples_masked:
  - 0.8250413181534693
  - 0.8246401777540443
  - 0.8264022529973806
  - 0.8232678109494319
  - 0.8241095496303356
  train_level0__f1_samples_oob:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__f1_weighted:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__f1_weighted_masked:
  - 0.7186983173593221
  - 0.71810285832221
  - 0.7157425914093155
  - 0.7147049680088445
  - 0.7175138785931984
  train_level0__f1_weighted_oob:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__fn_macro:
  - -0.23366178814664545
  - -0.2339665795369679
  - -0.2318269183381795
  - -0.23575242718446598
  - -0.23484848484848475
  train_level0__fn_macro_masked:
  - -0.18216765852558892
  - -0.18256415429891487
  - -0.18101750845577141
  - -0.1842769564396534
  - -0.1831499758321893
  train_level0__fn_macro_oob:
  - -0.23366178814664545
  - -0.2339665795369679
  - -0.2318269183381795
  - -0.23575242718446598
  - -0.23484848484848475
  train_level0__fn_micro:
  - -0.23366178814664543
  - -0.2339665795369679
  - -0.23182691833817948
  - -0.235752427184466
  - -0.23484848484848486
  train_level0__fn_micro_masked:
  - -0.17474642392717815
  - -0.1751357056694813
  - -0.17334464745034606
  - -0.17663825113749282
  - -0.17567353407290015
  train_level0__fn_micro_oob:
  - -0.23366178814664543
  - -0.2339665795369679
  - -0.23182691833817948
  - -0.235752427184466
  - -0.23484848484848486
  train_level0__fn_samples:
  - -0.23366178814664534
  - -0.23396657953696784
  - -0.23182691833817942
  - -0.23575242718446596
  - -0.23484848484848478
  train_level0__fn_samples_masked:
  - -0.17495868184653082
  - -0.1753598222459557
  - -0.1735977470026194
  - -0.17673218905056817
  - -0.17589045036966433
  train_level0__fn_samples_oob:
  - -0.23366178814664534
  - -0.23396657953696784
  - -0.23182691833817942
  - -0.23575242718446596
  - -0.23484848484848478
  train_level0__fn_weighted:
  - -0.34531399848303707
  - -0.34587018031843464
  - -0.34802544114092343
  - -0.3492697930608463
  - -0.34641408341690205
  train_level0__fn_weighted_masked:
  - -0.2813016826406777
  - -0.2818971416777901
  - -0.2842574085906846
  - -0.2852950319911554
  - -0.28248612140680157
  train_level0__fn_weighted_oob:
  - -0.34531399848303707
  - -0.34587018031843464
  - -0.34802544114092343
  - -0.3492697930608463
  - -0.34641408341690205
  train_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__jaccard_macro:
  - 0.6457713712124762
  - 0.6454766172261543
  - 0.6489949972170814
  - 0.6435045997481648
  - 0.6441636576700717
  train_level0__jaccard_macro_masked:
  - 0.7129998412756772
  - 0.7125182583756124
  - 0.7153572894603165
  - 0.710503670285152
  - 0.7116681751698026
  train_level0__jaccard_macro_oob:
  - 0.6457713712124762
  - 0.6454766172261543
  - 0.6489949972170814
  - 0.6435045997481648
  - 0.6441636576700717
  train_level0__jaccard_micro:
  - 0.6211898749045633
  - 0.6207894388440225
  - 0.6236047209441888
  - 0.618447154950602
  - 0.6196319018404908
  train_level0__jaccard_micro_masked:
  - 0.7024950740552148
  - 0.7019310964265093
  - 0.7045290182607123
  - 0.699757761628553
  - 0.7011525240951675
  train_level0__jaccard_micro_oob:
  - 0.6211898749045633
  - 0.6207894388440225
  - 0.6236047209441888
  - 0.618447154950602
  - 0.6196319018404908
  train_level0__jaccard_samples:
  - 0.6239028440885305
  - 0.6234733998011001
  - 0.6263367138481398
  - 0.6211533964140089
  - 0.6223328647442248
  train_level0__jaccard_samples_masked:
  - 0.7047461397030148
  - 0.7040407403072085
  - 0.7066095507586581
  - 0.702412376828621
  - 0.7034141917204934
  train_level0__jaccard_samples_oob:
  - 0.6239028440885305
  - 0.6234733998011001
  - 0.6263367138481398
  - 0.6211533964140089
  - 0.6223328647442248
  train_level0__jaccard_weighted:
  - 0.5159886928760944
  - 0.5152736064931414
  - 0.5140821665536147
  - 0.5121600422501403
  - 0.5151741028242109
  train_level0__jaccard_weighted_masked:
  - 0.5894683570143106
  - 0.5885767425283752
  - 0.5870674113032447
  - 0.5853880659122684
  - 0.5885427959206487
  train_level0__jaccard_weighted_oob:
  - 0.5159886928760944
  - 0.5152736064931414
  - 0.5140821665536147
  - 0.5121600422501403
  - 0.5151741028242109
  train_level0__label_ranking_average_precision_score:
  - 0.638731852404454
  - 0.6388112464425958
  - 0.6389837571679676
  - 0.6397428690926743
  - 0.6396748048321244
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5223428269113267
  - 0.5206067456848354
  - 0.5230186043408791
  - 0.5237906166930716
  - 0.5238452501395051
  train_level0__matthews_corrcoef_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__ndcg:
  - 0.8791204049839193
  - 0.8805079294506395
  - 0.8798414683827186
  - 0.8807596944507516
  - 0.8798633409534306
  train_level0__ndcg_oob:
  - 0.8209952924736631
  - 0.8189239834500661
  - 0.8210940835535473
  - 0.8234323954442061
  - 0.8220784055174786
  train_level0__neg_coverage_error:
  - -84.44527363184079
  - -84.28365384615384
  - -83.84010152284264
  - -84.2725
  - -85.23989898989899
  train_level0__neg_coverage_error_oob:
  - -90.88805970149254
  - -90.3701923076923
  - -90.21827411167513
  - -89.7125
  - -90.4469696969697
  train_level0__neg_hamming_loss_macro:
  - -0.23366178814664545
  - -0.2339665795369679
  - -0.2318269183381795
  - -0.23575242718446598
  - -0.23484848484848475
  train_level0__neg_hamming_loss_macro_masked:
  - -0.18216765852558892
  - -0.18256415429891487
  - -0.18101750845577141
  - -0.1842769564396534
  - -0.1831499758321893
  train_level0__neg_hamming_loss_macro_oob:
  - -0.23366178814664545
  - -0.2339665795369679
  - -0.2318269183381795
  - -0.23575242718446598
  - -0.23484848484848475
  train_level0__neg_hamming_loss_micro:
  - -0.23366178814664543
  - -0.2339665795369679
  - -0.23182691833817948
  - -0.235752427184466
  - -0.23484848484848486
  train_level0__neg_hamming_loss_micro_masked:
  - -0.17474642392717815
  - -0.1751357056694813
  - -0.17334464745034606
  - -0.17663825113749282
  - -0.17567353407290015
  train_level0__neg_hamming_loss_micro_oob:
  - -0.23366178814664543
  - -0.2339665795369679
  - -0.23182691833817948
  - -0.235752427184466
  - -0.23484848484848486
  train_level0__neg_hamming_loss_samples:
  - -0.23366178814664534
  - -0.23396657953696784
  - -0.23182691833817942
  - -0.23575242718446596
  - -0.23484848484848478
  train_level0__neg_hamming_loss_samples_masked:
  - -0.17495868184653082
  - -0.1753598222459557
  - -0.1735977470026194
  - -0.17673218905056817
  - -0.17589045036966433
  train_level0__neg_hamming_loss_samples_oob:
  - -0.23366178814664534
  - -0.23396657953696784
  - -0.23182691833817942
  - -0.23575242718446596
  - -0.23484848484848478
  train_level0__neg_hamming_loss_weighted:
  - -0.34531399848303707
  - -0.34587018031843464
  - -0.34802544114092343
  - -0.3492697930608463
  - -0.34641408341690205
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.2813016826406777
  - -0.2818971416777901
  - -0.2842574085906846
  - -0.2852950319911554
  - -0.28248612140680157
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.34531399848303707
  - -0.34587018031843464
  - -0.34802544114092343
  - -0.3492697930608463
  - -0.34641408341690205
  train_level0__neg_label_ranking_loss:
  - -0.18557471674465403
  - -0.18502120051946147
  - -0.18354069833003414
  - -0.18708661463293094
  - -0.18490848458424528
  train_level0__neg_label_ranking_loss_oob:
  - -0.25895757854698986
  - -0.2580441551405657
  - -0.2552344590868728
  - -0.25928672222929455
  - -0.2587842440152651
  train_level0__precision_macro:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__precision_macro_masked:
  - 0.817832341474411
  - 0.8174358457010852
  - 0.8189824915442285
  - 0.8157230435603467
  - 0.8168500241678105
  train_level0__precision_macro_oob:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__precision_micro:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__precision_micro_masked:
  - 0.8252535760728218
  - 0.8248642943305187
  - 0.8266553525496539
  - 0.8233617488625072
  - 0.8243264659270998
  train_level0__precision_micro_oob:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__precision_samples:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__precision_samples_masked:
  - 0.8250413181534693
  - 0.8246401777540443
  - 0.8264022529973806
  - 0.8232678109494319
  - 0.8241095496303356
  train_level0__precision_samples_oob:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__precision_weighted:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__precision_weighted_masked:
  - 0.7186983173593221
  - 0.71810285832221
  - 0.7157425914093155
  - 0.7147049680088445
  - 0.7175138785931984
  train_level0__precision_weighted_oob:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__recall_macro:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__recall_macro_masked:
  - 0.817832341474411
  - 0.8174358457010852
  - 0.8189824915442285
  - 0.8157230435603467
  - 0.8168500241678105
  train_level0__recall_macro_oob:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__recall_micro:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__recall_micro_masked:
  - 0.8252535760728218
  - 0.8248642943305187
  - 0.8266553525496539
  - 0.8233617488625072
  - 0.8243264659270998
  train_level0__recall_micro_oob:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__recall_samples:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__recall_samples_masked:
  - 0.8250413181534693
  - 0.8246401777540443
  - 0.8264022529973806
  - 0.8232678109494319
  - 0.8241095496303356
  train_level0__recall_samples_oob:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__recall_weighted:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__recall_weighted_masked:
  - 0.7186983173593221
  - 0.71810285832221
  - 0.7157425914093155
  - 0.7147049680088445
  - 0.7175138785931984
  train_level0__recall_weighted_oob:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__roc_auc_macro:
  - 0.707538375884148
  - 0.7152232082513167
  - 0.708908604218757
  - 0.705011454733505
  - 0.7139558595023946
  train_level0__roc_auc_macro_masked:
  - 0.5797954669117468
  - 0.5901233693266454
  - 0.5811754649810414
  - 0.57619208887662
  - 0.5887954235251274
  train_level0__roc_auc_macro_oob:
  - 0.5325674657509847
  - 0.5359480562327754
  - 0.5291304608463462
  - 0.5334356182719416
  - 0.5375070770445233
  train_level0__roc_auc_micro:
  - 0.8130056563178014
  - 0.8135491421037633
  - 0.8153154594422616
  - 0.8113388436850408
  - 0.8130546512853237
  train_level0__roc_auc_micro_masked:
  - 0.7532869573826553
  - 0.7545421479038659
  - 0.7562599210838661
  - 0.7509887846985928
  - 0.7534166335779979
  train_level0__roc_auc_micro_oob:
  - 0.7377600317005916
  - 0.7384492095174123
  - 0.7407979607766633
  - 0.7375156658499284
  - 0.7374784291998933
  train_level0__roc_auc_samples:
  - 0.814425283255346
  - 0.8149787994805386
  - 0.8164593016699658
  - 0.812913385367069
  - 0.8150915154157548
  train_level0__roc_auc_samples_masked:
  - 0.7563620406018811
  - 0.7573006277870795
  - 0.7584446976577894
  - 0.7541168826301846
  - 0.7567513095951739
  train_level0__roc_auc_samples_oob:
  - 0.74104242145301
  - 0.7419558448594343
  - 0.7447655409131272
  - 0.7407132777707054
  - 0.7412157559847349
  train_level0__roc_auc_weighted:
  - 0.7069462695441235
  - 0.7103095769771346
  - 0.7044902031060893
  - 0.6985151066502553
  - 0.709079669630692
  train_level0__roc_auc_weighted_masked:
  - 0.5828151688626337
  - 0.5864735195489328
  - 0.5777873207400841
  - 0.5702107182738135
  - 0.5853867049689048
  train_level0__roc_auc_weighted_oob:
  - 0.5416723213673563
  - 0.5380065286333087
  - 0.5342663270761884
  - 0.5342008330769109
  - 0.5439749160102375
  train_level0__tn_macro:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__tn_macro_masked:
  - 0.817832341474411
  - 0.8174358457010852
  - 0.8189824915442285
  - 0.8157230435603467
  - 0.8168500241678105
  train_level0__tn_macro_oob:
  - 0.7663382118533544
  - 0.7660334204630319
  - 0.7681730816618206
  - 0.764247572815534
  - 0.7651515151515154
  train_level0__tn_micro:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__tn_micro_masked:
  - 0.8252535760728218
  - 0.8248642943305187
  - 0.8266553525496539
  - 0.8233617488625072
  - 0.8243264659270998
  train_level0__tn_micro_oob:
  - 0.7663382118533546
  - 0.7660334204630321
  - 0.7681730816618205
  - 0.764247572815534
  - 0.7651515151515151
  train_level0__tn_samples:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__tn_samples_masked:
  - 0.8250413181534693
  - 0.8246401777540443
  - 0.8264022529973806
  - 0.8232678109494319
  - 0.8241095496303356
  train_level0__tn_samples_oob:
  - 0.7663382118533546
  - 0.7660334204630319
  - 0.7681730816618205
  - 0.7642475728155338
  - 0.7651515151515151
  train_level0__tn_weighted:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__tn_weighted_masked:
  - 0.7186983173593221
  - 0.71810285832221
  - 0.7157425914093155
  - 0.7147049680088445
  - 0.7175138785931984
  train_level0__tn_weighted_oob:
  - 0.6546860015169629
  - 0.6541298196815654
  - 0.6519745588590766
  - 0.6507302069391537
  - 0.6535859165830978
  train_level0__tp_macro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level10__average_precision_macro:
  - 0.3390499604883726
  - 0.35543045536967727
  - 0.35419231756720054
  - 0.3384441492659286
  - 0.35338775212675255
  train_level10__average_precision_macro_masked:
  - 0.26408518467640585
  - 0.27808716322398586
  - 0.2792682117457914
  - 0.26403577928796
  - 0.2758648452473121
  train_level10__average_precision_macro_oob:
  - 0.33393066116850745
  - 0.34896803802316956
  - 0.346289708804513
  - 0.33362850819989176
  - 0.34824771947537786
  train_level10__average_precision_micro:
  - 0.24670042547888205
  - 0.247030859849889
  - 0.2554968315892867
  - 0.24332640894430227
  - 0.2527071256402797
  train_level10__average_precision_micro_masked:
  - 0.17858019562868138
  - 0.1786969212999473
  - 0.18594544616140893
  - 0.17639293998902905
  - 0.18281874455895086
  train_level10__average_precision_micro_oob:
  - 0.24610116437554297
  - 0.2467016575253343
  - 0.25413386412948996
  - 0.24324546147147275
  - 0.25176075021672495
  train_level10__average_precision_samples:
  - 0.26159916932771393
  - 0.2634190005866644
  - 0.27162422684590865
  - 0.26075606070263674
  - 0.2710992245807104
  train_level10__average_precision_samples_masked:
  - 0.19694842057815792
  - 0.19875311331151957
  - 0.20642079545966047
  - 0.19658570973753908
  - 0.20535533364652048
  train_level10__average_precision_samples_oob:
  - 0.26092465602391574
  - 0.26328772329308286
  - 0.27035334665685734
  - 0.26074131312796855
  - 0.26994013553746243
  train_level10__average_precision_weighted:
  - 0.47685685594768557
  - 0.487820828393553
  - 0.4863608359026523
  - 0.468185033026376
  - 0.4868733780081914
  train_level10__average_precision_weighted_masked:
  - 0.3875705961833542
  - 0.39861260845108026
  - 0.39991205580632433
  - 0.380082840125743
  - 0.3973579882388373
  train_level10__average_precision_weighted_oob:
  - 0.47007687837962386
  - 0.4802536774158146
  - 0.47787430210339327
  - 0.462923832779043
  - 0.47962160664273085
  train_level10__f1_macro:
  - 0.3916823648746558
  - 0.4055265123226289
  - 0.3990931940269085
  - 0.39987864077669893
  - 0.39717563989408655
  train_level10__f1_macro_masked:
  - 0.3575376884699848
  - 0.37266047817750525
  - 0.3649414500767781
  - 0.36629309748457384
  - 0.3633775093110491
  train_level10__f1_macro_oob:
  - 0.38820460802782203
  - 0.4023291635548918
  - 0.39586516189443594
  - 0.3961650485436894
  - 0.3941355300578602
  train_level10__f1_micro:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.39987864077669905
  - 0.3971756398940865
  train_level10__f1_micro_masked:
  - 0.3503250975292588
  - 0.3654000804181745
  - 0.35888732730503037
  - 0.3593692798493803
  - 0.3562334918119387
  train_level10__f1_micro_oob:
  - 0.38820460802782203
  - 0.40232916355489173
  - 0.39586516189443594
  - 0.39616504854368934
  - 0.3941355300578602
  train_level10__f1_samples:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.399878640776699
  - 0.39717563989408644
  train_level10__f1_samples_masked:
  - 0.35093414503619175
  - 0.3659791737662793
  - 0.3595132329517396
  - 0.3598162738373898
  - 0.35682244618262055
  train_level10__f1_samples_oob:
  - 0.388204608027822
  - 0.4023291635548917
  - 0.39586516189443594
  - 0.3961650485436893
  - 0.39413553005786006
  train_level10__f1_weighted:
  - 0.49547276537210594
  - 0.5094362651064647
  - 0.4886361429089403
  - 0.49913157623803156
  - 0.4976545389166749
  train_level10__f1_weighted_masked:
  - 0.4538324541069358
  - 0.46989152638393805
  - 0.4462935008326894
  - 0.45771422857490607
  - 0.4581243851394697
  train_level10__f1_weighted_oob:
  - 0.49139393471916903
  - 0.5048299923268752
  - 0.4846574575261577
  - 0.49481982909502725
  - 0.49443569213378175
  train_level10__fn_macro:
  - -0.03142056706757475
  - -0.02975634802091113
  - -0.029052289192252723
  - -0.03572815533980583
  - -0.0306217514955379
  train_level10__fn_macro_masked:
  - -0.030376627667992723
  - -0.028046977173774672
  - -0.027799917696051887
  - -0.034819398977339364
  - -0.028974943043683487
  train_level10__fn_macro_oob:
  - -0.03204849538714196
  - -0.030526512322628825
  - -0.02944655265881425
  - -0.035970873786407766
  - -0.03108757477689517
  train_level10__fn_micro:
  - -0.03142056706757475
  - -0.02975634802091113
  - -0.029052289192252723
  - -0.03572815533980583
  - -0.030621751495537905
  train_level10__fn_micro_masked:
  - -0.028426527958387515
  - -0.02651286690792119
  - -0.025721937896104583
  - -0.03258197793002458
  - -0.027311146328578974
  train_level10__fn_micro_oob:
  - -0.03204849538714196
  - -0.03052651232262883
  - -0.029446552658814254
  - -0.035970873786407766
  - -0.031087574776895166
  train_level10__fn_samples:
  - -0.03142056706757475
  - -0.029756348020911125
  - -0.029052289192252716
  - -0.03572815533980582
  - -0.030621751495537898
  train_level10__fn_samples_masked:
  - -0.02833462782108139
  - -0.026426512588266265
  - -0.025696566028977005
  - -0.032409518586141474
  - -0.02718459808061929
  train_level10__fn_samples_oob:
  - -0.032048495387141954
  - -0.03052651232262882
  - -0.02944655265881425
  - -0.03597087378640776
  - -0.03108757477689516
  train_level10__fn_weighted:
  - -0.05562728990705387
  - -0.04945760598503741
  - -0.05566058910873994
  - -0.06297539380212086
  - -0.05266992927500287
  train_level10__fn_weighted_masked:
  - -0.05643602489418466
  - -0.04849838847693058
  - -0.055769933860464166
  - -0.06434787125718683
  - -0.051046042911681994
  train_level10__fn_weighted_oob:
  - -0.0561955082468793
  - -0.050941876079033194
  - -0.05581274387927759
  - -0.0631298260063832
  - -0.05313707067543586
  train_level10__fp_macro:
  - -0.5768970680577694
  - -0.56471713965646
  - -0.5718545167808388
  - -0.5643932038834951
  - -0.5722026086103755
  train_level10__fp_macro_masked:
  - -0.6120856838620223
  - -0.5992925446487202
  - -0.6072586322271701
  - -0.5988875035380868
  - -0.6076475476452674
  train_level10__fp_macro_oob:
  - -0.5797468965850361
  - -0.5671443241224794
  - -0.5746882854467499
  - -0.5678640776699028
  - -0.5747768951652446
  train_level10__fp_micro:
  - -0.5768970680577694
  - -0.5647171396564601
  - -0.5718545167808388
  - -0.5643932038834951
  - -0.5722026086103756
  train_level10__fp_micro_masked:
  - -0.6212483745123537
  - -0.6080870526739043
  - -0.6153907347988651
  - -0.6080487422205951
  - -0.6164553618594824
  train_level10__fp_micro_oob:
  - -0.579746896585036
  - -0.5671443241224795
  - -0.5746882854467498
  - -0.5678640776699029
  - -0.5747768951652447
  train_level10__fp_samples:
  - -0.5768970680577694
  - -0.56471713965646
  - -0.5718545167808388
  - -0.5643932038834951
  - -0.5722026086103756
  train_level10__fp_samples_masked:
  - -0.6207312271427269
  - -0.6075943136454545
  - -0.6147902010192834
  - -0.6077742075764688
  - -0.6159929557367602
  train_level10__fp_samples_oob:
  - -0.579746896585036
  - -0.5671443241224795
  - -0.5746882854467498
  - -0.567864077669903
  - -0.5747768951652447
  train_level10__fp_weighted:
  - -0.4488999447208403
  - -0.441106128908498
  - -0.45570326798231986
  - -0.43789302995984764
  - -0.44967553180832226
  train_level10__fp_weighted_masked:
  - -0.48973152099887957
  - -0.4816100851391314
  - -0.4979365653068464
  - -0.47793790016790716
  - -0.49082957194884835
  train_level10__fp_weighted_oob:
  - -0.4524105570339517
  - -0.44422813159409164
  - -0.45952979859456466
  - -0.44205034489858946
  - -0.4524272371907825
  train_level10__jaccard_macro:
  - 0.26320269181339023
  - 0.2745305100502149
  - 0.2655348070412587
  - 0.26812784604017
  - 0.2661572924315462
  train_level10__jaccard_macro_masked:
  - 0.23539976268711146
  - 0.24747067409738913
  - 0.23788751992405824
  - 0.24059890238588263
  - 0.23873653944450032
  train_level10__jaccard_macro_oob:
  - 0.26044404981241603
  - 0.2718313897987048
  - 0.26284294243995343
  - 0.2650396441582125
  - 0.2637060898551129
  train_level10__jaccard_micro:
  - 0.2435354536444725
  - 0.2543325526932084
  - 0.24929195911833518
  - 0.24990519529768676
  - 0.24779735682819384
  train_level10__jaccard_micro_masked:
  - 0.2123600819801356
  - 0.22354098763913657
  - 0.218685367114788
  - 0.21904336877002278
  - 0.21671781852072053
  train_level10__jaccard_micro_oob:
  - 0.2408522880517846
  - 0.2518223118161766
  - 0.2467779843008341
  - 0.24701110808438512
  - 0.2454351145038168
  train_level10__jaccard_samples:
  - 0.2476165616247811
  - 0.25877711156252325
  - 0.2545915044700574
  - 0.254438750898615
  - 0.2530285234779583
  train_level10__jaccard_samples_masked:
  - 0.21661318052660528
  - 0.228065149768727
  - 0.2242499056224797
  - 0.22370718024315753
  - 0.22232871425241468
  train_level10__jaccard_samples_oob:
  - 0.2448195067014241
  - 0.2561907339153186
  - 0.2521216385004012
  - 0.2514859712297656
  - 0.25064341546557284
  train_level10__jaccard_weighted:
  - 0.34536378414647206
  - 0.3595620266818163
  - 0.33701068457250377
  - 0.34716669605482475
  - 0.3477497533147173
  train_level10__jaccard_weighted_masked:
  - 0.3075850175493606
  - 0.3230326610344071
  - 0.29938430259341037
  - 0.30945820103715477
  - 0.3121310212665255
  train_level10__jaccard_weighted_oob:
  - 0.341936463284281
  - 0.35518845033566904
  - 0.3334537559428814
  - 0.34327921689273
  - 0.3448618670000635
  train_level10__label_ranking_average_precision_score:
  - 0.2615991693277139
  - 0.2634190005866641
  - 0.2716242268459084
  - 0.2607560607026366
  - 0.2710992245807104
  train_level10__label_ranking_average_precision_score_oob:
  - 0.2609246560239155
  - 0.2632877232930831
  - 0.27035334665685723
  - 0.2607413131279682
  - 0.26994013553746216
  train_level10__matthews_corrcoef_macro:
  - 0.15316663064637778
  - 0.16539284667708626
  - 0.16051949112699218
  - 0.15151175136663303
  - 0.15731240085180218
  train_level10__matthews_corrcoef_macro_masked:
  - 0.11987055462778626
  - 0.1331229919544558
  - 0.12923542948907327
  - 0.11518249362355612
  - 0.12444644393685096
  train_level10__matthews_corrcoef_macro_oob:
  - 0.14628444806508495
  - 0.15922285872582367
  - 0.15445771073463638
  - 0.14555114514249642
  - 0.1490182476154156
  train_level10__matthews_corrcoef_micro:
  - 0.11499706688979461
  - 0.1362110462234256
  - 0.13154740015871075
  - 0.10998269645562161
  - 0.12390544386120068
  train_level10__matthews_corrcoef_micro_masked:
  - 0.07599809128255829
  - 0.09869842376067117
  - 0.09541154631430379
  - 0.06805036026944841
  - 0.08677062711704937
  train_level10__matthews_corrcoef_micro_oob:
  - 0.10885691642933082
  - 0.1300502664293062
  - 0.1265928343455161
  - 0.10491170954222902
  - 0.11886555778988912
  train_level10__matthews_corrcoef_samples:
  - 0.11192577846475509
  - 0.12956098010905387
  - 0.12664003314805644
  - 0.10805337760087065
  - 0.11900934788497138
  train_level10__matthews_corrcoef_samples_masked:
  - 0.0736628747631232
  - 0.09179871941286552
  - 0.09006815194238542
  - 0.06758056295989197
  - 0.08337130947869639
  train_level10__matthews_corrcoef_samples_oob:
  - 0.10611362098249633
  - 0.12395814134587593
  - 0.12193896866686496
  - 0.1035847874974068
  - 0.1131830616037735
  train_level10__matthews_corrcoef_weighted:
  - 0.1926907213254856
  - 0.2042725400618466
  - 0.18761618830342838
  - 0.1865130044466948
  - 0.19149538796305723
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.15142282691709708
  - 0.16633890795560824
  - 0.14995034830330914
  - 0.1425415226771942
  - 0.15343214910506134
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.18323969534610166
  - 0.1958634334417109
  - 0.17884320715907312
  - 0.17692526349534807
  - 0.18302067486032955
  train_level10__ndcg:
  - 0.6149615212495652
  - 0.6093123950955364
  - 0.6143965937673269
  - 0.6103985679970915
  - 0.618885830266572
  train_level10__ndcg_oob:
  - 0.6156705786714408
  - 0.6110027742456636
  - 0.6143988492066678
  - 0.6118935497990613
  - 0.6193662947348889
  train_level10__neg_coverage_error:
  - -91.85572139303483
  - -91.81009615384616
  - -93.18274111675127
  - -91.795
  - -91.50252525252525
  train_level10__neg_coverage_error_oob:
  - -92.20646766169155
  - -92.06971153846153
  - -93.58629441624366
  - -92.14
  - -92.02777777777777
  train_level10__neg_hamming_loss_macro:
  - -0.6083176351253442
  - -0.5944734876773712
  - -0.6009068059730914
  - -0.600121359223301
  - -0.6028243601059133
  train_level10__neg_hamming_loss_macro_masked:
  - -0.6424623115300151
  - -0.6273395218224948
  - -0.635058549923222
  - -0.6337069025154262
  - -0.6366224906889507
  train_level10__neg_hamming_loss_macro_oob:
  - -0.611795391972178
  - -0.5976708364451083
  - -0.604134838105564
  - -0.6038349514563106
  - -0.6058644699421397
  train_level10__neg_hamming_loss_micro:
  - -0.6083176351253442
  - -0.5944734876773712
  - -0.6009068059730915
  - -0.600121359223301
  - -0.6028243601059136
  train_level10__neg_hamming_loss_micro_masked:
  - -0.6496749024707412
  - -0.6345999195818255
  - -0.6411126726949696
  - -0.6406307201506197
  - -0.6437665081880612
  train_level10__neg_hamming_loss_micro_oob:
  - -0.6117953919721779
  - -0.5976708364451083
  - -0.604134838105564
  - -0.6038349514563107
  - -0.6058644699421398
  train_level10__neg_hamming_loss_samples:
  - -0.6083176351253442
  - -0.5944734876773712
  - -0.6009068059730915
  - -0.6001213592233009
  - -0.6028243601059134
  train_level10__neg_hamming_loss_samples_masked:
  - -0.6490658549638083
  - -0.6340208262337206
  - -0.6404867670482604
  - -0.6401837261626102
  - -0.6431775538173795
  train_level10__neg_hamming_loss_samples_oob:
  - -0.6117953919721779
  - -0.5976708364451082
  - -0.604134838105564
  - -0.6038349514563106
  - -0.6058644699421398
  train_level10__neg_hamming_loss_weighted:
  - -0.5045272346278941
  - -0.49056373489353533
  - -0.5113638570910597
  - -0.5008684237619685
  - -0.5023454610833252
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.5461675458930643
  - -0.5301084736160621
  - -0.5537064991673106
  - -0.5422857714250939
  - -0.5418756148605304
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.5086060652808311
  - -0.4951700076731249
  - -0.5153425424738424
  - -0.5051801709049728
  - -0.5055643078662182
  train_level10__neg_label_ranking_loss:
  - -0.4690890874562156
  - -0.4578039825719037
  - -0.44228024509955616
  - -0.4772689623835328
  - -0.45313810563251505
  train_level10__neg_label_ranking_loss_oob:
  - -0.4735644433543775
  - -0.46126163184410657
  - -0.44763533243622744
  - -0.4812828780232467
  - -0.45807512588965243
  train_level10__precision_macro:
  - 0.3916823648746558
  - 0.4055265123226289
  - 0.3990931940269085
  - 0.39987864077669893
  - 0.39717563989408655
  train_level10__precision_macro_masked:
  - 0.3575376884699848
  - 0.37266047817750525
  - 0.3649414500767781
  - 0.36629309748457384
  - 0.3633775093110491
  train_level10__precision_macro_oob:
  - 0.38820460802782203
  - 0.4023291635548918
  - 0.39586516189443594
  - 0.3961650485436894
  - 0.3941355300578602
  train_level10__precision_micro:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.39987864077669905
  - 0.3971756398940865
  train_level10__precision_micro_masked:
  - 0.3503250975292588
  - 0.3654000804181745
  - 0.35888732730503037
  - 0.3593692798493803
  - 0.3562334918119387
  train_level10__precision_micro_oob:
  - 0.38820460802782203
  - 0.40232916355489173
  - 0.39586516189443594
  - 0.39616504854368934
  - 0.3941355300578602
  train_level10__precision_samples:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.399878640776699
  - 0.39717563989408644
  train_level10__precision_samples_masked:
  - 0.35093414503619175
  - 0.3659791737662793
  - 0.3595132329517396
  - 0.3598162738373898
  - 0.35682244618262055
  train_level10__precision_samples_oob:
  - 0.388204608027822
  - 0.4023291635548917
  - 0.39586516189443594
  - 0.3961650485436893
  - 0.39413553005786006
  train_level10__precision_weighted:
  - 0.49547276537210594
  - 0.5094362651064647
  - 0.4886361429089403
  - 0.49913157623803156
  - 0.4976545389166749
  train_level10__precision_weighted_masked:
  - 0.4538324541069358
  - 0.46989152638393805
  - 0.4462935008326894
  - 0.45771422857490607
  - 0.4581243851394697
  train_level10__precision_weighted_oob:
  - 0.49139393471916903
  - 0.5048299923268752
  - 0.4846574575261577
  - 0.49481982909502725
  - 0.49443569213378175
  train_level10__recall_macro:
  - 0.3916823648746558
  - 0.4055265123226289
  - 0.3990931940269085
  - 0.39987864077669893
  - 0.39717563989408655
  train_level10__recall_macro_masked:
  - 0.3575376884699848
  - 0.37266047817750525
  - 0.3649414500767781
  - 0.36629309748457384
  - 0.3633775093110491
  train_level10__recall_macro_oob:
  - 0.38820460802782203
  - 0.4023291635548918
  - 0.39586516189443594
  - 0.3961650485436894
  - 0.3941355300578602
  train_level10__recall_micro:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.39987864077669905
  - 0.3971756398940865
  train_level10__recall_micro_masked:
  - 0.3503250975292588
  - 0.3654000804181745
  - 0.35888732730503037
  - 0.3593692798493803
  - 0.3562334918119387
  train_level10__recall_micro_oob:
  - 0.38820460802782203
  - 0.40232916355489173
  - 0.39586516189443594
  - 0.39616504854368934
  - 0.3941355300578602
  train_level10__recall_samples:
  - 0.39168236487465585
  - 0.4055265123226288
  - 0.39909319402690846
  - 0.399878640776699
  - 0.39717563989408644
  train_level10__recall_samples_masked:
  - 0.35093414503619175
  - 0.3659791737662793
  - 0.3595132329517396
  - 0.3598162738373898
  - 0.35682244618262055
  train_level10__recall_samples_oob:
  - 0.388204608027822
  - 0.4023291635548917
  - 0.39586516189443594
  - 0.3961650485436893
  - 0.39413553005786006
  train_level10__recall_weighted:
  - 0.49547276537210594
  - 0.5094362651064647
  - 0.4886361429089403
  - 0.49913157623803156
  - 0.4976545389166749
  train_level10__recall_weighted_masked:
  - 0.4538324541069358
  - 0.46989152638393805
  - 0.4462935008326894
  - 0.45771422857490607
  - 0.4581243851394697
  train_level10__recall_weighted_oob:
  - 0.49139393471916903
  - 0.5048299923268752
  - 0.4846574575261577
  - 0.49481982909502725
  - 0.49443569213378175
  train_level10__roc_auc_macro:
  - 0.6470118087803005
  - 0.6685208161021367
  - 0.6663318480490886
  - 0.6472661943228956
  - 0.6665118695551572
  train_level10__roc_auc_macro_masked:
  - 0.6227246830077651
  - 0.6430938266360078
  - 0.6447922158096677
  - 0.6245513708495641
  - 0.6434964681566365
  train_level10__roc_auc_macro_oob:
  - 0.6391387519243381
  - 0.6613557124448542
  - 0.6563364102143496
  - 0.6397903099056328
  - 0.6591914168519678
  train_level10__roc_auc_micro:
  - 0.5577589095413422
  - 0.564539498221512
  - 0.5801813957121952
  - 0.5486626304516922
  - 0.5682373122999742
  train_level10__roc_auc_micro_masked:
  - 0.538343622962505
  - 0.5445341226261887
  - 0.562226017474406
  - 0.5285474364345305
  - 0.548408607868595
  train_level10__roc_auc_micro_oob:
  - 0.554417593242028
  - 0.5618136269781628
  - 0.5757482367185022
  - 0.5459623123819399
  - 0.5645255151854963
  train_level10__roc_auc_samples:
  - 0.5470310945618714
  - 0.5511118815834064
  - 0.5643300507594045
  - 0.5373666479057755
  - 0.5576276526090174
  train_level10__roc_auc_samples_masked:
  - 0.5290232756797206
  - 0.5329160789382542
  - 0.5469867186054913
  - 0.5200542785390667
  - 0.5408757612606366
  train_level10__roc_auc_samples_oob:
  - 0.543715814097808
  - 0.5488846435624876
  - 0.5596511358966433
  - 0.5349100490460392
  - 0.5535405546618658
  train_level10__roc_auc_weighted:
  - 0.6659820760355478
  - 0.6801803119934131
  - 0.6687945984027092
  - 0.6545835663539726
  - 0.6749725068906838
  train_level10__roc_auc_weighted_masked:
  - 0.6392644480804797
  - 0.6544691659767211
  - 0.6458416414283887
  - 0.6274020947344678
  - 0.6488042274046137
  train_level10__roc_auc_weighted_oob:
  - 0.6567102106864485
  - 0.6710899085258533
  - 0.6584844945471895
  - 0.6460190373941797
  - 0.666015420927907
  train_level10__tn_macro:
  - 0.18944114379558516
  - 0.20131628080657207
  - 0.19631856488098168
  - 0.19985436893203884
  - 0.19294890654113955
  train_level10__tn_macro_masked:
  - 0.20574665761238875
  - 0.21814330105236504
  - 0.21172385931705848
  - 0.2168355400222598
  - 0.20920247652254337
  train_level10__tn_macro_oob:
  - 0.18659131526831857
  - 0.19888909634055257
  - 0.1934847962150707
  - 0.19638349514563108
  - 0.19037461998627048
  train_level10__tn_micro:
  - 0.1894411437955852
  - 0.20131628080657207
  - 0.1963185648809817
  - 0.19985436893203884
  - 0.19294890654113955
  train_level10__tn_micro_masked:
  - 0.20400520156046814
  - 0.21677724165661438
  - 0.2112646177507889
  - 0.21531300664191202
  - 0.20787110406761755
  train_level10__tn_micro_oob:
  - 0.1865913152683186
  - 0.19888909634055266
  - 0.19348479621507073
  - 0.19638349514563108
  - 0.19037461998627048
  train_level10__tn_samples:
  - 0.18944114379558516
  - 0.20131628080657205
  - 0.19631856488098168
  - 0.19985436893203878
  - 0.19294890654113953
  train_level10__tn_samples_masked:
  - 0.20431009101074232
  - 0.2170458641085899
  - 0.2116120519780972
  - 0.21549360337296306
  - 0.2081165938935755
  train_level10__tn_samples_oob:
  - 0.1865913152683186
  - 0.1988890963405526
  - 0.19348479621507067
  - 0.19638349514563103
  - 0.19037461998627042
  train_level10__tn_weighted:
  - 0.20578605679612275
  - 0.21302369077306738
  - 0.1962712908767568
  - 0.21283717697930613
  - 0.20391038477477566
  train_level10__tn_weighted_masked:
  - 0.22896679636044276
  - 0.23649277318307843
  - 0.217806026102469
  - 0.23676706784093737
  - 0.2266843066443503
  train_level10__tn_weighted_oob:
  - 0.20227544448301132
  - 0.20990168808747364
  - 0.19244476026451185
  - 0.20867986204056418
  - 0.2011586793923155
  train_level10__tp_macro:
  - 0.2022412210790707
  - 0.2042102315160568
  - 0.20277462914592675
  - 0.20002427184466018
  - 0.20422673335294686
  train_level10__tp_macro_masked:
  - 0.1517910308575961
  - 0.15451717712514018
  - 0.15321759075971952
  - 0.149457557462314
  - 0.15417503278850583
  train_level10__tp_macro_oob:
  - 0.20161329275950352
  - 0.2034400672143391
  - 0.2023803656793652
  - 0.19978155339805825
  - 0.20376091007158964
  train_level10__tp_micro:
  - 0.20224122107907067
  - 0.20421023151605674
  - 0.20277462914592675
  - 0.2000242718446602
  - 0.20422673335294694
  train_level10__tp_micro_masked:
  - 0.14631989596879064
  - 0.1486228387615601
  - 0.14762270955424148
  - 0.14405627320746822
  - 0.14836238774432117
  train_level10__tp_micro_oob:
  - 0.20161329275950346
  - 0.20344006721433905
  - 0.20238036567936524
  - 0.19978155339805825
  - 0.2037609100715897
  train_level10__tp_samples:
  - 0.20224122107907064
  - 0.20421023151605672
  - 0.2027746291459267
  - 0.20002427184466015
  - 0.2042267333529469
  train_level10__tp_samples_masked:
  - 0.14662405402544942
  - 0.1489333096576894
  - 0.14790118097364244
  - 0.14432267046442668
  - 0.148705852289045
  train_level10__tp_samples_oob:
  - 0.2016132927595034
  - 0.20344006721433902
  - 0.20238036567936518
  - 0.1997815533980582
  - 0.20376091007158964
  train_level10__tp_weighted:
  - 0.28968670857598317
  - 0.29641257433339724
  - 0.2923648520321835
  - 0.2862943992587254
  - 0.2937441541418992
  train_level10__tp_weighted_masked:
  - 0.2248656577464931
  - 0.2333987532008595
  - 0.2284874747302204
  - 0.22094716073396864
  - 0.23144007849511955
  train_level10__tp_weighted_oob:
  - 0.28911849023615777
  - 0.2949283042394015
  - 0.29221269726164584
  - 0.2861399670544631
  - 0.29327701274146617
  train_level1__average_precision_macro:
  - 0.3660548067930042
  - 0.3718813928780795
  - 0.36521731005710245
  - 0.3624719190555441
  - 0.3709067439123834
  train_level1__average_precision_macro_masked:
  - 0.28832214849830806
  - 0.2916010003360321
  - 0.28386252094422
  - 0.27920615586444353
  - 0.2898399143289035
  train_level1__average_precision_macro_oob:
  - 0.3483989351625443
  - 0.35145614443019185
  - 0.34324193551772425
  - 0.3422102683968566
  - 0.3516869902913137
  train_level1__average_precision_micro:
  - 0.23275662832108834
  - 0.2303692791675979
  - 0.24155442925289347
  - 0.23085803004031408
  - 0.24359870936455794
  train_level1__average_precision_micro_masked:
  - 0.16762900612784817
  - 0.1665021431199045
  - 0.17484421334220496
  - 0.16642486177858298
  - 0.17552579117544753
  train_level1__average_precision_micro_oob:
  - 0.2242255283697965
  - 0.22067506302730727
  - 0.23059487657385377
  - 0.22188232531743263
  - 0.23322192104289394
  train_level1__average_precision_samples:
  - 0.25553799511799485
  - 0.25477985899253197
  - 0.26803917423779183
  - 0.2544311568471851
  - 0.26513675852276064
  train_level1__average_precision_samples_masked:
  - 0.1940493390433947
  - 0.19414938656527553
  - 0.2045435854092609
  - 0.19308134607129732
  - 0.2018316827022264
  train_level1__average_precision_samples_oob:
  - 0.24680901489634627
  - 0.24443809732563834
  - 0.2576625027731515
  - 0.24590674145228777
  - 0.25445492668448094
  train_level1__average_precision_weighted:
  - 0.4939511005449283
  - 0.499678374376346
  - 0.4918748020381204
  - 0.4838251407179521
  - 0.4955967913973813
  train_level1__average_precision_weighted_masked:
  - 0.4033161260786387
  - 0.4068113102273901
  - 0.39787213322668996
  - 0.3904529090912641
  - 0.40163826718428247
  train_level1__average_precision_weighted_oob:
  - 0.47320020336313284
  - 0.47583938043746576
  - 0.46779507691229677
  - 0.46074664964969775
  - 0.4725628073892285
  train_level1__f1_macro:
  - 0.3688595855673091
  - 0.36750840179238253
  - 0.3643240845695136
  - 0.36718446601941757
  - 0.3591252329116407
  train_level1__f1_macro_masked:
  - 0.33173011619774917
  - 0.3323097549033678
  - 0.3271749246855517
  - 0.3306625589194474
  - 0.3219808155679298
  train_level1__f1_macro_oob:
  - 0.3531855286673429
  - 0.3503080657206871
  - 0.3441920063082154
  - 0.3509223300970874
  - 0.3399284103167599
  train_level1__f1_micro:
  - 0.3688595855673091
  - 0.36750840179238237
  - 0.3643240845695136
  - 0.36718446601941745
  - 0.35912523291164067
  train_level1__f1_micro_masked:
  - 0.3240312093628088
  - 0.3244622034579815
  - 0.3207021823871019
  - 0.32338789812248314
  - 0.31473851030110933
  train_level1__f1_micro_oob:
  - 0.3531855286673429
  - 0.35030806572068707
  - 0.34419200630821545
  - 0.3509223300970874
  - 0.33992841031675985
  train_level1__f1_samples:
  - 0.368859585567309
  - 0.36750840179238237
  - 0.36432408456951354
  - 0.36718446601941745
  - 0.3591252329116406
  train_level1__f1_samples_masked:
  - 0.32458114048580217
  - 0.3249150492611578
  - 0.3210882655479642
  - 0.3237294068982739
  - 0.3152352005441304
  train_level1__f1_samples_oob:
  - 0.3531855286673429
  - 0.350308065720687
  - 0.34419200630821545
  - 0.35092233009708734
  - 0.3399284103167598
  train_level1__f1_weighted:
  - 0.48037795518531384
  - 0.47983071168233266
  - 0.4613874896405262
  - 0.4717584680325337
  - 0.4623995988700028
  train_level1__f1_weighted_masked:
  - 0.4344687473358015
  - 0.4373927528008019
  - 0.41437579462817964
  - 0.42663232245670113
  - 0.4180984395021622
  train_level1__f1_weighted_oob:
  - 0.4628377492383046
  - 0.4589545367350854
  - 0.4404934562657551
  - 0.4539514053330587
  - 0.442486246745564
  train_level1__fn_macro:
  - -0.023281650002415107
  - -0.029873039581777446
  - -0.026119954659701343
  - -0.03038834951456311
  - -0.026429341963322552
  train_level1__fn_macro_masked:
  - -0.02239900835972217
  - -0.027798159041288344
  - -0.02503687380748207
  - -0.029211136014593204
  - -0.024598805717800775
  train_level1__fn_macro_oob:
  - -0.023692218519055213
  - -0.032020164301717696
  - -0.02713025479276526
  - -0.03320388349514563
  - -0.02723840345199569
  train_level1__fn_micro:
  - -0.023281650002415107
  - -0.029873039581777446
  - -0.026119954659701346
  - -0.030388349514563106
  - -0.026429341963322545
  train_level1__fn_micro_masked:
  - -0.021378413524057217
  - -0.026638520305589063
  - -0.023335366338734058
  - -0.02758746927461953
  - -0.02329635499207607
  train_level1__fn_micro_oob:
  - -0.02369221851905521
  - -0.0320201643017177
  - -0.027130254792765266
  - -0.03320388349514563
  - -0.027238403451995685
  train_level1__fn_samples:
  - -0.023281650002415107
  - -0.029873039581777443
  - -0.026119954659701343
  - -0.030388349514563102
  - -0.026429341963322545
  train_level1__fn_samples_masked:
  - -0.02130720549398948
  - -0.026576437898634557
  - -0.023315394863206128
  - -0.027442179952541727
  - -0.023192441153616936
  train_level1__fn_samples_oob:
  - -0.023692218519055206
  - -0.032020164301717696
  - -0.027130254792765263
  - -0.03320388349514562
  - -0.027238403451995682
  train_level1__fn_weighted:
  - -0.03580521166775939
  - -0.045214847496643014
  - -0.04713344728754446
  - -0.05027643364562958
  - -0.04375285372779892
  train_level1__fn_weighted_masked:
  - -0.036024817206256624
  - -0.04326588636904483
  - -0.04798761071198018
  - -0.05061475754929802
  - -0.04186442949566949
  train_level1__fn_weighted_oob:
  - -0.03438080913263142
  - -0.04726093420295415
  - -0.045807218826616945
  - -0.05239961906722949
  - -0.04388308389247945
  train_level1__fp_macro:
  - -0.6078587644302759
  - -0.6026185586258401
  - -0.6095559607707851
  - -0.6024271844660193
  - -0.6144454251250366
  train_level1__fp_macro_masked:
  - -0.6458708754425284
  - -0.6398920860553438
  - -0.6477882015069663
  - -0.6401263050659594
  - -0.6534203787142694
  train_level1__fp_macro_oob:
  - -0.623122252813602
  - -0.6176717699775952
  - -0.6286777388990192
  - -0.6158737864077669
  - -0.6328331862312445
  train_level1__fp_micro:
  - -0.6078587644302758
  - -0.6026185586258401
  - -0.6095559607707851
  - -0.6024271844660194
  - -0.6144454251250367
  train_level1__fp_micro_masked:
  - -0.654590377113134
  - -0.6488992762364294
  - -0.6559624512741641
  - -0.6490246326028973
  - -0.6619651347068146
  train_level1__fp_micro_oob:
  - -0.6231222528136019
  - -0.6176717699775952
  - -0.6286777388990192
  - -0.615873786407767
  - -0.6328331862312445
  train_level1__fp_samples:
  - -0.6078587644302759
  - -0.6026185586258401
  - -0.609555960770785
  - -0.6024271844660194
  - -0.6144454251250367
  train_level1__fp_samples_masked:
  - -0.6541116540202083
  - -0.6485085128402077
  - -0.6555963395888297
  - -0.6488284131491844
  - -0.6615723583022526
  train_level1__fp_samples_oob:
  - -0.6231222528136019
  - -0.6176717699775952
  - -0.6286777388990192
  - -0.615873786407767
  - -0.6328331862312445
  train_level1__fp_weighted:
  - -0.48381683314692686
  - -0.4749544408210244
  - -0.49147906307192923
  - -0.47796509832183676
  - -0.4938475474021981
  train_level1__fp_weighted_masked:
  - -0.529506435457942
  - -0.5193413608301531
  - -0.5376365946598403
  - -0.522752919994001
  - -0.5400371310021683
  train_level1__fp_weighted_oob:
  - -0.5027814416290639
  - -0.4937845290619604
  - -0.5136993249076279
  - -0.4936489755997117
  - -0.5136306693619566
  train_level1__jaccard_macro:
  - 0.24946697262757608
  - 0.25006690208643084
  - 0.2455727059522428
  - 0.2464512009410597
  - 0.23790714217010944
  train_level1__jaccard_macro_masked:
  - 0.2204175153064388
  - 0.22347302364977328
  - 0.2173921872368294
  - 0.21825158300005554
  - 0.20947908692674044
  train_level1__jaccard_macro_oob:
  - 0.23635063029669146
  - 0.2354911898414649
  - 0.2303650998618296
  - 0.23323800684293966
  - 0.22293579255932064
  train_level1__jaccard_micro:
  - 0.226136010305157
  - 0.22512115970206864
  - 0.2227361062986788
  - 0.22487810679034367
  - 0.21886206072196987
  train_level1__jaccard_micro_masked:
  - 0.193339644015456
  - 0.19364660357266059
  - 0.19097397675593733
  - 0.19288176302696633
  - 0.18675945081813053
  train_level1__jaccard_micro_oob:
  - 0.21446588842611602
  - 0.21234756528874177
  - 0.20786951604262158
  - 0.21279915221806836
  - 0.2047673199332457
  train_level1__jaccard_samples:
  - 0.22976686508168317
  - 0.2283406671205453
  - 0.22581113553206825
  - 0.22840870539321792
  - 0.2233303814654329
  train_level1__jaccard_samples_masked:
  - 0.19711463109747607
  - 0.19684891863023013
  - 0.19406517358462555
  - 0.19636557372791055
  - 0.19149098685320756
  train_level1__jaccard_samples_oob:
  - 0.21794695216292675
  - 0.2153666812449447
  - 0.2105263083231349
  - 0.21612882132566547
  - 0.20889008512614562
  train_level1__jaccard_weighted:
  - 0.3384769572145718
  - 0.3402202882907205
  - 0.32046282521525027
  - 0.32816099550504363
  - 0.3200856662182782
  train_level1__jaccard_weighted_masked:
  - 0.2979022418664132
  - 0.3036302189248766
  - 0.28023590777747814
  - 0.28867058050213423
  - 0.28195914114462783
  train_level1__jaccard_weighted_oob:
  - 0.32308434679736764
  - 0.32143026986008305
  - 0.30415646136544616
  - 0.313346768633752
  - 0.30351369612031376
  train_level1__label_ranking_average_precision_score:
  - 0.2555379951179945
  - 0.254779858992532
  - 0.2680391742377917
  - 0.25443115684718515
  - 0.2651367585227604
  train_level1__label_ranking_average_precision_score_oob:
  - 0.24680901489634616
  - 0.24443809732563843
  - 0.2576625027731515
  - 0.24590674145228777
  - 0.25445492668448083
  train_level1__matthews_corrcoef_macro:
  - 0.13523083220790008
  - 0.12555960682915424
  - 0.1318087812732684
  - 0.12071162176821254
  - 0.12294159845239522
  train_level1__matthews_corrcoef_macro_masked:
  - 0.10580183527138101
  - 0.09560651312022221
  - 0.1034335865041318
  - 0.08955057899858161
  - 0.0953082194703716
  train_level1__matthews_corrcoef_macro_oob:
  - 0.10933610733982024
  - 0.094732565947211
  - 0.09594134237776843
  - 0.08969753747512497
  - 0.09374693721955374
  train_level1__matthews_corrcoef_micro:
  - 0.1175864053334818
  - 0.09182105905700395
  - 0.10201475700784515
  - 0.08923651359693636
  - 0.09373883808479426
  train_level1__matthews_corrcoef_micro_masked:
  - 0.08142605207844096
  - 0.05789467295324067
  - 0.06879544609031246
  - 0.0527793944426075
  - 0.06297912473862617
  train_level1__matthews_corrcoef_micro_oob:
  - 0.09701183419501887
  - 0.06255748525130553
  - 0.07311753720040233
  - 0.05869000480026124
  - 0.06592260451221506
  train_level1__matthews_corrcoef_samples:
  - 0.1148604888951226
  - 0.08656560147830238
  - 0.09626369823991855
  - 0.08580915614584934
  - 0.08712964061004072
  train_level1__matthews_corrcoef_samples_masked:
  - 0.07911390699097155
  - 0.052820312248565995
  - 0.06338261987376441
  - 0.05140231176332244
  - 0.05808418916390238
  train_level1__matthews_corrcoef_samples_oob:
  - 0.09490451573067157
  - 0.057606620445931005
  - 0.06921758037022903
  - 0.055850054007178504
  - 0.05909339874099476
  train_level1__matthews_corrcoef_weighted:
  - 0.16950593387401555
  - 0.16080944288184493
  - 0.15966963907466072
  - 0.15036835388274147
  - 0.15083254917396394
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.1319985361289409
  - 0.12347776495123065
  - 0.1228758225938305
  - 0.1111712142953067
  - 0.11798203749763522
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.13584114105796666
  - 0.11317696150322183
  - 0.11331134494361743
  - 0.10874384707447719
  - 0.11593391474022662
  train_level1__ndcg:
  - 0.5928881339719778
  - 0.5942368886634978
  - 0.6043422865976289
  - 0.5950462422010433
  - 0.5987709778368738
  train_level1__ndcg_oob:
  - 0.586962594751057
  - 0.5872882348959265
  - 0.5976580879118962
  - 0.5896823224158149
  - 0.5913887554147861
  train_level1__neg_coverage_error:
  - -92.1592039800995
  - -94.46153846153847
  - -94.21065989847716
  - -93.4125
  - -95.16161616161617
  train_level1__neg_coverage_error_oob:
  - -93.45024875621891
  - -95.8173076923077
  - -95.32233502538071
  - -94.795
  - -96.17424242424242
  train_level1__neg_hamming_loss_macro:
  - -0.631140414432691
  - -0.6324915982076176
  - -0.6356759154304865
  - -0.6328155339805824
  - -0.6408747670883593
  train_level1__neg_hamming_loss_macro_masked:
  - -0.6682698838022507
  - -0.6676902450966322
  - -0.6728250753144482
  - -0.6693374410805528
  - -0.67801918443207
  train_level1__neg_hamming_loss_macro_oob:
  - -0.646814471332657
  - -0.6496919342793129
  - -0.6558079936917847
  - -0.6490776699029125
  - -0.6600715896832402
  train_level1__neg_hamming_loss_micro:
  - -0.6311404144326909
  - -0.6324915982076176
  - -0.6356759154304864
  - -0.6328155339805825
  - -0.6408747670883593
  train_level1__neg_hamming_loss_micro_masked:
  - -0.6759687906371912
  - -0.6755377965420185
  - -0.6792978176128981
  - -0.6766121018775169
  - -0.6852614896988907
  train_level1__neg_hamming_loss_micro_oob:
  - -0.6468144713326571
  - -0.6496919342793129
  - -0.6558079936917846
  - -0.6490776699029126
  - -0.6600715896832402
  train_level1__neg_hamming_loss_samples:
  - -0.6311404144326909
  - -0.6324915982076175
  - -0.6356759154304864
  - -0.6328155339805825
  - -0.6408747670883593
  train_level1__neg_hamming_loss_samples_masked:
  - -0.675418859514198
  - -0.6750849507388422
  - -0.6789117344520358
  - -0.676270593101726
  - -0.6847647994558695
  train_level1__neg_hamming_loss_samples_oob:
  - -0.646814471332657
  - -0.6496919342793128
  - -0.6558079936917846
  - -0.6490776699029126
  - -0.6600715896832401
  train_level1__neg_hamming_loss_weighted:
  - -0.5196220448146862
  - -0.5201692883176673
  - -0.5386125103594738
  - -0.5282415319674664
  - -0.5376004011299971
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.5655312526641986
  - -0.5626072471991981
  - -0.5856242053718204
  - -0.5733676775432989
  - -0.5819015604978378
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.5371622507616953
  - -0.5410454632649145
  - -0.559506543734245
  - -0.5460485946669413
  - -0.557513753254436
  train_level1__neg_label_ranking_loss:
  - -0.4730417901906662
  - -0.48569409362431415
  - -0.4571448618299287
  - -0.4865285540359979
  - -0.4626665850904894
  train_level1__neg_label_ranking_loss_oob:
  - -0.4941832324566069
  - -0.5100990445273972
  - -0.48109377948206944
  - -0.5080260567820973
  - -0.4875953462745859
  train_level1__precision_macro:
  - 0.3688595855673091
  - 0.36750840179238253
  - 0.3643240845695136
  - 0.36718446601941757
  - 0.3591252329116407
  train_level1__precision_macro_masked:
  - 0.33173011619774917
  - 0.3323097549033678
  - 0.3271749246855517
  - 0.3306625589194474
  - 0.3219808155679298
  train_level1__precision_macro_oob:
  - 0.3531855286673429
  - 0.3503080657206871
  - 0.3441920063082154
  - 0.3509223300970874
  - 0.3399284103167599
  train_level1__precision_micro:
  - 0.3688595855673091
  - 0.36750840179238237
  - 0.3643240845695136
  - 0.36718446601941745
  - 0.35912523291164067
  train_level1__precision_micro_masked:
  - 0.3240312093628088
  - 0.3244622034579815
  - 0.3207021823871019
  - 0.32338789812248314
  - 0.31473851030110933
  train_level1__precision_micro_oob:
  - 0.3531855286673429
  - 0.35030806572068707
  - 0.34419200630821545
  - 0.3509223300970874
  - 0.33992841031675985
  train_level1__precision_samples:
  - 0.368859585567309
  - 0.36750840179238237
  - 0.36432408456951354
  - 0.36718446601941745
  - 0.3591252329116406
  train_level1__precision_samples_masked:
  - 0.32458114048580217
  - 0.3249150492611578
  - 0.3210882655479642
  - 0.3237294068982739
  - 0.3152352005441304
  train_level1__precision_samples_oob:
  - 0.3531855286673429
  - 0.350308065720687
  - 0.34419200630821545
  - 0.35092233009708734
  - 0.3399284103167598
  train_level1__precision_weighted:
  - 0.48037795518531384
  - 0.47983071168233266
  - 0.4613874896405262
  - 0.4717584680325337
  - 0.4623995988700028
  train_level1__precision_weighted_masked:
  - 0.4344687473358015
  - 0.4373927528008019
  - 0.41437579462817964
  - 0.42663232245670113
  - 0.4180984395021622
  train_level1__precision_weighted_oob:
  - 0.4628377492383046
  - 0.4589545367350854
  - 0.4404934562657551
  - 0.4539514053330587
  - 0.442486246745564
  train_level1__recall_macro:
  - 0.3688595855673091
  - 0.36750840179238253
  - 0.3643240845695136
  - 0.36718446601941757
  - 0.3591252329116407
  train_level1__recall_macro_masked:
  - 0.33173011619774917
  - 0.3323097549033678
  - 0.3271749246855517
  - 0.3306625589194474
  - 0.3219808155679298
  train_level1__recall_macro_oob:
  - 0.3531855286673429
  - 0.3503080657206871
  - 0.3441920063082154
  - 0.3509223300970874
  - 0.3399284103167599
  train_level1__recall_micro:
  - 0.3688595855673091
  - 0.36750840179238237
  - 0.3643240845695136
  - 0.36718446601941745
  - 0.35912523291164067
  train_level1__recall_micro_masked:
  - 0.3240312093628088
  - 0.3244622034579815
  - 0.3207021823871019
  - 0.32338789812248314
  - 0.31473851030110933
  train_level1__recall_micro_oob:
  - 0.3531855286673429
  - 0.35030806572068707
  - 0.34419200630821545
  - 0.3509223300970874
  - 0.33992841031675985
  train_level1__recall_samples:
  - 0.368859585567309
  - 0.36750840179238237
  - 0.36432408456951354
  - 0.36718446601941745
  - 0.3591252329116406
  train_level1__recall_samples_masked:
  - 0.32458114048580217
  - 0.3249150492611578
  - 0.3210882655479642
  - 0.3237294068982739
  - 0.3152352005441304
  train_level1__recall_samples_oob:
  - 0.3531855286673429
  - 0.350308065720687
  - 0.34419200630821545
  - 0.35092233009708734
  - 0.3399284103167598
  train_level1__recall_weighted:
  - 0.48037795518531384
  - 0.47983071168233266
  - 0.4613874896405262
  - 0.4717584680325337
  - 0.4623995988700028
  train_level1__recall_weighted_masked:
  - 0.4344687473358015
  - 0.4373927528008019
  - 0.41437579462817964
  - 0.42663232245670113
  - 0.4180984395021622
  train_level1__recall_weighted_oob:
  - 0.4628377492383046
  - 0.4589545367350854
  - 0.4404934562657551
  - 0.4539514053330587
  - 0.442486246745564
  train_level1__roc_auc_macro:
  - 0.662887435040876
  - 0.6771270038975208
  - 0.6756477627926096
  - 0.6563015294888125
  - 0.6686781929668904
  train_level1__roc_auc_macro_masked:
  - 0.6315862578399499
  - 0.647694361159692
  - 0.6468810484903338
  - 0.6260871339466308
  - 0.6399989155442658
  train_level1__roc_auc_macro_oob:
  - 0.6388215129517589
  - 0.6506349037423177
  - 0.6450045447298732
  - 0.6286234352051014
  - 0.6413769486634497
  train_level1__roc_auc_micro:
  - 0.5381053163556665
  - 0.5254971929467074
  - 0.5528387930603691
  - 0.5227215024256144
  - 0.5493422716673804
  train_level1__roc_auc_micro_masked:
  - 0.5180636367754125
  - 0.506892792973817
  - 0.5339157718215951
  - 0.502161361013793
  - 0.5291565718706479
  train_level1__roc_auc_micro_oob:
  - 0.5164706316347767
  - 0.5007272818167845
  - 0.5270795377078142
  - 0.4991021054216309
  - 0.5257768320442309
  train_level1__roc_auc_samples:
  - 0.5269582098093338
  - 0.514313372040452
  - 0.5428551381700714
  - 0.5134808780371529
  - 0.5373340624101581
  train_level1__roc_auc_samples_masked:
  - 0.507972793954232
  - 0.49648914027274793
  - 0.5246650710605572
  - 0.4954932883038281
  - 0.518550033514756
  train_level1__roc_auc_samples_oob:
  - 0.5058174053798518
  - 0.489913201500055
  - 0.5189062205179306
  - 0.4919896796144506
  - 0.5124053012260616
  train_level1__roc_auc_weighted:
  - 0.6688782120051168
  - 0.6808478579736084
  - 0.6727400093678692
  - 0.654261090891807
  - 0.6705731868060996
  train_level1__roc_auc_weighted_masked:
  - 0.6379392298164243
  - 0.65022886564196
  - 0.6411920679114047
  - 0.6211477915169198
  - 0.6404692957177213
  train_level1__roc_auc_weighted_oob:
  - 0.6418754743165903
  - 0.6500547676843803
  - 0.6401356066472129
  - 0.6244784407875946
  - 0.6405416964015404
  train_level1__tn_macro:
  - 0.15847944742307876
  - 0.16341486183719195
  - 0.15861712089103538
  - 0.16182038834951457
  - 0.1507060900264784
  train_level1__tn_macro_masked:
  - 0.17196146603188256
  - 0.1775437596457413
  - 0.1711942900372623
  - 0.17559673849438723
  - 0.16342964545354136
  train_level1__tn_macro_oob:
  - 0.1432159590397527
  - 0.1483616504854369
  - 0.13949534276280123
  - 0.148373786407767
  - 0.13231832892027068
  train_level1__tn_micro:
  - 0.1584794474230788
  - 0.16341486183719192
  - 0.15861712089103544
  - 0.16182038834951457
  - 0.1507060900264784
  train_level1__tn_micro_masked:
  - 0.1706631989596879
  - 0.17596501809408926
  - 0.17069290127548992
  - 0.17433711625960985
  - 0.16236133122028526
  train_level1__tn_micro_oob:
  - 0.1432159590397527
  - 0.1483616504854369
  - 0.13949534276280123
  - 0.148373786407767
  - 0.13231832892027068
  train_level1__tn_samples:
  - 0.15847944742307876
  - 0.1634148618371919
  - 0.15861712089103538
  - 0.1618203883495145
  - 0.15070609002647836
  train_level1__tn_samples_masked:
  - 0.17092966413326077
  - 0.17613166491383675
  - 0.17080591340855092
  - 0.17443939780024742
  - 0.16253719132808306
  train_level1__tn_samples_oob:
  - 0.14321595903975268
  - 0.14836165048543687
  - 0.1394953427628012
  - 0.14837378640776694
  - 0.13231832892027065
  train_level1__tn_weighted:
  - 0.1708691683700361
  - 0.17917537886054097
  - 0.16049549578714736
  - 0.172765108617317
  - 0.1597383691808997
  train_level1__tn_weighted_masked:
  - 0.1891918819013804
  - 0.19876149749205654
  - 0.17810599674947522
  - 0.1919520480148436
  - 0.17747674759103033
  train_level1__tn_weighted_oob:
  - 0.151904559887899
  - 0.16034529061960487
  - 0.13827523395144858
  - 0.157081231339442
  - 0.13995524722114133
  train_level1__tp_macro:
  - 0.21038013814423034
  - 0.20409353995519045
  - 0.20570696367847816
  - 0.2053640776699029
  - 0.20841914288516225
  train_level1__tp_macro_masked:
  - 0.15976865016586672
  - 0.15476599525762652
  - 0.15598063464828935
  - 0.15506582042506017
  - 0.15855117011438855
  train_level1__tp_macro_oob:
  - 0.20996956962759025
  - 0.2019464152352502
  - 0.2046966635454142
  - 0.20254854368932035
  - 0.2076100813964891
  train_level1__tp_micro:
  - 0.21038013814423032
  - 0.20409353995519045
  - 0.20570696367847816
  - 0.20536407766990292
  - 0.2084191428851623
  train_level1__tp_micro_masked:
  - 0.15336801040312092
  - 0.14849718536389225
  - 0.150009281111612
  - 0.1490507818628733
  - 0.1523771790808241
  train_level1__tp_micro_oob:
  - 0.2099695696275902
  - 0.2019464152352502
  - 0.20469666354541421
  - 0.20254854368932038
  - 0.20761008139648918
  train_level1__tp_samples:
  - 0.21038013814423026
  - 0.2040935399551904
  - 0.20570696367847813
  - 0.20536407766990286
  - 0.20841914288516222
  train_level1__tp_samples_masked:
  - 0.15365147635254134
  - 0.1487833843473211
  - 0.15028235213941332
  - 0.14929000909802642
  - 0.15269800921604737
  train_level1__tp_samples_oob:
  - 0.20996956962759014
  - 0.20194641523525014
  - 0.2046966635454142
  - 0.20254854368932032
  - 0.2076100813964891
  train_level1__tp_weighted:
  - 0.30950878681527766
  - 0.3006553328217917
  - 0.30089199385337895
  - 0.29899335941521676
  - 0.30266122968910314
  train_level1__tp_weighted_masked:
  - 0.24527686543442112
  - 0.23863125530874527
  - 0.23626979787870442
  - 0.23468027444185738
  - 0.24062169191113209
  train_level1__tp_weighted_oob:
  - 0.31093318935040565
  - 0.2986092461154805
  - 0.3022182223143065
  - 0.2968701739936168
  - 0.3025309995244226
  train_level2__average_precision_macro:
  - 0.3462825890087236
  - 0.3594945223117573
  - 0.3561620213461995
  - 0.34226613398698524
  - 0.3539999987572878
  train_level2__average_precision_macro_masked:
  - 0.27009484405458123
  - 0.28195369972708567
  - 0.2791208542867197
  - 0.2677782197050325
  - 0.2779988884356376
  train_level2__average_precision_macro_oob:
  - 0.33858520926928687
  - 0.3526215114889626
  - 0.3476804040332626
  - 0.3361917680942336
  - 0.34637036881861466
  train_level2__average_precision_micro:
  - 0.23813499387244852
  - 0.23939001177418873
  - 0.2510926317492739
  - 0.2356374266574559
  - 0.24613882131712983
  train_level2__average_precision_micro_masked:
  - 0.17243183070054985
  - 0.173585637105547
  - 0.18270066747498093
  - 0.1709466789990911
  - 0.17870376161627313
  train_level2__average_precision_micro_oob:
  - 0.2363425691481515
  - 0.2376441807668097
  - 0.24832183068870212
  - 0.2338523471212642
  - 0.24369922398133254
  train_level2__average_precision_samples:
  - 0.2544060498946424
  - 0.2563718016527289
  - 0.2689040289574007
  - 0.2527328750570604
  - 0.2645766666415287
  train_level2__average_precision_samples_masked:
  - 0.19205333748547726
  - 0.19433936737270668
  - 0.20451892227414284
  - 0.19071545010488197
  - 0.20065750859352358
  train_level2__average_precision_samples_oob:
  - 0.2525435044970621
  - 0.25471884721452737
  - 0.26629388284591987
  - 0.2511101599730691
  - 0.2625201821567527
  train_level2__average_precision_weighted:
  - 0.48242147391147316
  - 0.4910985735476514
  - 0.4859823758248068
  - 0.4714861822209637
  - 0.486635490382825
  train_level2__average_precision_weighted_masked:
  - 0.39249526009394564
  - 0.40223863991263975
  - 0.39719227502961696
  - 0.38379639206179683
  - 0.3990843537099109
  train_level2__average_precision_weighted_oob:
  - 0.4728018974314542
  - 0.4821564168013156
  - 0.47651040470816625
  - 0.4647432783487813
  - 0.47699409886417116
  train_level2__f1_macro:
  - 0.38190117374293575
  - 0.39073002240477983
  - 0.38647676309693946
  - 0.3860679611650485
  - 0.3840345199568501
  train_level2__f1_macro_masked:
  - 0.34667198229313695
  - 0.3564314265359153
  - 0.35133699045378497
  - 0.3516258241323286
  - 0.34919505875528073
  train_level2__f1_macro_oob:
  - 0.3767569917403275
  - 0.3837985436893205
  - 0.3779508156325465
  - 0.37932038834951465
  - 0.3771697558105326
  train_level2__f1_micro:
  - 0.3819011737429358
  - 0.39073002240477966
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995685006
  train_level2__f1_micro_masked:
  - 0.33919375812743824
  - 0.3489646160032167
  - 0.3450982471957784
  - 0.34459494796297263
  - 0.34199683042789225
  train_level2__f1_micro_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254646
  - 0.37932038834951454
  - 0.3771697558105325
  train_level2__f1_samples:
  - 0.38190117374293575
  - 0.3907300224047796
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995684995
  train_level2__f1_samples_masked:
  - 0.3397872943161679
  - 0.3495817753883624
  - 0.3456950169834291
  - 0.3450032210841937
  - 0.34252452766465813
  train_level2__f1_samples_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254634
  - 0.37932038834951454
  - 0.37716975581053247
  train_level2__f1_weighted:
  - 0.4894702199596335
  - 0.49780572606944185
  - 0.4785774715977762
  - 0.48702409142386494
  - 0.4858731906179447
  train_level2__f1_weighted_masked:
  - 0.4465516891682485
  - 0.4563842023799143
  - 0.43518056356333307
  - 0.4444524571835643
  - 0.44468850542394145
  train_level2__f1_weighted_oob:
  - 0.48461516705876306
  - 0.49009279685401874
  - 0.46929710970682703
  - 0.47901266344074955
  - 0.4773810766607509
  train_level2__fn_macro:
  - -0.027846205863884463
  - -0.02854275578790142
  - -0.027524518259326794
  - -0.03485436893203883
  - -0.029248798666274393
  train_level2__fn_macro_masked:
  - -0.026735561821759186
  - -0.027106890576283262
  - -0.0262270738702547
  - -0.033597882945207096
  - -0.02743439037222446
  train_level2__fn_macro_oob:
  - -0.02859488962952229
  - -0.028892830470500376
  - -0.028608742792371
  - -0.03616504854368932
  - -0.03042561537707169
  train_level2__fn_micro:
  - -0.027846205863884463
  - -0.028542755787901417
  - -0.027524518259326794
  - -0.03485436893203883
  - -0.029248798666274393
  train_level2__fn_micro_masked:
  - -0.02517555266579974
  - -0.025708685162846804
  - -0.024289994961682267
  - -0.03153600753098687
  - -0.025911251980982566
  train_level2__fn_micro_oob:
  - -0.02859488962952229
  - -0.028892830470500373
  - -0.028608742792371
  - -0.03616504854368932
  - -0.03042561537707169
  train_level2__fn_samples:
  - -0.027846205863884456
  - -0.028542755787901417
  - -0.02752451825932679
  - -0.03485436893203883
  - -0.029248798666274393
  train_level2__fn_samples_masked:
  - -0.02508928669437036
  - -0.025625683987301414
  - -0.02425548919531839
  - -0.03138632994046965
  - -0.02579659331856455
  train_level2__fn_samples_oob:
  - -0.028594889629522287
  - -0.028892830470500373
  - -0.028608742792370998
  - -0.036165048543689314
  - -0.030425615377071683
  train_level2__fn_weighted:
  - -0.04738452440639181
  - -0.04637612699021676
  - -0.05255652387858697
  - -0.06005559559353442
  - -0.049290535588687796
  train_level2__fn_weighted_masked:
  - -0.04759725632986303
  - -0.04574065815836916
  - -0.052306154105221
  - -0.06080521838184636
  - -0.047639232774652145
  train_level2__fn_weighted_oob:
  - -0.04760486970830601
  - -0.0464003452906196
  - -0.05325821635760904
  - -0.061485380417996484
  - -0.0509099766851098
  train_level2__fp_macro:
  - -0.5902526203931798
  - -0.5807272218073188
  - -0.5859987186437337
  - -0.5790776699029125
  - -0.5867166813768755
  train_level2__fp_macro_masked:
  - -0.6265924558851039
  - -0.6164616828878015
  - -0.6224359356759605
  - -0.6147762929224643
  - -0.6233705508724948
  train_level2__fp_macro_oob:
  - -0.5946481186301502
  - -0.5873086258401793
  - -0.5934404415750826
  - -0.5845145631067961
  - -0.5924046288123958
  train_level2__fp_micro:
  - -0.5902526203931797
  - -0.580727221807319
  - -0.5859987186437337
  - -0.5790776699029127
  - -0.5867166813768756
  train_level2__fp_micro_masked:
  - -0.635630689206762
  - -0.6253266988339364
  - -0.6306117578425393
  - -0.6238690445060405
  - -0.6320919175911252
  train_level2__fp_micro_oob:
  - -0.5946481186301502
  - -0.5873086258401793
  - -0.5934404415750826
  - -0.5845145631067962
  - -0.5924046288123958
  train_level2__fp_samples:
  - -0.5902526203931797
  - -0.5807272218073188
  - -0.5859987186437337
  - -0.5790776699029125
  - -0.5867166813768755
  train_level2__fp_samples_masked:
  - -0.6351234189894618
  - -0.6247925406243362
  - -0.6300494938212525
  - -0.6236104489753366
  - -0.6316788790167772
  train_level2__fp_samples_oob:
  - -0.5946481186301501
  - -0.5873086258401792
  - -0.5934404415750825
  - -0.5845145631067962
  - -0.5924046288123958
  train_level2__fp_weighted:
  - -0.46314525563397474
  - -0.45581814694034145
  - -0.4688660045236368
  - -0.45292031298260066
  - -0.4648362737933674
  train_level2__fp_weighted_masked:
  - -0.5058510545018885
  - -0.4978751394617167
  - -0.5125132823314459
  - -0.4947423244345893
  - -0.5076722618014065
  train_level2__fp_weighted_oob:
  - -0.4677799632329309
  - -0.46350685785536166
  - -0.477444673935564
  - -0.4595019561412539
  - -0.47170894665413926
  train_level2__jaccard_macro:
  - 0.25632791080909956
  - 0.2633444914266044
  - 0.2559174268164444
  - 0.2570793716303948
  - 0.255734757600713
  train_level2__jaccard_macro_masked:
  - 0.22795753762159254
  - 0.23560632604967882
  - 0.2279406071299252
  - 0.22934317143491884
  - 0.22793012234152893
  train_level2__jaccard_macro_oob:
  - 0.25244722348363957
  - 0.2577422928813867
  - 0.24901889909044383
  - 0.25141592650967054
  - 0.2498418800041534
  train_level2__jaccard_micro:
  - 0.23601844803653785
  - 0.24279954752443658
  - 0.23952351863164326
  - 0.23920955274160074
  - 0.2376502002670227
  train_level2__jaccard_micro_masked:
  - 0.20423439506404836
  - 0.21136107644068314
  - 0.20853095756954237
  - 0.2081635232047515
  - 0.20627031160389983
  train_level2__jaccard_micro_oob:
  - 0.23210141046241742
  - 0.2374694950253426
  - 0.23300823382857838
  - 0.23405020068292098
  - 0.2324147933284989
  train_level2__jaccard_samples:
  - 0.24011513029608159
  - 0.24722281473440066
  - 0.24464889195213071
  - 0.2439065455340557
  - 0.24290917005250534
  train_level2__jaccard_samples_masked:
  - 0.20852163057413212
  - 0.2158432085311811
  - 0.21393212439529496
  - 0.21291238080441743
  - 0.21186359945407193
  train_level2__jaccard_samples_oob:
  - 0.23613092313561765
  - 0.24190753269858478
  - 0.2381258698823365
  - 0.23868152849497704
  - 0.23761639943204743
  train_level2__jaccard_weighted:
  - 0.34204340174052117
  - 0.35047436611494215
  - 0.32903989896604696
  - 0.3369128308976377
  - 0.33790276974309585
  train_level2__jaccard_weighted_masked:
  - 0.30326178889001565
  - 0.3127118191876297
  - 0.29096791243544773
  - 0.2986626891394111
  - 0.3012229590205787
  train_level2__jaccard_weighted_oob:
  - 0.33848261814321723
  - 0.34378725604827703
  - 0.32082198524476996
  - 0.3296206927460153
  - 0.33002470438986237
  train_level2__label_ranking_average_precision_score:
  - 0.25440604989464266
  - 0.25637180165272855
  - 0.2689040289574008
  - 0.2527328750570604
  - 0.26457666664152835
  train_level2__label_ranking_average_precision_score_oob:
  - 0.25254350449706203
  - 0.25471884721452737
  - 0.2662938828459196
  - 0.2511101599730692
  - 0.2625201821567528
  train_level2__matthews_corrcoef_macro:
  - 0.1463255084475845
  - 0.15207230921027362
  - 0.15136332459301313
  - 0.136676391462027
  - 0.14272841135352085
  train_level2__matthews_corrcoef_macro_masked:
  - 0.11526670032461889
  - 0.12019122226564202
  - 0.12155312444250556
  - 0.10284193716485204
  - 0.11246565321371824
  train_level2__matthews_corrcoef_macro_oob:
  - 0.13669416276106028
  - 0.14088305916654045
  - 0.1365645572032439
  - 0.12239982328122727
  - 0.13031677326623434
  train_level2__matthews_corrcoef_micro:
  - 0.11615826918485025
  - 0.12380674039300288
  - 0.12276000451365435
  - 0.0967741040421058
  - 0.11354855582969932
  train_level2__matthews_corrcoef_micro_masked:
  - 0.07925089293834334
  - 0.08653601401513564
  - 0.08861693163886528
  - 0.05768608751836316
  - 0.0789722256943432
  train_level2__matthews_corrcoef_micro_oob:
  - 0.10749104698228369
  - 0.11462665121553338
  - 0.10910497135394179
  - 0.08436231437289893
  - 0.10136572665206531
  train_level2__matthews_corrcoef_samples:
  - 0.11217269259751507
  - 0.11770628960980395
  - 0.11670244969675715
  - 0.09457710574182211
  - 0.10892137406235039
  train_level2__matthews_corrcoef_samples_masked:
  - 0.07554355528480372
  - 0.08029910221840729
  - 0.08201709967600605
  - 0.0572279353723715
  - 0.07605714179320192
  train_level2__matthews_corrcoef_samples_oob:
  - 0.10406032242782234
  - 0.10912519183903721
  - 0.10421310224473933
  - 0.08209963817328308
  - 0.09686129518013643
  train_level2__matthews_corrcoef_weighted:
  - 0.18172529532293055
  - 0.19033301132987948
  - 0.1768184624580836
  - 0.16924931822075923
  - 0.1763067486795554
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.14269379098451068
  - 0.1522215310091905
  - 0.14114587532557374
  - 0.1271700032945425
  - 0.1405062220915056
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.16977955951151408
  - 0.17481659798235127
  - 0.1556576587991027
  - 0.15069326233604768
  - 0.15928135227466844
  train_level2__ndcg:
  - 0.6010170183277392
  - 0.5990844823584427
  - 0.6071567180571037
  - 0.5985678466037
  - 0.6094009026837465
  train_level2__ndcg_oob:
  - 0.6010845432522856
  - 0.5992492492556294
  - 0.6060728819460348
  - 0.5983329643752449
  - 0.6085662197106212
  train_level2__neg_coverage_error:
  - -91.7860696517413
  - -92.0360576923077
  - -93.72842639593908
  - -92.17
  - -92.13383838383838
  train_level2__neg_coverage_error_oob:
  - -92.28109452736318
  - -92.49278846153847
  - -93.99238578680203
  - -92.595
  - -92.66919191919192
  train_level2__neg_hamming_loss_macro:
  - -0.6180988262570642
  - -0.6092699775952202
  - -0.6135232369030605
  - -0.6139320388349514
  - -0.6159654800431499
  train_level2__neg_hamming_loss_macro_masked:
  - -0.6533280177068629
  - -0.6435685734640847
  - -0.6486630095462151
  - -0.6483741758676713
  - -0.6508049412447191
  train_level2__neg_hamming_loss_macro_oob:
  - -0.6232430082596726
  - -0.6162014563106796
  - -0.6220491843674536
  - -0.6206796116504852
  - -0.6228302441894674
  train_level2__neg_hamming_loss_micro:
  - -0.6180988262570642
  - -0.6092699775952203
  - -0.6135232369030604
  - -0.6139320388349515
  - -0.61596548004315
  train_level2__neg_hamming_loss_micro_masked:
  - -0.6608062418725618
  - -0.6510353839967833
  - -0.6549017528042216
  - -0.6554050520370274
  - -0.6580031695721078
  train_level2__neg_hamming_loss_micro_oob:
  - -0.6232430082596725
  - -0.6162014563106796
  - -0.6220491843674536
  - -0.6206796116504855
  - -0.6228302441894675
  train_level2__neg_hamming_loss_samples:
  - -0.6180988262570641
  - -0.6092699775952203
  - -0.6135232369030604
  - -0.6139320388349515
  - -0.61596548004315
  train_level2__neg_hamming_loss_samples_masked:
  - -0.6602127056838321
  - -0.6504182246116377
  - -0.6543049830165709
  - -0.6549967789158063
  - -0.657475472335342
  train_level2__neg_hamming_loss_samples_oob:
  - -0.6232430082596725
  - -0.6162014563106796
  - -0.6220491843674536
  - -0.6206796116504854
  - -0.6228302441894674
  train_level2__neg_hamming_loss_weighted:
  - -0.5105297800403664
  - -0.5021942739305582
  - -0.5214225284022238
  - -0.5129759085761351
  - -0.5141268093820552
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.5534483108317515
  - -0.5436157976200858
  - -0.5648194364366669
  - -0.5555475428164357
  - -0.5553114945760586
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.5153848329412369
  - -0.509907203145981
  - -0.5307028902931732
  - -0.5209873365592504
  - -0.5226189233392491
  train_level2__neg_label_ranking_loss:
  - -0.4721986901904512
  - -0.4671760093779425
  - -0.44447916465207815
  - -0.48227689198999907
  - -0.46114885129792366
  train_level2__neg_label_ranking_loss_oob:
  - -0.47922165602623334
  - -0.47414730397043664
  - -0.4525790488063463
  - -0.48886271847018636
  - -0.4685408253615326
  train_level2__precision_macro:
  - 0.38190117374293575
  - 0.39073002240477983
  - 0.38647676309693946
  - 0.3860679611650485
  - 0.3840345199568501
  train_level2__precision_macro_masked:
  - 0.34667198229313695
  - 0.3564314265359153
  - 0.35133699045378497
  - 0.3516258241323286
  - 0.34919505875528073
  train_level2__precision_macro_oob:
  - 0.3767569917403275
  - 0.3837985436893205
  - 0.3779508156325465
  - 0.37932038834951465
  - 0.3771697558105326
  train_level2__precision_micro:
  - 0.3819011737429358
  - 0.39073002240477966
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995685006
  train_level2__precision_micro_masked:
  - 0.33919375812743824
  - 0.3489646160032167
  - 0.3450982471957784
  - 0.34459494796297263
  - 0.34199683042789225
  train_level2__precision_micro_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254646
  - 0.37932038834951454
  - 0.3771697558105325
  train_level2__precision_samples:
  - 0.38190117374293575
  - 0.3907300224047796
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995684995
  train_level2__precision_samples_masked:
  - 0.3397872943161679
  - 0.3495817753883624
  - 0.3456950169834291
  - 0.3450032210841937
  - 0.34252452766465813
  train_level2__precision_samples_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254634
  - 0.37932038834951454
  - 0.37716975581053247
  train_level2__precision_weighted:
  - 0.4894702199596335
  - 0.49780572606944185
  - 0.4785774715977762
  - 0.48702409142386494
  - 0.4858731906179447
  train_level2__precision_weighted_masked:
  - 0.4465516891682485
  - 0.4563842023799143
  - 0.43518056356333307
  - 0.4444524571835643
  - 0.44468850542394145
  train_level2__precision_weighted_oob:
  - 0.48461516705876306
  - 0.49009279685401874
  - 0.46929710970682703
  - 0.47901266344074955
  - 0.4773810766607509
  train_level2__recall_macro:
  - 0.38190117374293575
  - 0.39073002240477983
  - 0.38647676309693946
  - 0.3860679611650485
  - 0.3840345199568501
  train_level2__recall_macro_masked:
  - 0.34667198229313695
  - 0.3564314265359153
  - 0.35133699045378497
  - 0.3516258241323286
  - 0.34919505875528073
  train_level2__recall_macro_oob:
  - 0.3767569917403275
  - 0.3837985436893205
  - 0.3779508156325465
  - 0.37932038834951465
  - 0.3771697558105326
  train_level2__recall_micro:
  - 0.3819011737429358
  - 0.39073002240477966
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995685006
  train_level2__recall_micro_masked:
  - 0.33919375812743824
  - 0.3489646160032167
  - 0.3450982471957784
  - 0.34459494796297263
  - 0.34199683042789225
  train_level2__recall_micro_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254646
  - 0.37932038834951454
  - 0.3771697558105325
  train_level2__recall_samples:
  - 0.38190117374293575
  - 0.3907300224047796
  - 0.3864767630969395
  - 0.38606796116504855
  - 0.38403451995684995
  train_level2__recall_samples_masked:
  - 0.3397872943161679
  - 0.3495817753883624
  - 0.3456950169834291
  - 0.3450032210841937
  - 0.34252452766465813
  train_level2__recall_samples_oob:
  - 0.3767569917403275
  - 0.38379854368932037
  - 0.37795081563254634
  - 0.37932038834951454
  - 0.37716975581053247
  train_level2__recall_weighted:
  - 0.4894702199596335
  - 0.49780572606944185
  - 0.4785774715977762
  - 0.48702409142386494
  - 0.4858731906179447
  train_level2__recall_weighted_masked:
  - 0.4465516891682485
  - 0.4563842023799143
  - 0.43518056356333307
  - 0.4444524571835643
  - 0.44468850542394145
  train_level2__recall_weighted_oob:
  - 0.48461516705876306
  - 0.49009279685401874
  - 0.46929710970682703
  - 0.47901266344074955
  - 0.4773810766607509
  train_level2__roc_auc_macro:
  - 0.6455736026948988
  - 0.6634066876844753
  - 0.6654150547818201
  - 0.6438322810682399
  - 0.6611710997994225
  train_level2__roc_auc_macro_masked:
  - 0.6206173331858696
  - 0.6382847370382054
  - 0.643432209697619
  - 0.6200371381742614
  - 0.6390992759965961
  train_level2__roc_auc_macro_oob:
  - 0.6356946243655939
  - 0.6541743988740135
  - 0.6531841585359431
  - 0.6346798914535741
  - 0.650659460625871
  train_level2__roc_auc_micro:
  - 0.5476545300013509
  - 0.551956687813112
  - 0.573831367409349
  - 0.5373890664615187
  - 0.5576756203042244
  train_level2__roc_auc_micro_masked:
  - 0.5289871760157285
  - 0.5330578614463458
  - 0.5561122091177542
  - 0.5180755574592755
  - 0.5397650401735437
  train_level2__roc_auc_micro_oob:
  - 0.541409757752854
  - 0.5459457015080433
  - 0.5662753380848073
  - 0.53139112603496
  - 0.5506783668311461
  train_level2__roc_auc_samples:
  - 0.5363440636525824
  - 0.5380624767875491
  - 0.5590169054744498
  - 0.5255718693461072
  - 0.5465352757980496
  train_level2__roc_auc_samples_masked:
  - 0.518839221039538
  - 0.5213476919939422
  - 0.5419745006889457
  - 0.5088181226100026
  - 0.5309394639500923
  train_level2__roc_auc_samples_oob:
  - 0.5299848277163878
  - 0.5316836810506648
  - 0.5511555750964355
  - 0.5196089034960794
  - 0.5397193681588129
  train_level2__roc_auc_weighted:
  - 0.6631654931267323
  - 0.6746440982216289
  - 0.665079493875924
  - 0.6493656015316137
  - 0.6691750477498735
  train_level2__roc_auc_weighted_masked:
  - 0.6363464571691749
  - 0.648874028283763
  - 0.6416370209501507
  - 0.6221652488297866
  - 0.6439576737111365
  train_level2__roc_auc_weighted_oob:
  - 0.6514002211623747
  - 0.6624740127793284
  - 0.6524908251041461
  - 0.6387903848707605
  - 0.656339507744491
  train_level2__tn_macro:
  - 0.17608559146017486
  - 0.1853061986557132
  - 0.18217436301808684
  - 0.18516990291262136
  - 0.1784348337746396
  train_level2__tn_macro_masked:
  - 0.19123988558930732
  - 0.20097416281328373
  - 0.1965465558682682
  - 0.2009467506378824
  - 0.19347947329531595
  train_level2__tn_macro_oob:
  - 0.17169009322320436
  - 0.17872479462285285
  - 0.17473264008673794
  - 0.17973300970873782
  - 0.17274688633911936
  train_level2__tn_micro:
  - 0.17608559146017486
  - 0.1853061986557132
  - 0.18217436301808684
  - 0.18516990291262136
  - 0.1784348337746396
  train_level2__tn_micro_masked:
  - 0.18962288686605983
  - 0.19953759549658223
  - 0.19604359470711463
  - 0.1994927043564667
  - 0.19223454833597464
  train_level2__tn_micro_oob:
  - 0.17169009322320436
  - 0.17872479462285287
  - 0.17473264008673797
  - 0.17973300970873787
  - 0.17274688633911936
  train_level2__tn_samples:
  - 0.17608559146017483
  - 0.18530619865571316
  - 0.18217436301808682
  - 0.18516990291262134
  - 0.17843483377463956
  train_level2__tn_samples_masked:
  - 0.18991789916400745
  - 0.19984763712970816
  - 0.19635275917612807
  - 0.1996573619740952
  - 0.19243067061355842
  train_level2__tn_samples_oob:
  - 0.17169009322320436
  - 0.17872479462285285
  - 0.17473264008673792
  - 0.17973300970873785
  - 0.17274688633911928
  train_level2__tn_weighted:
  - 0.19154074588298814
  - 0.19831167274122385
  - 0.18310855433543977
  - 0.19780989395655307
  - 0.1887496427897305
  train_level2__tn_weighted_masked:
  - 0.21284726285743386
  - 0.22022771886049322
  - 0.20322930907786954
  - 0.2199626435742552
  - 0.20984161679179214
  train_level2__tn_weighted_oob:
  - 0.18690603828403202
  - 0.1906229618262037
  - 0.17452988492351257
  - 0.19122825079789973
  - 0.18187696992895866
  train_level2__tp_macro:
  - 0.20581558228276098
  - 0.20542382374906643
  - 0.20430240007885273
  - 0.20089805825242718
  - 0.2055996861822104
  train_level2__tp_macro_masked:
  - 0.15543209670382965
  - 0.1554572637226316
  - 0.1547904345855167
  - 0.1506790734944463
  - 0.15571558545996486
  train_level2__tp_macro_oob:
  - 0.20506689851712315
  - 0.20507374906646755
  - 0.20321817554580848
  - 0.19958737864077666
  - 0.20442286947141308
  train_level2__tp_micro:
  - 0.20581558228276095
  - 0.20542382374906648
  - 0.2043024000788527
  - 0.20089805825242718
  - 0.20559968618221044
  train_level2__tp_micro_masked:
  - 0.1495708712613784
  - 0.1494270205066345
  - 0.14905465248866379
  - 0.14510224360650595
  - 0.14976228209191758
  train_level2__tp_micro_oob:
  - 0.20506689851712312
  - 0.20507374906646753
  - 0.20321817554580848
  - 0.1995873786407767
  - 0.20442286947141317
  train_level2__tp_samples:
  - 0.2058155822827609
  - 0.20542382374906643
  - 0.20430240007885264
  - 0.20089805825242713
  - 0.20559968618221042
  train_level2__tp_samples_masked:
  - 0.14986939515216044
  - 0.14973413825865425
  - 0.14934225780730107
  - 0.1453458591100985
  - 0.15009385705109976
  train_level2__tp_samples_oob:
  - 0.20506689851712306
  - 0.20507374906646744
  - 0.20321817554580845
  - 0.1995873786407766
  - 0.2044228694714131
  train_level2__tp_weighted:
  - 0.2979294740766452
  - 0.2994940533282179
  - 0.29546891726233643
  - 0.28921419746731186
  - 0.29712354782821426
  train_level2__tp_weighted_masked:
  - 0.23370442631081473
  - 0.236156483519421
  - 0.2319512544854636
  - 0.2244898136093091
  - 0.2348468886321494
  train_level2__tp_weighted_oob:
  - 0.29770912877473105
  - 0.29946983502781505
  - 0.2947672247833144
  - 0.2877844126428498
  - 0.2955041067317922
  train_level3__average_precision_macro:
  - 0.342423278742059
  - 0.35686910807492805
  - 0.35545409769353564
  - 0.33849052910267374
  - 0.35577410660015407
  train_level3__average_precision_macro_masked:
  - 0.26687957580765026
  - 0.27965320937829397
  - 0.27911008980506347
  - 0.2632182433935038
  - 0.27960186333298415
  train_level3__average_precision_macro_oob:
  - 0.3376366645792561
  - 0.3482540942153153
  - 0.34711359607102443
  - 0.3320340041172503
  - 0.3485141529075878
  train_level3__average_precision_micro:
  - 0.24313547181090434
  - 0.24381450576367042
  - 0.25345229906438455
  - 0.23951784602362128
  - 0.24858635056450673
  train_level3__average_precision_micro_masked:
  - 0.1760595512826812
  - 0.17655166544177223
  - 0.1846237185149484
  - 0.17394597769561837
  - 0.18048864272010637
  train_level3__average_precision_micro_oob:
  - 0.24225352597108363
  - 0.24282686748858262
  - 0.25167510612146893
  - 0.23857038668133096
  - 0.24704551491600468
  train_level3__average_precision_samples:
  - 0.2586795465296557
  - 0.2604592995256524
  - 0.2711118213143988
  - 0.2572491400723246
  - 0.2670026630947665
  train_level3__average_precision_samples_masked:
  - 0.19488569452584
  - 0.19702873898253734
  - 0.20626632808259
  - 0.19437044199634865
  - 0.20254031744759593
  train_level3__average_precision_samples_oob:
  - 0.25766786888586524
  - 0.25965235395407416
  - 0.2694062809169287
  - 0.25650384296651074
  - 0.26568875883036486
  train_level3__average_precision_weighted:
  - 0.4786362740332389
  - 0.48783884576467773
  - 0.4861033878190914
  - 0.46791857952106886
  - 0.4889229211101486
  train_level3__average_precision_weighted_masked:
  - 0.3891442158585387
  - 0.39921120924056713
  - 0.39812643538305675
  - 0.37974792645060307
  - 0.4010148468933841
  train_level3__average_precision_weighted_oob:
  - 0.4714353901316402
  - 0.47815822632524496
  - 0.47766336578292556
  - 0.4602748652099828
  - 0.4798331029044069
  train_level3__f1_macro:
  - 0.3872385644592571
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.39077669902912626
  - 0.39114445425125044
  train_level3__f1_macro_masked:
  - 0.3527178782067671
  - 0.3628263172008289
  - 0.3579869678281804
  - 0.3569619096413805
  - 0.35680710463532933
  train_level3__f1_macro_oob:
  - 0.38146645413708147
  - 0.3914068334578044
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.387295282926351
  train_level3__f1_micro:
  - 0.38723856445925714
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.3907766990291262
  - 0.3911444542512504
  train_level3__f1_micro_masked:
  - 0.3453576072821847
  - 0.3555237233614797
  - 0.35188671740341015
  - 0.3500339940379687
  - 0.3496038034865293
  train_level3__f1_micro_oob:
  - 0.3814664541370816
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.38677184466019415
  - 0.3872952829263509
  train_level3__f1_samples:
  - 0.3872385644592571
  - 0.39649458551157574
  - 0.39243999802868257
  - 0.39077669902912615
  - 0.3911444542512504
  train_level3__f1_samples_masked:
  - 0.34594121160887215
  - 0.3561478733507028
  - 0.3524703702124156
  - 0.3504179229022056
  - 0.3501665485257422
  train_level3__f1_samples_oob:
  - 0.3814664541370815
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.38729528292635085
  train_level3__f1_weighted:
  - 0.4929476647768908
  - 0.5013710915020143
  - 0.482303914586139
  - 0.4901415628539072
  - 0.49295228092597343
  train_level3__f1_weighted_masked:
  - 0.45101739100457533
  - 0.46059206901117794
  - 0.43995023517159515
  - 0.4484575807721412
  - 0.45235420579037766
  train_level3__f1_weighted_oob:
  - 0.48649234447915474
  - 0.4946774889698829
  - 0.47556701932041856
  - 0.48502239266961805
  - 0.48902006809930393
  train_level3__fn_macro:
  - -0.02960923537651548
  - -0.029616318147871544
  - -0.02865802572569119
  - -0.03618932038834951
  - -0.029690104932823383
  train_level3__fn_macro_masked:
  - -0.02840358636362977
  - -0.028031200757614554
  - -0.027197104185094904
  - -0.03477131596482338
  - -0.027990055088972496
  train_level3__fn_macro_oob:
  - -0.03011640825001208
  - -0.030059746079163556
  - -0.029766891725395494
  - -0.03711165048543689
  - -0.03018044522898892
  train_level3__fn_micro:
  - -0.02960923537651548
  - -0.029616318147871547
  - -0.028658025725691195
  - -0.036189320388349516
  - -0.02969010493282338
  train_level3__fn_micro_masked:
  - -0.026657997399219768
  - -0.02651286690792119
  - -0.025138553737636234
  - -0.03260812719000052
  - -0.026439513998943474
  train_level3__fn_micro_oob:
  - -0.030116408250012074
  - -0.030059746079163556
  - -0.029766891725395494
  - -0.037111650485436895
  - -0.03018044522898892
  train_level3__fn_samples:
  - -0.029609235376515473
  - -0.029616318147871544
  - -0.02865802572569119
  - -0.036189320388349516
  - -0.029690104932823376
  train_level3__fn_samples_masked:
  - -0.026568625471584426
  - -0.02642237040052319
  - -0.025108185132021288
  - -0.03244852159400234
  - -0.026310361355999467
  train_level3__fn_samples_oob:
  - -0.03011640825001207
  - -0.03005974607916355
  - -0.02976689172539549
  - -0.03711165048543689
  - -0.030180445228988915
  train_level3__fn_weighted:
  - -0.05148906629642486
  - -0.04893895070017264
  - -0.055514909009288994
  - -0.06279831154123339
  - -0.05000680149443069
  train_level3__fn_weighted_masked:
  - -0.051741378722673204
  - -0.04827871038902914
  - -0.054912740761856677
  - -0.06331035842125024
  - -0.048558481147251746
  train_level3__fn_weighted_oob:
  - -0.05131885790684819
  - -0.04945161135622483
  - -0.05641623718015125
  - -0.0637545042726243
  - -0.050200037750930335
  train_level3__fp_macro:
  - -0.5831522001642275
  - -0.5738890963405526
  - -0.5789019762456261
  - -0.5730339805825242
  - -0.5791654408159261
  train_level3__fp_macro_masked:
  - -0.6188785354296032
  - -0.6091424820415566
  - -0.6148159279867247
  - -0.6082667743937962
  - -0.6152028402756982
  train_level3__fp_macro_oob:
  - -0.5884171376129064
  - -0.5785334204630319
  - -0.5838302695776453
  - -0.5761165048543688
  - -0.5825242718446602
  train_level3__fp_micro:
  - -0.5831522001642274
  - -0.5738890963405526
  - -0.5789019762456261
  - -0.5730339805825243
  - -0.5791654408159262
  train_level3__fp_micro_masked:
  - -0.6279843953185956
  - -0.6179634097305992
  - -0.6229747288589537
  - -0.6173578787720307
  - -0.6239566825145272
  train_level3__fp_micro_oob:
  - -0.5884171376129064
  - -0.5785334204630321
  - -0.5838302695776453
  - -0.5761165048543689
  - -0.5825242718446602
  train_level3__fp_samples:
  - -0.5831522001642274
  - -0.5738890963405526
  - -0.5789019762456261
  - -0.5730339805825243
  - -0.5791654408159261
  train_level3__fp_samples_masked:
  - -0.6274901629195434
  - -0.617429756248774
  - -0.6224214446555631
  - -0.617133555503792
  - -0.6235230901182582
  train_level3__fp_samples_oob:
  - -0.5884171376129064
  - -0.5785334204630321
  - -0.5838302695776453
  - -0.5761165048543689
  - -0.5825242718446602
  train_level3__fp_weighted:
  - -0.45556326892668436
  - -0.44968995779781307
  - -0.46218117640457196
  - -0.44706012560485947
  - -0.457040917579596
  train_level3__fp_weighted_masked:
  - -0.49724123027275147
  - -0.4911292205997929
  - -0.5051370240665483
  - -0.48823206080660864
  - -0.4990873130623706
  train_level3__fp_weighted_oob:
  - -0.46218879761399717
  - -0.4558708996738923
  - -0.4680167434994301
  - -0.4512231030577575
  - -0.4607798941497657
  train_level3__jaccard_macro:
  - 0.2601188662669336
  - 0.26747181543345555
  - 0.2602731199421418
  - 0.2604807408479875
  - 0.26156880205510963
  train_level3__jaccard_macro_masked:
  - 0.23217345357704916
  - 0.24006244307499383
  - 0.23270973540356774
  - 0.2331013423500436
  - 0.23387133645436006
  train_level3__jaccard_macro_oob:
  - 0.25570758023103474
  - 0.26308754131525935
  - 0.2551699166444194
  - 0.25710803388658665
  - 0.2585334913111129
  train_level3__jaccard_micro:
  - 0.24010901794004014
  - 0.2472673817806046
  - 0.24412152426499892
  - 0.24283559577677225
  - 0.24311968547133583
  train_level3__jaccard_micro_masked:
  - 0.20872039106584303
  - 0.21619267386952337
  - 0.21350881709357702
  - 0.2121461852990586
  - 0.21183022853850586
  train_level3__jaccard_micro_oob:
  - 0.2356864676126953
  - 0.24332245194051505
  - 0.2394667318235267
  - 0.239750244489581
  - 0.240152632299062
  train_level3__jaccard_samples:
  - 0.24417783224810186
  - 0.25173327725113787
  - 0.24915022464611128
  - 0.24760157255097914
  - 0.2483617069183189
  train_level3__jaccard_samples_masked:
  - 0.2129592796994434
  - 0.22071925427033323
  - 0.21877562870612027
  - 0.2169744493136757
  - 0.2173945291716962
  train_level3__jaccard_samples_oob:
  - 0.23969904740995024
  - 0.2477369463908522
  - 0.24463105827336232
  - 0.24443482989033807
  - 0.24531316359757974
  train_level3__jaccard_weighted:
  - 0.34422337603776515
  - 0.3525930558609891
  - 0.33150479268402616
  - 0.3390580217034358
  - 0.3442360002834531
  train_level3__jaccard_weighted_masked:
  - 0.30620334292491524
  - 0.3152989682363739
  - 0.29434366674907514
  - 0.3014999100555249
  - 0.30768255821048
  train_level3__jaccard_weighted_oob:
  - 0.3389718707081708
  - 0.346270792668496
  - 0.3254785457949567
  - 0.33432973943713246
  - 0.34085904438565406
  train_level3__label_ranking_average_precision_score:
  - 0.25867954652965564
  - 0.2604592995256526
  - 0.27111182131439865
  - 0.2572491400723247
  - 0.2670026630947666
  train_level3__label_ranking_average_precision_score_oob:
  - 0.2576678688858652
  - 0.2596523539540744
  - 0.2694062809169287
  - 0.25650384296651074
  - 0.26568875883036475
  train_level3__matthews_corrcoef_macro:
  - 0.1511385518845842
  - 0.15494563693191354
  - 0.1559582287995752
  - 0.13918642274843226
  - 0.15025710654037086
  train_level3__matthews_corrcoef_macro_masked:
  - 0.11929756858196419
  - 0.12300319626378003
  - 0.1255734655790187
  - 0.10504323716985577
  - 0.11866140813396912
  train_level3__matthews_corrcoef_macro_oob:
  - 0.13823508307473314
  - 0.1471121988066331
  - 0.14428036286777937
  - 0.13017417719872762
  - 0.14284690750023352
  train_level3__matthews_corrcoef_micro:
  - 0.11613026409400373
  - 0.12661544820684134
  - 0.12549711315844925
  - 0.09791857568745164
  - 0.12022590845754333
  train_level3__matthews_corrcoef_micro_masked:
  - 0.07878620596613269
  - 0.08935524185995822
  - 0.09134926021623582
  - 0.058688901247760786
  - 0.08411748880239643
  train_level3__matthews_corrcoef_micro_oob:
  - 0.10767222830414097
  - 0.11932267919282424
  - 0.1147826773528578
  - 0.09017611483082655
  - 0.1141038477472288
  train_level3__matthews_corrcoef_samples:
  - 0.11262585556425905
  - 0.12028494466010284
  - 0.12053017014830819
  - 0.09519279489881434
  - 0.11510566077721689
  train_level3__matthews_corrcoef_samples_masked:
  - 0.07571640197375333
  - 0.08271364709772515
  - 0.0859578077130434
  - 0.057442125847610014
  - 0.08089079899657055
  train_level3__matthews_corrcoef_samples_oob:
  - 0.1042203104908144
  - 0.11355966758597481
  - 0.10956608612207396
  - 0.08834416575121683
  - 0.10884769148497803
  train_level3__matthews_corrcoef_weighted:
  - 0.18884127255845348
  - 0.19245500446805563
  - 0.180192923885915
  - 0.17109036940247038
  - 0.18434966313371226
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.14912319724933198
  - 0.15438665164300583
  - 0.1441448021926539
  - 0.12909859421342232
  - 0.14712391010682194
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.17049535793853526
  - 0.1784491041931892
  - 0.1634601203158732
  - 0.15763931055103997
  - 0.17611043172611318
  train_level3__ndcg:
  - 0.6097061400207447
  - 0.6058320539402484
  - 0.6115404346239252
  - 0.6056422066177349
  - 0.6133745628294605
  train_level3__ndcg_oob:
  - 0.6105398889380161
  - 0.6066673700824106
  - 0.6117142419779324
  - 0.6063012288210691
  - 0.6135205389409593
  train_level3__neg_coverage_error:
  - -91.56218905472637
  - -91.8485576923077
  - -93.60913705583756
  - -91.98
  - -91.87878787878788
  train_level3__neg_coverage_error_oob:
  - -91.95273631840796
  - -92.19951923076923
  - -93.93147208121827
  - -92.4425
  - -92.4040404040404
  train_level3__neg_hamming_loss_macro:
  - -0.6127614355407429
  - -0.6035054144884241
  - -0.6075600019713173
  - -0.6092233009708737
  - -0.6088555457487496
  train_level3__neg_hamming_loss_macro_masked:
  - -0.6472821217932329
  - -0.6371736827991712
  - -0.6420130321718197
  - -0.6430380903586196
  - -0.6431928953646705
  train_level3__neg_hamming_loss_macro_oob:
  - -0.6185335458629185
  - -0.6085931665421956
  - -0.6135971613030408
  - -0.6132281553398057
  - -0.612704717073649
  train_level3__neg_hamming_loss_micro:
  - -0.6127614355407429
  - -0.6035054144884242
  - -0.6075600019713173
  - -0.6092233009708737
  - -0.6088555457487497
  train_level3__neg_hamming_loss_micro_masked:
  - -0.6546423927178153
  - -0.6444762766385203
  - -0.6481132825965898
  - -0.6499660059620312
  - -0.6503961965134707
  train_level3__neg_hamming_loss_micro_oob:
  - -0.6185335458629184
  - -0.6085931665421956
  - -0.6135971613030408
  - -0.6132281553398058
  - -0.6127047170736492
  train_level3__neg_hamming_loss_samples:
  - -0.6127614355407429
  - -0.6035054144884241
  - -0.6075600019713173
  - -0.6092233009708737
  - -0.6088555457487497
  train_level3__neg_hamming_loss_samples_masked:
  - -0.6540587883911279
  - -0.6438521266492973
  - -0.6475296297875844
  - -0.6495820770977943
  - -0.6498334514742579
  train_level3__neg_hamming_loss_samples_oob:
  - -0.6185335458629183
  - -0.6085931665421955
  - -0.6135971613030408
  - -0.6132281553398058
  - -0.6127047170736492
  train_level3__neg_hamming_loss_weighted:
  - -0.5070523352231092
  - -0.4986289084979857
  - -0.517696085413861
  - -0.5098584371460928
  - -0.5070477190740266
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.5489826089954247
  - -0.539407930988822
  - -0.560049764828405
  - -0.5515424192278588
  - -0.5476457942096223
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.5135076555208454
  - -0.505322511030117
  - -0.5244329806795816
  - -0.514977607330382
  - -0.510979931900696
  train_level3__neg_label_ranking_loss:
  - -0.4702383317527376
  - -0.46287954469555326
  - -0.443925373394509
  - -0.4798066640540553
  - -0.45783676918973104
  train_level3__neg_label_ranking_loss_oob:
  - -0.4758418930168395
  - -0.467776954289547
  - -0.4505992263117838
  - -0.48451287650071395
  - -0.4637029966433255
  train_level3__precision_macro:
  - 0.3872385644592571
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.39077669902912626
  - 0.39114445425125044
  train_level3__precision_macro_masked:
  - 0.3527178782067671
  - 0.3628263172008289
  - 0.3579869678281804
  - 0.3569619096413805
  - 0.35680710463532933
  train_level3__precision_macro_oob:
  - 0.38146645413708147
  - 0.3914068334578044
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.387295282926351
  train_level3__precision_micro:
  - 0.38723856445925714
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.3907766990291262
  - 0.3911444542512504
  train_level3__precision_micro_masked:
  - 0.3453576072821847
  - 0.3555237233614797
  - 0.35188671740341015
  - 0.3500339940379687
  - 0.3496038034865293
  train_level3__precision_micro_oob:
  - 0.3814664541370816
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.38677184466019415
  - 0.3872952829263509
  train_level3__precision_samples:
  - 0.3872385644592571
  - 0.39649458551157574
  - 0.39243999802868257
  - 0.39077669902912615
  - 0.3911444542512504
  train_level3__precision_samples_masked:
  - 0.34594121160887215
  - 0.3561478733507028
  - 0.3524703702124156
  - 0.3504179229022056
  - 0.3501665485257422
  train_level3__precision_samples_oob:
  - 0.3814664541370815
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.38729528292635085
  train_level3__precision_weighted:
  - 0.4929476647768908
  - 0.5013710915020143
  - 0.482303914586139
  - 0.4901415628539072
  - 0.49295228092597343
  train_level3__precision_weighted_masked:
  - 0.45101739100457533
  - 0.46059206901117794
  - 0.43995023517159515
  - 0.4484575807721412
  - 0.45235420579037766
  train_level3__precision_weighted_oob:
  - 0.48649234447915474
  - 0.4946774889698829
  - 0.47556701932041856
  - 0.48502239266961805
  - 0.48902006809930393
  train_level3__recall_macro:
  - 0.3872385644592571
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.39077669902912626
  - 0.39114445425125044
  train_level3__recall_macro_masked:
  - 0.3527178782067671
  - 0.3628263172008289
  - 0.3579869678281804
  - 0.3569619096413805
  - 0.35680710463532933
  train_level3__recall_macro_oob:
  - 0.38146645413708147
  - 0.3914068334578044
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.387295282926351
  train_level3__recall_micro:
  - 0.38723856445925714
  - 0.3964945855115758
  - 0.3924399980286827
  - 0.3907766990291262
  - 0.3911444542512504
  train_level3__recall_micro_masked:
  - 0.3453576072821847
  - 0.3555237233614797
  - 0.35188671740341015
  - 0.3500339940379687
  - 0.3496038034865293
  train_level3__recall_micro_oob:
  - 0.3814664541370816
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.38677184466019415
  - 0.3872952829263509
  train_level3__recall_samples:
  - 0.3872385644592571
  - 0.39649458551157574
  - 0.39243999802868257
  - 0.39077669902912615
  - 0.3911444542512504
  train_level3__recall_samples_masked:
  - 0.34594121160887215
  - 0.3561478733507028
  - 0.3524703702124156
  - 0.3504179229022056
  - 0.3501665485257422
  train_level3__recall_samples_oob:
  - 0.3814664541370815
  - 0.3914068334578043
  - 0.38640283869695924
  - 0.3867718446601942
  - 0.38729528292635085
  train_level3__recall_weighted:
  - 0.4929476647768908
  - 0.5013710915020143
  - 0.482303914586139
  - 0.4901415628539072
  - 0.49295228092597343
  train_level3__recall_weighted_masked:
  - 0.45101739100457533
  - 0.46059206901117794
  - 0.43995023517159515
  - 0.4484575807721412
  - 0.45235420579037766
  train_level3__recall_weighted_oob:
  - 0.48649234447915474
  - 0.4946774889698829
  - 0.47556701932041856
  - 0.48502239266961805
  - 0.48902006809930393
  train_level3__roc_auc_macro:
  - 0.6465941389397751
  - 0.664625755854307
  - 0.6653373466897342
  - 0.6435915557634114
  - 0.6634573587352712
  train_level3__roc_auc_macro_masked:
  - 0.6225937100089856
  - 0.6396196220420926
  - 0.6442225673696736
  - 0.6204522763040452
  - 0.6417667510641009
  train_level3__roc_auc_macro_oob:
  - 0.6380951494560556
  - 0.6560901661241463
  - 0.6540321565519169
  - 0.6352480631510541
  - 0.6543318043248695
  train_level3__roc_auc_micro:
  - 0.5537791465188999
  - 0.558392304891125
  - 0.5765635051656512
  - 0.5427891434727706
  - 0.5622773976837295
  train_level3__roc_auc_micro_masked:
  - 0.5350325415845826
  - 0.5390764590381539
  - 0.5592207708225493
  - 0.5234767479027509
  - 0.5440819835100423
  train_level3__roc_auc_micro_oob:
  - 0.5492424635157771
  - 0.5540490652538748
  - 0.570769761720368
  - 0.5386966974167696
  - 0.5571138175545424
  train_level3__roc_auc_samples:
  - 0.542576803802187
  - 0.544481187067071
  - 0.5613784725760805
  - 0.5320643070597691
  - 0.5512864999351755
  train_level3__roc_auc_samples_masked:
  - 0.5250601807342996
  - 0.5273629436796136
  - 0.5446970300511522
  - 0.5153396904495816
  - 0.5355475756659246
  train_level3__roc_auc_samples_oob:
  - 0.5382244486859431
  - 0.5404784944825025
  - 0.5552896994485232
  - 0.5283685726533591
  - 0.5460181775296055
  train_level3__roc_auc_weighted:
  - 0.6647574274227513
  - 0.6748817459578786
  - 0.6659561394553133
  - 0.6497609125662833
  - 0.6713289012486928
  train_level3__roc_auc_weighted_masked:
  - 0.6385698328665922
  - 0.6496495454399231
  - 0.6433655279593834
  - 0.6227992308891631
  - 0.6464068518068204
  train_level3__roc_auc_weighted_oob:
  - 0.6545330858379989
  - 0.6639520629981361
  - 0.6543712453407066
  - 0.6401967051304991
  - 0.6604632329295094
  train_level3__tn_macro:
  - 0.18318601168912713
  - 0.19214432412247945
  - 0.1892711054161944
  - 0.19121359223300974
  - 0.18598607433558892
  train_level3__tn_macro_masked:
  - 0.19895380604480795
  - 0.20829336365952844
  - 0.20416656355750382
  - 0.20745626916655047
  - 0.20164718389211259
  train_level3__tn_macro_oob:
  - 0.17792107424044826
  - 0.1875
  - 0.18434281208417522
  - 0.18813106796116505
  - 0.18262724330685498
  train_level3__tn_micro:
  - 0.18318601168912718
  - 0.19214432412247945
  - 0.18927110541619438
  - 0.1912135922330097
  - 0.1859860743355889
  train_level3__tn_micro_masked:
  - 0.19726918075422628
  - 0.2069008845999196
  - 0.20368062369070034
  - 0.20600387009047644
  - 0.20036978341257264
  train_level3__tn_micro_oob:
  - 0.17792107424044826
  - 0.1875
  - 0.18434281208417524
  - 0.18813106796116505
  - 0.18262724330685495
  train_level3__tn_samples:
  - 0.18318601168912715
  - 0.19214432412247942
  - 0.18927110541619432
  - 0.1912135922330097
  - 0.18598607433558884
  train_level3__tn_samples_masked:
  - 0.19755115523392575
  - 0.20721042150527025
  - 0.2039808083418174
  - 0.20613425544563976
  - 0.2005864595120774
  train_level3__tn_samples_oob:
  - 0.1779210742404482
  - 0.18749999999999994
  - 0.1843428120841752
  - 0.18813106796116505
  - 0.18262724330685495
  train_level3__tn_weighted:
  - 0.1991227325902786
  - 0.20443986188375216
  - 0.18979338245450467
  - 0.20367008133429423
  - 0.19654499900350195
  train_level3__tn_weighted_masked:
  - 0.22145708708657086
  - 0.22697363772241697
  - 0.21060556734276722
  - 0.22647290720223592
  - 0.21842656553082804
  train_level3__tn_weighted_oob:
  - 0.1924972039029658
  - 0.19825892000767312
  - 0.1839578153596464
  - 0.19950710388139603
  - 0.19280602243333217
  train_level3__tp_macro:
  - 0.20405255277012999
  - 0.20435026138909634
  - 0.2031688926124883
  - 0.1995631067961165
  - 0.2051583799156614
  train_level3__tp_macro_masked:
  - 0.15376407216195906
  - 0.1545329535413003
  - 0.15382040427067648
  - 0.14950564047482998
  - 0.15515992074321683
  train_level3__tp_macro_oob:
  - 0.20354537989663338
  - 0.20390683345780433
  - 0.202060026612784
  - 0.19864077669902913
  - 0.20466803961949584
  train_level3__tp_micro:
  - 0.20405255277012993
  - 0.20435026138909634
  - 0.2031688926124883
  - 0.1995631067961165
  - 0.20515837991566147
  train_level3__tp_micro_masked:
  - 0.1480884265279584
  - 0.1486228387615601
  - 0.14820609371270982
  - 0.1440301239474923
  - 0.14923402007395667
  train_level3__tp_micro_oob:
  - 0.20354537989663335
  - 0.20390683345780433
  - 0.202060026612784
  - 0.19864077669902913
  - 0.20466803961949592
  train_level3__tp_samples:
  - 0.2040525527701299
  - 0.2043502613890963
  - 0.20316889261248824
  - 0.19956310679611647
  - 0.2051583799156614
  train_level3__tp_samples_masked:
  - 0.1483900563749464
  - 0.14893745184543247
  - 0.14848956187059817
  - 0.14428366745656582
  - 0.14958008901366485
  train_level3__tp_samples_oob:
  - 0.20354537989663324
  - 0.20390683345780428
  - 0.20206002661278397
  - 0.19864077669902905
  - 0.20466803961949592
  train_level3__tp_weighted:
  - 0.2938249321866122
  - 0.296931229618262
  - 0.29251053213163447
  - 0.28647148151961294
  - 0.2964072819224713
  train_level3__tp_weighted_masked:
  - 0.22956030391800455
  - 0.233618431288761
  - 0.2293446678288279
  - 0.22198467356990523
  - 0.23392764025954985
  train_level3__tp_weighted_oob:
  - 0.29399514057618886
  - 0.2964185689622098
  - 0.2916092039607722
  - 0.28551528878822197
  - 0.2962140456659717
  train_level4__average_precision_macro:
  - 0.3417152604652737
  - 0.35677811315321317
  - 0.35360710538669016
  - 0.3378608622401261
  - 0.3554879485383669
  train_level4__average_precision_macro_masked:
  - 0.2668031590080535
  - 0.2803481182077297
  - 0.2778455611226058
  - 0.2628656908011633
  - 0.2807224107926123
  train_level4__average_precision_macro_oob:
  - 0.3362613326842524
  - 0.349954469808822
  - 0.34610274791343987
  - 0.33071793768634145
  - 0.3492160905405483
  train_level4__average_precision_micro:
  - 0.24432723824739022
  - 0.24440266275205874
  - 0.2540257988690236
  - 0.24128402778911534
  - 0.25019520472839635
  train_level4__average_precision_micro_masked:
  - 0.17693319335289368
  - 0.17728221318950496
  - 0.1850118798314626
  - 0.1750237023660839
  - 0.18155286750070973
  train_level4__average_precision_micro_oob:
  - 0.24391693266923362
  - 0.24361908979585595
  - 0.252617527769525
  - 0.2402063208524449
  - 0.2489805077630413
  train_level4__average_precision_samples:
  - 0.2599159568504067
  - 0.2607408122407925
  - 0.27060045718407705
  - 0.25833202952846174
  - 0.26868543601023953
  train_level4__average_precision_samples_masked:
  - 0.19593974893544167
  - 0.19739761327604158
  - 0.20573138077998923
  - 0.1949302503603478
  - 0.2036850954501848
  train_level4__average_precision_samples_oob:
  - 0.2593849342881708
  - 0.2601051372499824
  - 0.2691252716117219
  - 0.25760630749154095
  - 0.2675409558747998
  train_level4__average_precision_weighted:
  - 0.4774993160668799
  - 0.48783145722274884
  - 0.483796830522698
  - 0.46774292313506116
  - 0.4887909506735389
  train_level4__average_precision_weighted_masked:
  - 0.38802263913781254
  - 0.39992688018790173
  - 0.39658020564654656
  - 0.3793992471023573
  - 0.40219527936024346
  train_level4__average_precision_weighted_oob:
  - 0.4702570735886503
  - 0.47904952989111926
  - 0.4760000071982534
  - 0.45943539889668494
  - 0.4812100171531513
  train_level4__f1_macro:
  - 0.3881563058493938
  - 0.3987350634802092
  - 0.3947809373613917
  - 0.3926699029126214
  - 0.3938903599097775
  train_level4__f1_macro_masked:
  - 0.3538426213680533
  - 0.3652576974330803
  - 0.36047620721800055
  - 0.3591256048209558
  - 0.3599423405520179
  train_level4__f1_macro_oob:
  - 0.3843404337535622
  - 0.39479088872292767
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.3899676375404532
  train_level4__f1_micro:
  - 0.3881563058493938
  - 0.3987350634802091
  - 0.39478093736139175
  - 0.3926699029126214
  - 0.3938903599097774
  train_level4__f1_micro_masked:
  - 0.34647594278283483
  - 0.35798652995577
  - 0.35437935880777494
  - 0.352178233355996
  - 0.3527733755942948
  train_level4__f1_micro_oob:
  - 0.3843404337535623
  - 0.39479088872292756
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.38996763754045305
  train_level4__f1_samples:
  - 0.38815630584939376
  - 0.39873506348020915
  - 0.39478093736139175
  - 0.3926699029126213
  - 0.39389035990977733
  train_level4__f1_samples_masked:
  - 0.34706269660388467
  - 0.3585927850307261
  - 0.3549992040185715
  - 0.3525672777120157
  - 0.3533525860638678
  train_level4__f1_samples_oob:
  - 0.3843404337535622
  - 0.39479088872292745
  - 0.38899019269626933
  - 0.38883495145631064
  - 0.38996763754045305
  train_level4__f1_weighted:
  - 0.49366552251661594
  - 0.5031133704201036
  - 0.48454253211436865
  - 0.4920161124266447
  - 0.49501250104131406
  train_level4__f1_weighted_masked:
  - 0.4522193927047899
  - 0.4626164948039965
  - 0.44238249668580015
  - 0.45086881620881697
  - 0.4550292975610244
  train_level4__f1_weighted_oob:
  - 0.4889768213197579
  - 0.4986584020717438
  - 0.47766858964397957
  - 0.4871293627097704
  - 0.4907665758746248
  train_level4__fn_macro:
  - -0.030333768052939185
  - -0.029522964899178494
  - -0.028830515992311862
  - -0.036359223300970876
  - -0.030352064332646853
  train_level4__fn_macro_masked:
  - -0.02912449079165754
  - -0.027878326565300503
  - -0.02738596905433017
  - -0.03487090014022312
  - -0.028538486049934524
  train_level4__fn_macro_oob:
  - -0.030937545283292275
  - -0.03017643764002987
  - -0.03043221132521808
  - -0.037160194174757286
  - -0.030548200451113075
  train_level4__fn_micro:
  - -0.03033376805293919
  - -0.02952296489917849
  - -0.028830515992311862
  - -0.036359223300970876
  - -0.030352064332646856
  train_level4__fn_micro_masked:
  - -0.027308192457737322
  - -0.02636208283071974
  - -0.025350693431624726
  - -0.03268657496992835
  - -0.02694136291600634
  train_level4__fn_micro_oob:
  - -0.030937545283292275
  - -0.030176437640029873
  - -0.030432211325218075
  - -0.03716019417475728
  - -0.03054820045111307
  train_level4__fn_samples:
  - -0.03033376805293918
  - -0.02952296489917849
  - -0.028830515992311855
  - -0.03635922330097086
  - -0.030352064332646856
  train_level4__fn_samples_masked:
  - -0.027211273462266268
  - -0.02627875186968491
  - -0.02532224548104591
  - -0.03252332234634106
  - -0.02682323937346942
  train_level4__fn_samples_oob:
  - -0.030937545283292272
  - -0.03017643764002987
  - -0.03043221132521807
  - -0.03716019417475728
  - -0.03054820045111307
  train_level4__fn_weighted:
  - -0.053199377788062274
  - -0.04888739689238442
  - -0.05537057779964777
  - -0.06335709873365591
  - -0.05145040550615246
  train_level4__fn_weighted_masked:
  - -0.053406603099112035
  - -0.04809197020105832
  - -0.05478977706908459
  - -0.06369670455351077
  - -0.049722124212891766
  train_level4__fn_weighted_oob:
  - -0.05299163099232519
  - -0.049639363130634946
  - -0.057444900549052116
  - -0.06402089982497683
  - -0.051265605211737376
  train_level4__fp_macro:
  - -0.581509926097667
  - -0.5717419716206124
  - -0.5763885466462965
  - -0.5709708737864078
  - -0.5757575757575757
  train_level4__fp_macro_masked:
  - -0.6170328878402891
  - -0.6068639760016191
  - -0.6121378237276693
  - -0.606003495038821
  - -0.6115191733980475
  train_level4__fp_macro_oob:
  - -0.5847220209631455
  - -0.5750326736370425
  - -0.5805775959785127
  - -0.5740048543689321
  - -0.5794841620084338
  train_level4__fp_micro:
  - -0.581509926097667
  - -0.5717419716206124
  - -0.5763885466462964
  - -0.5709708737864078
  - -0.5757575757575758
  train_level4__fp_micro_masked:
  - -0.6262158647594278
  - -0.6156513872135102
  - -0.6202699477606004
  - -0.6151351916740756
  - -0.6202852614896989
  train_level4__fp_micro_oob:
  - -0.5847220209631454
  - -0.5750326736370426
  - -0.5805775959785127
  - -0.574004854368932
  - -0.5794841620084339
  train_level4__fp_samples:
  - -0.5815099260976669
  - -0.5717419716206125
  - -0.5763885466462964
  - -0.5709708737864078
  - -0.5757575757575758
  train_level4__fp_samples_masked:
  - -0.6257260299338491
  - -0.615128463099589
  - -0.6196785505003826
  - -0.6149093999416432
  - -0.6198241745626627
  train_level4__fp_samples_oob:
  - -0.5847220209631454
  - -0.5750326736370426
  - -0.5805775959785127
  - -0.574004854368932
  - -0.5794841620084338
  train_level4__fp_weighted:
  - -0.4531350996953218
  - -0.4479992326875119
  - -0.46008689008598364
  - -0.44462678883969936
  - -0.45353709345253346
  train_level4__fp_weighted_masked:
  - -0.49437400419609806
  - -0.4892915349949452
  - -0.5028277262451152
  - -0.48543447923767236
  - -0.4952485782260839
  train_level4__fp_weighted_oob:
  - -0.45803154768791693
  - -0.4517022347976213
  - -0.46488650980696833
  - -0.44884973746525275
  - -0.4579678189136378
  train_level4__jaccard_macro:
  - 0.2608213901002709
  - 0.26925235321393776
  - 0.2622250551830603
  - 0.2620371829527409
  - 0.263706267576303
  train_level4__jaccard_macro_masked:
  - 0.23303743654730572
  - 0.24195133930592438
  - 0.23467810276878
  - 0.23482236464629241
  - 0.23628216832961005
  train_level4__jaccard_macro_oob:
  - 0.2577801471188399
  - 0.26603883547442886
  - 0.25721436791545466
  - 0.25882295065586375
  - 0.260554511976436
  train_level4__jaccard_micro:
  - 0.2408151033862751
  - 0.24901254900817654
  - 0.24593586417573646
  - 0.24429947751502523
  - 0.24524500076324227
  train_level4__jaccard_micro_masked:
  - 0.20953789046525528
  - 0.2180168046649015
  - 0.21534693351380965
  - 0.21372349879395708
  - 0.21416201654800845
  train_level4__jaccard_micro_oob:
  - 0.23788454064396544
  - 0.24594358825239895
  - 0.24145737098106396
  - 0.24133775233504068
  - 0.2422110552763819
  train_level4__jaccard_samples:
  - 0.24486554161760576
  - 0.2534724700722753
  - 0.251018722707274
  - 0.24905301510242503
  - 0.25045468415839306
  train_level4__jaccard_samples_masked:
  - 0.21376139440213876
  - 0.22252430860073685
  - 0.22067865472707993
  - 0.21853996143064158
  - 0.21969603289722614
  train_level4__jaccard_samples_oob:
  - 0.24188447558991308
  - 0.2503891354053059
  - 0.2466246792899178
  - 0.24597475129934274
  - 0.2473753932714636
  train_level4__jaccard_weighted:
  - 0.3447031543129417
  - 0.3541540359588728
  - 0.33358465638588763
  - 0.3407113249472725
  - 0.3456298786433592
  train_level4__jaccard_weighted_masked:
  - 0.30714652993863195
  - 0.3170522774897063
  - 0.2964535965561198
  - 0.30356634663689946
  - 0.3096317504239095
  train_level4__jaccard_weighted_oob:
  - 0.34071219139336684
  - 0.3502084044511321
  - 0.32720022156640355
  - 0.336202748712182
  - 0.3420254780669976
  train_level4__label_ranking_average_precision_score:
  - 0.2599159568504067
  - 0.2607408122407924
  - 0.2706004571840769
  - 0.2583320295284615
  - 0.2686854360102397
  train_level4__label_ranking_average_precision_score_oob:
  - 0.25938493428817067
  - 0.26010513724998235
  - 0.2691252716117217
  - 0.2576063074915407
  - 0.26754095587479976
  train_level4__matthews_corrcoef_macro:
  - 0.1519291773759956
  - 0.1579194213320674
  - 0.15665510256968868
  - 0.1412165348346048
  - 0.15192917024057667
  train_level4__matthews_corrcoef_macro_masked:
  - 0.11955122928732673
  - 0.12603286344787823
  - 0.12589495361812073
  - 0.10707250985638299
  - 0.11972261301453221
  train_level4__matthews_corrcoef_macro_oob:
  - 0.14150599006372655
  - 0.15111574817601364
  - 0.14472511851147307
  - 0.1324313723276391
  - 0.14401063420110186
  train_level4__matthews_corrcoef_micro:
  - 0.11467753031701128
  - 0.12945206278172616
  - 0.12751821125405585
  - 0.0995794960173415
  - 0.12109160231844633
  train_level4__matthews_corrcoef_micro_masked:
  - 0.07705471904440314
  - 0.09235166315216
  - 0.09278218256268488
  - 0.060507751461483524
  - 0.08502206226369782
  train_level4__matthews_corrcoef_micro_oob:
  - 0.10817969232509754
  - 0.12277013383450713
  - 0.11542571803844993
  - 0.09246171193830088
  - 0.11592575678806659
  train_level4__matthews_corrcoef_samples:
  - 0.11094365060379308
  - 0.12356601658069635
  - 0.12268642975847692
  - 0.09700876856582928
  - 0.11611252951572341
  train_level4__matthews_corrcoef_samples_masked:
  - 0.07383145826340363
  - 0.08595838212048525
  - 0.08734044158783545
  - 0.05937420278707437
  - 0.08210859165654613
  train_level4__matthews_corrcoef_samples_oob:
  - 0.10494055359086564
  - 0.11781691850375571
  - 0.11084161063397036
  - 0.09063653439008888
  - 0.11126787709880477
  train_level4__matthews_corrcoef_weighted:
  - 0.19150108265677807
  - 0.19452116080202075
  - 0.18201652900470727
  - 0.17470355884966787
  - 0.18467728501640077
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.15157412142928792
  - 0.15675886709325823
  - 0.1455898158593677
  - 0.13307028567520904
  - 0.14713638030148607
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.17589494388656093
  - 0.1847774501353088
  - 0.16431222395710796
  - 0.16124104613209417
  - 0.175270615903734
  train_level4__ndcg:
  - 0.6102952544643272
  - 0.6061793694422295
  - 0.6125246544282194
  - 0.6076045696181506
  - 0.615157224006022
  train_level4__ndcg_oob:
  - 0.6117655006386238
  - 0.6074899103650714
  - 0.6125824789866473
  - 0.6083085083189175
  - 0.6154475900530848
  train_level4__neg_coverage_error:
  - -91.58955223880596
  - -91.83413461538461
  - -93.42639593908629
  - -91.93
  - -91.77020202020202
  train_level4__neg_coverage_error_oob:
  - -91.85572139303483
  - -92.15865384615384
  - -93.69035532994924
  - -92.3475
  - -92.3409090909091
  train_level4__neg_hamming_loss_macro:
  - -0.6118436941506062
  - -0.6012649365197908
  - -0.6052190626386083
  - -0.6073300970873786
  - -0.6061096400902225
  train_level4__neg_hamming_loss_macro_masked:
  - -0.6461573786319467
  - -0.6347423025669195
  - -0.6395237927819994
  - -0.6408743951790443
  - -0.6400576594479818
  train_level4__neg_hamming_loss_macro_oob:
  - -0.6156595662464378
  - -0.6052091112770723
  - -0.6110098073037307
  - -0.6111650485436892
  - -0.6100323624595468
  train_level4__neg_hamming_loss_micro:
  - -0.6118436941506062
  - -0.6012649365197908
  - -0.6052190626386083
  - -0.6073300970873786
  - -0.6061096400902226
  train_level4__neg_hamming_loss_micro_masked:
  - -0.6535240572171651
  - -0.64201347004423
  - -0.6456206411922251
  - -0.6478217666440039
  - -0.6472266244057052
  train_level4__neg_hamming_loss_micro_oob:
  - -0.6156595662464377
  - -0.6052091112770724
  - -0.6110098073037307
  - -0.6111650485436894
  - -0.610032362459547
  train_level4__neg_hamming_loss_samples:
  - -0.6118436941506061
  - -0.6012649365197908
  - -0.6052190626386083
  - -0.6073300970873786
  - -0.6061096400902226
  train_level4__neg_hamming_loss_samples_masked:
  - -0.6529373033961153
  - -0.641407214969274
  - -0.6450007959814285
  - -0.6474327222879844
  - -0.6466474139361321
  train_level4__neg_hamming_loss_samples_oob:
  - -0.6156595662464377
  - -0.6052091112770724
  - -0.6110098073037307
  - -0.6111650485436892
  - -0.6100323624595468
  train_level4__neg_hamming_loss_weighted:
  - -0.506334477483384
  - -0.4968866295798964
  - -0.5154574678856314
  - -0.5079838875733552
  - -0.504987498958686
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.54778060729521
  - -0.5373835051960035
  - -0.5576175033141998
  - -0.5491311837911831
  - -0.5449707024389756
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.5110231786802422
  - -0.5013415979282562
  - -0.5223314103560206
  - -0.5128706372902295
  - -0.5092334241253753
  train_level4__neg_label_ranking_loss:
  - -0.47000478908510424
  - -0.46162330503156856
  - -0.4443355292577778
  - -0.48056968088583785
  - -0.45680080742444606
  train_level4__neg_label_ranking_loss_oob:
  - -0.4747347643089624
  - -0.4659660675146674
  - -0.45073559377849254
  - -0.48523192848290647
  - -0.4624562236131029
  train_level4__precision_macro:
  - 0.3881563058493938
  - 0.3987350634802092
  - 0.3947809373613917
  - 0.3926699029126214
  - 0.3938903599097775
  train_level4__precision_macro_masked:
  - 0.3538426213680533
  - 0.3652576974330803
  - 0.36047620721800055
  - 0.3591256048209558
  - 0.3599423405520179
  train_level4__precision_macro_oob:
  - 0.3843404337535622
  - 0.39479088872292767
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.3899676375404532
  train_level4__precision_micro:
  - 0.3881563058493938
  - 0.3987350634802091
  - 0.39478093736139175
  - 0.3926699029126214
  - 0.3938903599097774
  train_level4__precision_micro_masked:
  - 0.34647594278283483
  - 0.35798652995577
  - 0.35437935880777494
  - 0.352178233355996
  - 0.3527733755942948
  train_level4__precision_micro_oob:
  - 0.3843404337535623
  - 0.39479088872292756
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.38996763754045305
  train_level4__precision_samples:
  - 0.38815630584939376
  - 0.39873506348020915
  - 0.39478093736139175
  - 0.3926699029126213
  - 0.39389035990977733
  train_level4__precision_samples_masked:
  - 0.34706269660388467
  - 0.3585927850307261
  - 0.3549992040185715
  - 0.3525672777120157
  - 0.3533525860638678
  train_level4__precision_samples_oob:
  - 0.3843404337535622
  - 0.39479088872292745
  - 0.38899019269626933
  - 0.38883495145631064
  - 0.38996763754045305
  train_level4__precision_weighted:
  - 0.49366552251661594
  - 0.5031133704201036
  - 0.48454253211436865
  - 0.4920161124266447
  - 0.49501250104131406
  train_level4__precision_weighted_masked:
  - 0.4522193927047899
  - 0.4626164948039965
  - 0.44238249668580015
  - 0.45086881620881697
  - 0.4550292975610244
  train_level4__precision_weighted_oob:
  - 0.4889768213197579
  - 0.4986584020717438
  - 0.47766858964397957
  - 0.4871293627097704
  - 0.4907665758746248
  train_level4__recall_macro:
  - 0.3881563058493938
  - 0.3987350634802092
  - 0.3947809373613917
  - 0.3926699029126214
  - 0.3938903599097775
  train_level4__recall_macro_masked:
  - 0.3538426213680533
  - 0.3652576974330803
  - 0.36047620721800055
  - 0.3591256048209558
  - 0.3599423405520179
  train_level4__recall_macro_oob:
  - 0.3843404337535622
  - 0.39479088872292767
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.3899676375404532
  train_level4__recall_micro:
  - 0.3881563058493938
  - 0.3987350634802091
  - 0.39478093736139175
  - 0.3926699029126214
  - 0.3938903599097774
  train_level4__recall_micro_masked:
  - 0.34647594278283483
  - 0.35798652995577
  - 0.35437935880777494
  - 0.352178233355996
  - 0.3527733755942948
  train_level4__recall_micro_oob:
  - 0.3843404337535623
  - 0.39479088872292756
  - 0.3889901926962693
  - 0.3888349514563107
  - 0.38996763754045305
  train_level4__recall_samples:
  - 0.38815630584939376
  - 0.39873506348020915
  - 0.39478093736139175
  - 0.3926699029126213
  - 0.39389035990977733
  train_level4__recall_samples_masked:
  - 0.34706269660388467
  - 0.3585927850307261
  - 0.3549992040185715
  - 0.3525672777120157
  - 0.3533525860638678
  train_level4__recall_samples_oob:
  - 0.3843404337535622
  - 0.39479088872292745
  - 0.38899019269626933
  - 0.38883495145631064
  - 0.38996763754045305
  train_level4__recall_weighted:
  - 0.49366552251661594
  - 0.5031133704201036
  - 0.48454253211436865
  - 0.4920161124266447
  - 0.49501250104131406
  train_level4__recall_weighted_masked:
  - 0.4522193927047899
  - 0.4626164948039965
  - 0.44238249668580015
  - 0.45086881620881697
  - 0.4550292975610244
  train_level4__recall_weighted_oob:
  - 0.4889768213197579
  - 0.4986584020717438
  - 0.47766858964397957
  - 0.4871293627097704
  - 0.4907665758746248
  train_level4__roc_auc_macro:
  - 0.6473367722565211
  - 0.6654347519117881
  - 0.6648509806079478
  - 0.6436196533437977
  - 0.6646315671610439
  train_level4__roc_auc_macro_masked:
  - 0.6229946959810488
  - 0.6408366699076549
  - 0.6438747786783409
  - 0.620007473986823
  - 0.6429454045471625
  train_level4__roc_auc_macro_oob:
  - 0.6389179640266842
  - 0.6572166202243266
  - 0.653724518269156
  - 0.6349298100099208
  - 0.6561820691185055
  train_level4__roc_auc_micro:
  - 0.555312968830276
  - 0.5596446929168867
  - 0.5772109044706932
  - 0.5444587952576023
  - 0.5641622750692086
  train_level4__roc_auc_micro_masked:
  - 0.5363418484739739
  - 0.5405994248046065
  - 0.5597260032191467
  - 0.5248027895008284
  - 0.5457814328537969
  train_level4__roc_auc_micro_oob:
  - 0.5515140037412366
  - 0.5557937864111011
  - 0.571976413985752
  - 0.5404515099930394
  - 0.5595932321499993
  train_level4__roc_auc_samples:
  - 0.5435630495911611
  - 0.5458142252454502
  - 0.5617704903943602
  - 0.5329738433721631
  - 0.552976553243009
  train_level4__roc_auc_samples_masked:
  - 0.5258347088670506
  - 0.5288184100429282
  - 0.544730002065922
  - 0.5160467506218859
  - 0.5373510169799326
  train_level4__roc_auc_samples_oob:
  - 0.5402926238832088
  - 0.5423839695781433
  - 0.5560576237312225
  - 0.5293534722048807
  - 0.5482544701811995
  train_level4__roc_auc_weighted:
  - 0.66559209517136
  - 0.6755411047367079
  - 0.6662046160008286
  - 0.6502252701420694
  - 0.6723477364753134
  train_level4__roc_auc_weighted_masked:
  - 0.6389704986411393
  - 0.6507742833735887
  - 0.643450260282457
  - 0.623110918601705
  - 0.647639259867834
  train_level4__roc_auc_weighted_oob:
  - 0.6559523609621479
  - 0.6647155999384073
  - 0.6547336543633213
  - 0.6404119335436966
  - 0.6624250199734785
  train_level4__tn_macro:
  - 0.18482828575568758
  - 0.19429144884241967
  - 0.19178453501552412
  - 0.19327669902912623
  - 0.18939393939393942
  train_level4__tn_macro_masked:
  - 0.20079945363412202
  - 0.21057186969946584
  - 0.20684466781655925
  - 0.20971954852152555
  - 0.20533085076976323
  train_level4__tn_macro_oob:
  - 0.18161619089020917
  - 0.19100074682598955
  - 0.18759548568330786
  - 0.19024271844660195
  - 0.18566735314308133
  train_level4__tn_micro:
  - 0.18482828575568758
  - 0.19429144884241972
  - 0.19178453501552412
  - 0.19327669902912623
  - 0.1893939393939394
  train_level4__tn_micro_masked:
  - 0.199037711313394
  - 0.20921290711700843
  - 0.2063854047890536
  - 0.20822655718843155
  - 0.20404120443740095
  train_level4__tn_micro_oob:
  - 0.18161619089020914
  - 0.19100074682598955
  - 0.18759548568330786
  - 0.19024271844660195
  - 0.1856673531430813
  train_level4__tn_samples:
  - 0.18482828575568752
  - 0.1942914488424197
  - 0.1917845350155241
  - 0.19327669902912617
  - 0.18939393939393936
  train_level4__tn_samples_masked:
  - 0.19931528821962008
  - 0.2095117146544553
  - 0.20672370249699798
  - 0.20835841100778854
  - 0.20428537506767297
  train_level4__tn_samples_oob:
  - 0.1816161908902091
  - 0.1910007468259895
  - 0.18759548568330786
  - 0.1902427184466019
  - 0.18566735314308125
  train_level4__tn_weighted:
  - 0.20155090182164115
  - 0.20613058699405334
  - 0.19188766877309305
  - 0.20610341809945434
  - 0.20004882313056443
  train_level4__tn_weighted_masked:
  - 0.22432431316322426
  - 0.22881132332726464
  - 0.21291486516420016
  - 0.22927048877117226
  - 0.22226530036711467
  train_level4__tn_weighted_oob:
  - 0.196654453829046
  - 0.202427584883944
  - 0.18708804905210816
  - 0.20188046947390093
  - 0.19561809766946
  train_level4__tp_macro:
  - 0.20332802009370626
  - 0.20444361463778937
  - 0.20299640234586763
  - 0.19939320388349516
  - 0.2044964205158379
  train_level4__tp_macro_masked:
  - 0.15304316773393128
  - 0.15468582773361436
  - 0.15363153940144125
  - 0.14940605629943024
  - 0.15461148978225478
  train_level4__tp_macro_oob:
  - 0.2027242428633532
  - 0.20379014189693803
  - 0.2013947070129614
  - 0.1985922330097087
  - 0.2043002843973717
  train_level4__tp_micro:
  - 0.20332802009370624
  - 0.2044436146377894
  - 0.20299640234586763
  - 0.19939320388349516
  - 0.204496420515838
  train_level4__tp_micro_masked:
  - 0.14743823146944082
  - 0.14877362283876155
  - 0.14799395401872134
  - 0.14395167616756446
  - 0.14873217115689383
  train_level4__tp_micro_oob:
  - 0.20272424286335314
  - 0.203790141896938
  - 0.20139470701296142
  - 0.19859223300970874
  - 0.20430028439737177
  train_level4__tp_samples:
  - 0.20332802009370618
  - 0.20444361463778934
  - 0.20299640234586758
  - 0.1993932038834951
  - 0.20449642051583794
  train_level4__tp_samples_masked:
  - 0.14774740838426453
  - 0.14908107037627075
  - 0.14827550152157354
  - 0.1442088667042271
  - 0.14906721099619485
  train_level4__tp_samples_oob:
  - 0.20272424286335308
  - 0.20379014189693795
  - 0.20139470701296136
  - 0.19859223300970869
  - 0.20430028439737175
  train_level4__tp_weighted:
  - 0.2921146206949748
  - 0.2969827834260502
  - 0.2926548633412756
  - 0.28591269432719035
  - 0.2949636779107495
  train_level4__tp_weighted_masked:
  - 0.22789507954156574
  - 0.23380517147673183
  - 0.2294676315216
  - 0.22159832743764468
  - 0.23276399719390978
  train_level4__tp_weighted_oob:
  - 0.29232236749071183
  - 0.2962308171877997
  - 0.2905805405918713
  - 0.28524889323586944
  - 0.29514847820516465
  train_level5__average_precision_macro:
  - 0.33985368375402725
  - 0.35786318835349656
  - 0.3527093505895193
  - 0.3354196923444035
  - 0.35445959036404157
  train_level5__average_precision_macro_masked:
  - 0.26495071217723787
  - 0.28055830132564297
  - 0.27808957660238
  - 0.260118813255255
  - 0.27677958018242654
  train_level5__average_precision_macro_oob:
  - 0.33393594386027126
  - 0.35181596467767823
  - 0.34342939845160875
  - 0.33003116508103464
  - 0.3466184295217778
  train_level5__average_precision_micro:
  - 0.24441291637005716
  - 0.24465919625526536
  - 0.25456049462079544
  - 0.2406142673474106
  - 0.25188092810662455
  train_level5__average_precision_micro_masked:
  - 0.17703180866554288
  - 0.17719629880072765
  - 0.18559545797831312
  - 0.1744953915630818
  - 0.18267107903104818
  train_level5__average_precision_micro_oob:
  - 0.24339515303851159
  - 0.24405014192901128
  - 0.25283286072638683
  - 0.2400632761039734
  - 0.25047537424002836
  train_level5__average_precision_samples:
  - 0.2600451308228315
  - 0.2614909938788247
  - 0.2710087184538055
  - 0.25799053848711806
  - 0.2696855058210925
  train_level5__average_precision_samples_masked:
  - 0.1960307912713742
  - 0.19766786492985974
  - 0.20607451454360434
  - 0.19461105572142626
  - 0.2044329004022347
  train_level5__average_precision_samples_oob:
  - 0.25895899485163854
  - 0.2610045040679131
  - 0.2695316027298955
  - 0.2574248863741691
  - 0.26849306537811995
  train_level5__average_precision_weighted:
  - 0.47558629875945974
  - 0.4892999531651234
  - 0.48427984829571
  - 0.46431414130141546
  - 0.4878218675145321
  train_level5__average_precision_weighted_masked:
  - 0.38654496898745266
  - 0.4003622013344665
  - 0.3979739483862273
  - 0.3752707720090832
  - 0.39877936636313
  train_level5__average_precision_weighted_oob:
  - 0.4675282386736555
  - 0.48136643579924576
  - 0.47463597833371873
  - 0.45825475102703267
  - 0.47828542859102535
  train_level5__f1_macro:
  - 0.3887117809013185
  - 0.40046209858103055
  - 0.39569267162781524
  - 0.39339805825242724
  - 0.394552319309601
  train_level5__f1_macro_masked:
  - 0.35427224694821374
  - 0.3674091983258644
  - 0.3615641758338327
  - 0.35981650115095515
  - 0.36052802634501485
  train_level5__f1_macro_oob:
  - 0.38417137612906344
  - 0.3963078790141898
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.39102186917720905
  train_level5__f1_micro:
  - 0.38871178090131864
  - 0.4004620985810306
  - 0.3956926716278153
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__f1_micro_masked:
  - 0.3469440832249675
  - 0.36009750703659027
  - 0.3554665747394659
  - 0.3529104126353224
  - 0.3533808769149498
  train_level5__f1_micro_oob:
  - 0.38417137612906344
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.391021869177209
  train_level5__f1_samples:
  - 0.3887117809013186
  - 0.40046209858103055
  - 0.3956926716278152
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__f1_samples_masked:
  - 0.34752225416770816
  - 0.3606792032350711
  - 0.35610479553530056
  - 0.3533395523584518
  - 0.35398017205023297
  train_level5__f1_samples_oob:
  - 0.3841713761290634
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553397
  - 0.391021869177209
  train_level5__f1_weighted:
  - 0.49390772237006186
  - 0.5049050450796086
  - 0.48523774992230395
  - 0.4921522701534026
  - 0.4954345627693576
  train_level5__f1_weighted_masked:
  - 0.4521353937463909
  - 0.4653130461421274
  - 0.4434753088759047
  - 0.45101622409596104
  - 0.4553213909180491
  train_level5__f1_weighted_oob:
  - 0.48794734338642715
  - 0.4997839535775945
  - 0.4784307123864774
  - 0.4884703490167816
  - 0.49179576324894214
  train_level5__fn_macro:
  - -0.030526976766652177
  - -0.029592979835698276
  - -0.028855157458971957
  - -0.03662621359223301
  - -0.030548200451113075
  train_level5__fn_macro_masked:
  - -0.029482506437119332
  - -0.027696676793547606
  - -0.027304327017758808
  - -0.03525443499161899
  - -0.028903024271851548
  train_level5__fn_macro_oob:
  - -0.03139641597836062
  - -0.030409820761762508
  - -0.030407569858557984
  - -0.03713592233009709
  - -0.03062175149553791
  train_level5__fn_micro:
  - -0.030526976766652177
  - -0.029592979835698283
  - -0.028855157458971957
  - -0.03662621359223301
  - -0.03054820045111307
  train_level5__fn_micro_masked:
  - -0.02764629388816645
  - -0.02618616807398472
  - -0.02527114104637904
  - -0.03302651534961561
  - -0.027258320126782885
  train_level5__fn_micro_oob:
  - -0.031396415978360626
  - -0.030409820761762508
  - -0.03040756985855798
  - -0.03713592233009709
  - -0.030621751495537905
  train_level5__fn_samples:
  - -0.03052697676665217
  - -0.029592979835698276
  - -0.02885515745897195
  - -0.03662621359223301
  - -0.03054820045111307
  train_level5__fn_samples_masked:
  - -0.027564550326437516
  - -0.026101871612885366
  - -0.02524331517791002
  - -0.03284976448760669
  - -0.02713829649730383
  train_level5__fn_samples_oob:
  - -0.031396415978360626
  - -0.030409820761762504
  - -0.03040756985855798
  - -0.03713592233009708
  - -0.030621751495537898
  train_level5__fn_weighted:
  - -0.05348760075591037
  - -0.04923988106656436
  - -0.05553784013605442
  - -0.0642049315350561
  - -0.05213160944448136
  train_level5__fn_weighted_masked:
  - -0.054026002791014924
  - -0.04782605789727456
  - -0.05467682891897007
  - -0.064658670339547
  - -0.05071394469276031
  train_level5__fn_weighted_oob:
  - -0.054400092560453556
  - -0.050431133704201034
  - -0.05793832444145171
  - -0.06428008854113045
  - -0.05192598286867
  train_level5__fp_macro:
  - -0.5807612423320292
  - -0.569944921583271
  - -0.5754521709132128
  - -0.5699757281553398
  - -0.5748994802392859
  train_level5__fp_macro_masked:
  - -0.616245246614667
  - -0.604894124880588
  - -0.6111314971484085
  - -0.6049290638574257
  - -0.6105689493831336
  train_level5__fp_macro_oob:
  - -0.584432207892576
  - -0.5732823002240478
  - -0.5793455226455079
  - -0.5728883495145631
  - -0.578356379327253
  train_level5__fp_micro:
  - -0.5807612423320292
  - -0.5699449215832711
  - -0.5754521709132128
  - -0.5699757281553398
  - -0.574899480239286
  train_level5__fp_micro_masked:
  - -0.6254096228868661
  - -0.613716324889425
  - -0.619262284214155
  - -0.6140630720150619
  - -0.6193608029582673
  train_level5__fp_micro_oob:
  - -0.584432207892576
  - -0.5732823002240478
  - -0.5793455226455079
  - -0.5728883495145631
  - -0.5783563793272531
  train_level5__fp_samples:
  - -0.5807612423320291
  - -0.569944921583271
  - -0.5754521709132128
  - -0.5699757281553398
  - -0.574899480239286
  train_level5__fp_samples_masked:
  - -0.6249131955058543
  - -0.6132189251520436
  - -0.6186518892867895
  - -0.6138106831539415
  - -0.6188815314524632
  train_level5__fp_samples_oob:
  - -0.584432207892576
  - -0.5732823002240478
  - -0.5793455226455079
  - -0.5728883495145631
  - -0.578356379327253
  train_level5__fp_weighted:
  - -0.45260467687402783
  - -0.4458550738538269
  - -0.45922440994164165
  - -0.4436427983115413
  - -0.4524338277861611
  train_level5__fp_weighted_masked:
  - -0.4938386034625941
  - -0.4868608959605981
  - -0.5018478622051252
  - -0.484325105564492
  - -0.49396466438919057
  train_level5__fp_weighted_oob:
  - -0.45765256405311944
  - -0.4497849127182044
  - -0.46363096317207086
  - -0.44724956244208786
  - -0.4562782538823879
  train_level5__jaccard_macro:
  - 0.2611607974724072
  - 0.27070337325110383
  - 0.26289007381446766
  - 0.26251777012000227
  - 0.2641465664795738
  train_level5__jaccard_macro_masked:
  - 0.23321904290643228
  - 0.24373824708467406
  - 0.2354649920145339
  - 0.23526548769877562
  - 0.23659668055595048
  train_level5__jaccard_macro_oob:
  - 0.25746858726254845
  - 0.2671101633843944
  - 0.2582348625695955
  - 0.2598006453977076
  - 0.2612660214759268
  train_level5__jaccard_micro:
  - 0.2412428616394622
  - 0.2503611188117367
  - 0.2466439345068043
  - 0.24486342760454435
  - 0.2457584411221233
  train_level5__jaccard_micro_masked:
  - 0.20988042794210196
  - 0.21958470615278522
  - 0.2161504103713498
  - 0.214263034228742
  - 0.2146099677579763
  train_level5__jaccard_micro_oob:
  - 0.2377550257828264
  - 0.24712217128720076
  - 0.24242656175853783
  - 0.24221729757435967
  - 0.24302497447696833
  train_level5__jaccard_samples:
  - 0.24527383568233124
  - 0.25475951071642455
  - 0.25180606849479104
  - 0.24962185374765222
  - 0.25100234131910126
  train_level5__jaccard_samples_masked:
  - 0.21408487302711798
  - 0.2240331339348689
  - 0.22156041526211054
  - 0.21909914502364067
  - 0.22019431788594976
  train_level5__jaccard_samples_oob:
  - 0.24181022892718648
  - 0.2514988715917293
  - 0.24762878312751366
  - 0.2468535322199414
  - 0.24815864771158952
  train_level5__jaccard_weighted:
  - 0.3447056274797536
  - 0.355769045718504
  - 0.33413242142330485
  - 0.34071112005125337
  - 0.3459017169438202
  train_level5__jaccard_weighted_masked:
  - 0.30683033569698953
  - 0.3195077113281915
  - 0.29731387718759844
  - 0.30361148005522254
  - 0.3097427784918943
  train_level5__jaccard_weighted_oob:
  - 0.33936388844503684
  - 0.35097926187713513
  - 0.3278861136210945
  - 0.33752979740746814
  - 0.3427705948281545
  train_level5__label_ranking_average_precision_score:
  - 0.2600451308228316
  - 0.26149099387882446
  - 0.2710087184538054
  - 0.25799053848711795
  - 0.26968550582109263
  train_level5__label_ranking_average_precision_score_oob:
  - 0.25895899485163865
  - 0.2610045040679132
  - 0.26953160272989535
  - 0.2574248863741692
  - 0.2684930653781202
  train_level5__matthews_corrcoef_macro:
  - 0.15097494260237992
  - 0.16018757892066954
  - 0.15722865025613383
  - 0.14267634193935055
  - 0.15326310801616883
  train_level5__matthews_corrcoef_macro_masked:
  - 0.11817231447260111
  - 0.1289400372965995
  - 0.12678103127986373
  - 0.10771120048118642
  - 0.12061304541776963
  train_level5__matthews_corrcoef_macro_oob:
  - 0.14097455435561584
  - 0.1534100061291383
  - 0.1469328651592328
  - 0.13525856183352897
  - 0.1483665784750625
  train_level5__matthews_corrcoef_micro:
  - 0.11465037970849681
  - 0.13114351572973493
  - 0.12845049567961142
  - 0.09955926654337616
  - 0.12117647276758603
  train_level5__matthews_corrcoef_micro_masked:
  - 0.07604989368939545
  - 0.09510793235052015
  - 0.09415614667577911
  - 0.05983347009405722
  - 0.08424770158548849
  train_level5__matthews_corrcoef_micro_oob:
  - 0.10640306664369645
  - 0.12368827708504532
  - 0.11694077936950523
  - 0.09388675591795187
  - 0.11688661030785684
  train_level5__matthews_corrcoef_samples:
  - 0.1110670003788817
  - 0.12520170131360622
  - 0.12360940470025535
  - 0.09699990633167759
  - 0.11588812024609092
  train_level5__matthews_corrcoef_samples_masked:
  - 0.07290806597747009
  - 0.08866931839878685
  - 0.08865393740302226
  - 0.059102379191128714
  - 0.08084461731229503
  train_level5__matthews_corrcoef_samples_oob:
  - 0.10336888560492731
  - 0.11805533605147651
  - 0.11189102167287177
  - 0.09235993196898881
  - 0.11143593377605907
  train_level5__matthews_corrcoef_weighted:
  - 0.18992918484971058
  - 0.19810016048370493
  - 0.18276991666125417
  - 0.174917296674495
  - 0.186548220092701
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.1494153499151369
  - 0.1615639064917245
  - 0.14707968872132354
  - 0.1325160746189845
  - 0.14823928078206466
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.17443866834205463
  - 0.18783544167141814
  - 0.1669065415307533
  - 0.16464193028153098
  - 0.18096821616427408
  train_level5__ndcg:
  - 0.6118657478020195
  - 0.6057652669410415
  - 0.6130955937225973
  - 0.6076749040440197
  - 0.6178166381195807
  train_level5__ndcg_oob:
  - 0.6121983648278331
  - 0.6071916805315453
  - 0.6130867995239203
  - 0.6085813822169921
  - 0.6181621433472542
  train_level5__neg_coverage_error:
  - -91.65671641791045
  - -92.00240384615384
  - -93.38578680203045
  - -92.0275
  - -91.60858585858585
  train_level5__neg_coverage_error_oob:
  - -92.0223880597015
  - -92.38701923076923
  - -93.6751269035533
  - -92.4875
  - -92.22474747474747
  train_level5__neg_hamming_loss_macro:
  - -0.6112882190986814
  - -0.5995379014189693
  - -0.6043073283721848
  - -0.6066019417475728
  - -0.6054476806903991
  train_level5__neg_hamming_loss_macro_masked:
  - -0.6457277530517861
  - -0.6325908016741357
  - -0.6384358241661674
  - -0.6401834988490448
  - -0.639471973654985
  train_level5__neg_hamming_loss_macro_oob:
  - -0.6158286238709366
  - -0.6036921209858103
  - -0.6097530925040658
  - -0.6100242718446601
  - -0.608978130822791
  train_level5__neg_hamming_loss_micro:
  - -0.6112882190986814
  - -0.5995379014189693
  - -0.6043073283721847
  - -0.6066019417475729
  - -0.6054476806903991
  train_level5__neg_hamming_loss_micro_masked:
  - -0.6530559167750325
  - -0.6399024929634097
  - -0.644533425260534
  - -0.6470895873646776
  - -0.6466191230850502
  train_level5__neg_hamming_loss_micro_oob:
  - -0.6158286238709366
  - -0.6036921209858103
  - -0.6097530925040658
  - -0.6100242718446602
  - -0.6089781308227911
  train_level5__neg_hamming_loss_samples:
  - -0.6112882190986813
  - -0.5995379014189693
  - -0.6043073283721847
  - -0.6066019417475728
  - -0.6054476806903991
  train_level5__neg_hamming_loss_samples_masked:
  - -0.6524777458322919
  - -0.639320796764929
  - -0.6438952044646995
  - -0.6466604476415482
  - -0.646019827949767
  train_level5__neg_hamming_loss_samples_oob:
  - -0.6158286238709365
  - -0.6036921209858103
  - -0.6097530925040658
  - -0.6100242718446601
  - -0.608978130822791
  train_level5__neg_hamming_loss_weighted:
  - -0.5060922776299381
  - -0.4950949549203914
  - -0.514762250077696
  - -0.5078477298465974
  - -0.5045654372306424
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.5478646062536091
  - -0.5346869538578726
  - -0.5565246911240953
  - -0.548983775904039
  - -0.544678609081951
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.5120526566135729
  - -0.5002160464224055
  - -0.5215692876135226
  - -0.5115296509832183
  - -0.5082042367510577
  train_level5__neg_label_ranking_loss:
  - -0.46939060342725664
  - -0.460130858955695
  - -0.4440692592940827
  - -0.48088116836111316
  - -0.4565478128225817
  train_level5__neg_label_ranking_loss_oob:
  - -0.4742307562219097
  - -0.46416104411363557
  - -0.449773625536792
  - -0.4855629389801169
  - -0.46212232033910194
  train_level5__precision_macro:
  - 0.3887117809013185
  - 0.40046209858103055
  - 0.39569267162781524
  - 0.39339805825242724
  - 0.394552319309601
  train_level5__precision_macro_masked:
  - 0.35427224694821374
  - 0.3674091983258644
  - 0.3615641758338327
  - 0.35981650115095515
  - 0.36052802634501485
  train_level5__precision_macro_oob:
  - 0.38417137612906344
  - 0.3963078790141898
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.39102186917720905
  train_level5__precision_micro:
  - 0.38871178090131864
  - 0.4004620985810306
  - 0.3956926716278153
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__precision_micro_masked:
  - 0.3469440832249675
  - 0.36009750703659027
  - 0.3554665747394659
  - 0.3529104126353224
  - 0.3533808769149498
  train_level5__precision_micro_oob:
  - 0.38417137612906344
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.391021869177209
  train_level5__precision_samples:
  - 0.3887117809013186
  - 0.40046209858103055
  - 0.3956926716278152
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__precision_samples_masked:
  - 0.34752225416770816
  - 0.3606792032350711
  - 0.35610479553530056
  - 0.3533395523584518
  - 0.35398017205023297
  train_level5__precision_samples_oob:
  - 0.3841713761290634
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553397
  - 0.391021869177209
  train_level5__precision_weighted:
  - 0.49390772237006186
  - 0.5049050450796086
  - 0.48523774992230395
  - 0.4921522701534026
  - 0.4954345627693576
  train_level5__precision_weighted_masked:
  - 0.4521353937463909
  - 0.4653130461421274
  - 0.4434753088759047
  - 0.45101622409596104
  - 0.4553213909180491
  train_level5__precision_weighted_oob:
  - 0.48794734338642715
  - 0.4997839535775945
  - 0.4784307123864774
  - 0.4884703490167816
  - 0.49179576324894214
  train_level5__recall_macro:
  - 0.3887117809013185
  - 0.40046209858103055
  - 0.39569267162781524
  - 0.39339805825242724
  - 0.394552319309601
  train_level5__recall_macro_masked:
  - 0.35427224694821374
  - 0.3674091983258644
  - 0.3615641758338327
  - 0.35981650115095515
  - 0.36052802634501485
  train_level5__recall_macro_oob:
  - 0.38417137612906344
  - 0.3963078790141898
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.39102186917720905
  train_level5__recall_micro:
  - 0.38871178090131864
  - 0.4004620985810306
  - 0.3956926716278153
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__recall_micro_masked:
  - 0.3469440832249675
  - 0.36009750703659027
  - 0.3554665747394659
  - 0.3529104126353224
  - 0.3533808769149498
  train_level5__recall_micro_oob:
  - 0.38417137612906344
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553398
  - 0.391021869177209
  train_level5__recall_samples:
  - 0.3887117809013186
  - 0.40046209858103055
  - 0.3956926716278152
  - 0.3933980582524272
  - 0.3945523193096009
  train_level5__recall_samples_masked:
  - 0.34752225416770816
  - 0.3606792032350711
  - 0.35610479553530056
  - 0.3533395523584518
  - 0.35398017205023297
  train_level5__recall_samples_oob:
  - 0.3841713761290634
  - 0.3963078790141897
  - 0.39024690749593416
  - 0.3899757281553397
  - 0.391021869177209
  train_level5__recall_weighted:
  - 0.49390772237006186
  - 0.5049050450796086
  - 0.48523774992230395
  - 0.4921522701534026
  - 0.4954345627693576
  train_level5__recall_weighted_masked:
  - 0.4521353937463909
  - 0.4653130461421274
  - 0.4434753088759047
  - 0.45101622409596104
  - 0.4553213909180491
  train_level5__recall_weighted_oob:
  - 0.48794734338642715
  - 0.4997839535775945
  - 0.4784307123864774
  - 0.4884703490167816
  - 0.49179576324894214
  train_level5__roc_auc_macro:
  - 0.6467333905863337
  - 0.6665727497604003
  - 0.6649917163467253
  - 0.6433436473715809
  - 0.6659171918181214
  train_level5__roc_auc_macro_masked:
  - 0.6225182529064517
  - 0.6420288451225451
  - 0.6441034084065757
  - 0.6199377150493318
  - 0.6437140963754826
  train_level5__roc_auc_macro_oob:
  - 0.6385786676099364
  - 0.6588143553393269
  - 0.6541850531438633
  - 0.6353413320521831
  - 0.6573806417135176
  train_level5__roc_auc_micro:
  - 0.5554819523323363
  - 0.56077355281935
  - 0.5779447793905527
  - 0.5442203139788953
  - 0.5659123209989746
  train_level5__roc_auc_micro_masked:
  - 0.536481212535487
  - 0.5414190896722668
  - 0.5604994675795607
  - 0.524412840875643
  - 0.5472288383902305
  train_level5__roc_auc_micro_oob:
  - 0.5514336366176361
  - 0.5573322201305985
  - 0.5727783336421115
  - 0.5406665373129449
  - 0.5613017445189372
  train_level5__roc_auc_samples:
  - 0.5444089773598229
  - 0.5468568466254697
  - 0.562410075030699
  - 0.5327953740827659
  - 0.5546079070938335
  train_level5__roc_auc_samples_masked:
  - 0.5267428371926071
  - 0.5294235317372684
  - 0.545208875777228
  - 0.5157345364679048
  - 0.5386345258297371
  train_level5__roc_auc_samples_oob:
  - 0.5405749389828514
  - 0.543907609996247
  - 0.557289114181877
  - 0.5294579155288638
  - 0.5498435667596745
  train_level5__roc_auc_weighted:
  - 0.6649693748601444
  - 0.6768422124288936
  - 0.6666083385958363
  - 0.6498752049378864
  - 0.6739976482964628
  train_level5__roc_auc_weighted_masked:
  - 0.6382761871234452
  - 0.6518705882042228
  - 0.644129082574905
  - 0.6226033064324519
  - 0.6487936062412902
  train_level5__roc_auc_weighted_oob:
  - 0.655428958894083
  - 0.6665961132586816
  - 0.6555423016059708
  - 0.6407733800193758
  - 0.6639242938097866
  train_level5__tn_macro:
  - 0.1855769695213254
  - 0.19608849887976096
  - 0.19272091074860773
  - 0.19427184466019418
  - 0.1902520349122291
  train_level5__tn_macro_masked:
  - 0.20158709485974421
  - 0.21254172082049702
  - 0.20785099439582008
  - 0.21079397970292083
  - 0.20628107478467717
  train_level5__tn_macro_oob:
  - 0.18190600396077863
  - 0.1927511202389843
  - 0.18882755901631265
  - 0.19135922330097088
  - 0.18679513582426208
  train_level5__tn_micro:
  - 0.1855769695213254
  - 0.19608849887976101
  - 0.19272091074860775
  - 0.19427184466019418
  - 0.19025203491222908
  train_level5__tn_micro_masked:
  - 0.1998439531859558
  - 0.21114796944109368
  - 0.20739306833549892
  - 0.20929867684744521
  - 0.20496566296883253
  train_level5__tn_micro_oob:
  - 0.18190600396077863
  - 0.19275112023898433
  - 0.18882755901631265
  - 0.19135922330097088
  - 0.18679513582426205
  train_level5__tn_samples:
  - 0.18557696952132535
  - 0.19608849887976096
  - 0.19272091074860773
  - 0.19427184466019412
  - 0.19025203491222906
  train_level5__tn_samples_masked:
  - 0.20012812264761484
  - 0.2114212526020008
  - 0.20775036371059108
  - 0.20945712779549033
  - 0.20522801817787253
  train_level5__tn_samples_oob:
  - 0.1819060039607786
  - 0.19275112023898427
  - 0.18882755901631262
  - 0.1913592233009708
  - 0.18679513582426202
  train_level5__tn_weighted:
  - 0.2020813246429352
  - 0.20827474582773833
  - 0.192750148917435
  - 0.2070874086276125
  - 0.2011520887969369
  train_level5__tn_weighted_masked:
  - 0.22485971389672813
  - 0.23124196236161174
  - 0.2138947292041902
  - 0.23037986244435257
  - 0.22354921420400795
  train_level5__tn_weighted_oob:
  - 0.19703343746384358
  - 0.20434490696336088
  - 0.18834359568700576
  - 0.20348064449706577
  - 0.19730766270070998
  train_level5__tp_macro:
  - 0.20313481137999329
  - 0.20437359970126964
  - 0.20297176087920757
  - 0.19912621359223298
  - 0.20430028439737172
  train_level5__tp_macro_masked:
  - 0.1526851520884695
  - 0.15486747750536725
  - 0.15371318143801257
  - 0.14902252144803438
  - 0.15424695156033774
  train_level5__tp_macro_oob:
  - 0.2022653721682848
  - 0.2035567587752054
  - 0.2014193484796215
  - 0.19861650485436888
  - 0.20422673335294692
  train_level5__tp_micro:
  - 0.20313481137999323
  - 0.20437359970126961
  - 0.20297176087920754
  - 0.199126213592233
  - 0.20430028439737177
  train_level5__tp_micro_masked:
  - 0.1471001300390117
  - 0.1489495375954966
  - 0.14807350640396702
  - 0.1436117357878772
  - 0.14841521394611729
  train_level5__tp_micro_oob:
  - 0.2022653721682848
  - 0.20355675877520538
  - 0.2014193484796215
  - 0.19861650485436894
  - 0.20422673335294694
  train_level5__tp_samples:
  - 0.2031348113799932
  - 0.2043735997012696
  - 0.20297176087920749
  - 0.19912621359223295
  - 0.20430028439737175
  train_level5__tp_samples_masked:
  - 0.1473941315200933
  - 0.1492579506330703
  - 0.14835443182470942
  - 0.14388242456296146
  - 0.14875215387236046
  train_level5__tp_samples_oob:
  - 0.20226537216828475
  - 0.20355675877520535
  - 0.20141934847962145
  - 0.19861650485436885
  - 0.2042267333529469
  train_level5__tp_weighted:
  - 0.2918263977271266
  - 0.2966302992518703
  - 0.29248760100486904
  - 0.2850648615257902
  - 0.2942824739724207
  train_level5__tp_weighted_masked:
  - 0.22727567984966285
  - 0.2340710837805156
  - 0.22958057967171452
  - 0.22063636165160846
  - 0.23177217671404124
  train_level5__tp_weighted_oob:
  - 0.29091390592258354
  - 0.29543904661423354
  - 0.2900871166994717
  - 0.2849897045197158
  - 0.29448810054823205
  train_level6__average_precision_macro:
  - 0.3410780366949429
  - 0.35614897543069485
  - 0.3531877271196627
  - 0.33611715439640655
  - 0.35431687388397426
  train_level6__average_precision_macro_masked:
  - 0.26611587755120236
  - 0.2799270417957909
  - 0.2795035215375447
  - 0.26127234780841413
  - 0.2762622609803919
  train_level6__average_precision_macro_oob:
  - 0.33417320919145643
  - 0.35174223233618396
  - 0.34401436767811533
  - 0.3300204896621316
  - 0.3476006407580678
  train_level6__average_precision_micro:
  - 0.2458456278839643
  - 0.2464779054329614
  - 0.25554287830947975
  - 0.24237062793238345
  - 0.25273359533659273
  train_level6__average_precision_micro_masked:
  - 0.1780602655007152
  - 0.17854731593111112
  - 0.18597454036518948
  - 0.17575365694169567
  - 0.18335279834641485
  train_level6__average_precision_micro_oob:
  - 0.24504042220949132
  - 0.24605077778900003
  - 0.2540757078145029
  - 0.2416679021938623
  - 0.25161239935591306
  train_level6__average_precision_samples:
  - 0.26111256811673056
  - 0.2627332712450677
  - 0.27217013887763525
  - 0.25940589802355674
  - 0.27098829385326495
  train_level6__average_precision_samples_masked:
  - 0.19673724538474954
  - 0.1984244504316307
  - 0.20670568671399678
  - 0.19554361337967494
  - 0.20537421870003217
  train_level6__average_precision_samples_oob:
  - 0.2602834264009359
  - 0.26240570028280535
  - 0.27058067825150184
  - 0.25886040090127876
  - 0.26971608528116825
  train_level6__average_precision_weighted:
  - 0.47694492231247093
  - 0.4885186414287853
  - 0.4841643196447996
  - 0.4656437058959127
  - 0.48761579854502424
  train_level6__average_precision_weighted_masked:
  - 0.3878746776192875
  - 0.40093694031022853
  - 0.3977826338403311
  - 0.3773003474545148
  - 0.398438725605918
  train_level6__average_precision_weighted_oob:
  - 0.4683316618009337
  - 0.4821797429921258
  - 0.47505695193432423
  - 0.4588640459696375
  - 0.47906365338513524
  train_level6__f1_macro:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.39499999999999996
  - 0.3957781700500148
  train_level6__f1_macro_masked:
  - 0.3553386977570299
  - 0.3698294983670241
  - 0.3634710150146327
  - 0.3613215299789716
  - 0.3619882578245185
  train_level6__f1_macro_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544123
  - 0.39116504854368944
  - 0.39290967931744636
  train_level6__f1_micro:
  - 0.38982273100516834
  - 0.40295929798356983
  - 0.39761470602730276
  - 0.395
  - 0.3957781700500147
  train_level6__f1_micro_masked:
  - 0.3480104031209363
  - 0.36261057498994775
  - 0.3573493145236138
  - 0.3544270697139271
  - 0.35486001056524036
  train_level6__f1_micro_oob:
  - 0.385258175143699
  - 0.3988284167289022
  - 0.39209501749544134
  - 0.39116504854368933
  - 0.3929096793174463
  train_level6__f1_samples:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.395
  - 0.3957781700500147
  train_level6__f1_samples_masked:
  - 0.34857070273081736
  - 0.36318128756705487
  - 0.3579883137523701
  - 0.3548500546158529
  - 0.35547598354112214
  train_level6__f1_samples_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544134
  - 0.3911650485436893
  - 0.3929096793174463
  train_level6__f1_weighted:
  - 0.49512694923316236
  - 0.5064785152503357
  - 0.48750091724507066
  - 0.4938219396684856
  - 0.49633167461228855
  train_level6__f1_weighted_masked:
  - 0.4532074570753751
  - 0.466501480279559
  - 0.445714106563882
  - 0.45235768251347824
  - 0.4565263574152267
  train_level6__f1_weighted_oob:
  - 0.4885484721097355
  - 0.5019367446767696
  - 0.48077184554024655
  - 0.4898991042932152
  - 0.49320140543128344
  train_level6__fn_macro:
  - -0.03050282567743805
  - -0.02966299477221807
  - -0.028781233058991672
  - -0.03640776699029127
  - -0.030915955673237232
  train_level6__fn_macro_masked:
  - -0.029587590595416505
  - -0.0279953649480707
  - -0.02740516823932595
  - -0.03522379391872383
  - -0.029176533295643632
  train_level6__fn_macro_oob:
  - -0.031348113799932374
  - -0.030573188946975353
  - -0.03003794785865655
  - -0.036844660194174754
  - -0.031112091791703444
  train_level6__fn_micro:
  - -0.03050282567743805
  - -0.029662994772218072
  - -0.028781233058991672
  - -0.03640776699029126
  - -0.03091595567323723
  train_level6__fn_micro_masked:
  - -0.02775032509752926
  - -0.026437474869320465
  - -0.025377210893373286
  - -0.03300036608963966
  - -0.02749603803486529
  train_level6__fn_micro_oob:
  - -0.031348113799932374
  - -0.030573188946975353
  - -0.030037947858656548
  - -0.036844660194174754
  - -0.031112091791703444
  train_level6__fn_samples:
  - -0.030502825677438047
  - -0.02966299477221807
  - -0.02878123305899167
  - -0.03640776699029126
  - -0.03091595567323722
  train_level6__fn_samples_masked:
  - -0.027666168157884922
  - -0.026354098746582403
  - -0.025348412137727233
  - -0.03283174690477835
  - -0.02736892755980856
  train_level6__fn_samples_oob:
  - -0.03134811379993237
  - -0.030573188946975353
  - -0.03003794785865654
  - -0.036844660194174754
  - -0.03111209179170344
  train_level6__fn_weighted:
  - -0.05333436178281718
  - -0.04966789756378285
  - -0.05526563417245071
  - -0.06373082466797075
  - -0.0529678241861142
  train_level6__fn_weighted_masked:
  - -0.05414292867077504
  - -0.04876350089237119
  - -0.05470996371271883
  - -0.06456715723127908
  - -0.05146643560311289
  train_level6__fn_weighted_oob:
  - -0.05454201858922443
  - -0.051099175139075394
  - -0.05721963595082704
  - -0.06380186348193143
  - -0.05275191628151228
  train_level6__fp_macro:
  - -0.5796744433173937
  - -0.5673777072442121
  - -0.5736040609137056
  - -0.5685922330097087
  - -0.573305874276748
  train_level6__fp_macro_masked:
  - -0.6150737116475535
  - -0.6021751366849052
  - -0.6091238167460413
  - -0.6034546761023044
  - -0.6088352088798379
  train_level6__fp_macro_oob:
  - -0.5833937110563686
  - -0.5705983943241225
  - -0.5778670346459022
  - -0.571990291262136
  - -0.5759782288908502
  train_level6__fp_micro:
  - -0.5796744433173936
  - -0.5673777072442121
  - -0.5736040609137056
  - -0.5685922330097087
  - -0.5733058742767481
  train_level6__fp_micro_masked:
  - -0.6242392717815345
  - -0.6109519501407318
  - -0.617273474583013
  - -0.6125725641964332
  - -0.6176439513998944
  train_level6__fp_micro_oob:
  - -0.5833937110563686
  - -0.5705983943241225
  - -0.5778670346459022
  - -0.571990291262136
  - -0.5759782288908503
  train_level6__fp_samples:
  - -0.5796744433173936
  - -0.5673777072442121
  - -0.5736040609137056
  - -0.5685922330097087
  - -0.5733058742767481
  train_level6__fp_samples_masked:
  - -0.6237631291112977
  - -0.6104646136863627
  - -0.6166632741099026
  - -0.6123181984793686
  - -0.6171550888990693
  train_level6__fp_samples_oob:
  - -0.5833937110563687
  - -0.5705983943241224
  - -0.5778670346459021
  - -0.5719902912621359
  - -0.5759782288908503
  train_level6__fp_weighted:
  - -0.4515386889840205
  - -0.44385358718588147
  - -0.4572334485824786
  - -0.44244723566354377
  - -0.45070050120159744
  train_level6__fp_weighted_masked:
  - -0.4926496142538499
  - -0.48473501882806985
  - -0.49957592972339915
  - -0.48307516025524266
  - -0.49200720698166045
  train_level6__fp_weighted_oob:
  - -0.45690950930104
  - -0.44696408018415495
  - -0.4620085185089264
  - -0.44629903222485323
  - -0.45404667828720446
  train_level6__jaccard_macro:
  - 0.2620124107783699
  - 0.27249335078010367
  - 0.2644854284522868
  - 0.26388746213439257
  - 0.2651374193568304
  train_level6__jaccard_macro_masked:
  - 0.23395598382947536
  - 0.24533754315225464
  - 0.2369613320958675
  - 0.2364805193025858
  - 0.23775569299121496
  train_level6__jaccard_macro_oob:
  - 0.25807749960232496
  - 0.2691246343903931
  - 0.2598566451823223
  - 0.2607700597160204
  - 0.2627090880426413
  train_level6__jaccard_micro:
  - 0.2420992635478694
  - 0.2523162355691948
  - 0.24813926308667036
  - 0.24610591900311526
  - 0.24671037549860161
  train_level6__jaccard_micro_masked:
  - 0.21066137691084558
  - 0.22145652674391836
  - 0.21754431278855776
  - 0.21538217066581916
  - 0.2157020149313639
  train_level6__jaccard_micro_oob:
  - 0.23858809452587496
  - 0.2490853702974915
  - 0.2438545944951879
  - 0.24313559833443968
  - 0.24448512585812357
  train_level6__jaccard_samples:
  - 0.24614917960402483
  - 0.2567655278500341
  - 0.2533103126895247
  - 0.25071166508675163
  - 0.2519617922369708
  train_level6__jaccard_samples_masked:
  - 0.21488593037223933
  - 0.22597626234597382
  - 0.22297375951358686
  - 0.22007402346385746
  - 0.2212881880264531
  train_level6__jaccard_samples_oob:
  - 0.24264290694601365
  - 0.2534424992178052
  - 0.2491426317363794
  - 0.24772057967902897
  - 0.2496508285088131
  train_level6__jaccard_weighted:
  - 0.3456568780629258
  - 0.3568111668512303
  - 0.3362730218158802
  - 0.34222984825163577
  - 0.34665495233082505
  train_level6__jaccard_weighted_masked:
  - 0.30756787983082545
  - 0.3200515785085056
  - 0.2992816820763708
  - 0.30475598708374224
  - 0.31078018942376223
  train_level6__jaccard_weighted_oob:
  - 0.3395182801760902
  - 0.3527304206312986
  - 0.33009174247197304
  - 0.33882804659121035
  - 0.3439008794892561
  train_level6__label_ranking_average_precision_score:
  - 0.26111256811673045
  - 0.26273327124506773
  - 0.27217013887763525
  - 0.2594058980235566
  - 0.27098829385326495
  train_level6__label_ranking_average_precision_score_oob:
  - 0.2602834264009356
  - 0.2624057002828052
  - 0.27058067825150184
  - 0.25886040090127876
  - 0.26971608528116847
  train_level6__matthews_corrcoef_macro:
  - 0.1526881872693371
  - 0.1632420961018448
  - 0.15991988815287242
  - 0.14420281487919057
  - 0.1544370153522638
  train_level6__matthews_corrcoef_macro_masked:
  - 0.11928111189921081
  - 0.13106151088263165
  - 0.12856973207197256
  - 0.10873933844464437
  - 0.12209871298787246
  train_level6__matthews_corrcoef_macro_oob:
  - 0.14358135918505832
  - 0.15667354371518033
  - 0.1499048164505452
  - 0.13733724792619284
  - 0.14818463009625946
  train_level6__matthews_corrcoef_micro:
  - 0.11600867016355623
  - 0.13368477191153894
  - 0.1308461154161438
  - 0.10213624103152799
  - 0.1213204531671711
  train_level6__matthews_corrcoef_micro_masked:
  - 0.07664432554734987
  - 0.09640143170807051
  - 0.09546551938329736
  - 0.06145059262585479
  - 0.08465794585938545
  train_level6__matthews_corrcoef_micro_oob:
  - 0.10783451284338007
  - 0.12597218837745947
  - 0.12031200031301277
  - 0.09623394643719162
  - 0.11737996778719804
  train_level6__matthews_corrcoef_samples:
  - 0.1122506729173896
  - 0.1270178234007722
  - 0.12595658518137604
  - 0.09991723091818012
  - 0.1161511453154547
  train_level6__matthews_corrcoef_samples_masked:
  - 0.07363996770385188
  - 0.08942386839007219
  - 0.08995204704383576
  - 0.060927398736351196
  - 0.08104814581690446
  train_level6__matthews_corrcoef_samples_oob:
  - 0.1043606893139209
  - 0.12025664969388986
  - 0.11537079192759156
  - 0.09440702972995889
  - 0.11191716843149556
  train_level6__matthews_corrcoef_weighted:
  - 0.19330227323423566
  - 0.19878539853656477
  - 0.18682005964287396
  - 0.17591124859324908
  - 0.1880625123410398
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.15190319547559156
  - 0.1607673287034241
  - 0.15000625095099007
  - 0.1324281945462804
  - 0.14991106956082728
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.17741261879945533
  - 0.19290065424940744
  - 0.17203600582493223
  - 0.16773549715537428
  - 0.1804751858420741
  train_level6__ndcg:
  - 0.6135136440927582
  - 0.6092646153018044
  - 0.6152688363724339
  - 0.6097900690785673
  - 0.6191495744467499
  train_level6__ndcg_oob:
  - 0.6145285492224664
  - 0.6104378396681602
  - 0.6150543327370003
  - 0.6104581951612368
  - 0.6195640128130238
  train_level6__neg_coverage_error:
  - -91.72388059701493
  - -91.85817307692308
  - -93.29695431472081
  - -91.9675
  - -91.6540404040404
  train_level6__neg_coverage_error_oob:
  - -92.1094527363184
  - -92.22596153846153
  - -93.51522842639594
  - -92.4525
  - -92.25252525252525
  train_level6__neg_hamming_loss_macro:
  - -0.6101772689948317
  - -0.5970407020164301
  - -0.6023852939726974
  - -0.605
  - -0.6042218299499852
  train_level6__neg_hamming_loss_macro_masked:
  - -0.64466130224297
  - -0.6301705016329758
  - -0.6365289849853674
  - -0.6386784700210284
  - -0.6380117421754813
  train_level6__neg_hamming_loss_macro_oob:
  - -0.614741824856301
  - -0.6011715832710979
  - -0.6079049825045587
  - -0.6088349514563105
  - -0.6070903206825535
  train_level6__neg_hamming_loss_micro:
  - -0.6101772689948317
  - -0.5970407020164302
  - -0.6023852939726972
  - -0.605
  - -0.6042218299499853
  train_level6__neg_hamming_loss_micro_masked:
  - -0.6519895968790638
  - -0.6373894250100522
  - -0.6426506854763862
  - -0.6455729302860729
  - -0.6451399894347596
  train_level6__neg_hamming_loss_micro_oob:
  - -0.614741824856301
  - -0.6011715832710979
  - -0.6079049825045587
  - -0.6088349514563107
  - -0.6070903206825536
  train_level6__neg_hamming_loss_samples:
  - -0.6101772689948316
  - -0.5970407020164301
  - -0.6023852939726972
  - -0.605
  - -0.6042218299499853
  train_level6__neg_hamming_loss_samples_masked:
  - -0.6514292972691826
  - -0.6368187124329451
  - -0.6420116862476298
  - -0.6451499453841469
  - -0.6445240164588779
  train_level6__neg_hamming_loss_samples_oob:
  - -0.614741824856301
  - -0.6011715832710978
  - -0.6079049825045587
  - -0.6088349514563106
  - -0.6070903206825536
  train_level6__neg_hamming_loss_weighted:
  - -0.5048730507668376
  - -0.49352148474966434
  - -0.5124990827549294
  - -0.5061780603315145
  - -0.5036683253877114
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.546792542924625
  - -0.533498519720441
  - -0.554285893436118
  - -0.5476423174865217
  - -0.5434736425847734
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.5114515278902645
  - -0.4980632553232304
  - -0.5192281544597533
  - -0.5101008957067846
  - -0.5067985945687166
  train_level6__neg_label_ranking_loss:
  - -0.46904081686013954
  - -0.45999691799488407
  - -0.44303707833474154
  - -0.48049869093996717
  - -0.4558420165300262
  train_level6__neg_label_ranking_loss_oob:
  - -0.47390503195686834
  - -0.4638438039741197
  - -0.4488734218159427
  - -0.48522559846847235
  - -0.4611988305681326
  train_level6__precision_macro:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.39499999999999996
  - 0.3957781700500148
  train_level6__precision_macro_masked:
  - 0.3553386977570299
  - 0.3698294983670241
  - 0.3634710150146327
  - 0.3613215299789716
  - 0.3619882578245185
  train_level6__precision_macro_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544123
  - 0.39116504854368944
  - 0.39290967931744636
  train_level6__precision_micro:
  - 0.38982273100516834
  - 0.40295929798356983
  - 0.39761470602730276
  - 0.395
  - 0.3957781700500147
  train_level6__precision_micro_masked:
  - 0.3480104031209363
  - 0.36261057498994775
  - 0.3573493145236138
  - 0.3544270697139271
  - 0.35486001056524036
  train_level6__precision_micro_oob:
  - 0.385258175143699
  - 0.3988284167289022
  - 0.39209501749544134
  - 0.39116504854368933
  - 0.3929096793174463
  train_level6__precision_samples:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.395
  - 0.3957781700500147
  train_level6__precision_samples_masked:
  - 0.34857070273081736
  - 0.36318128756705487
  - 0.3579883137523701
  - 0.3548500546158529
  - 0.35547598354112214
  train_level6__precision_samples_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544134
  - 0.3911650485436893
  - 0.3929096793174463
  train_level6__precision_weighted:
  - 0.49512694923316236
  - 0.5064785152503357
  - 0.48750091724507066
  - 0.4938219396684856
  - 0.49633167461228855
  train_level6__precision_weighted_masked:
  - 0.4532074570753751
  - 0.466501480279559
  - 0.445714106563882
  - 0.45235768251347824
  - 0.4565263574152267
  train_level6__precision_weighted_oob:
  - 0.4885484721097355
  - 0.5019367446767696
  - 0.48077184554024655
  - 0.4898991042932152
  - 0.49320140543128344
  train_level6__recall_macro:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.39499999999999996
  - 0.3957781700500148
  train_level6__recall_macro_masked:
  - 0.3553386977570299
  - 0.3698294983670241
  - 0.3634710150146327
  - 0.3613215299789716
  - 0.3619882578245185
  train_level6__recall_macro_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544123
  - 0.39116504854368944
  - 0.39290967931744636
  train_level6__recall_micro:
  - 0.38982273100516834
  - 0.40295929798356983
  - 0.39761470602730276
  - 0.395
  - 0.3957781700500147
  train_level6__recall_micro_masked:
  - 0.3480104031209363
  - 0.36261057498994775
  - 0.3573493145236138
  - 0.3544270697139271
  - 0.35486001056524036
  train_level6__recall_micro_oob:
  - 0.385258175143699
  - 0.3988284167289022
  - 0.39209501749544134
  - 0.39116504854368933
  - 0.3929096793174463
  train_level6__recall_samples:
  - 0.3898227310051683
  - 0.40295929798356983
  - 0.3976147060273027
  - 0.395
  - 0.3957781700500147
  train_level6__recall_samples_masked:
  - 0.34857070273081736
  - 0.36318128756705487
  - 0.3579883137523701
  - 0.3548500546158529
  - 0.35547598354112214
  train_level6__recall_samples_oob:
  - 0.3852581751436989
  - 0.3988284167289021
  - 0.39209501749544134
  - 0.3911650485436893
  - 0.3929096793174463
  train_level6__recall_weighted:
  - 0.49512694923316236
  - 0.5064785152503357
  - 0.48750091724507066
  - 0.4938219396684856
  - 0.49633167461228855
  train_level6__recall_weighted_masked:
  - 0.4532074570753751
  - 0.466501480279559
  - 0.445714106563882
  - 0.45235768251347824
  - 0.4565263574152267
  train_level6__recall_weighted_oob:
  - 0.4885484721097355
  - 0.5019367446767696
  - 0.48077184554024655
  - 0.4898991042932152
  - 0.49320140543128344
  train_level6__roc_auc_macro:
  - 0.6473120827847699
  - 0.6663827102001203
  - 0.6657810361965993
  - 0.6434858193170141
  - 0.6668074916204688
  train_level6__roc_auc_macro_masked:
  - 0.6231196217755502
  - 0.6412060924255659
  - 0.6442533423004561
  - 0.6207457474048503
  - 0.6446559124111576
  train_level6__roc_auc_macro_oob:
  - 0.6386192897801852
  - 0.6591152563351432
  - 0.655324321225316
  - 0.6357646043429817
  - 0.6586361847210783
  train_level6__roc_auc_micro:
  - 0.5569579842567083
  - 0.5626822624455223
  - 0.5791991446326719
  - 0.5460194219378338
  - 0.5671566352388084
  train_level6__roc_auc_micro_masked:
  - 0.5378375760490981
  - 0.5432094619594567
  - 0.5614422113036914
  - 0.5261478865821212
  - 0.5482518591380313
  train_level6__roc_auc_micro_oob:
  - 0.5530283682346847
  - 0.5595777412028531
  - 0.574358155360367
  - 0.5425447194127835
  - 0.5629582600742568
  train_level6__roc_auc_samples:
  - 0.5456215250999197
  - 0.5487698989364772
  - 0.5638875091927334
  - 0.5343482183958695
  - 0.5561736514897927
  train_level6__roc_auc_samples_masked:
  - 0.527750479483105
  - 0.5312303846588132
  - 0.546602389477745
  - 0.5168826402515676
  - 0.5401193945927591
  train_level6__roc_auc_samples_oob:
  - 0.5421001400969112
  - 0.5459530255784625
  - 0.5588105033872092
  - 0.5308980293684202
  - 0.5516712622615144
  train_level6__roc_auc_weighted:
  - 0.6659669703782685
  - 0.6777690410487033
  - 0.6675289492929256
  - 0.6503704487911448
  - 0.6746607640075047
  train_level6__roc_auc_weighted_masked:
  - 0.6393010131210148
  - 0.6526330765470262
  - 0.6447978325854181
  - 0.623481431692642
  - 0.649389871338068
  train_level6__roc_auc_weighted_oob:
  - 0.6560558890619624
  - 0.6680065481339239
  - 0.6566498837611507
  - 0.6413243710096673
  - 0.6648686671437706
  train_level6__tn_macro:
  - 0.18666376853596095
  - 0.19865571321882006
  - 0.1945690207481149
  - 0.19565533980582525
  - 0.19184564087476713
  train_level6__tn_macro_masked:
  - 0.2027586298268576
  - 0.21526070901617989
  - 0.20985867479818723
  - 0.21226836745804212
  - 0.208014815287973
  train_level6__tn_macro_oob:
  - 0.18294450079698593
  - 0.19543502613890965
  - 0.19030604701591838
  - 0.19225728155339808
  - 0.18917328626066493
  train_level6__tn_micro:
  - 0.18666376853596098
  - 0.19865571321882
  - 0.19456902074811494
  - 0.19565533980582525
  - 0.19184564087476708
  train_level6__tn_micro_masked:
  - 0.2010143042912874
  - 0.21391234418978688
  - 0.20938187796664104
  - 0.21078918466607394
  - 0.20668251452720549
  train_level6__tn_micro_oob:
  - 0.18294450079698593
  - 0.19543502613890965
  - 0.19030604701591838
  - 0.19225728155339805
  - 0.1891732862606649
  train_level6__tn_samples:
  - 0.18666376853596092
  - 0.19865571321881997
  - 0.19456902074811488
  - 0.19565533980582522
  - 0.19184564087476705
  train_level6__tn_samples_masked:
  - 0.2012781890421715
  - 0.2141755640676816
  - 0.20973897888747792
  - 0.21094961247006314
  - 0.2069544607312664
  train_level6__tn_samples_oob:
  - 0.1829445007969859
  - 0.19543502613890956
  - 0.19030604701591833
  - 0.19225728155339802
  - 0.18917328626066487
  train_level6__tn_weighted:
  - 0.20314731253294255
  - 0.2102762324956839
  - 0.19474111027659793
  - 0.20828297127561002
  - 0.2028854153815006
  train_level6__tn_weighted_masked:
  - 0.22604870310547243
  - 0.23336783949414003
  - 0.21616666168591622
  - 0.2316298077536019
  - 0.22550667161153817
  train_level6__tn_weighted_oob:
  - 0.19777649221592297
  - 0.2071657394974103
  - 0.18996604035015022
  - 0.2044311747143004
  - 0.19953923829589348
  train_level6__tp_macro:
  - 0.2031589624692074
  - 0.20430358476474983
  - 0.20304568527918784
  - 0.1993446601941747
  - 0.20393252917524757
  train_level6__tp_macro_masked:
  - 0.15258006793017234
  - 0.15456878935084414
  - 0.15361234021644546
  - 0.14905316252092954
  - 0.15397344253654568
  train_level6__tp_macro_oob:
  - 0.2023136743467131
  - 0.20339339058999256
  - 0.20178897047952293
  - 0.19890776699029122
  - 0.20373639305678135
  train_level6__tp_micro:
  - 0.20315896246920737
  - 0.2043035847647498
  - 0.20304568527918782
  - 0.19934466019417477
  - 0.20393252917524762
  train_level6__tp_micro_masked:
  - 0.1469960988296489
  - 0.14869823080016084
  - 0.14796743655697275
  - 0.14363788504785316
  - 0.14817749603803487
  train_level6__tp_micro_oob:
  - 0.20231367434671305
  - 0.20339339058999253
  - 0.20178897047952293
  - 0.19890776699029125
  - 0.2037363930567814
  train_level6__tp_samples:
  - 0.2031589624692073
  - 0.2043035847647498
  - 0.2030456852791878
  - 0.1993446601941747
  - 0.2039325291752476
  train_level6__tp_samples_masked:
  - 0.1472925136886459
  - 0.14900572349937324
  - 0.1482493348648922
  - 0.14390044214578981
  - 0.14852152280985575
  train_level6__tp_samples_oob:
  - 0.202313674346713
  - 0.20339339058999248
  - 0.2017889704795229
  - 0.19890776699029122
  - 0.20373639305678135
  train_level6__tp_weighted:
  - 0.29197963670021987
  - 0.2962022827546518
  - 0.2927598069684727
  - 0.2855389683928755
  - 0.2934462592307878
  train_level6__tp_weighted_masked:
  - 0.2271587539699027
  - 0.23313364078541898
  - 0.22954744487796577
  - 0.22072787475987637
  - 0.23101968580368862
  train_level6__tp_weighted_oob:
  - 0.2907719798938126
  - 0.2947710051793593
  - 0.2908058051900964
  - 0.28546792957891487
  - 0.29366216713538973
  train_level7__average_precision_macro:
  - 0.3404977884052992
  - 0.3571757983880473
  - 0.35540079515359785
  - 0.33697949952025436
  - 0.35370053113497113
  train_level7__average_precision_macro_masked:
  - 0.2645834929524526
  - 0.2795888490859284
  - 0.2810887329905801
  - 0.26165597199500035
  - 0.2752570091717461
  train_level7__average_precision_macro_oob:
  - 0.3348466218140722
  - 0.35049827300679376
  - 0.34831552026931456
  - 0.33145617603829985
  - 0.34724874327303323
  train_level7__average_precision_micro:
  - 0.24730176696676884
  - 0.24608107106692995
  - 0.255669998381284
  - 0.2425388830189769
  - 0.2524564888839075
  train_level7__average_precision_micro_masked:
  - 0.17901669776632784
  - 0.1781153747390281
  - 0.1862184478790243
  - 0.17584114786003768
  - 0.18278536992378647
  train_level7__average_precision_micro_oob:
  - 0.24693100866333448
  - 0.2460700554934989
  - 0.254456737205873
  - 0.24200432975698558
  - 0.25114051463205045
  train_level7__average_precision_samples:
  - 0.26261744695271505
  - 0.2626637900920735
  - 0.2717428601322906
  - 0.2591442091057096
  - 0.2702618815435754
  train_level7__average_precision_samples_masked:
  - 0.19795486197156253
  - 0.19849219688179917
  - 0.20656477532654857
  - 0.1953786808878553
  - 0.20450613960010944
  train_level7__average_precision_samples_oob:
  - 0.2620229179989103
  - 0.26256866330968537
  - 0.2705861113782532
  - 0.2587621502568184
  - 0.2690168200077105
  train_level7__average_precision_weighted:
  - 0.47675464278780033
  - 0.48862807916299045
  - 0.48703374344905104
  - 0.46591906927345256
  - 0.48686644614281394
  train_level7__average_precision_weighted_masked:
  - 0.3868092082779833
  - 0.3996765761897019
  - 0.40090311679101903
  - 0.37692725823751183
  - 0.396638395592795
  train_level7__average_precision_weighted_oob:
  - 0.4694358037479492
  - 0.4806417578484456
  - 0.4795586914208284
  - 0.45952123254406435
  - 0.4781563958588904
  train_level7__f1_macro:
  - 0.39030575278945073
  - 0.40372946228528755
  - 0.3974422157606821
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__f1_macro_masked:
  - 0.3560855609364946
  - 0.3707325964068739
  - 0.36333646125496105
  - 0.3624308112228334
  - 0.36106684014111035
  train_level7__f1_macro_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954988
  train_level7__f1_micro:
  - 0.3903057527894508
  - 0.40372946228528755
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__f1_micro_masked:
  - 0.3487906371911573
  - 0.3635152794531564
  - 0.35724324467661955
  - 0.35557763715286855
  - 0.3539355520338088
  train_level7__f1_micro_oob:
  - 0.3869004492102594
  - 0.39987864077669905
  - 0.3927603370952639
  - 0.3925485436893204
  - 0.3918799646954987
  train_level7__f1_samples:
  - 0.3903057527894508
  - 0.4037294622852875
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__f1_samples_masked:
  - 0.3493718734991616
  - 0.3640953659969072
  - 0.3578787792870343
  - 0.3560118250985196
  - 0.3545396630002256
  train_level7__f1_samples_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954987
  train_level7__f1_weighted:
  - 0.4951300345816139
  - 0.5071300115096873
  - 0.48707331917538577
  - 0.49412745804591796
  - 0.4955328944524059
  train_level7__f1_weighted_masked:
  - 0.45350260798686126
  - 0.46738552584153426
  - 0.44520543148384656
  - 0.4529205063453498
  - 0.4556482541980896
  train_level7__f1_weighted_oob:
  - 0.49047012997030354
  - 0.5023899386150009
  - 0.4816027616630409
  - 0.4904892927005045
  - 0.49156720140121335
  train_level7__fn_macro:
  - -0.031179056175433508
  - -0.030059746079163552
  - -0.02912621359223301
  - -0.03643203883495145
  - -0.03125919388055311
  train_level7__fn_macro_masked:
  - -0.030116328648185923
  - -0.0283653998269941
  - -0.027726943706660134
  - -0.03519927438782639
  - -0.029634728990674274
  train_level7__fn_macro_oob:
  - -0.031493020335217115
  - -0.030783233756534727
  - -0.030161155191957025
  - -0.03669902912621359
  - -0.03160243208786898
  train_level7__fn_micro:
  - -0.03117905617543351
  - -0.030059746079163556
  - -0.02912621359223301
  - -0.036432038834951455
  - -0.03125919388055311
  train_level7__fn_micro_masked:
  - -0.0282184655396619
  - -0.02678930438279051
  - -0.025668902972607464
  - -0.03297421682966372
  - -0.02791864764923402
  train_level7__fn_micro_oob:
  - -0.03149302033521712
  - -0.030783233756534727
  - -0.030161155191957025
  - -0.03669902912621359
  - -0.03160243208786898
  train_level7__fn_samples:
  - -0.031179056175433508
  - -0.03005974607916355
  - -0.029126213592233007
  - -0.036432038834951455
  - -0.03125919388055309
  train_level7__fn_samples_masked:
  - -0.02812967417556704
  - -0.02670160518776455
  - -0.02564017500737221
  - -0.03280176488938934
  - -0.0277943615525704
  train_level7__fn_samples_oob:
  - -0.031493020335217115
  - -0.030783233756534724
  - -0.03016115519195702
  - -0.03669902912621359
  - -0.03160243208786898
  train_level7__fn_weighted:
  - -0.054766220576703044
  - -0.050292298100901585
  - -0.05589178882212783
  - -0.06396350252239266
  - -0.053743932697894486
  train_level7__fn_weighted_masked:
  - -0.055483375685300075
  - -0.04937521416166375
  - -0.055433357057235656
  - -0.06457172987821516
  - -0.05240128476184426
  train_level7__fn_weighted_oob:
  - -0.05498528031676244
  - -0.05143415499712259
  - -0.05729517378017196
  - -0.06415088026356429
  - -0.05389657088686215
  train_level7__fp_macro:
  - -0.5785151910351157
  - -0.5662107916355489
  - -0.5734315706470849
  - -0.5675485436893204
  - -0.5737716975581052
  train_level7__fp_macro_masked:
  - -0.6137981104153194
  - -0.600902003766132
  - -0.6089365950383788
  - -0.6023699143893403
  - -0.6092984308682154
  train_level7__fp_macro_oob:
  - -0.5816065304545235
  - -0.5693381254667662
  - -0.577078507712779
  - -0.5707524271844661
  - -0.5765176032166323
  train_level7__fp_micro:
  - -0.5785151910351157
  - -0.5662107916355489
  - -0.5734315706470849
  - -0.5675485436893204
  - -0.5737716975581053
  train_level7__fp_micro_masked:
  - -0.6229908972691808
  - -0.6096954161640531
  - -0.617087852350773
  - -0.6114481460174677
  - -0.6181458003169572
  train_level7__fp_micro_oob:
  - -0.5816065304545235
  - -0.5693381254667662
  - -0.577078507712779
  - -0.5707524271844661
  - -0.5765176032166324
  train_level7__fp_samples:
  - -0.5785151910351156
  - -0.5662107916355489
  - -0.5734315706470849
  - -0.5675485436893204
  - -0.5737716975581053
  train_level7__fp_samples_masked:
  - -0.6224984523252713
  - -0.6092030288153282
  - -0.6164810457055935
  - -0.6111864100120912
  - -0.617665975447204
  train_level7__fp_samples_oob:
  - -0.5816065304545236
  - -0.5693381254667662
  - -0.577078507712779
  - -0.5707524271844661
  - -0.5765176032166324
  train_level7__fp_weighted:
  - -0.45010374484168303
  - -0.44257769038941114
  - -0.45703489200248626
  - -0.44190903943168947
  - -0.45072317284969965
  train_level7__fp_weighted_masked:
  - -0.4910140163278387
  - -0.48323925999680195
  - -0.49936121145891776
  - -0.482507763776435
  - -0.4919504610400661
  train_level7__fp_weighted_oob:
  - -0.45454458971293393
  - -0.4461759063878765
  - -0.46110206455678715
  - -0.4453598270359312
  - -0.4545362277119246
  train_level7__jaccard_macro:
  - 0.2623318724081382
  - 0.2731624813044981
  - 0.2642710990114623
  - 0.26462509404187623
  - 0.26446331430708137
  train_level7__jaccard_macro_masked:
  - 0.23451357772265938
  - 0.24611242403319225
  - 0.23676584926899935
  - 0.23727989781806996
  - 0.2370013732389258
  train_level7__jaccard_macro_oob:
  - 0.259485046181064
  - 0.26989833166141075
  - 0.26036743665887147
  - 0.26184072426816835
  - 0.2618326922378711
  train_level7__jaccard_micro:
  - 0.24247198091551514
  - 0.25292044972732725
  - 0.24800492042746214
  - 0.24689788753707403
  - 0.24608193566125927
  train_level7__jaccard_micro_masked:
  - 0.21123344201357716
  - 0.2221317894930819
  - 0.21746569814366423
  - 0.21623254778488057
  - 0.21501925545571246
  train_level7__jaccard_micro_oob:
  - 0.2398490837226015
  - 0.24990519529768676
  - 0.2443694902261403
  - 0.24420553550666646
  - 0.24368825466520308
  train_level7__jaccard_samples:
  - 0.2464934168452373
  - 0.25733593781645736
  - 0.25323055578343723
  - 0.2514380376309557
  - 0.2513123739534642
  train_level7__jaccard_samples_masked:
  - 0.215418047695059
  - 0.22659830489272587
  - 0.22295202176485673
  - 0.22087421288782216
  - 0.2205973246558526
  train_level7__jaccard_samples_oob:
  - 0.24383919742017035
  - 0.25421320532877023
  - 0.24969072330527495
  - 0.24876350629473734
  - 0.24890296153285843
  train_level7__jaccard_weighted:
  - 0.3454728559761797
  - 0.3575354185976804
  - 0.3357399681355063
  - 0.3424073752560452
  - 0.3459499435615576
  train_level7__jaccard_weighted_masked:
  - 0.3076735468051797
  - 0.320984537597955
  - 0.2986885253243531
  - 0.30517827698034183
  - 0.31002710185885196
  train_level7__jaccard_weighted_oob:
  - 0.3412934045579921
  - 0.35313652195965356
  - 0.3307578006089504
  - 0.3392489736839388
  - 0.3422364141551102
  train_level7__label_ranking_average_precision_score:
  - 0.26261744695271494
  - 0.2626637900920735
  - 0.27174286013229043
  - 0.2591442091057095
  - 0.2702618815435752
  train_level7__label_ranking_average_precision_score_oob:
  - 0.2620229179989103
  - 0.2625686633096854
  - 0.270586111378253
  - 0.25876215025681837
  - 0.2690168200077107
  train_level7__matthews_corrcoef_macro:
  - 0.15198040279978445
  - 0.16244493063349694
  - 0.15908240810205906
  - 0.14525711139392167
  - 0.15330546386090077
  train_level7__matthews_corrcoef_macro_masked:
  - 0.11889964130888048
  - 0.1301402813937279
  - 0.12812997568349885
  - 0.10977722238498436
  - 0.12081251777961256
  train_level7__matthews_corrcoef_macro_oob:
  - 0.1460913708540643
  - 0.15676848654057352
  - 0.15005096407453075
  - 0.14026861533555002
  - 0.1461254658759208
  train_level7__matthews_corrcoef_micro:
  - 0.11424380445805067
  - 0.13319101803478167
  - 0.12945915963765345
  - 0.1032405583013068
  - 0.11923470419230599
  train_level7__matthews_corrcoef_micro_masked:
  - 0.07539187159589446
  - 0.09575142762172499
  - 0.09409696472802506
  - 0.06269961609302775
  - 0.08195879328407381
  train_level7__matthews_corrcoef_micro_oob:
  - 0.10924361829097001
  - 0.1264386769181843
  - 0.1206373920701029
  - 0.09832955911406963
  - 0.11453250621254987
  train_level7__matthews_corrcoef_samples:
  - 0.11073359774176586
  - 0.12672740010750455
  - 0.12425149603992347
  - 0.10126544606239428
  - 0.114149459754109
  train_level7__matthews_corrcoef_samples_masked:
  - 0.07274861375912868
  - 0.0892079382518338
  - 0.0878790950073269
  - 0.06226747024424704
  - 0.07836534114930337
  train_level7__matthews_corrcoef_samples_oob:
  - 0.10622510780388893
  - 0.12081682296139516
  - 0.11553541147555847
  - 0.09636724261990123
  - 0.10855984995635992
  train_level7__matthews_corrcoef_weighted:
  - 0.19197683395017145
  - 0.19933671863234648
  - 0.185839230930549
  - 0.1764178418186955
  - 0.18687552882035635
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.1510237198030448
  - 0.16126910165374136
  - 0.14899263066019713
  - 0.13351938435178098
  - 0.14831783314098543
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.18055432904178637
  - 0.19187396585888775
  - 0.1729359409027601
  - 0.16987895722926136
  - 0.17644838714216682
  train_level7__ndcg:
  - 0.6160440089575614
  - 0.6078386456914916
  - 0.6143885699393274
  - 0.6091978737674103
  - 0.6188382974428837
  train_level7__ndcg_oob:
  - 0.6173195452954278
  - 0.6099718494993481
  - 0.6147918735173468
  - 0.6100056375260087
  - 0.6186280312343801
  train_level7__neg_coverage_error:
  - -91.81840796019901
  - -91.82451923076923
  - -93.23350253807106
  - -91.9675
  - -91.55555555555556
  train_level7__neg_coverage_error_oob:
  - -92.18905472636816
  - -92.15384615384616
  - -93.53045685279187
  - -92.4025
  - -92.11868686868686
  train_level7__neg_hamming_loss_macro:
  - -0.6096942472105492
  - -0.5962705377147124
  - -0.6025577842393179
  - -0.6039805825242719
  - -0.6050308914386584
  train_level7__neg_hamming_loss_macro_masked:
  - -0.6439144390635054
  - -0.629267403593126
  - -0.6366635387450389
  - -0.6375691887771666
  - -0.6389331598588895
  train_level7__neg_hamming_loss_macro_oob:
  - -0.6130995507897407
  - -0.600121359223301
  - -0.6072396629047362
  - -0.6074514563106796
  - -0.6081200353045012
  train_level7__neg_hamming_loss_micro:
  - -0.6096942472105492
  - -0.5962705377147125
  - -0.6025577842393179
  - -0.6039805825242719
  - -0.6050308914386584
  train_level7__neg_hamming_loss_micro_masked:
  - -0.6512093628088427
  - -0.6364847205468436
  - -0.6427567553233804
  - -0.6444223628471314
  - -0.6460644479661912
  train_level7__neg_hamming_loss_micro_oob:
  - -0.6130995507897407
  - -0.600121359223301
  - -0.6072396629047361
  - -0.6074514563106796
  - -0.6081200353045013
  train_level7__neg_hamming_loss_samples:
  - -0.6096942472105492
  - -0.5962705377147124
  - -0.6025577842393178
  - -0.6039805825242719
  - -0.6050308914386584
  train_level7__neg_hamming_loss_samples_masked:
  - -0.6506281265008383
  - -0.6359046340030928
  - -0.6421212207129657
  - -0.6439881749014805
  - -0.6454603369997745
  train_level7__neg_hamming_loss_samples_oob:
  - -0.6130995507897405
  - -0.600121359223301
  - -0.6072396629047361
  - -0.6074514563106796
  - -0.6081200353045013
  train_level7__neg_hamming_loss_weighted:
  - -0.5048699654183861
  - -0.4928699884903127
  - -0.5129266808246142
  - -0.5058725419540822
  - -0.5044671055475941
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.5464973920131387
  - -0.5326144741584657
  - -0.5547945685161534
  - -0.5470794936546503
  - -0.5443517458019104
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.5095298700296964
  - -0.49761006138499914
  - -0.518397238336959
  - -0.5095107072994954
  - -0.5084327985987867
  train_level7__neg_label_ranking_loss:
  - -0.4687384389571411
  - -0.45842560158113754
  - -0.4428359699933689
  - -0.4799126202328134
  - -0.4552101780213992
  train_level7__neg_label_ranking_loss_oob:
  - -0.4733270681785846
  - -0.4622502695337613
  - -0.44827283599858203
  - -0.4845396657066172
  - -0.4605146917269618
  train_level7__precision_macro:
  - 0.39030575278945073
  - 0.40372946228528755
  - 0.3974422157606821
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__precision_macro_masked:
  - 0.3560855609364946
  - 0.3707325964068739
  - 0.36333646125496105
  - 0.3624308112228334
  - 0.36106684014111035
  train_level7__precision_macro_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954988
  train_level7__precision_micro:
  - 0.3903057527894508
  - 0.40372946228528755
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__precision_micro_masked:
  - 0.3487906371911573
  - 0.3635152794531564
  - 0.35724324467661955
  - 0.35557763715286855
  - 0.3539355520338088
  train_level7__precision_micro_oob:
  - 0.3869004492102594
  - 0.39987864077669905
  - 0.3927603370952639
  - 0.3925485436893204
  - 0.3918799646954987
  train_level7__precision_samples:
  - 0.3903057527894508
  - 0.4037294622852875
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__precision_samples_masked:
  - 0.3493718734991616
  - 0.3640953659969072
  - 0.3578787792870343
  - 0.3560118250985196
  - 0.3545396630002256
  train_level7__precision_samples_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954987
  train_level7__precision_weighted:
  - 0.4951300345816139
  - 0.5071300115096873
  - 0.48707331917538577
  - 0.49412745804591796
  - 0.4955328944524059
  train_level7__precision_weighted_masked:
  - 0.45350260798686126
  - 0.46738552584153426
  - 0.44520543148384656
  - 0.4529205063453498
  - 0.4556482541980896
  train_level7__precision_weighted_oob:
  - 0.49047012997030354
  - 0.5023899386150009
  - 0.4816027616630409
  - 0.4904892927005045
  - 0.49156720140121335
  train_level7__recall_macro:
  - 0.39030575278945073
  - 0.40372946228528755
  - 0.3974422157606821
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__recall_macro_masked:
  - 0.3560855609364946
  - 0.3707325964068739
  - 0.36333646125496105
  - 0.3624308112228334
  - 0.36106684014111035
  train_level7__recall_macro_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954988
  train_level7__recall_micro:
  - 0.3903057527894508
  - 0.40372946228528755
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__recall_micro_masked:
  - 0.3487906371911573
  - 0.3635152794531564
  - 0.35724324467661955
  - 0.35557763715286855
  - 0.3539355520338088
  train_level7__recall_micro_oob:
  - 0.3869004492102594
  - 0.39987864077669905
  - 0.3927603370952639
  - 0.3925485436893204
  - 0.3918799646954987
  train_level7__recall_samples:
  - 0.3903057527894508
  - 0.4037294622852875
  - 0.39744221576068206
  - 0.39601941747572816
  - 0.3949691085613416
  train_level7__recall_samples_masked:
  - 0.3493718734991616
  - 0.3640953659969072
  - 0.3578787792870343
  - 0.3560118250985196
  - 0.3545396630002256
  train_level7__recall_samples_oob:
  - 0.38690044921025935
  - 0.39987864077669905
  - 0.39276033709526387
  - 0.39254854368932035
  - 0.3918799646954987
  train_level7__recall_weighted:
  - 0.4951300345816139
  - 0.5071300115096873
  - 0.48707331917538577
  - 0.49412745804591796
  - 0.4955328944524059
  train_level7__recall_weighted_masked:
  - 0.45350260798686126
  - 0.46738552584153426
  - 0.44520543148384656
  - 0.4529205063453498
  - 0.4556482541980896
  train_level7__recall_weighted_oob:
  - 0.49047012997030354
  - 0.5023899386150009
  - 0.4816027616630409
  - 0.4904892927005045
  - 0.49156720140121335
  train_level7__roc_auc_macro:
  - 0.6478846702830047
  - 0.6680275778138214
  - 0.6667540699168506
  - 0.6454334519965972
  - 0.6665187521881543
  train_level7__roc_auc_macro_masked:
  - 0.6233748009826572
  - 0.6430362437958833
  - 0.646022561274793
  - 0.6221559670967242
  - 0.6441740182404311
  train_level7__roc_auc_macro_oob:
  - 0.63990939156374
  - 0.6604856736803385
  - 0.6568067980045583
  - 0.6377893006811507
  - 0.6580822100325612
  train_level7__roc_auc_micro:
  - 0.5582907332203193
  - 0.562972543050563
  - 0.5796564694316169
  - 0.5466957643984738
  - 0.5671003183193785
  train_level7__roc_auc_micro_masked:
  - 0.5388857110521397
  - 0.5432164042336208
  - 0.5619471566322449
  - 0.5267388063787302
  - 0.547811164272183
  train_level7__roc_auc_micro_oob:
  - 0.5549872380851403
  - 0.5602536600946526
  - 0.5751532301386905
  - 0.5434636516003717
  - 0.5628981816689692
  train_level7__roc_auc_samples:
  - 0.5472312497677333
  - 0.5494130654576437
  - 0.563959798567739
  - 0.5347792538525485
  - 0.5562155662707745
  train_level7__roc_auc_samples_masked:
  - 0.5293010150752085
  - 0.5315018602407675
  - 0.5468017589265071
  - 0.5176300120290679
  - 0.539755161446275
  train_level7__roc_auc_samples_oob:
  - 0.5441129359158279
  - 0.546934006835565
  - 0.5592614941492278
  - 0.5313923415935342
  - 0.5516896030927885
  train_level7__roc_auc_weighted:
  - 0.666477467388808
  - 0.6788563717971144
  - 0.668491534805233
  - 0.6519064333793715
  - 0.6741648669606166
  train_level7__roc_auc_weighted_masked:
  - 0.6395773416218358
  - 0.6533727632592168
  - 0.6460408005883048
  - 0.6245672412865964
  - 0.6486859935420454
  train_level7__roc_auc_weighted_oob:
  - 0.6570224522661736
  - 0.668981836044697
  - 0.6584471542301469
  - 0.6430538719705836
  - 0.6641193952069778
  train_level7__tn_macro:
  - 0.1878230208182389
  - 0.1998226288274832
  - 0.19474151101473564
  - 0.19669902912621362
  - 0.19137981759340986
  train_level7__tn_macro_masked:
  - 0.20403423105909171
  - 0.21653384193495304
  - 0.21004589650584976
  - 0.21335312917100635
  - 0.20755159329959538
  train_level7__tn_macro_oob:
  - 0.1847316813988311
  - 0.1966952949962659
  - 0.19109457394904142
  - 0.19349514563106793
  - 0.18863391193488283
  train_level7__tn_micro:
  - 0.1878230208182389
  - 0.1998226288274832
  - 0.1947415110147356
  - 0.1966990291262136
  - 0.19137981759340983
  train_level7__tn_micro_masked:
  - 0.2022626788036411
  - 0.21516887816646563
  - 0.20956750019888096
  - 0.2119136028450395
  - 0.20618066561014264
  train_level7__tn_micro_oob:
  - 0.1847316813988311
  - 0.19669529499626587
  - 0.19109457394904145
  - 0.19349514563106796
  - 0.1886339119348828
  train_level7__tn_samples:
  - 0.18782302081823887
  - 0.19982262882748314
  - 0.19474151101473555
  - 0.19669902912621354
  - 0.1913798175934098
  train_level7__tn_samples_masked:
  - 0.20254286582819786
  - 0.21543714893871613
  - 0.20992120729178704
  - 0.21208140093734074
  - 0.20644357418313172
  train_level7__tn_samples_oob:
  - 0.18473168139883106
  - 0.19669529499626584
  - 0.19109457394904142
  - 0.19349514563106796
  - 0.1886339119348828
  train_level7__tn_weighted:
  - 0.20458225667527993
  - 0.21155212929215428
  - 0.19493966685659037
  - 0.2088211675074642
  - 0.2028627437333983
  train_level7__tn_weighted_masked:
  - 0.22768430103148365
  - 0.2348635983254079
  - 0.21638137995039766
  - 0.23219720423240953
  - 0.22556341755313242
  train_level7__tn_weighted_oob:
  - 0.20014141180402895
  - 0.2079539132936888
  - 0.19087249430228947
  - 0.2053703799032225
  - 0.19904968887117336
  train_level7__tp_macro:
  - 0.20248273197121197
  - 0.20390683345780436
  - 0.20270070474594645
  - 0.19932038834951452
  - 0.20358929096793166
  train_level7__tp_macro_masked:
  - 0.15205132987740289
  - 0.15419875447192075
  - 0.15329056474911124
  - 0.14907768205182698
  - 0.15351524684151505
  train_level7__tp_macro_oob:
  - 0.2021687678114283
  - 0.20318334578043318
  - 0.20166576314622248
  - 0.1990533980582524
  - 0.2032460527606158
  train_level7__tp_micro:
  - 0.2024827319712119
  - 0.20390683345780433
  - 0.20270070474594648
  - 0.19932038834951457
  - 0.20358929096793174
  train_level7__tp_micro_masked:
  - 0.14652795838751626
  - 0.1483464012866908
  - 0.1476757444777386
  - 0.1436640343078291
  - 0.14775488642366613
  train_level7__tp_micro_oob:
  - 0.20216876781142828
  - 0.20318334578043315
  - 0.20166576314622248
  - 0.19905339805825242
  - 0.20324605276061586
  train_level7__tp_samples:
  - 0.20248273197121186
  - 0.2039068334578043
  - 0.2027007047459464
  - 0.19932038834951452
  - 0.2035892909679317
  train_level7__tp_samples_masked:
  - 0.14682900767096374
  - 0.1486582170581911
  - 0.14795757199524723
  - 0.14393042416117882
  - 0.1480960888170939
  train_level7__tp_samples_oob:
  - 0.20216876781142823
  - 0.20318334578043312
  - 0.20166576314622242
  - 0.19905339805825237
  - 0.20324605276061583
  train_level7__tp_weighted:
  - 0.290547777906334
  - 0.29557788221753306
  - 0.29213365231879557
  - 0.28530629053845363
  - 0.29267015071900754
  train_level7__tp_weighted_masked:
  - 0.2258183069553777
  - 0.23252192751612638
  - 0.22882405153344892
  - 0.2207233021129403
  - 0.23008483664495727
  train_level7__tp_weighted_oob:
  - 0.2903287181662746
  - 0.2944360253213121
  - 0.29073026736075147
  - 0.285118912797282
  - 0.2925175125300398
  train_level8__average_precision_macro:
  - 0.3435161529706854
  - 0.35429824306402474
  - 0.3541552981412362
  - 0.3378191992393093
  - 0.35315789116379076
  train_level8__average_precision_macro_masked:
  - 0.26777444011785995
  - 0.27729908199456577
  - 0.2807193140989407
  - 0.2627917129272304
  - 0.27634422311996637
  train_level8__average_precision_macro_oob:
  - 0.33812675198006903
  - 0.34885156693393815
  - 0.34682457207005835
  - 0.3333252783678415
  - 0.34751039040117404
  train_level8__average_precision_micro:
  - 0.24626912834806536
  - 0.2464180488417414
  - 0.2548750163303845
  - 0.24311341058669705
  - 0.25149949712989605
  train_level8__average_precision_micro_masked:
  - 0.17846655670330797
  - 0.1783289198968778
  - 0.18572633834502078
  - 0.17634152780694856
  - 0.18221221417910266
  train_level8__average_precision_micro_oob:
  - 0.2457824604899737
  - 0.24614953604819043
  - 0.25364771512492673
  - 0.24270156457273095
  - 0.25043837438320976
  train_level8__average_precision_samples:
  - 0.2607808453158075
  - 0.2633648186525142
  - 0.27109673425584657
  - 0.2598969574164026
  - 0.26966527705882903
  train_level8__average_precision_samples_masked:
  - 0.19650783412385772
  - 0.1987448109872185
  - 0.20624597156256433
  - 0.1958802246051582
  - 0.2041720734123837
  train_level8__average_precision_samples_oob:
  - 0.26034903328916165
  - 0.2630505264545913
  - 0.26965953420546585
  - 0.25950335347092607
  - 0.26849431081250125
  train_level8__average_precision_weighted:
  - 0.4792810785532451
  - 0.4868979669880756
  - 0.4857857095666718
  - 0.4678838896587319
  - 0.4873982112080564
  train_level8__average_precision_weighted_masked:
  - 0.389506877779632
  - 0.398486440435838
  - 0.40063869455065954
  - 0.37912141778147185
  - 0.3981629824501202
  train_level8__average_precision_weighted_oob:
  - 0.47179303273333223
  - 0.4796186896958787
  - 0.477175341401937
  - 0.4621311645746478
  - 0.479869574612951
  train_level8__f1_macro:
  - 0.39112688982273086
  - 0.40454630321135177
  - 0.39840323296042585
  - 0.3971601941747572
  - 0.3958517210944396
  train_level8__f1_macro_masked:
  - 0.3571420061762544
  - 0.37168723485483846
  - 0.3642871914030265
  - 0.36364104482725024
  - 0.3617088220269857
  train_level8__f1_macro_oob:
  - 0.38728686663768536
  - 0.4013956310679612
  - 0.39492878616135235
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__f1_micro:
  - 0.391126889822731
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__f1_micro_masked:
  - 0.34988296488946685
  - 0.3644199839163651
  - 0.3581713558378192
  - 0.356754353851786
  - 0.35459587955625993
  train_level8__f1_micro_oob:
  - 0.38728686663768536
  - 0.40139563106796117
  - 0.3949287861613523
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__f1_samples:
  - 0.39112688982273097
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__f1_samples_masked:
  - 0.35046643408176237
  - 0.36500583913838713
  - 0.3588236780970589
  - 0.35718735332225193
  - 0.3551968494374748
  train_level8__f1_samples_oob:
  - 0.3872868666376853
  - 0.4013956310679611
  - 0.39492878616135235
  - 0.39390776699029123
  - 0.3934000196136119
  train_level8__f1_weighted:
  - 0.4951215498733721
  - 0.5085128524841741
  - 0.48839442185503645
  - 0.49585452486358494
  - 0.4962921310400171
  train_level8__f1_weighted_masked:
  - 0.4540733311669148
  - 0.46901245226528243
  - 0.4464587884149393
  - 0.4545800914897292
  - 0.45604022167423847
  train_level8__f1_weighted_oob:
  - 0.49120135755331873
  - 0.5040859389986572
  - 0.48397141216892847
  - 0.49202228971481515
  - 0.49367909178432207
  train_level8__fn_macro:
  - -0.03134811379993238
  - -0.02984970126960418
  - -0.028855157458971957
  - -0.03594660194174758
  - -0.030940472688045503
  train_level8__fn_macro_masked:
  - -0.03012054994782216
  - -0.028094976723036128
  - -0.02753604969750597
  - -0.03471580756325402
  - -0.02956285509388826
  train_level8__fn_macro_oob:
  - -0.03142056706757475
  - -0.030783233756534724
  - -0.02986545759203588
  - -0.03635922330097087
  - -0.0314798470138276
  train_level8__fn_micro:
  - -0.031348113799932374
  - -0.029849701269604182
  - -0.028855157458971957
  - -0.03594660194174757
  - -0.030940472688045503
  train_level8__fn_micro_masked:
  - -0.028192457737321198
  - -0.026537997587454766
  - -0.02548328074036753
  - -0.03250353015009675
  - -0.02786582144743793
  train_level8__fn_micro_oob:
  - -0.03142056706757475
  - -0.030783233756534727
  - -0.029865457592035877
  - -0.036359223300970876
  - -0.0314798470138276
  train_level8__fn_samples:
  - -0.031348113799932374
  - -0.02984970126960418
  - -0.02885515745897195
  - -0.03594660194174757
  - -0.030940472688045503
  train_level8__fn_samples_masked:
  - -0.02811529824221947
  - -0.026455979989054537
  - -0.025456273425709906
  - -0.032331601583896606
  - -0.027746386666238857
  train_level8__fn_samples_oob:
  - -0.03142056706757475
  - -0.030783233756534724
  - -0.029865457592035873
  - -0.036359223300970876
  - -0.03147984701382759
  train_level8__fn_weighted:
  - -0.05566174296476275
  - -0.049870516017648185
  - -0.05542183561241756
  - -0.06308529805415422
  - -0.05308698215055873
  train_level8__fn_weighted_masked:
  - -0.0558910923000785
  - -0.048851276539758376
  - -0.05517199691217055
  - -0.0639092746837758
  - -0.052080608784644544
  train_level8__fn_weighted_oob:
  - -0.05520408294445087
  - -0.05143055821983503
  - -0.056781246762664446
  - -0.0636276124781221
  - -0.05380351168011676
  train_level8__fp_macro:
  - -0.5775249963773367
  - -0.5656039955190441
  - -0.5727416095806023
  - -0.5668932038834951
  - -0.5732078062175149
  train_level8__fp_macro_masked:
  - -0.6127374438759234
  - -0.6002177884221255
  - -0.6081767588994675
  - -0.6016431476094958
  - -0.608728322879126
  train_level8__fp_macro_oob:
  - -0.5812925662947399
  - -0.567821135175504
  - -0.5752057562466119
  - -0.5697330097087379
  - -0.5751201333725605
  train_level8__fp_micro:
  - -0.5775249963773366
  - -0.5656039955190441
  - -0.5727416095806023
  - -0.5668932038834952
  - -0.573207806217515
  train_level8__fp_micro_masked:
  - -0.6219245773732119
  - -0.6090420184961801
  - -0.6163453634218132
  - -0.6107421159981172
  - -0.6175382989963022
  train_level8__fp_micro_oob:
  - -0.5812925662947399
  - -0.5678211351755041
  - -0.5752057562466117
  - -0.5697330097087379
  - -0.5751201333725605
  train_level8__fp_samples:
  - -0.5775249963773366
  - -0.565603995519044
  - -0.5727416095806023
  - -0.5668932038834952
  - -0.5732078062175149
  train_level8__fp_samples_masked:
  - -0.621418267676018
  - -0.6085381808725583
  - -0.615720048477231
  - -0.6104810450938516
  - -0.6170567638962863
  train_level8__fp_samples_oob:
  - -0.5812925662947399
  - -0.5678211351755041
  - -0.5752057562466119
  - -0.5697330097087377
  - -0.5751201333725606
  train_level8__fp_weighted:
  - -0.44921670716186507
  - -0.4416166314981777
  - -0.45618374253254607
  - -0.44106017708226086
  - -0.4506208868094243
  train_level8__fp_weighted_masked:
  - -0.4900355765330067
  - -0.48213627119495917
  - -0.49836921467289014
  - -0.481510633826495
  - -0.491879169541117
  train_level8__fp_weighted_oob:
  - -0.4535945595022304
  - -0.4444835027815078
  - -0.4592473410684071
  - -0.4443500978070626
  - -0.4525173965355613
  train_level8__jaccard_macro:
  - 0.2628133392540665
  - 0.2738572021832777
  - 0.2650891726764732
  - 0.26563196278225437
  - 0.26514707851006597
  train_level8__jaccard_macro_masked:
  - 0.23519700992376102
  - 0.24685667535222847
  - 0.23752145369732164
  - 0.2382800692140943
  - 0.2374429982388324
  train_level8__jaccard_macro_oob:
  - 0.2599238903726487
  - 0.27117462464571906
  - 0.26219254201862563
  - 0.2630291147894369
  - 0.26314374593840917
  train_level8__jaccard_micro:
  - 0.24310611405497096
  - 0.2535619203651151
  - 0.24875376946273617
  - 0.24778533246513318
  - 0.246767537826685
  train_level8__jaccard_micro_masked:
  - 0.21203524201301874
  - 0.22280779927169922
  - 0.21815392069773076
  - 0.21710348339459906
  - 0.21550686250902962
  train_level8__jaccard_micro_oob:
  - 0.24014616029711275
  - 0.25109128866957675
  - 0.24605063174539815
  - 0.24525849692463467
  - 0.2448649473523577
  train_level8__jaccard_samples:
  - 0.24715856207512885
  - 0.2580139272062149
  - 0.25409934733087247
  - 0.2523939909515098
  - 0.25198151743545866
  train_level8__jaccard_samples_masked:
  - 0.21624388174666287
  - 0.22732787992882933
  - 0.2237691101076749
  - 0.2218185677435993
  - 0.22108088028018924
  train_level8__jaccard_samples_oob:
  - 0.24411537003248293
  - 0.25550519626624213
  - 0.2514711136082224
  - 0.2497621778011057
  - 0.2500619298377173
  train_level8__jaccard_weighted:
  - 0.34517584073037016
  - 0.3587909840595865
  - 0.33701090573516
  - 0.3440094442065583
  - 0.34660032531603185
  train_level8__jaccard_weighted_masked:
  - 0.30800117414756645
  - 0.32235181522219875
  - 0.29980022005071205
  - 0.30659537934045233
  - 0.3103274659713495
  train_level8__jaccard_weighted_oob:
  - 0.34205018558994366
  - 0.35465805391807537
  - 0.3329853277650111
  - 0.3406617107593055
  - 0.3442120385860178
  train_level8__label_ranking_average_precision_score:
  - 0.26078084531580753
  - 0.26336481865251415
  - 0.2710967342558467
  - 0.25989695741640273
  - 0.26966527705882887
  train_level8__label_ranking_average_precision_score_oob:
  - 0.26034903328916137
  - 0.2630505264545912
  - 0.269659534205466
  - 0.25950335347092623
  - 0.2684943108125014
  train_level8__matthews_corrcoef_macro:
  - 0.15358828566858157
  - 0.16528031677251617
  - 0.16123129584429646
  - 0.14768249432321884
  - 0.15427866593507447
  train_level8__matthews_corrcoef_macro_masked:
  - 0.12084399221066579
  - 0.1333150244988533
  - 0.13019161277891408
  - 0.1125928290678142
  - 0.12056026165220261
  train_level8__matthews_corrcoef_macro_oob:
  - 0.14735707423401675
  - 0.1584641248559021
  - 0.1536614165923198
  - 0.14240052341157008
  - 0.14973423889494053
  train_level8__matthews_corrcoef_micro:
  - 0.11460797112248237
  - 0.13480979711138671
  - 0.13146475083862644
  - 0.10614157820503108
  - 0.12132086581396609
  train_level8__matthews_corrcoef_micro_masked:
  - 0.07657047588582805
  - 0.09767271395584187
  - 0.09577590213190909
  - 0.06580190592327968
  - 0.08282332330166779
  train_level8__matthews_corrcoef_micro_oob:
  - 0.10993904778443125
  - 0.12813832988074753
  - 0.12409730498281196
  - 0.10102360919922257
  - 0.1166931471592811
  train_level8__matthews_corrcoef_samples:
  - 0.11167868873467195
  - 0.12865347504655408
  - 0.1267925949651689
  - 0.10413777958610491
  - 0.11645537881181171
  train_level8__matthews_corrcoef_samples_masked:
  - 0.07421369899457463
  - 0.09124572199357937
  - 0.09034071198815034
  - 0.06512778563824038
  - 0.07924813137225772
  train_level8__matthews_corrcoef_samples_oob:
  - 0.10688374144753421
  - 0.12212051200013609
  - 0.11916683547118789
  - 0.0991344214858718
  - 0.11155190277103735
  train_level8__matthews_corrcoef_weighted:
  - 0.19270390911924007
  - 0.20373963011138957
  - 0.18902260342293156
  - 0.18113176535586947
  - 0.18836271340209673
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.15252843595804966
  - 0.16610924982319014
  - 0.15176545022009125
  - 0.13883079326471048
  - 0.1485297489656042
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.183907282691865
  - 0.19449689227128955
  - 0.17785629590591037
  - 0.17271891284307808
  - 0.18284516178321594
  train_level8__ndcg:
  - 0.6139126385378028
  - 0.6094033134797869
  - 0.6133167430164226
  - 0.6103686010494375
  - 0.616874353428413
  train_level8__ndcg_oob:
  - 0.6150121821452418
  - 0.6111646514834631
  - 0.6136146943059891
  - 0.6117489920459012
  - 0.617219883188058
  train_level8__neg_coverage_error:
  - -91.8407960199005
  - -91.89903846153847
  - -93.21573604060913
  - -91.96
  - -91.5530303030303
  train_level8__neg_coverage_error_oob:
  - -92.17412935323384
  - -92.25721153846153
  - -93.55329949238579
  - -92.3125
  - -92.14646464646465
  train_level8__neg_hamming_loss_macro:
  - -0.608873110177269
  - -0.5954536967886482
  - -0.6015967670395741
  - -0.6028398058252428
  - -0.6041482789055603
  train_level8__neg_hamming_loss_macro_masked:
  - -0.6428579938237455
  - -0.6283127651451615
  - -0.6357128085969735
  - -0.6363589551727497
  - -0.6382911779730143
  train_level8__neg_hamming_loss_macro_oob:
  - -0.6127131333623147
  - -0.5986043689320387
  - -0.6050712138386477
  - -0.6060922330097087
  - -0.6065999803863881
  train_level8__neg_hamming_loss_micro:
  - -0.608873110177269
  - -0.5954536967886482
  - -0.6015967670395742
  - -0.6028398058252428
  - -0.6041482789055604
  train_level8__neg_hamming_loss_micro_masked:
  - -0.6501170351105332
  - -0.6355800160836349
  - -0.6418286441621808
  - -0.643245646148214
  - -0.6454041204437401
  train_level8__neg_hamming_loss_micro_oob:
  - -0.6127131333623146
  - -0.5986043689320388
  - -0.6050712138386477
  - -0.6060922330097087
  - -0.6065999803863882
  train_level8__neg_hamming_loss_samples:
  - -0.608873110177269
  - -0.5954536967886482
  - -0.6015967670395742
  - -0.6028398058252428
  - -0.6041482789055603
  train_level8__neg_hamming_loss_samples_masked:
  - -0.6495335659182376
  - -0.6349941608616129
  - -0.641176321902941
  - -0.6428126466777482
  - -0.6448031505625252
  train_level8__neg_hamming_loss_samples_oob:
  - -0.6127131333623146
  - -0.5986043689320388
  - -0.6050712138386477
  - -0.6060922330097087
  - -0.6065999803863882
  train_level8__neg_hamming_loss_weighted:
  - -0.5048784501266278
  - -0.49148714751582584
  - -0.5116055781449635
  - -0.504145475136415
  - -0.5037078689599829
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.5459266688330852
  - -0.5309875477347177
  - -0.5535412115850606
  - -0.5454199085102708
  - -0.5439597783257616
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.5087986424466813
  - -0.49591406100134283
  - -0.5160285878310715
  - -0.5079777102851849
  - -0.5063209082156779
  train_level8__neg_label_ranking_loss:
  - -0.46862165250247917
  - -0.45881167197972855
  - -0.4429867950572912
  - -0.47982975536752986
  - -0.4549605156020173
  train_level8__neg_label_ranking_loss_oob:
  - -0.4727900984957826
  - -0.4628996476523154
  - -0.44864157689095485
  - -0.48349614975172384
  - -0.46033863859921464
  train_level8__precision_macro:
  - 0.39112688982273086
  - 0.40454630321135177
  - 0.39840323296042585
  - 0.3971601941747572
  - 0.3958517210944396
  train_level8__precision_macro_masked:
  - 0.3571420061762544
  - 0.37168723485483846
  - 0.3642871914030265
  - 0.36364104482725024
  - 0.3617088220269857
  train_level8__precision_macro_oob:
  - 0.38728686663768536
  - 0.4013956310679612
  - 0.39492878616135235
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__precision_micro:
  - 0.391126889822731
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__precision_micro_masked:
  - 0.34988296488946685
  - 0.3644199839163651
  - 0.3581713558378192
  - 0.356754353851786
  - 0.35459587955625993
  train_level8__precision_micro_oob:
  - 0.38728686663768536
  - 0.40139563106796117
  - 0.3949287861613523
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__precision_samples:
  - 0.39112688982273097
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__precision_samples_masked:
  - 0.35046643408176237
  - 0.36500583913838713
  - 0.3588236780970589
  - 0.35718735332225193
  - 0.3551968494374748
  train_level8__precision_samples_oob:
  - 0.3872868666376853
  - 0.4013956310679611
  - 0.39492878616135235
  - 0.39390776699029123
  - 0.3934000196136119
  train_level8__precision_weighted:
  - 0.4951215498733721
  - 0.5085128524841741
  - 0.48839442185503645
  - 0.49585452486358494
  - 0.4962921310400171
  train_level8__precision_weighted_masked:
  - 0.4540733311669148
  - 0.46901245226528243
  - 0.4464587884149393
  - 0.4545800914897292
  - 0.45604022167423847
  train_level8__precision_weighted_oob:
  - 0.49120135755331873
  - 0.5040859389986572
  - 0.48397141216892847
  - 0.49202228971481515
  - 0.49367909178432207
  train_level8__recall_macro:
  - 0.39112688982273086
  - 0.40454630321135177
  - 0.39840323296042585
  - 0.3971601941747572
  - 0.3958517210944396
  train_level8__recall_macro_masked:
  - 0.3571420061762544
  - 0.37168723485483846
  - 0.3642871914030265
  - 0.36364104482725024
  - 0.3617088220269857
  train_level8__recall_macro_oob:
  - 0.38728686663768536
  - 0.4013956310679612
  - 0.39492878616135235
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__recall_micro:
  - 0.391126889822731
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__recall_micro_masked:
  - 0.34988296488946685
  - 0.3644199839163651
  - 0.3581713558378192
  - 0.356754353851786
  - 0.35459587955625993
  train_level8__recall_micro_oob:
  - 0.38728686663768536
  - 0.40139563106796117
  - 0.3949287861613523
  - 0.3939077669902913
  - 0.3934000196136119
  train_level8__recall_samples:
  - 0.39112688982273097
  - 0.40454630321135177
  - 0.3984032329604258
  - 0.3971601941747573
  - 0.39585172109443956
  train_level8__recall_samples_masked:
  - 0.35046643408176237
  - 0.36500583913838713
  - 0.3588236780970589
  - 0.35718735332225193
  - 0.3551968494374748
  train_level8__recall_samples_oob:
  - 0.3872868666376853
  - 0.4013956310679611
  - 0.39492878616135235
  - 0.39390776699029123
  - 0.3934000196136119
  train_level8__recall_weighted:
  - 0.4951215498733721
  - 0.5085128524841741
  - 0.48839442185503645
  - 0.49585452486358494
  - 0.4962921310400171
  train_level8__recall_weighted_masked:
  - 0.4540733311669148
  - 0.46901245226528243
  - 0.4464587884149393
  - 0.4545800914897292
  - 0.45604022167423847
  train_level8__recall_weighted_oob:
  - 0.49120135755331873
  - 0.5040859389986572
  - 0.48397141216892847
  - 0.49202228971481515
  - 0.49367909178432207
  train_level8__roc_auc_macro:
  - 0.64933821854512
  - 0.6670150030576427
  - 0.6665878009848537
  - 0.644760829786634
  - 0.6654622225172433
  train_level8__roc_auc_macro_masked:
  - 0.624726508657463
  - 0.6414247954058636
  - 0.6456786601915275
  - 0.6221398188628234
  - 0.6432432910008942
  train_level8__roc_auc_macro_oob:
  - 0.6419674397803197
  - 0.6597958161912396
  - 0.6572562827948547
  - 0.637882983881237
  - 0.6574865087230602
  train_level8__roc_auc_micro:
  - 0.5576948813170013
  - 0.5630927920426823
  - 0.5793631301802173
  - 0.5473309782349975
  - 0.5667069294507252
  train_level8__roc_auc_micro_masked:
  - 0.5384236954429802
  - 0.5432854422648545
  - 0.5616925248237061
  - 0.527456257310802
  - 0.5473972168730902
  train_level8__roc_auc_micro_oob:
  - 0.554363429921277
  - 0.5601998112296264
  - 0.574929142640889
  - 0.5443634589859203
  - 0.5627314035074462
  train_level8__roc_auc_samples:
  - 0.5459981617912819
  - 0.549687896995704
  - 0.5634825864394456
  - 0.5355240225223069
  - 0.5558169317999361
  train_level8__roc_auc_samples_masked:
  - 0.5279278360490612
  - 0.5317923043698948
  - 0.5461416836818784
  - 0.518391187435592
  - 0.5395312338592059
  train_level8__roc_auc_samples_oob:
  - 0.5431295185248614
  - 0.5468358358608406
  - 0.5586808568787702
  - 0.5329851795336089
  - 0.5513849841753937
  train_level8__roc_auc_weighted:
  - 0.6673514101265808
  - 0.6783545459909804
  - 0.6682669941812233
  - 0.6520857211439327
  - 0.6740364944898498
  train_level8__roc_auc_weighted_masked:
  - 0.6405739628311621
  - 0.6527167854269141
  - 0.6457692591349066
  - 0.6250880260919217
  - 0.6483377363861694
  train_level8__roc_auc_weighted_oob:
  - 0.6583896597857023
  - 0.6691157505404515
  - 0.6580934720583265
  - 0.643695552606338
  - 0.6646954035422966
  train_level8__tn_macro:
  - 0.18881321547601798
  - 0.20042942494398805
  - 0.19543147208121828
  - 0.19735436893203884
  - 0.19194370893400023
  train_level8__tn_macro_masked:
  - 0.20509489759848773
  - 0.2172180572789596
  - 0.21080573264476102
  - 0.21407989595085086
  - 0.2081217012886847
  train_level8__tn_macro_oob:
  - 0.1850456455586147
  - 0.19821228528752796
  - 0.19296732541520872
  - 0.19451456310679616
  - 0.19003138177895457
  train_level8__tn_micro:
  - 0.18881321547601798
  - 0.20042942494398805
  - 0.19543147208121828
  - 0.19735436893203884
  - 0.1919437089340002
  train_level8__tn_micro_masked:
  - 0.20332899869960988
  - 0.21582227583433855
  - 0.21030998912784069
  - 0.21261963286438995
  - 0.20678816693079768
  train_level8__tn_micro_oob:
  - 0.1850456455586147
  - 0.19821228528752802
  - 0.19296732541520872
  - 0.19451456310679613
  - 0.1900313817789546
  train_level8__tn_samples:
  - 0.18881321547601793
  - 0.200429424943988
  - 0.1954314720812182
  - 0.19735436893203884
  - 0.19194370893400015
  train_level8__tn_samples_masked:
  - 0.20362305047745108
  - 0.21610199688148596
  - 0.21068220452014938
  - 0.21278676585558032
  - 0.2070527857340494
  train_level8__tn_samples_oob:
  - 0.18504564555861464
  - 0.19821228528752796
  - 0.1929673254152087
  - 0.1945145631067961
  - 0.19003138177895454
  train_level8__tn_weighted:
  - 0.20546929435509792
  - 0.21251318818338777
  - 0.19579081632653061
  - 0.20967002985689284
  - 0.20296502977367367
  train_level8__tn_weighted_masked:
  - 0.22866274082631557
  - 0.23596658712725063
  - 0.2173733767364253
  - 0.23319433418234958
  - 0.22563470905208158
  train_level8__tn_weighted_oob:
  - 0.20109144201473256
  - 0.2096463169000576
  - 0.19272721779066956
  - 0.206380109132091
  - 0.20106852004753661
  train_level8__tp_macro:
  - 0.2023136743467131
  - 0.20411687826736372
  - 0.20297176087920757
  - 0.19980582524271842
  - 0.20390801216043927
  train_level8__tp_macro_masked:
  - 0.15204710857776665
  - 0.15446917757587872
  - 0.15348145875826544
  - 0.14956114887639935
  - 0.15358712073830105
  train_level8__tp_macro_oob:
  - 0.2022412210790707
  - 0.20318334578043318
  - 0.2019614607461436
  - 0.19939320388349513
  - 0.2033686378346572
  train_level8__tp_micro:
  - 0.20231367434671305
  - 0.20411687826736372
  - 0.20297176087920754
  - 0.19980582524271845
  - 0.20390801216043936
  train_level8__tp_micro_masked:
  - 0.14655396618985694
  - 0.14859770808202655
  - 0.14786136670997851
  - 0.14413472098739605
  - 0.14780771262546222
  train_level8__tp_micro_oob:
  - 0.20224122107907067
  - 0.20318334578043315
  - 0.2019614607461436
  - 0.19939320388349516
  - 0.20336863783465725
  train_level8__tp_samples:
  - 0.202313674346713
  - 0.20411687826736366
  - 0.20297176087920749
  - 0.1998058252427184
  - 0.20390801216043927
  train_level8__tp_samples_masked:
  - 0.14684338360431134
  - 0.14890384225690112
  - 0.14814147357690954
  - 0.14440058746667156
  - 0.14814406370342545
  train_level8__tp_samples_oob:
  - 0.2022412210790706
  - 0.20318334578043312
  - 0.20196146074614355
  - 0.19939320388349507
  - 0.20336863783465722
  train_level8__tp_weighted:
  - 0.2896522555182743
  - 0.2959996643007864
  - 0.29260360552850584
  - 0.2861844950066921
  - 0.29332710126634337
  train_level8__tp_weighted_masked:
  - 0.2254105903405993
  - 0.23304586513803177
  - 0.22908541167851404
  - 0.2213857573073797
  - 0.23040551262215697
  train_level8__tp_weighted_oob:
  - 0.29010991553858617
  - 0.2944396220985996
  - 0.291244194378259
  - 0.28564218058272417
  - 0.2926105717367853
  train_level9__average_precision_macro:
  - 0.34000907041879513
  - 0.35471084064589536
  - 0.3550155142400252
  - 0.33739345035999
  - 0.35478383540693925
  train_level9__average_precision_macro_masked:
  - 0.26486163602447577
  - 0.2784081030081456
  - 0.28113787741758595
  - 0.26324493886542505
  - 0.27755912834903124
  train_level9__average_precision_macro_oob:
  - 0.33418659776156384
  - 0.35052966650695244
  - 0.34856997274684237
  - 0.3329736485873863
  - 0.3496573979117079
  train_level9__average_precision_micro:
  - 0.24396338251872274
  - 0.2473117549569119
  - 0.2559081488633604
  - 0.24297396842420652
  - 0.25260109764693955
  train_level9__average_precision_micro_masked:
  - 0.17665376088291337
  - 0.179133509051397
  - 0.18656801006498563
  - 0.17619668612311734
  - 0.18313821361423646
  train_level9__average_precision_micro_oob:
  - 0.24384074836118177
  - 0.24712561668391103
  - 0.2548718240200926
  - 0.24245533159483168
  - 0.25206886046792515
  train_level9__average_precision_samples:
  - 0.2597317029976255
  - 0.26375766029117037
  - 0.27163156055637344
  - 0.25978856224476277
  - 0.2708829261383786
  train_level9__average_precision_samples_masked:
  - 0.195785673605846
  - 0.19919259616184834
  - 0.2065889666486593
  - 0.19573270112318028
  - 0.20536806502920696
  train_level9__average_precision_samples_oob:
  - 0.25936937658951664
  - 0.2636878344251275
  - 0.2705695284411613
  - 0.2595433509287852
  - 0.2699805354321955
  train_level9__average_precision_weighted:
  - 0.4758694263319391
  - 0.487459553587032
  - 0.48692178001783143
  - 0.46787880064225273
  - 0.48925397043303015
  train_level9__average_precision_weighted_masked:
  - 0.38640912331517596
  - 0.3992844589968293
  - 0.40174200796777376
  - 0.37950855859440713
  - 0.3996677834907328
  train_level9__average_precision_weighted_oob:
  - 0.46852421146744183
  - 0.4813377022436715
  - 0.479721731897
  - 0.4625172111106422
  - 0.4821733655114919
  train_level9__f1_macro:
  - 0.3922136888373665
  - 0.4058999253174011
  - 0.3991178354935686
  - 0.3985922330097088
  - 0.3966117485534962
  train_level9__f1_macro_masked:
  - 0.3581217365487233
  - 0.37307899571359154
  - 0.3649385086786071
  - 0.3650310348248147
  - 0.3628505898855238
  train_level9__f1_macro_oob:
  - 0.38760083079746893
  - 0.4031226661687828
  - 0.394066334828249
  - 0.3955339805825242
  - 0.3938658428949692
  train_level9__f1_micro:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__f1_micro_masked:
  - 0.3508712613784135
  - 0.36582730197024527
  - 0.35880777491978466
  - 0.35806181685058314
  - 0.35567881669307977
  train_level9__f1_micro_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.394066334828249
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__f1_samples:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__f1_samples_masked:
  - 0.3514657434777015
  - 0.3664154222722655
  - 0.359446727632975
  - 0.3585232205079364
  - 0.3562661383767258
  train_level9__f1_samples_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.39406633482824893
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__f1_weighted:
  - 0.49627264195816784
  - 0.5096439190485326
  - 0.48948945060257604
  - 0.4981012560485947
  - 0.49728072034680243
  train_level9__f1_weighted_masked:
  - 0.4549341231120077
  - 0.4701873103605682
  - 0.4473207076382293
  - 0.45704486571611935
  - 0.4579685640195698
  train_level9__f1_weighted_oob:
  - 0.49096944219471117
  - 0.5056330328026089
  - 0.48301882618529646
  - 0.4937097189333883
  - 0.49377109649580686
  train_level9__fn_macro:
  - -0.03129981162150414
  - -0.02994305451829724
  - -0.02870730865901138
  - -0.035339805825242716
  - -0.030793370599195843
  train_level9__fn_macro_masked:
  - -0.03025585646878538
  - -0.0282441542532298
  - -0.02750434789757986
  - -0.03422696174424327
  - -0.029106215016585002
  train_level9__fn_macro_oob:
  - -0.03204849538714196
  - -0.030643203883495142
  - -0.029692967325415206
  - -0.03587378640776699
  - -0.03128371089536138
  train_level9__fn_micro:
  - -0.03129981162150413
  - -0.029943054518297235
  - -0.028707308659011384
  - -0.035339805825242716
  - -0.030793370599195843
  train_level9__fn_micro_masked:
  - -0.028322496749024706
  - -0.026688781664656214
  - -0.025456763278618972
  - -0.032085141990481666
  - -0.027443211833069203
  train_level9__fn_micro_oob:
  - -0.03204849538714196
  - -0.030643203883495146
  - -0.02969296732541521
  - -0.03587378640776699
  - -0.03128371089536138
  train_level9__fn_samples:
  - -0.03129981162150412
  - -0.029943054518297228
  - -0.028707308659011384
  - -0.035339805825242716
  - -0.030793370599195836
  train_level9__fn_samples_masked:
  - -0.028235743321234352
  - -0.02659701581812333
  - -0.02542471219800761
  - -0.03191342212803621
  - -0.027319716959924606
  train_level9__fn_samples_oob:
  - -0.032048495387141954
  - -0.030643203883495142
  - -0.029692967325415202
  - -0.035873786407766985
  - -0.03128371089536138
  train_level9__fn_weighted:
  - -0.05548073585560569
  - -0.04992374832150393
  - -0.05500206110362926
  - -0.0617908987954288
  - -0.052935134833036496
  train_level9__fn_weighted_masked:
  - -0.056091196110907224
  - -0.048979307560084014
  - -0.055065507324356125
  - -0.06249721570978087
  - -0.05116187846688911
  train_level9__fn_weighted_oob:
  - -0.05607415120778536
  - -0.05132073661998849
  - -0.05628620420249318
  - -0.06276433645629569
  - -0.05341493017659633
  train_level9__fp_macro:
  - -0.5764864995411294
  - -0.5641570201643018
  - -0.57217485584742
  - -0.5660679611650484
  - -0.5725948808473079
  train_level9__fp_macro_masked:
  - -0.6116224069824913
  - -0.5986768500331787
  - -0.607557143423813
  - -0.6007420034309421
  - -0.608043195097891
  train_level9__fp_macro_oob:
  - -0.5803506738153892
  - -0.5662341299477222
  - -0.5762406978463358
  - -0.5685922330097087
  - -0.5748504462096694
  train_level9__fp_micro:
  - -0.5764864995411293
  - -0.5641570201643017
  - -0.57217485584742
  - -0.5660679611650485
  - -0.572594880847308
  train_level9__fp_micro_masked:
  - -0.6208062418725617
  - -0.6074839163650985
  - -0.6157354618015963
  - -0.6098530411589352
  - -0.616877971473851
  train_level9__fp_micro_oob:
  - -0.5803506738153891
  - -0.5662341299477222
  - -0.5762406978463358
  - -0.5685922330097087
  - -0.5748504462096695
  train_level9__fp_samples:
  - -0.5764864995411294
  - -0.5641570201643018
  - -0.57217485584742
  - -0.5660679611650485
  - -0.572594880847308
  train_level9__fp_samples_masked:
  - -0.6202985132010642
  - -0.6069875619096112
  - -0.6151285601690173
  - -0.6095633573640273
  - -0.6164141446633497
  train_level9__fp_samples_oob:
  - -0.5803506738153891
  - -0.5662341299477222
  - -0.5762406978463358
  - -0.5685922330097086
  - -0.5748504462096695
  train_level9__fp_weighted:
  - -0.44824662218622646
  - -0.44043233262996356
  - -0.4555084882937947
  - -0.4401078451559765
  - -0.4497841448201611
  train_level9__fp_weighted_masked:
  - -0.48897468077708517
  - -0.4808333820793478
  - -0.49761378503741466
  - -0.48045791857409986
  - -0.49086955751354105
  train_level9__fp_weighted_oob:
  - -0.45295640659750347
  - -0.44304623057740267
  - -0.46069496961221035
  - -0.44352594461031614
  - -0.4528139733275969
  train_level9__jaccard_macro:
  - 0.26376116799893545
  - 0.274921083415294
  - 0.26568592038535094
  - 0.26702007896028
  - 0.26573060709953916
  train_level9__jaccard_macro_masked:
  - 0.23599513276570402
  - 0.2478889825017005
  - 0.23800623445494723
  - 0.239567415719534
  - 0.23838182326207874
  train_level9__jaccard_macro_oob:
  - 0.25999495476128875
  - 0.2725303566410363
  - 0.2613893421126136
  - 0.26432297837866636
  - 0.26338156715985045
  train_level9__jaccard_micro:
  - 0.2439464038935288
  - 0.25462637620051537
  - 0.24931118875736913
  - 0.24890114886780443
  - 0.24735852230156424
  train_level9__jaccard_micro_masked:
  - 0.21276159535712597
  - 0.22386085779753026
  - 0.21862629461472588
  - 0.21807265372425985
  - 0.21630738587078743
  train_level9__jaccard_micro_oob:
  - 0.2403876398604017
  - 0.25244435350686173
  - 0.2453814521573682
  - 0.24652063415224496
  - 0.24522599258139854
  train_level9__jaccard_samples:
  - 0.24795059238778963
  - 0.2590800916118679
  - 0.25465567195563016
  - 0.2534376908160603
  - 0.25257731829550417
  train_level9__jaccard_samples_masked:
  - 0.2169258201650023
  - 0.2283946421228178
  - 0.22424234816118682
  - 0.2227270600459569
  - 0.22189990539489238
  train_level9__jaccard_samples_oob:
  - 0.24435678973609934
  - 0.25679584433793134
  - 0.250747306175982
  - 0.2510631126498643
  - 0.25044757522097394
  train_level9__jaccard_weighted:
  - 0.34626728883424285
  - 0.359863196801426
  - 0.3380191080876211
  - 0.34631771484656254
  - 0.34751878459431307
  train_level9__jaccard_weighted_masked:
  - 0.30873789237024496
  - 0.323382690751099
  - 0.3004874347615181
  - 0.3089835321071477
  - 0.3121470105140495
  train_level9__jaccard_weighted_oob:
  - 0.3415752703466328
  - 0.35590933100360406
  - 0.3321322854558289
  - 0.3420704822837553
  - 0.34419835340490196
  train_level9__label_ranking_average_precision_score:
  - 0.2597317029976256
  - 0.26375766029117026
  - 0.27163156055637344
  - 0.25978856224476293
  - 0.27088292613837855
  train_level9__label_ranking_average_precision_score_oob:
  - 0.2593693765895167
  - 0.2636878344251275
  - 0.2705695284411613
  - 0.259543350928785
  - 0.2699805354321954
  train_level9__matthews_corrcoef_macro:
  - 0.15438526170988023
  - 0.16556049323441643
  - 0.16230055584942965
  - 0.15000701249095283
  - 0.1559807273830314
  train_level9__matthews_corrcoef_macro_masked:
  - 0.1209521034345771
  - 0.1330717723574908
  - 0.13086177912448657
  - 0.11415307164875416
  - 0.1229176855516605
  train_level9__matthews_corrcoef_macro_oob:
  - 0.1455155603914321
  - 0.16111508465637653
  - 0.1525498233843013
  - 0.14463406294830575
  - 0.15041988608857151
  train_level9__matthews_corrcoef_micro:
  - 0.11601625782486369
  - 0.13599052577033982
  - 0.13276837600199498
  - 0.10977279507820038
  - 0.12268345257621817
  train_level9__matthews_corrcoef_micro_masked:
  - 0.07697600954061044
  - 0.09834974810784462
  - 0.09648784494814086
  - 0.06881457896692109
  - 0.08567276292189675
  train_level9__matthews_corrcoef_micro_oob:
  - 0.10815801521555404
  - 0.13053982478187331
  - 0.12372544112332926
  - 0.10449770148044868
  - 0.11789147982594242
  train_level9__matthews_corrcoef_samples:
  - 0.11341247212526107
  - 0.12964237269821385
  - 0.12767247449466443
  - 0.10829064308998021
  - 0.11779298314383377
  train_level9__matthews_corrcoef_samples_masked:
  - 0.07519122398013317
  - 0.09189170102657887
  - 0.09108631107499265
  - 0.06884812751921476
  - 0.0821309774510221
  train_level9__matthews_corrcoef_samples_oob:
  - 0.10567431248637904
  - 0.12451040439972591
  - 0.11867092826055609
  - 0.1027038498610339
  - 0.11234093016461152
  train_level9__matthews_corrcoef_weighted:
  - 0.19360550695693968
  - 0.20389053646391173
  - 0.19132450132043982
  - 0.184964169970462
  - 0.19126727103866978
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.15242358708027154
  - 0.16587703559262915
  - 0.15357183792440332
  - 0.14189261855342994
  - 0.15323295857682698
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.18138639424028374
  - 0.19781125493725493
  - 0.17676279631818215
  - 0.17496399182308855
  - 0.18342620169873708
  train_level9__ndcg:
  - 0.6097782524615358
  - 0.6104098453835222
  - 0.6144064096054739
  - 0.6099543531921157
  - 0.6170203426508516
  train_level9__ndcg_oob:
  - 0.6118860945115194
  - 0.61201898107806
  - 0.6150432710532392
  - 0.6107300061936523
  - 0.6182897748171348
  train_level9__neg_coverage_error:
  - -91.85572139303483
  - -91.9014423076923
  - -93.13451776649747
  - -91.895
  - -91.58585858585859
  train_level9__neg_coverage_error_oob:
  - -92.13432835820896
  - -92.1826923076923
  - -93.51776649746193
  - -92.1825
  - -92.12373737373737
  train_level9__neg_hamming_loss_macro:
  - -0.6077863111626335
  - -0.594100074682599
  - -0.6008821645064314
  - -0.6014077669902912
  - -0.6033882514465039
  train_level9__neg_hamming_loss_macro_masked:
  - -0.6418782634512765
  - -0.6269210042864085
  - -0.6350614913213929
  - -0.6349689651751852
  - -0.637149410114476
  train_level9__neg_hamming_loss_macro_oob:
  - -0.612399169202531
  - -0.5968773338312173
  - -0.6059336651717511
  - -0.6044660194174758
  - -0.6061341571050308
  train_level9__neg_hamming_loss_micro:
  - -0.6077863111626335
  - -0.594100074682599
  - -0.6008821645064314
  - -0.6014077669902913
  - -0.6033882514465039
  train_level9__neg_hamming_loss_micro_masked:
  - -0.6491287386215865
  - -0.6341726980297547
  - -0.6411922250802153
  - -0.6419381831494169
  - -0.6443211833069202
  train_level9__neg_hamming_loss_micro_oob:
  - -0.612399169202531
  - -0.5968773338312173
  - -0.6059336651717511
  - -0.6044660194174757
  - -0.6061341571050309
  train_level9__neg_hamming_loss_samples:
  - -0.6077863111626334
  - -0.594100074682599
  - -0.6008821645064315
  - -0.6014077669902912
  - -0.6033882514465039
  train_level9__neg_hamming_loss_samples_masked:
  - -0.6485342565222983
  - -0.6335845777277345
  - -0.640553272367025
  - -0.6414767794920635
  - -0.6437338616232742
  train_level9__neg_hamming_loss_samples_oob:
  - -0.6123991692025309
  - -0.5968773338312173
  - -0.605933665171751
  - -0.6044660194174757
  - -0.6061341571050308
  train_level9__neg_hamming_loss_weighted:
  - -0.5037273580418322
  - -0.49035608095146743
  - -0.5105105493974239
  - -0.5018987439514053
  - -0.5027192796531976
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.5450658768879924
  - -0.5298126896394317
  - -0.5526792923617707
  - -0.5429551342838806
  - -0.5420314359804302
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.5090305578052888
  - -0.4943669671973912
  - -0.5169811738147035
  - -0.5062902810666118
  - -0.5062289035041931
  train_level9__neg_label_ranking_loss:
  - -0.468527008770253
  - -0.45838806015802464
  - -0.4424018851797462
  - -0.4785165637007233
  - -0.4541328334329989
  train_level9__neg_label_ranking_loss_oob:
  - -0.47300445629092824
  - -0.46201909008377623
  - -0.4478696731318227
  - -0.48230134592607415
  - -0.4595506431359122
  train_level9__precision_macro:
  - 0.3922136888373665
  - 0.4058999253174011
  - 0.3991178354935686
  - 0.3985922330097088
  - 0.3966117485534962
  train_level9__precision_macro_masked:
  - 0.3581217365487233
  - 0.37307899571359154
  - 0.3649385086786071
  - 0.3650310348248147
  - 0.3628505898855238
  train_level9__precision_macro_oob:
  - 0.38760083079746893
  - 0.4031226661687828
  - 0.394066334828249
  - 0.3955339805825242
  - 0.3938658428949692
  train_level9__precision_micro:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__precision_micro_masked:
  - 0.3508712613784135
  - 0.36582730197024527
  - 0.35880777491978466
  - 0.35806181685058314
  - 0.35567881669307977
  train_level9__precision_micro_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.394066334828249
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__precision_samples:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__precision_samples_masked:
  - 0.3514657434777015
  - 0.3664154222722655
  - 0.359446727632975
  - 0.3585232205079364
  - 0.3562661383767258
  train_level9__precision_samples_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.39406633482824893
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__precision_weighted:
  - 0.49627264195816784
  - 0.5096439190485326
  - 0.48948945060257604
  - 0.4981012560485947
  - 0.49728072034680243
  train_level9__precision_weighted_masked:
  - 0.4549341231120077
  - 0.4701873103605682
  - 0.4473207076382293
  - 0.45704486571611935
  - 0.4579685640195698
  train_level9__precision_weighted_oob:
  - 0.49096944219471117
  - 0.5056330328026089
  - 0.48301882618529646
  - 0.4937097189333883
  - 0.49377109649580686
  train_level9__recall_macro:
  - 0.3922136888373665
  - 0.4058999253174011
  - 0.3991178354935686
  - 0.3985922330097088
  - 0.3966117485534962
  train_level9__recall_macro_masked:
  - 0.3581217365487233
  - 0.37307899571359154
  - 0.3649385086786071
  - 0.3650310348248147
  - 0.3628505898855238
  train_level9__recall_macro_oob:
  - 0.38760083079746893
  - 0.4031226661687828
  - 0.394066334828249
  - 0.3955339805825242
  - 0.3938658428949692
  train_level9__recall_micro:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__recall_micro_masked:
  - 0.3508712613784135
  - 0.36582730197024527
  - 0.35880777491978466
  - 0.35806181685058314
  - 0.35567881669307977
  train_level9__recall_micro_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.394066334828249
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__recall_samples:
  - 0.39221368883736657
  - 0.40589992531740104
  - 0.39911783549356855
  - 0.39859223300970875
  - 0.3966117485534961
  train_level9__recall_samples_masked:
  - 0.3514657434777015
  - 0.3664154222722655
  - 0.359446727632975
  - 0.3585232205079364
  - 0.3562661383767258
  train_level9__recall_samples_oob:
  - 0.387600830797469
  - 0.4031226661687827
  - 0.39406633482824893
  - 0.39553398058252426
  - 0.3938658428949691
  train_level9__recall_weighted:
  - 0.49627264195816784
  - 0.5096439190485326
  - 0.48948945060257604
  - 0.4981012560485947
  - 0.49728072034680243
  train_level9__recall_weighted_masked:
  - 0.4549341231120077
  - 0.4701873103605682
  - 0.4473207076382293
  - 0.45704486571611935
  - 0.4579685640195698
  train_level9__recall_weighted_oob:
  - 0.49096944219471117
  - 0.5056330328026089
  - 0.48301882618529646
  - 0.4937097189333883
  - 0.49377109649580686
  train_level9__roc_auc_macro:
  - 0.6472764503933282
  - 0.6670270454854768
  - 0.667236326511673
  - 0.6462181224599408
  - 0.6666343717218861
  train_level9__roc_auc_macro_masked:
  - 0.6226494497862258
  - 0.6415772519424479
  - 0.6469453905405713
  - 0.6231827383771148
  - 0.6446518213455645
  train_level9__roc_auc_macro_oob:
  - 0.639558960615414
  - 0.6604427526850275
  - 0.6578010713279214
  - 0.6386466100509192
  - 0.6593345362921799
  train_level9__roc_auc_micro:
  - 0.5559456353746289
  - 0.5642644265247068
  - 0.5804128156683858
  - 0.5480588307946169
  - 0.5680550700663126
  train_level9__roc_auc_micro_masked:
  - 0.5366825839303849
  - 0.5445524357159074
  - 0.5627833220513139
  - 0.5281266337238282
  - 0.5487752365323724
  train_level9__roc_auc_micro_oob:
  - 0.5528684059809297
  - 0.561498154197117
  - 0.5761136764884307
  - 0.5450699355165888
  - 0.564498437170363
  train_level9__roc_auc_samples:
  - 0.5449685605531552
  - 0.5507548348102785
  - 0.5643317261255753
  - 0.5362229058999384
  - 0.5570240535220834
  train_level9__roc_auc_samples_masked:
  - 0.527262549208897
  - 0.5329175582180767
  - 0.5472196837689953
  - 0.5188441702180231
  - 0.5406555894056561
  train_level9__roc_auc_samples_oob:
  - 0.5420538155427677
  - 0.5482027979028026
  - 0.5596948438011723
  - 0.5335880833072427
  - 0.5527573709670386
  train_level9__roc_auc_weighted:
  - 0.6660483873006819
  - 0.678926736773749
  - 0.6691258345729476
  - 0.6538417425678255
  - 0.6754980278106794
  train_level9__roc_auc_weighted_masked:
  - 0.6390588662462443
  - 0.6534813509494054
  - 0.6470338491390762
  - 0.6266156678279597
  - 0.6499647048696798
  train_level9__roc_auc_weighted_oob:
  - 0.6570122480334256
  - 0.6700799291455624
  - 0.659152255998964
  - 0.6452948521534876
  - 0.6666703110223758
  train_level9__tn_macro:
  - 0.18985171231222525
  - 0.20187640029873047
  - 0.1959982258144005
  - 0.19817961165048545
  - 0.1925566343042071
  train_level9__tn_macro_masked:
  - 0.20620993449191988
  - 0.2187589956679065
  - 0.21142534812041558
  - 0.21498104012940455
  - 0.20880682906991965
  train_level9__tn_macro_oob:
  - 0.1859875380379655
  - 0.19979929051530992
  - 0.19193238381548472
  - 0.19565533980582525
  - 0.19030106894184565
  train_level9__tn_micro:
  - 0.18985171231222528
  - 0.20187640029873039
  - 0.19599822581440046
  - 0.19817961165048545
  - 0.1925566343042071
  train_level9__tn_micro_masked:
  - 0.20444733420026007
  - 0.21738037796542017
  - 0.2109198907480576
  - 0.213508707703572
  - 0.2074484944532488
  train_level9__tn_micro_oob:
  - 0.1859875380379655
  - 0.19979929051530992
  - 0.1919323838154847
  - 0.19565533980582525
  - 0.19030106894184565
  train_level9__tn_samples:
  - 0.18985171231222528
  - 0.20187640029873036
  - 0.1959982258144004
  - 0.1981796116504854
  - 0.19255663430420708
  train_level9__tn_samples_masked:
  - 0.20474280495240502
  - 0.2176526158444332
  - 0.2112736928283632
  - 0.21370445358540444
  - 0.20769540496698602
  train_level9__tn_samples_oob:
  - 0.18598753803796547
  - 0.1997992905153099
  - 0.19193238381548466
  - 0.19565533980582522
  - 0.1903010689418456
  train_level9__tn_weighted:
  - 0.2064393793307365
  - 0.21369748705160177
  - 0.19646607056528193
  - 0.21062236178317717
  - 0.2038017717629368
  train_level9__tn_weighted_masked:
  - 0.2297236365822372
  - 0.237269476242862
  - 0.21812880637190077
  - 0.2342470494347447
  - 0.22664432107965746
  train_level9__tn_weighted_oob:
  - 0.20172959491945955
  - 0.21108358910416264
  - 0.19127958924686625
  - 0.20720426232883762
  - 0.20077194325550102
  train_level9__tp_macro:
  - 0.20236197652514132
  - 0.20402352501867071
  - 0.2031196096791681
  - 0.20041262135922328
  - 0.2040551142492889
  train_level9__tp_macro_masked:
  - 0.15191180205680344
  - 0.15432000004568505
  - 0.15351316055819156
  - 0.1500499946954101
  - 0.1540437608156043
  train_level9__tp_macro_oob:
  - 0.20161329275950352
  - 0.20332337565347278
  - 0.2021339510127643
  - 0.199878640776699
  - 0.2035647739531234
  train_level9__tp_micro:
  - 0.2023619765251413
  - 0.20402352501867066
  - 0.20311960967916812
  - 0.2004126213592233
  - 0.20405511424928902
  train_level9__tp_micro_masked:
  - 0.14642392717815345
  - 0.1484469240048251
  - 0.14788788417172707
  - 0.14455310914701114
  - 0.14823032223983096
  train_level9__tp_micro_oob:
  - 0.20161329275950346
  - 0.20332337565347275
  - 0.20213395101276427
  - 0.19987864077669903
  - 0.20356477395312347
  train_level9__tp_samples:
  - 0.2023619765251412
  - 0.2040235250186706
  - 0.20311960967916806
  - 0.20041262135922325
  - 0.20405511424928893
  train_level9__tp_samples_masked:
  - 0.14672293852529644
  - 0.14876280642783232
  - 0.14817303480461186
  - 0.14481876692253196
  - 0.14857073340973967
  train_level9__tp_samples_oob:
  - 0.2016132927595034
  - 0.20332337565347267
  - 0.2021339510127642
  - 0.19987864077669898
  - 0.20356477395312345
  train_level9__tp_weighted:
  - 0.28983326262743137
  - 0.29594643199693066
  - 0.29302338003729417
  - 0.2874788942654175
  - 0.29347894858386553
  train_level9__tp_weighted_masked:
  - 0.22521048652977055
  - 0.23291783411770609
  - 0.22919190126632846
  - 0.22279781628137457
  - 0.23132424293991244
  train_level9__tp_weighted_oob:
  - 0.2892398472752517
  - 0.29454944369844616
  - 0.29173923693843024
  - 0.2865054566045506
  - 0.29299915324030573
start: 2023-12-31 13:33:39.699164
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop70
  params:
    drop: 0.7
    random_state: 0
