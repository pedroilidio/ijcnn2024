active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            MDMzMzMzC8BAMzMzMzPjPzAzMzMzMwPAQDMzMzMz4z9oZmZmZmYSQA==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T8AmZmZmZnJvwCZmZmZmcm/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcA0MzMzMzMbQICZmZmZmcm/0MzMzMzM/D/MzMzMzMwUwA==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+YmZmZmZkBwICZmZmZmcm/oJmZmZmZ6T+gmZmZmZnpPw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/gJmZmZmZ6b8AmpmZmZnJPw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z8wMzMzMzMLwEAzMzMzM+M/oJmZmZmZ+T9AMzMzMzPjPw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMGMBoZmZmZmYGQNDMzMzMzPw/0MzMzMzM/D+AmZmZmZnJvw==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZAcBoZmZmZmYOQGhmZmZmZg5AmJmZmZmZAcCYmZmZmZkJwA==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMzC0DIzMzMzMwMwJCZmZmZmfm/yMzMzMzMBMCcmZmZmZkRQA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmFsCcmZmZmZkZQJyZmZmZmRlAyMzMzMzMBMBkZmZmZmYSwA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAJkAAAAAAAAAIwAAAAAAAAAAAAAAAAAAA8L8AAAAAAAAcwA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAADwvwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmEkBoZmZmZmYSQDAzMzMzMwvAQDMzMzMz4z+YmZmZmZkZwA==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMDMCcmZmZmZkdQMjMzMzMzAzAODMzMzMzA0DIzMzMzMwEwA==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz479kZmZmZmYSwMCZmZmZmdk/ODMzMzMzA0A4MzMzMzMDQA==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAgQAAAAAAAABBAAAAAAAAAHMAAAAAAAAAIwA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAcwAAAAAAAAAhAAAAAAAAAAMAAAAAAAADwPw==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D+gmZmZmZnpP4CZmZmZmcm/oJmZmZmZ6T+YmZmZmZkJwA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzF8BoZmZmZmYgQKCZmZmZmQFAAJqZmZmZyT8wMzMzMzMTwA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMBMA4MzMzMzMDQDgzMzMzMwtAyMzMzMzMDMDAmZmZmZnZPw==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA0DQzMzMzMwMwNDMzMzMzAzAMDMzMzMzA0AwMzMzMzMDQA==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZAUCQmZmZmZnpv5CZmZmZmem/ZGZmZmZmBsCcmZmZmZkBQA==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAIQAAAAAAAAAjAAAAAAAAAHEAAAAAAAAAcwA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T/gzMzMzMz8P8CZmZmZmek/yMzMzMzMEMDAmZmZmZnpPw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0BoZmZmZmb2P5iZmZmZmfm/mJmZmZmZ+b+YmZmZmZn5vw==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIMAAAAAAAAAUQAAAAAAAABBAAAAAAAAACMAAAAAAAAAAQA==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmGkAwMzMzMzMLwKCZmZmZmfk/MDMzMzMzC8BgZmZmZmb2vw==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAYQAAAAAAAAADAAAAAAAAA8D8AAAAAAAAAwA==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAAAAAAAAAAAABAAAAAAAAA8D8AAAAAAAAYwA==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmHkBAMzMzMzPjPzAzMzMzMwPAmJmZmZmZEcBgZmZmZmb2vw==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBsBoZmZmZmYmQICZmZmZmem/wMzMzMzM/L8wMzMzMzMXwA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkBmZmZmZmYgwGhmZmZmZgZA0MzMzMzM/D+AmZmZmZnJvw==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBsDQzMzMzMwUQKCZmZmZmQlAoJmZmZmZCUCYmZmZmZkhwA==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAwAAAAAAAAAhAAAAAAAAAAMAAAAAAAAAAAA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D84MzMzMzMfQMjMzMzMzBjAcGZmZmZmDkDIzMzMzMwcwA==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFEAAAAAAAAAAQAAAAAAAAADAAAAAAAAA8D8AAAAAAAAYwA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAgQAAAAAAAAAjAAAAAAAAA8L8AAAAAAADwvw==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwMwDAzMzMzM+O/aGZmZmZm9j80MzMzMzMDQA==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9gZmZmZmb2v0AzMzMzM+M/oJmZmZmZ+T9AMzMzMzPjPw==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz4z9kZmZmZmb2v87MzMzMzAxAODMzMzMz4z8yMzMzMzMLwA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ODMzMzMz8z+cmZmZmZkBQGRmZmZmZgbAODMzMzMz8z/IzMzMzMz8vw==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAAwAAAAAAAAPA/AAAAAAAA8D8AAAAAAAAIwA==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0CYmZmZmZn5v2hmZmZmZvY/ZmZmZmZmEsBoZmZmZmb2Pw==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZHUCgmZmZmZnZP5iZmZmZmfm/zMzMzMzMBMDMzMzMzMwMwA==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmBsCamZmZmZkBQJqZmZmZmQlAZmZmZmZmBsCgmZmZmZnJPw==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmIEAAmpmZmZnJP4CZmZmZmem/wMzMzMzM/L8wMzMzMzMXwA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T8wMzMzMzMLwDQzMzMzMyFAYGZmZmZm9r+YmZmZmZkVwA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j+gmZmZmZnZP2hmZmZmZvY/mJmZmZmZ+b+YmZmZmZn5vw==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z9AMzMzMzPjP0AzMzMzM+M/YGZmZmZm9r+AmZmZmZnZvw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcBwZmZmZmYOQHBmZmZmZg5AyMzMzMzMEMAgMzMzMzPzvw==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb9oZmZmZmYOQJiZmZmZmQnAMDMzMzMz87+gmZmZmZnpPw==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAEMAAAAAAAAAAQA==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+gmZmZmZnpP4CZmZmZmcm/oJmZmZmZ6T+YmZmZmZkBwA==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAADwPwAAAAAAAADAAAAAAAAACMAAAAAAAAAQQA==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAAwAAAAAAAAABAAAAAAAAAAMAAAAAAAAAAAA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZmBkBgZmZmZmYGQEAzMzMzM/O/YGZmZmZmBkDQzMzMzMwcwA==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcAwMzMzMzPzv6CZmZmZmek/0MzMzMzM/D/QzMzMzMz8Pw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmEsCgmZmZmZnZP6CZmZmZmdk/oJmZmZmZ2T80MzMzMzMLQA==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz879oZmZmZmYGQJiZmZmZmQHA0MzMzMzM/D8wMzMzMzPzvw==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87/QzMzMzMz8P6CZmZmZmek/0MzMzMzM/D+YmZmZmZkJwA==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAkQAAAAAAAAPA/AAAAAAAAKsAAAAAAAADwvw==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMGECgmZmZmZnpvzQzMzMzMxPAoJmZmZmZ6b+AmZmZmZnJPw==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZCUCgmZmZmZnJP5qZmZmZmQFAMzMzMzMzE8CYmZmZmZnpvw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIEAAAAAAAAAQwAAAAAAAAPA/AAAAAAAAIMAAAAAAAAAIQA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAIQAAAAAAAABhAAAAAAAAACEAAAAAAAAAgwA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAYwAAAAAAAAADAAAAAAAAACEAAAAAAAAAAQA==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAAAQQAAAAAAAAAAAAAAAAAAACMAAAAAAAAAQwA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZFUCQmZmZmZn5vyAzMzMzM+O/yMzMzMzMDMDAmZmZmZnZPw==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L9oZmZmZmYmQMDMzMzMzPy/AJqZmZmZyT8wMzMzMzMfwA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ+T8wMzMzMzMLwNDMzMzMzAxAMDMzMzMzA8BAMzMzMzPjPw==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wJmZmZmZ6T84MzMzMzMTQDgzMzMzMxNAyMzMzMzMGMDIzMzMzMwQwA==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAQwAAAAAAAAPA/AAAAAAAACMAAAAAAAAAQQA==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz47/MzMzMzMwmQEAzMzMzM+O/aGZmZmZmHsDQzMzMzMwEwA==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmGkCYmZmZmZkRwDAzMzMzMwPAgJmZmZmZ2b9AMzMzMzPjPw==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZGUBAMzMzMzMLQMDMzMzMzAzAQDMzMzMzA0AwMzMzMzMhwA==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZCcA0MzMzMzMXQGhmZmZmZg5AZmZmZmZmIsBoZmZmZmYGQA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkBmZmZmZmYiwKCZmZmZmek/aGZmZmZmBkDQzMzMzMz8Pw==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMzE0CAZmZmZmYGQACYmZmZmcm/AJqZmZmZ6T9gZmZmZmYgwA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8CAmZmZmZnZv9DMzMzMzAxAMDMzMzMzC8DQzMzMzMwEQA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUDQzMzMzMwUQGBmZmZmZg7AQDMzMzMz8z8wMzMzMzMXwA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEMAAAAAAAAAmQAAAAAAAAPC/AAAAAAAACEAAAAAAAAAiwA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz47+cmZmZmZkZQMCZmZmZmdk/ZGZmZmZmGsDAmZmZmZnZPw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+YmZmZmZkBwJiZmZmZmQHAoJmZmZmZ6T9oZmZmZmYGQA==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8DQzMzMzMwEQGhmZmZmZhpAMDMzMzMzA8CYmZmZmZkRwA==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmIkBgZmZmZmYOwDAzMzMzMxfAoJmZmZmZAUDAzMzMzMz8vw==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0A0MzMzMzMLQDAzMzMzM+O/zMzMzMzMBMDMzMzMzMwMwA==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2b+gmZmZmZnZvzAzMzMzM+M/MDMzMzMz4z+gmZmZmZnZvw==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz8z/QzMzMzMwcQEAzMzMzM/M/MDMzMzMzH8DAzMzMzMz8vw==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZCUDAmZmZmZnJP8CZmZmZmck/ODMzMzMz8z8yMzMzMzMTwA==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T/QzMzMzMz8P6CZmZmZmek/mJmZmZmZAcAwMzMzMzPzvw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mZmZmZmZEcBkZmZmZmb2v5yZmZmZmfk/Z2ZmZmZmEkCQmZmZmZnZvw==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b8wMzMzMzPjv8zMzMzMzAzAaGZmZmZm9j+amZmZmZkRQA==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAADwPwAAAAAAAPC/AAAAAAAAAAAAAAAAAAAAwA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAIEAAAAAAAAAYwAAAAAAAABTAAAAAAAAACEAAAAAAAAAAAA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACEAAAAAAAADwvwAAAAAAABRAAAAAAAAACMAAAAAAAAAQwA==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T+amZmZmZkZQMzMzMzMzAzAzMzMzMzMDMCgmZmZmZnZPw==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b9oZmZmZmb2PzQzMzMzMwtAZmZmZmZmEsBoZmZmZmb2Pw==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mpmZmZmZEUCgmZmZmZnZP2ZmZmZmZhbAaGZmZmZm9j8wMzMzMzPjvw==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0A0MzMzMzMDQMzMzMzMzATAaGZmZmZm9j9mZmZmZmYSwA==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAAAAAAAAAAAAAAAAAAAAAA8D8AAAAAAAAAwA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ2T/MzMzMzMwEwGhmZmZmZvY/zMzMzMzMBMA0MzMzMzMLQA==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ6b+amZmZmZkBQDQzMzMzM/M/oJmZmZmZyT9mZmZmZmYGwA==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwPwAAAAAAAAAAAAAAAAAACEAAAAAAAAAAwA==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          oJmZmZmZEUCgmZmZmZkRQMDMzMzMzATAADMzMzMz479gZmZmZmYWwA==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 06:26:11.904905
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_tree_embedder_proba
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - xt
                      - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                        params:
                          estimator:
                            call: deep_forest.tree_embedder.ForestEmbedder
                            params:
                              estimator:
                                call: sklearn.ensemble._forest.ExtraTreesRegressor
                                params:
                                  bootstrap: true
                                  ccp_alpha: 0.0
                                  criterion: squared_error
                                  max_depth: null
                                  max_features: sqrt
                                  max_leaf_nodes: null
                                  max_samples: 0.5
                                  min_impurity_decrease: 0.0
                                  min_samples_leaf: 5
                                  min_samples_split: 2
                                  min_weight_fraction_leaf: 0.0
                                  monotonic_cst: null
                                  n_estimators: 150
                                  n_jobs: 14
                                  oob_score: false
                                  random_state: 0
                                  verbose: true
                                  warm_start: false
                              max_node_size: 0.8
                              max_pvalue: 1.0
                              method: path
                              node_weights: log_node_size
                          method: predict
                          post_transformer:
                            call: sklearn.pipeline.Pipeline
                            params:
                              memory: null
                              steps:
                              - - densifier
                                - call: nakano_datasets_v2.estimators.Densifier
                                  params: {}
                              - - pca
                                - call: sklearn.decomposition._pca.PCA
                                  params:
                                    copy: true
                                    iterated_power: auto
                                    n_components: 0.8
                                    n_oversamples: 10
                                    power_iteration_normalizer: auto
                                    random_state: 0
                                    svd_solver: auto
                                    tol: 0.0
                                    whiten: false
                              verbose: false
                    - - rf
                      - call: deep_forest.estimator_adapters.TreeEmbedderWithOutput
                        params:
                          estimator:
                            call: deep_forest.tree_embedder.ForestEmbedder
                            params:
                              estimator:
                                call: sklearn.ensemble._forest.RandomForestRegressor
                                params:
                                  bootstrap: true
                                  ccp_alpha: 0.0
                                  criterion: squared_error
                                  max_depth: null
                                  max_features: sqrt
                                  max_leaf_nodes: null
                                  max_samples: 0.5
                                  min_impurity_decrease: 0.0
                                  min_samples_leaf: 5
                                  min_samples_split: 2
                                  min_weight_fraction_leaf: 0.0
                                  monotonic_cst: null
                                  n_estimators: 150
                                  n_jobs: 14
                                  oob_score: false
                                  random_state: 0
                                  verbose: true
                                  warm_start: false
                              max_node_size: 0.95
                              max_pvalue: 1.0
                              method: path
                              node_weights: log_node_size
                          method: predict
                          post_transformer:
                            call: sklearn.pipeline.Pipeline
                            params:
                              memory: null
                              steps:
                              - - densifier
                                - call: nakano_datasets_v2.estimators.Densifier
                                  params: {}
                              - - pca
                                - call: sklearn.decomposition._pca.PCA
                                  params:
                                    copy: true
                                    iterated_power: auto
                                    n_components: 0.8
                                    n_oversamples: 10
                                    power_iteration_normalizer: auto
                                    random_state: 0
                                    svd_solver: auto
                                    tol: 0.0
                                    whiten: false
                              verbose: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_tree_embedder_proba
  params: {}
hash: ee4de8e05d62a9390d8ba9ed4e5d3685fd20e189765343e874b475f1f9509964
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/ee4de8e_20231231T062020531004_cascade_lc_tree_embedder_proba_CAL500.yml
results:
  fit_time:
  - 328.1711928844452
  - 329.78841280937195
  - 335.5266354084015
  - 332.52008724212646
  - 339.2239327430725
  fitted_params:
    estimator.level1.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 204
    - 203
    - 203
    - 200
    - 200
    estimator.level1.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 202
    - 202
    - 201
    - 199
    - 197
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level10.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 27
    - 29
    - 25
    - 28
    - 25
    estimator.level10.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 23
    - 24
    - 23
    - 24
    - 22
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level2.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 200
    - 200
    - 198
    - 194
    - 197
    estimator.level2.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 207
    - 205
    - 207
    - 203
    - 204
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level3.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 70
    - 86
    - 72
    - 84
    - 81
    estimator.level3.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 106
    - 117
    - 108
    - 112
    - 111
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level4.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 51
    - 58
    - 48
    - 58
    - 48
    estimator.level4.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 41
    - 49
    - 40
    - 47
    - 46
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level5.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 30
    - 35
    - 29
    - 33
    - 33
    estimator.level5.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 40
    - 42
    - 36
    - 42
    - 39
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level6.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 36
    - 37
    - 31
    - 36
    - 33
    estimator.level6.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 30
    - 33
    - 28
    - 30
    - 31
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level7.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 25
    - 29
    - 26
    - 26
    - 26
    estimator.level7.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 32
    - 33
    - 29
    - 32
    - 31
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level8.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 30
    - 30
    - 27
    - 32
    - 28
    estimator.level8.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 24
    - 28
    - 25
    - 26
    - 26
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
    estimator.level9.alternating_forests.column_transformer_.transformers_.rf.post_transformer_.pca.n_components_:
    - 23
    - 26
    - 23
    - 24
    - 22
    estimator.level9.alternating_forests.column_transformer_.transformers_.xt.post_transformer_.pca.n_components_:
    - 28
    - 28
    - 26
    - 29
    - 26
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.09392841807815688
      - 0.3567380213068142
      - 0.2165216134797828
      - 0.17260823735088437
      - 0.3298518009768009
      - 0.26151344707588775
      - 0.21958317244221498
      - 0.16486654159921488
      - 0.2378933795142586
      - 0.18617054375245293
      - 0.277999235678568
      - 0.18323462162343868
      - 0.10013102256669332
      - 0.18080350719239607
      - 0.27590537583515107
      - 0.21219853024628307
      - 0.21524572987987617
      - 0.18854744510232313
      - 0.22831330210794493
      - 0.14436050117443555
      - 0.25307551605147643
      - 0.11448993178855785
      - 0.2714282880891612
      - 0.23482611562487635
      - 0.118444607960737
      - 0.17434167702954018
      - 0.20692983838145124
      - 0.20640219060548726
      - 0.12451477659943098
      - 0.11386692206019935
      - 0.2705166001189966
      - 0.18557466856051938
      - 0.2879123126258344
      - 0.12564953405470644
      - 0.2726328006547786
      - 0.1274806564208738
      - 0.09444044430746558
      - 0.06216231086920744
      - 0.06293877418877417
      - 0.04791020419683423
      - 0.08543173096744525
      - 0.05966296278297874
      - 0.054950336910564175
      - 0.10026507655818001
      - 0.04271598035802582
      - 0.17672338229403445
      - 0.0766913203335617
      - 0.043124278168921025
      - 0.17368328971802294
      - 0.18761474033213155
      - 0.05447938139546437
      - 0.30022291791133693
      - 0.1466992740219661
      - 0.08775844679605377
      - 0.10956595978081846
      - 0.3877495693922833
      - 0.0935588159735887
      - 0.030781557623662886
      - 0.04335651577030887
      - 0.12078331320755564
      - 0.20450648251962972
      - 0.12531851113397424
      - 0.03452364331270581
      - 0.22486273147287553
      - 0.1840409378345386
      - 0.22289627929937145
      - 0.17487241885285076
      - 0.24454848780410715
      - 0.3168010123459317
      - 0.16859799398924596
      - 0.1906730689248625
      - 0.09275919493942748
      - 0.24471344068118267
      - 0.15260882022930214
      - 0.30682382002787134
      - 0.0872505287381912
      - 0.14428290896679086
      - 0.46336970405986594
      - 0.33781645997346954
      - 0.3824193148907326
      - 0.18957916784270387
      - 0.10657060053611775
      - 0.05631205789745726
      - 0.10052864518191595
      - 0.30666257718889295
      - 0.10826191352507143
      - 0.03951264155345788
      - 0.16402155294200746
      - 0.12328593432533648
      - 0.034885543808613764
      - 0.027671063504396836
      - 0.04315277380128611
      - 0.034941833653173854
      - 0.1346244019227046
      - 0.04245511306363234
      - 0.10393631253006252
      - 0.06378524482621038
      - 0.05770797044835506
      - 0.05838585923880041
      - 0.06407165057165057
      - 0.061315212477451565
      - 0.0494117383564274
      - 0.03613363244942193
    - - 0.08721162839674373
      - 0.36859935790312626
      - 0.22809203886790094
      - 0.16979547467184825
      - 0.33646902267591916
      - 0.23782984557377718
      - 0.21515759441017168
      - 0.15893595353349263
      - 0.19677304284862424
      - 0.16211093800379514
      - 0.2544468696812446
      - 0.21049759552069175
      - 0.09688102523612692
      - 0.18857909519674218
      - 0.21633612371564176
      - 0.23098470633833793
      - 0.17075770002714968
      - 0.15767500726323827
      - 0.24585773023273022
      - 0.1241696360281404
      - 0.23591465059488315
      - 0.1251525304687743
      - 0.2927752144858886
      - 0.2521056238447543
      - 0.13807880709923978
      - 0.15902383000597284
      - 0.16045974176930922
      - 0.21497053082418932
      - 0.08866680738827859
      - 0.10375843381833044
      - 0.28040062432581486
      - 0.16207862190224814
      - 0.28272295207779075
      - 0.12413707197361042
      - 0.2797105810898298
      - 0.13153320007013186
      - 0.10550507388795416
      - 0.04230240712562365
      - 0.055432987360698203
      - 0.04211011211011211
      - 0.07733475489157307
      - 0.03888732989856585
      - 0.041195567226971166
      - 0.07695158931422667
      - 0.04383168505960626
      - 0.18371623943432447
      - 0.07737778970722439
      - 0.033831714880101976
      - 0.17576052827891064
      - 0.21843737033469174
      - 0.08598705031740746
      - 0.3104378418298872
      - 0.1355742492461242
      - 0.08012936137936139
      - 0.11125410687980675
      - 0.3731726128277853
      - 0.11762050449550449
      - 0.0430391177450001
      - 0.06264737472123835
      - 0.12224399980540898
      - 0.21978053774928763
      - 0.09122281181750244
      - 0.027154401751175943
      - 0.2546290793681103
      - 0.19609082766279734
      - 0.1904772044195121
      - 0.18568283224588678
      - 0.18121270655286023
      - 0.3159043999594238
      - 0.15948814034906705
      - 0.21166209502259603
      - 0.058877134769991915
      - 0.2493172425864733
      - 0.0941406121351176
      - 0.3050541327885077
      - 0.11619596403868127
      - 0.11909853712179291
      - 0.4656152721343746
      - 0.34860101633060814
      - 0.3629439706052609
      - 0.19357933883818154
      - 0.11844834647756104
      - 0.0505071813770009
      - 0.098110969078711
      - 0.28366784052267924
      - 0.08485309333523619
      - 0.03771533383602349
      - 0.1621460828323492
      - 0.07643556505916058
      - 0.038442859410601354
      - 0.027622434255087314
      - 0.06306567963871333
      - 0.04247882672882673
      - 0.1179639962310417
      - 0.039492489290876384
      - 0.11515138075013887
      - 0.05712746344003297
      - 0.05103307640072347
      - 0.06584350545288045
      - 0.061337445094396245
      - 0.053669618361893406
      - 0.04930559206874996
      - 0.03803182150144767
    - - 0.08264775732395478
      - 0.3823270322520135
      - 0.22908733376075024
      - 0.1883231090892381
      - 0.33772213725917427
      - 0.24197093064531855
      - 0.2316638115607188
      - 0.18591469672766664
      - 0.19223888346640594
      - 0.1931828923764407
      - 0.28050189249988444
      - 0.19495696554907077
      - 0.09310674236618595
      - 0.1677165134443615
      - 0.22052969033167052
      - 0.2317542106545181
      - 0.2106866574487983
      - 0.20626784343705074
      - 0.23678932646629275
      - 0.14825779890212876
      - 0.28130204517704516
      - 0.12868689212988293
      - 0.27970117004207906
      - 0.23720664193297547
      - 0.1636380265149392
      - 0.21572556182816283
      - 0.19123679174396743
      - 0.21833183922847502
      - 0.09510405710900759
      - 0.06757733045273628
      - 0.2777967452915349
      - 0.18304114736699
      - 0.30350713141871677
      - 0.13648972625369238
      - 0.2830576126771778
      - 0.10737874909561655
      - 0.11230755678430093
      - 0.05037552577446194
      - 0.06720547364892603
      - 0.06261004270753114
      - 0.07422583801894148
      - 0.06267124715891319
      - 0.03433162429012872
      - 0.08204297711744521
      - 0.04561214444774228
      - 0.19132420156578425
      - 0.09453894917261728
      - 0.053033244648151484
      - 0.18592739156582477
      - 0.2129625089279855
      - 0.05591097243399876
      - 0.30795548268284556
      - 0.13917814196990397
      - 0.08434394196589319
      - 0.10136642768995707
      - 0.40748611853263017
      - 0.09912808058224777
      - 0.04413552397423365
      - 0.04788709554334554
      - 0.11554901905176629
      - 0.23028306381964914
      - 0.10013426851114678
      - 0.03630641657290169
      - 0.2306582306582306
      - 0.20339721042846043
      - 0.20652167134125893
      - 0.20106358217313267
      - 0.18738064184492753
      - 0.3641029987558444
      - 0.17327359884804733
      - 0.21672827627015687
      - 0.08846199056873214
      - 0.2388497824639129
      - 0.13997379983461913
      - 0.29996235576592706
      - 0.11290662727323891
      - 0.13197064748355508
      - 0.48946721488388156
      - 0.34822219606702354
      - 0.39070983517186053
      - 0.20526584674980394
      - 0.10307436327844488
      - 0.04700052038761715
      - 0.15715560104147064
      - 0.30587963344571545
      - 0.08593506254796576
      - 0.04481067875226662
      - 0.17151476995226994
      - 0.09278444769516198
      - 0.030894804948869543
      - 0.038608541107181926
      - 0.07238703325659848
      - 0.040276154408169076
      - 0.14298433151162865
      - 0.052707491722643246
      - 0.09394946139132188
      - 0.06506465206960255
      - 0.05034552564844186
      - 0.04512083468730644
      - 0.0798201683819356
      - 0.048389633426555306
      - 0.039799826909201905
      - 0.03833619120518434
    - - 0.0981782398887662
      - 0.406990891332907
      - 0.23195406100991206
      - 0.18448239260739258
      - 0.3114252734773081
      - 0.2208915296700982
      - 0.24310175775693013
      - 0.14013390204566675
      - 0.21816061131850606
      - 0.1647888696246588
      - 0.23770321053215787
      - 0.1705900261934744
      - 0.09194437953150353
      - 0.1776842864500312
      - 0.24235514697887142
      - 0.2110636213728997
      - 0.200989154754215
      - 0.1781060411278407
      - 0.24917951366814997
      - 0.13293559888387474
      - 0.23044743869211953
      - 0.10258468383468383
      - 0.3011261712162741
      - 0.2518369719118567
      - 0.13987199256587837
      - 0.1528739412402778
      - 0.17931004514266602
      - 0.20370062943592354
      - 0.10902883492169207
      - 0.08603276683633827
      - 0.2694211930703118
      - 0.21222884714264023
      - 0.32381582897171013
      - 0.11282126689735382
      - 0.2911263309164976
      - 0.12973395206541272
      - 0.11371871149462275
      - 0.06579577997444078
      - 0.05361592559173204
      - 0.03555739911563696
      - 0.07806750194250195
      - 0.040516603447637925
      - 0.04672554349520641
      - 0.08111295585727403
      - 0.028536129342580957
      - 0.16554199962813404
      - 0.07755874895121218
      - 0.03318827628936433
      - 0.1714973262032085
      - 0.19326973040868373
      - 0.06221687176743357
      - 0.31973674046288925
      - 0.13699685946386253
      - 0.11566179894984241
      - 0.08454752849489691
      - 0.37238415454707585
      - 0.1445764935821754
      - 0.04908453255227449
      - 0.061146610481716865
      - 0.11497789844564037
      - 0.19660946205629462
      - 0.11421959748645603
      - 0.02899077358347021
      - 0.24982656397323577
      - 0.20082586946240594
      - 0.19594539552658108
      - 0.19385317747386704
      - 0.18914713004386915
      - 0.3273002902216384
      - 0.1860584167708012
      - 0.1726979929731822
      - 0.06909344906793885
      - 0.23164053589877764
      - 0.14479082210060468
      - 0.32586608809327056
      - 0.07743738232832748
      - 0.13341099136553683
      - 0.4762878494474344
      - 0.3686235050047212
      - 0.3805494566483578
      - 0.2021595082227266
      - 0.09173349337973115
      - 0.043218515547975817
      - 0.11367274267555164
      - 0.29086543686080724
      - 0.10850899546095305
      - 0.050116667933305895
      - 0.14571325665075663
      - 0.10865129768190993
      - 0.031688523894406254
      - 0.07230663725959424
      - 0.08530854822743739
      - 0.04360119226740379
      - 0.13657673103448362
      - 0.04665194513679362
      - 0.0949459458669985
      - 0.06337708587708588
      - 0.04206556966425388
      - 0.06732929716095146
      - 0.056123933433716036
      - 0.045305994131182095
      - 0.0707250236213651
      - 0.04142247246559093
    - - 0.10821506359725153
      - 0.3994352162324649
      - 0.21765099279805156
      - 0.1741727394165195
      - 0.3269573387471114
      - 0.25103610457894165
      - 0.22754611392663174
      - 0.15522976941768746
      - 0.21789952601808274
      - 0.17538191880217346
      - 0.24625225431677034
      - 0.18207374878641636
      - 0.07623621902788569
      - 0.19112948415817527
      - 0.2220417282958428
      - 0.24021363389470005
      - 0.19095948900636397
      - 0.14750582752241254
      - 0.20077763463708154
      - 0.12294447816599713
      - 0.23946042383542376
      - 0.12560646716502152
      - 0.2887897782294333
      - 0.2583200761701053
      - 0.10296102225983941
      - 0.17881520579691312
      - 0.18154903671208017
      - 0.19302933656381932
      - 0.07206337723579102
      - 0.08566948033240168
      - 0.2816744066524768
      - 0.1817012366745097
      - 0.27941751881224464
      - 0.1212523937060382
      - 0.29792642215545173
      - 0.12045013067740337
      - 0.12650976766345728
      - 0.10251237260600662
      - 0.059061015451464895
      - 0.0467501915605191
      - 0.08937677105780553
      - 0.042625074789708936
      - 0.04920027124999911
      - 0.09173100561989453
      - 0.04601132374569874
      - 0.15542772674362992
      - 0.06868258682774812
      - 0.03726378889656626
      - 0.1679619153456363
      - 0.18622611798632202
      - 0.0666841853130462
      - 0.33133222826129394
      - 0.135730489178765
      - 0.10755297210993411
      - 0.09852065959402916
      - 0.365425284723777
      - 0.10360097939885174
      - 0.07928773422959468
      - 0.0738950863950864
      - 0.10554509375340732
      - 0.24924203013857293
      - 0.11173490026582808
      - 0.034616579141240285
      - 0.25293673002964706
      - 0.16301160413327526
      - 0.2112125576969327
      - 0.18643291375641946
      - 0.1647990430293801
      - 0.30637054104796035
      - 0.16851714051127537
      - 0.20894192854985577
      - 0.08289930895870612
      - 0.26603188199946215
      - 0.1100548835634063
      - 0.3058506743531495
      - 0.10623366382294953
      - 0.12868456640258963
      - 0.4628135383555235
      - 0.3392017987681253
      - 0.36232648121379174
      - 0.17043108875952753
      - 0.1089418198289166
      - 0.05077460155585156
      - 0.09876960861809346
      - 0.3239616787533454
      - 0.08070306016734588
      - 0.05528405980992187
      - 0.18099891765152037
      - 0.06087570174510496
      - 0.02681140593228505
      - 0.03251816790973418
      - 0.06870190741158483
      - 0.045837715807227994
      - 0.11544914284449231
      - 0.03317987155421323
      - 0.0948715210574793
      - 0.07212809754699617
      - 0.05495015188892739
      - 0.06183644611063967
      - 0.07519642193555237
      - 0.055200161248548346
      - 0.04072548796233007
      - 0.03629551538205384
  score_time:
  - 10.196141242980957
  - 10.218392610549927
  - 10.912905216217041
  - 10.167930603027344
  - 10.838186740875244
  test_level0__average_precision_macro:
  - 0.317919057341108
  - 0.32339896561864456
  - 0.2984033409732915
  - 0.29614250556696275
  - 0.31237433226951505
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.5082413460633186
  - 0.5022353516448743
  - 0.4977723950199496
  - 0.48026855829430726
  - 0.507219176882964
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.5454000642503906
  - 0.5311468393381648
  - 0.5326776732724431
  - 0.5130559932438
  - 0.5362094149872695
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.4409317840470262
  - 0.44327825789729275
  - 0.4256041167108825
  - 0.40259995869922094
  - 0.4296405073860449
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7656755663430419
  - 0.7684061488673138
  - 0.7738712413988122
  - 0.7586273190425838
  - 0.7647920864627219
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7656755663430421
  - 0.768406148867314
  - 0.7738712413988124
  - 0.7586273190425838
  - 0.7647920864627221
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.765675566343042
  - 0.7684061488673137
  - 0.7738712413988122
  - 0.7586273190425836
  - 0.7647920864627221
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.641992777059077
  - 0.6519252434946937
  - 0.6556167939733848
  - 0.6492226283560254
  - 0.6482992499707019
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.234324433656958
  - -0.2315938511326861
  - -0.22612875860118767
  - -0.24137268095741615
  - -0.2352079135372779
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.23432443365695793
  - -0.23159385113268607
  - -0.22612875860118767
  - -0.24137268095741612
  - -0.23520791353727788
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.23432443365695788
  - -0.23159385113268605
  - -0.22612875860118764
  - -0.2413726809574161
  - -0.23520791353727785
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.3580072229409227
  - -0.3480747565053059
  - -0.3443832060266151
  - -0.3507773716439744
  - -0.35170075002929796
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6478669100778323
  - 0.6491807236236554
  - 0.6567602871845984
  - 0.6359622350527762
  - 0.6448245820911035
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.620319541171651
  - 0.6239119724092625
  - 0.631150061500615
  - 0.6111197150379433
  - 0.6191606110040041
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6235409724591348
  - 0.6259508279291663
  - 0.6334569746929418
  - 0.614141182787756
  - 0.621982525346849
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5023929696080992
  - 0.5142254173154243
  - 0.5175337502337465
  - 0.5081978768402905
  - 0.5087355002433115
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5454000642503903
  - 0.531146839338165
  - 0.532677673272443
  - 0.5130559932438001
  - 0.5362094149872696
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.0005352600450679333
  - 0.0005946106763162391
  - 0.0005418587624174369
  - 0.0
  - 0.0008449482650210422
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.025696476269267236
  - 0.031705466842055205
  - 0.02538874930385229
  - 0.0
  - 0.04872981713221773
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.004384137345937883
  - 0.005041259269091526
  - 0.0036924396222971175
  - 0.0
  - 0.013291915841194438
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0019970116041085634
  - 0.0022970176061095707
  - 0.002068812692661659
  - 0.0
  - 0.0032771265977582426
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8318079565965121
  - 0.8296612969738345
  - 0.8263926875782959
  - 0.8187200756576578
  - 0.829509461207506
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -89.22916666666667
  - -90.26041666666667
  - -88.55339805825243
  - -91.4950495049505
  - -89.33018867924528
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.234324433656958
  - -0.2315938511326861
  - -0.22612875860118767
  - -0.24137268095741615
  - -0.2352079135372779
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.23432443365695793
  - -0.23159385113268607
  - -0.22612875860118767
  - -0.24137268095741612
  - -0.23520791353727788
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.23432443365695788
  - -0.23159385113268605
  - -0.22612875860118764
  - -0.2413726809574161
  - -0.23520791353727785
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.3580072229409227
  - -0.3480747565053059
  - -0.3443832060266151
  - -0.3507773716439744
  - -0.35170075002929796
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.24129694543521216
  - -0.25473652863208535
  - -0.24890901339715862
  - -0.2678428421340648
  - -0.24880783812887136
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7656755663430419
  - 0.7684061488673138
  - 0.7738712413988122
  - 0.7586273190425838
  - 0.7647920864627219
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7656755663430421
  - 0.768406148867314
  - 0.7738712413988124
  - 0.7586273190425838
  - 0.7647920864627221
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.765675566343042
  - 0.7684061488673137
  - 0.7738712413988122
  - 0.7586273190425836
  - 0.7647920864627221
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.641992777059077
  - 0.6519252434946937
  - 0.6556167939733848
  - 0.6492226283560254
  - 0.6482992499707019
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7656755663430419
  - 0.7684061488673138
  - 0.7738712413988122
  - 0.7586273190425838
  - 0.7647920864627219
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7656755663430421
  - 0.768406148867314
  - 0.7738712413988124
  - 0.7586273190425838
  - 0.7647920864627221
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.765675566343042
  - 0.7684061488673137
  - 0.7738712413988122
  - 0.7586273190425836
  - 0.7647920864627221
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.641992777059077
  - 0.6519252434946937
  - 0.6556167939733848
  - 0.6492226283560254
  - 0.6482992499707019
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5672931624262858
  - 0.5906447220496268
  - 0.5591771622207341
  - 0.5364968542433127
  - 0.5699170785531031
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7535821512944786
  - 0.7448093303976066
  - 0.7474608532994292
  - 0.72776428418456
  - 0.7482652978790256
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7587030545647878
  - 0.7452634713679146
  - 0.7510909866028413
  - 0.7321571578659354
  - 0.7511921618711286
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.569806411682559
  - 0.5940890557722385
  - 0.5680558755255868
  - 0.5343300205648099
  - 0.5706383026988548
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.7654733009708735
  - 0.7681027508090614
  - 0.7736827222169855
  - 0.7586273190425838
  - 0.764059351529584
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7654733009708737
  - 0.7681027508090615
  - 0.7736827222169855
  - 0.7586273190425838
  - 0.7640593515295842
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7654733009708737
  - 0.7681027508090614
  - 0.7736827222169855
  - 0.7586273190425836
  - 0.764059351529584
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.6412381414402758
  - 0.6507531981392642
  - 0.6548970291504753
  - 0.6492226283560254
  - 0.645457342083675
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 0.00020226537216828477
  - 0.00030339805825242716
  - 0.00018851918182675084
  - 0.0
  - 0.0007327349331379373
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 0.0002022653721682848
  - 0.00030339805825242716
  - 0.00018851918182675087
  - 0.0
  - 0.0007327349331379373
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 0.00020226537216828477
  - 0.00030339805825242716
  - 0.00018851918182675084
  - 0.0
  - 0.0007327349331379373
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.0007546356188012075
  - 0.0011720453554295682
  - 0.0007197648229095481
  - 0.0
  - 0.0028419078870268373
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.2889489954609368
  - 0.30070053934261404
  - 0.29426477368275034
  - 0.2696974802048923
  - 0.30980996802821786
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.2620427516053741
  - 0.2662970101731455
  - 0.25809810600515637
  - 0.240617487461018
  - 0.28498367146509246
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.28169584790262114
  - 0.29338611148194954
  - 0.27474861579868165
  - 0.2595822005222732
  - 0.3042426803419153
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.4212032032706126
  - 0.43006818999693397
  - 0.42079215948371934
  - 0.37977806107607837
  - 0.43151883084349635
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.4076658576051779
  - 0.3735841423948219
  - 0.38580450560844576
  - 0.3722003268287994
  - 0.3899981681626672
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.407665857605178
  - 0.373584142394822
  - 0.38580450560844565
  - 0.3722003268287994
  - 0.38999816816266714
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.407665857605178
  - 0.373584142394822
  - 0.3858045056084458
  - 0.3722003268287993
  - 0.3899981681626671
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.482230127928705
  - 0.46118621892716966
  - 0.4685628560915152
  - 0.43866788112503
  - 0.46614980077346774
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.036205501618122984
  - -0.023968446601941747
  - -0.03148270336506739
  - -0.0383543208689801
  - -0.0239054771936252
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.03620550161812298
  - -0.023968446601941747
  - -0.031482703365067394
  - -0.0383543208689801
  - -0.023905477193625208
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.03620550161812298
  - -0.023968446601941747
  - -0.03148270336506739
  - -0.0383543208689801
  - -0.023905477193625204
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.046176512864740546
  - -0.030150639627852895
  - -0.039194833867765455
  - -0.046744817850960727
  - -0.030187946794796673
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.5561286407766991
  - -0.6024474110032363
  - -0.582712791026487
  - -0.5894453523022205
  - -0.5860963546437077
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.556128640776699
  - -0.6024474110032363
  - -0.582712791026487
  - -0.5894453523022205
  - -0.5860963546437077
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.556128640776699
  - -0.6024474110032362
  - -0.582712791026487
  - -0.5894453523022206
  - -0.5860963546437076
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.47159335920655454
  - -0.5086631414449775
  - -0.4922423100407191
  - -0.5145873010240092
  - -0.5036622524317357
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.26984972848254
  - 0.2425342854958754
  - 0.25296830470985077
  - 0.23974492335434083
  - 0.2558893231735349
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.256017783423309
  - 0.2296977987812461
  - 0.239007299270073
  - 0.22865241525924176
  - 0.24223461144612585
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.261563895602891
  - 0.2360178787712495
  - 0.24412227696765054
  - 0.23306165879067334
  - 0.2483607385867414
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.33274220567281626
  - 0.3152238691696618
  - 0.32053782350267224
  - 0.29414128337632867
  - 0.3207777012374299
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.2816958479026212
  - 0.2933861114819497
  - 0.27474861579868165
  - 0.2595822005222732
  - 0.30424268034191543
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.07962639569197931
  - 0.08898459993425291
  - 0.08016591774701537
  - 0.03243387857166984
  - 0.10278228237552706
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.11725014292315653
  - 0.12091682682419438
  - 0.10838499871868182
  - 0.06764661255029714
  - 0.13920100614459593
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.11943369420909038
  - 0.110678800312117
  - 0.10686530472443158
  - 0.07094060122356263
  - 0.1302581042052546
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.09033967829104327
  - 0.09351152051465818
  - 0.09172973030983352
  - 0.03065169305475621
  - 0.10968505498616084
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6338815077303029
  - 0.6397792437472792
  - 0.6289472001852173
  - 0.6226132930116887
  - 0.6495967629270093
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -88.20833333333333
  - -88.96875
  - -91.1747572815534
  - -93.13861386138613
  - -88.71698113207547
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.5923341423948221
  - -0.626415857605178
  - -0.6141954943915544
  - -0.6277996731712006
  - -0.6100018318373328
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.592334142394822
  - -0.626415857605178
  - -0.6141954943915543
  - -0.6277996731712007
  - -0.6100018318373328
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.592334142394822
  - -0.626415857605178
  - -0.6141954943915542
  - -0.6277996731712007
  - -0.6100018318373328
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5177698720712951
  - -0.5388137810728304
  - -0.5314371439084847
  - -0.5613321188749699
  - -0.5338501992265322
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.4715993290775173
  - -0.4562696529215513
  - -0.4689596147520499
  - -0.5195148645964158
  - -0.43060058218737857
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.4076658576051779
  - 0.3735841423948219
  - 0.38580450560844576
  - 0.3722003268287994
  - 0.3899981681626672
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.407665857605178
  - 0.373584142394822
  - 0.38580450560844565
  - 0.3722003268287994
  - 0.38999816816266714
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.407665857605178
  - 0.373584142394822
  - 0.3858045056084458
  - 0.3722003268287993
  - 0.3899981681626671
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.482230127928705
  - 0.46118621892716966
  - 0.4685628560915152
  - 0.43866788112503
  - 0.46614980077346774
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.4076658576051779
  - 0.3735841423948219
  - 0.38580450560844576
  - 0.3722003268287994
  - 0.3899981681626672
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.407665857605178
  - 0.373584142394822
  - 0.38580450560844565
  - 0.3722003268287994
  - 0.38999816816266714
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.407665857605178
  - 0.373584142394822
  - 0.3858045056084458
  - 0.3722003268287993
  - 0.3899981681626671
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.482230127928705
  - 0.46118621892716966
  - 0.4685628560915152
  - 0.43866788112503
  - 0.46614980077346774
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5690609165821924
  - 0.5977831253366898
  - 0.5851921844303904
  - 0.5356346302805458
  - 0.6084363427668887
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.5707589073722842
  - 0.5793443536974741
  - 0.5713008783296109
  - 0.5169375629137523
  - 0.6017633353858571
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.5631495029304675
  - 0.5735129836110876
  - 0.561089794047481
  - 0.5171762110715292
  - 0.5912815788255915
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5728964495445111
  - 0.6020370598293233
  - 0.5851656093571248
  - 0.5320246793850709
  - 0.6005027140232373
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.20934466019417475
  - 0.1656553398058252
  - 0.19096993119049857
  - 0.1691819667403633
  - 0.17796299688587655
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.20934466019417475
  - 0.16565533980582525
  - 0.19096993119049863
  - 0.16918196674036334
  - 0.17796299688587652
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.20934466019417472
  - 0.1656553398058252
  - 0.19096993119049857
  - 0.16918196674036332
  - 0.17796299688587652
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.1696447822337214
  - 0.14209005669428695
  - 0.16265471910975607
  - 0.13463532733201639
  - 0.14179508965193954
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.19832119741100324
  - 0.20792880258899682
  - 0.19483457441794702
  - 0.20301836008843605
  - 0.21203517127679067
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.19832119741100324
  - 0.20792880258899676
  - 0.19483457441794702
  - 0.20301836008843602
  - 0.2120351712767906
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.1983211974110032
  - 0.2079288025889967
  - 0.19483457441794702
  - 0.20301836008843602
  - 0.21203517127679058
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.3125853456949835
  - 0.3190961622328826
  - 0.3059081369817592
  - 0.3040325537930137
  - 0.32435471112152814
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.3110071040436376
  - 0.33326328544273753
  - 0.3055229960654443
  - 0.28158302583043565
  - 0.3397430821994353
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.27866677860830985
  - 0.27690206968690645
  - 0.2569591324259358
  - 0.250179505479797
  - 0.3026874865319469
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.3137717204279588
  - 0.311280994298805
  - 0.28770354457582153
  - 0.2810864877769988
  - 0.3354130331976864
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.43846494476932907
  - 0.4592193592459779
  - 0.42768485838457115
  - 0.3887197724268128
  - 0.46133565213717
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.40442961165048535
  - 0.36549352750809055
  - 0.37882929588085584
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.4044296116504854
  - 0.3654935275080906
  - 0.3788292958808559
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.40442961165048547
  - 0.3654935275080906
  - 0.3788292958808558
  - 0.38325483033740254
  - 0.37854918483238686
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.47544289923817756
  - 0.45254579153946817
  - 0.4548873244562338
  - 0.44399493712812144
  - 0.45046437360834407
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.028317152103559874
  - -0.019316343042071197
  - -0.029786030728626636
  - -0.03912332980870903
  - -0.019417475728155338
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.02831715210355987
  - -0.019316343042071197
  - -0.029786030728626636
  - -0.03912332980870903
  - -0.019417475728155338
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.028317152103559867
  - -0.019316343042071197
  - -0.029786030728626633
  - -0.03912332980870902
  - -0.019417475728155338
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.032314575247951706
  - -0.02216437708969327
  - -0.03394621173216662
  - -0.04236409304012838
  - -0.022035772881753193
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.5672532362459547
  - -0.6151901294498382
  - -0.5913846733905176
  - -0.5776218398538884
  - -0.6020333394394578
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.5672532362459547
  - -0.6151901294498382
  - -0.5913846733905175
  - -0.5776218398538883
  - -0.6020333394394578
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.5672532362459547
  - -0.6151901294498382
  - -0.5913846733905174
  - -0.5776218398538882
  - -0.6020333394394577
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.4922425255138709
  - -0.5252898313708386
  - -0.5111664638115995
  - -0.5136409698317501
  - -0.5274998535099028
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.27189294172588724
  - 0.24091898634005246
  - 0.2528879880508088
  - 0.2515562835886063
  - 0.253097130781154
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.25347024149077774
  - 0.22361093924019304
  - 0.2336763765335194
  - 0.23705333254057911
  - 0.23346325481556798
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.2582009928399889
  - 0.2279413034464651
  - 0.23712490684820867
  - 0.24025544344531027
  - 0.23739564486533604
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.3294599091862844
  - 0.31164148678845194
  - 0.312116208239086
  - 0.30006203965148204
  - 0.3107349494418266
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.31377172042795876
  - 0.311280994298805
  - 0.28770354457582165
  - 0.2810864877769988
  - 0.3354130331976864
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.08398489881761462
  - 0.0852975883247845
  - 0.06389171321974109
  - 0.024601485277722587
  - 0.08580909206609617
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.13989716035096808
  - 0.12941596658440918
  - 0.10647057130688982
  - 0.07901730964561879
  - 0.142960205967779
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.1412437717215583
  - 0.12302708898747823
  - 0.10750110349263546
  - 0.0811296205297952
  - 0.13656276853597313
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.08626793174767607
  - 0.08636918831296403
  - 0.06585294798714074
  - 0.023843648965564363
  - 0.0880738529730016
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.6399567757057029
  - 0.6366506039320999
  - 0.6172509768421729
  - 0.620318766278185
  - 0.6594128701535636
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -87.64583333333333
  - -88.86458333333333
  - -90.59223300970874
  - -93.66336633663366
  - -88.0754716981132
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.5955703883495146
  - -0.6345064724919094
  - -0.6211707041191442
  - -0.6167451696625974
  - -0.6214508151676131
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.5955703883495146
  - -0.6345064724919094
  - -0.6211707041191441
  - -0.6167451696625973
  - -0.6214508151676131
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.5955703883495146
  - -0.6345064724919093
  - -0.6211707041191441
  - -0.6167451696625973
  - -0.621450815167613
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.5245571007618226
  - -0.5474542084605319
  - -0.5451126755437661
  - -0.5560050628718786
  - -0.5495356263916559
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.39991968478514134
  - -0.3949549453455122
  - -0.4138839577921028
  - -0.4496110202571599
  - -0.38276155907322307
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.40442961165048535
  - 0.36549352750809055
  - 0.37882929588085584
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.4044296116504854
  - 0.3654935275080906
  - 0.3788292958808559
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.40442961165048547
  - 0.3654935275080906
  - 0.3788292958808558
  - 0.38325483033740254
  - 0.37854918483238686
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.47544289923817756
  - 0.45254579153946817
  - 0.4548873244562338
  - 0.44399493712812144
  - 0.45046437360834407
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.40442961165048535
  - 0.36549352750809055
  - 0.37882929588085584
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.4044296116504854
  - 0.3654935275080906
  - 0.3788292958808559
  - 0.38325483033740265
  - 0.37854918483238686
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.40442961165048547
  - 0.3654935275080906
  - 0.3788292958808558
  - 0.38325483033740254
  - 0.37854918483238686
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.47544289923817756
  - 0.45254579153946817
  - 0.4548873244562338
  - 0.44399493712812144
  - 0.45046437360834407
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5778796731731332
  - 0.6089565522179315
  - 0.58070364220255
  - 0.5278044645103377
  - 0.6106548785663112
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.6020162015565751
  - 0.6063437194863033
  - 0.587414006956166
  - 0.5454733839126091
  - 0.6238690488599932
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.6000969828972064
  - 0.6051506090364872
  - 0.5861436985949419
  - 0.5508766668694289
  - 0.6172728619587402
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5795554864350606
  - 0.6197452824999474
  - 0.5836335758996334
  - 0.5269288053721186
  - 0.6006133598959658
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.19822006472491907
  - 0.1529126213592233
  - 0.18229804882646808
  - 0.1810054791886956
  - 0.1620260120901264
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.1982200647249191
  - 0.1529126213592233
  - 0.1822980488264681
  - 0.18100547918869556
  - 0.1620260120901264
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.19822006472491904
  - 0.15291262135922326
  - 0.182298048826468
  - 0.18100547918869558
  - 0.16202601209012632
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.1489956159264051
  - 0.12546336676842562
  - 0.14373056533887582
  - 0.13558165852427537
  - 0.11795748857377243
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.20620954692556637
  - 0.21258090614886735
  - 0.1965312470543878
  - 0.20224935114870712
  - 0.21652317274226052
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.20620954692556634
  - 0.21258090614886732
  - 0.1965312470543878
  - 0.2022493511487071
  - 0.2165231727422605
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.20620954692556628
  - 0.21258090614886727
  - 0.19653124705438774
  - 0.20224935114870712
  - 0.21652317274226043
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.32644728331177225
  - 0.3270824247710422
  - 0.3111567591173581
  - 0.30841327860384604
  - 0.3325068850345717
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.2933989219797778
  - 0.31089754870909836
  - 0.294860119777913
  - 0.2727970052658484
  - 0.3182840961307991
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.26151121111764053
  - 0.27025698987672037
  - 0.2533026053076447
  - 0.24073925354758854
  - 0.28776146826131677
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.2835221366608292
  - 0.29694130244095707
  - 0.27390399417948225
  - 0.26103376381017984
  - 0.30587772542257735
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.4251682906617482
  - 0.44208529804582336
  - 0.4196479087576165
  - 0.3846188427376049
  - 0.4400980826148194
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.40523867313915846
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698836
  - 0.3852353910972705
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698837
  - 0.38523539109727056
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.3827881986992176
  - 0.36912429106988376
  - 0.3852353910972705
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.4807747592353026
  - 0.45985971798226494
  - 0.46567166593207526
  - 0.43661355382850126
  - 0.46404034337278804
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.03478964401294499
  - -0.021945792880258903
  - -0.03148270336506739
  - -0.037681438046717294
  - -0.02161568052756915
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.03478964401294499
  - -0.0219457928802589
  - -0.031482703365067394
  - -0.037681438046717294
  - -0.021615680527569153
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.03478964401294498
  - -0.0219457928802589
  - -0.03148270336506739
  - -0.037681438046717294
  - -0.021615680527569146
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.04393057352307029
  - -0.02801551824393081
  - -0.03927570631977777
  - -0.04574328400581993
  - -0.026946853392710652
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.5599716828478966
  - -0.6053802588996764
  - -0.5857290979357149
  - -0.593194270883399
  - -0.5931489283751603
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.5599716828478964
  - -0.6053802588996764
  - -0.5857290979357149
  - -0.593194270883399
  - -0.5931489283751603
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.5599716828478964
  - -0.6053802588996763
  - -0.5857290979357149
  - -0.593194270883399
  - -0.5931489283751603
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.4752946672416269
  - -0.5121247637738043
  - -0.495052627748147
  - -0.5176431621656788
  - -0.5090128032345013
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.26846596984959653
  - 0.2425084283810373
  - 0.2508794183103772
  - 0.23765641866445805
  - 0.25292937475943617
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.25410615765108757
  - 0.22901000559318874
  - 0.23669639214314858
  - 0.22633502298715077
  - 0.2385706182643222
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.25984034609884904
  - 0.2349856043057752
  - 0.24163452175004765
  - 0.23073279403555097
  - 0.24436607240511896
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.3318330698081997
  - 0.31456656064970545
  - 0.3184504982117126
  - 0.29281333578534163
  - 0.31943686678398825
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.2835221366608292
  - 0.29694130244095707
  - 0.27390399417948225
  - 0.26103376381017984
  - 0.3058777254225773
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.08045795888342466
  - 0.0964600076662967
  - 0.07665016242134699
  - 0.026863144544063872
  - 0.10258860514785376
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.11912343369976622
  - 0.12748932336411692
  - 0.104974518366668
  - 0.06589797174280351
  - 0.14222244388355648
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.12286974311583994
  - 0.12091769406703273
  - 0.10443482644483974
  - 0.07202110485405583
  - 0.13483468011366376
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.0887550468616197
  - 0.09552443643914682
  - 0.08733621216235753
  - 0.025881883379568163
  - 0.10938461468477614
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6313994252887168
  - 0.641636951330978
  - 0.6254869228155354
  - 0.6222681477138282
  - 0.6531181913643773
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -87.60416666666667
  - -88.66666666666667
  - -90.87378640776699
  - -92.89108910891089
  - -89.0377358490566
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.5947613268608415
  - -0.6273260517799354
  - -0.6172118013007822
  - -0.6308757089301164
  - -0.6147646089027294
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.5947613268608414
  - -0.6273260517799353
  - -0.6172118013007823
  - -0.6308757089301164
  - -0.6147646089027294
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.5947613268608414
  - -0.6273260517799352
  - -0.6172118013007823
  - -0.6308757089301162
  - -0.6147646089027293
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.5192252407646974
  - -0.5401402820177351
  - -0.5343283340679247
  - -0.5633864461714987
  - -0.535959656627212
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.45137585561323285
  - -0.44338980800810973
  - -0.4545973410727591
  - -0.5112960990279634
  - -0.4257598748512987
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.40523867313915846
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698836
  - 0.3852353910972705
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698837
  - 0.38523539109727056
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.3827881986992176
  - 0.36912429106988376
  - 0.3852353910972705
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.4807747592353026
  - 0.45985971798226494
  - 0.46567166593207526
  - 0.43661355382850126
  - 0.46404034337278804
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.40523867313915846
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698836
  - 0.3852353910972705
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.38278819869921765
  - 0.3691242910698837
  - 0.38523539109727056
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.40523867313915857
  - 0.3726739482200647
  - 0.3827881986992176
  - 0.36912429106988376
  - 0.3852353910972705
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.4807747592353026
  - 0.45985971798226494
  - 0.46567166593207526
  - 0.43661355382850126
  - 0.46404034337278804
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5697387306421278
  - 0.6057073855238481
  - 0.5804436985489839
  - 0.5381934028081661
  - 0.6092330062743092
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.5749403318989517
  - 0.586054302142336
  - 0.5700592640087423
  - 0.5180932987606685
  - 0.6038661794838958
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.5690312921014054
  - 0.5787890050113912
  - 0.5634831720624774
  - 0.5184799819732783
  - 0.5906257244436939
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5726500109036958
  - 0.6147146890134596
  - 0.5817816273778206
  - 0.5370725908706615
  - 0.599548596454926
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.20550161812297735
  - 0.1627224919093851
  - 0.18795362428127063
  - 0.16543304815918478
  - 0.17091042315442395
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.20550161812297735
  - 0.16272249190938512
  - 0.18795362428127063
  - 0.16543304815918486
  - 0.1709104231544239
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.20550161812297732
  - 0.1627224919093851
  - 0.18795362428127063
  - 0.1654330481591848
  - 0.17091042315442384
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.16594347419864885
  - 0.1386284343654601
  - 0.1598444014023283
  - 0.13157946619034663
  - 0.13644453884917382
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.19973705501618125
  - 0.20995145631067966
  - 0.19483457441794702
  - 0.20369124291069884
  - 0.21432496794284672
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.19973705501618122
  - 0.2099514563106796
  - 0.19483457441794702
  - 0.20369124291069884
  - 0.21432496794284667
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.1997370550161812
  - 0.20995145631067955
  - 0.194834574417947
  - 0.20369124291069882
  - 0.21432496794284664
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.31483128503665375
  - 0.3212312836168047
  - 0.30582726452974685
  - 0.3050340876381545
  - 0.32759580452361425
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.293861220282787
  - 0.3072993092603987
  - 0.2965703570511114
  - 0.27384209367129964
  - 0.31266674672336187
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.26561791622461606
  - 0.26866232475355156
  - 0.2546792029763074
  - 0.24281652860672057
  - 0.284104063964303
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.2860412906460802
  - 0.2954557790760089
  - 0.27335975130192514
  - 0.262000833961954
  - 0.3030334300430516
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.4260905657633811
  - 0.43676154359511904
  - 0.41950494131132254
  - 0.3847093210444767
  - 0.43282226091498643
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.40756472491909373
  - 0.37510113268608397
  - 0.38448487133565856
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.40756472491909385
  - 0.37510113268608414
  - 0.3844848713356584
  - 0.37239257906373163
  - 0.38908224949624476
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.4075647249190939
  - 0.3751011326860841
  - 0.3844848713356584
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.48201900963058797
  - 0.4625672336095363
  - 0.46703841037108323
  - 0.4397127884831495
  - 0.4660326086956523
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.03580097087378641
  - -0.02315938511326861
  - -0.03167122254689414
  - -0.03681630298952226
  - -0.023355925993771755
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.035800970873786406
  - -0.023159385113268607
  - -0.03167122254689415
  - -0.03681630298952225
  - -0.023355925993771752
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.035800970873786406
  - -0.023159385113268607
  - -0.03167122254689414
  - -0.03681630298952225
  - -0.023355925993771752
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.04570037372430646
  - -0.029110335804622765
  - -0.039773071899653456
  - -0.04490735811932447
  - -0.029587337395992033
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.5566343042071197
  - -0.6017394822006473
  - -0.5838439061174474
  - -0.5907911179467461
  - -0.5875618245099835
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.5566343042071198
  - -0.6017394822006472
  - -0.5838439061174474
  - -0.5907911179467461
  - -0.5875618245099835
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.5566343042071198
  - -0.6017394822006472
  - -0.5838439061174474
  - -0.5907911179467462
  - -0.5875618245099835
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.4722806166451056
  - -0.508322430585841
  - -0.4931885177292633
  - -0.515379853397526
  - -0.5043800539083556
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.27011117802223444
  - 0.2442031846450588
  - 0.25194786374370365
  - 0.2399375977702944
  - 0.2554309400119318
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.2559380160040645
  - 0.2308458330740026
  - 0.23799521559017445
  - 0.22879754311363099
  - 0.24152831476006367
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.261734966519482
  - 0.23709073386589852
  - 0.24291957109014337
  - 0.23305107847541576
  - 0.247512229505382
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.3327748516996583
  - 0.3167924472131931
  - 0.31927300376072193
  - 0.295193326747399
  - 0.3207713469259661
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.28604129064608025
  - 0.29545577907600884
  - 0.27335975130192514
  - 0.26200083396195395
  - 0.30303343004305144
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.08017279681416105
  - 0.09212034429232373
  - 0.0783778075772528
  - 0.03762808782726509
  - 0.10172001024926815
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.11844627708925905
  - 0.12569103949048116
  - 0.10623701420454147
  - 0.07287481918715177
  - 0.1401613044941441
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.12180482517117804
  - 0.11593460632411616
  - 0.10484308051350764
  - 0.07809729854810822
  - 0.1306282201976159
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.0900995171681896
  - 0.09728558796789252
  - 0.08870424735911456
  - 0.03473024486111645
  - 0.10590835805981844
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.6361055056326207
  - 0.6421655612537596
  - 0.627467720673441
  - 0.6245262689038318
  - 0.6468570789897206
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -87.61458333333333
  - -88.58333333333333
  - -90.6504854368932
  - -92.94059405940594
  - -88.84905660377359
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.5924352750809062
  - -0.624898867313916
  - -0.6155151286643415
  - -0.6276074209362684
  - -0.6109177505037553
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.5924352750809061
  - -0.6248988673139159
  - -0.6155151286643415
  - -0.6276074209362684
  - -0.6109177505037553
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.5924352750809061
  - -0.6248988673139159
  - -0.6155151286643415
  - -0.6276074209362683
  - -0.6109177505037553
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.517980990369412
  - -0.5374327663904637
  - -0.5329615896289168
  - -0.5602872115168505
  - -0.5339673913043478
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.4565949792837949
  - -0.4495153701333761
  - -0.4581639697318062
  - -0.5132073366800418
  - -0.4288103823613185
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.40756472491909373
  - 0.37510113268608397
  - 0.38448487133565856
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.40756472491909385
  - 0.37510113268608414
  - 0.3844848713356584
  - 0.37239257906373163
  - 0.38908224949624476
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.4075647249190939
  - 0.3751011326860841
  - 0.3844848713356584
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.48201900963058797
  - 0.4625672336095363
  - 0.46703841037108323
  - 0.4397127884831495
  - 0.4660326086956523
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.40756472491909373
  - 0.37510113268608397
  - 0.38448487133565856
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.40756472491909385
  - 0.37510113268608414
  - 0.3844848713356584
  - 0.37239257906373163
  - 0.38908224949624476
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.4075647249190939
  - 0.3751011326860841
  - 0.3844848713356584
  - 0.3723925790637316
  - 0.3890822494962447
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.48201900963058797
  - 0.4625672336095363
  - 0.46703841037108323
  - 0.4397127884831495
  - 0.4660326086956523
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5755868027570386
  - 0.6012334177687215
  - 0.5840551803177386
  - 0.5398321272511368
  - 0.6053373193765709
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.5775419539688652
  - 0.5830225200950772
  - 0.5707768114406522
  - 0.5205874436311956
  - 0.60107607653258
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.5707082032445281
  - 0.5759074178732266
  - 0.5635669154394221
  - 0.520598890851966
  - 0.588259949750657
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.5766988135804849
  - 0.6091800719241535
  - 0.5828070601244835
  - 0.5370914656108523
  - 0.5951138660524546
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.20883899676375403
  - 0.16636326860841422
  - 0.18983881609953815
  - 0.1678362010958377
  - 0.17649752701960073
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.20883899676375406
  - 0.16636326860841424
  - 0.18983881609953812
  - 0.16783620109583774
  - 0.17649752701960067
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.20883899676375398
  - 0.1663632686084142
  - 0.18983881609953812
  - 0.16783620109583772
  - 0.17649752701960061
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.16895752479517034
  - 0.1424307675534235
  - 0.161708511421212
  - 0.13384277495849944
  - 0.14107728817531937
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.19872572815533984
  - 0.2087378640776699
  - 0.19464605523612027
  - 0.2045563779678939
  - 0.21258472247664414
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.19872572815533981
  - 0.2087378640776699
  - 0.19464605523612027
  - 0.2045563779678939
  - 0.21258472247664406
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.19872572815533976
  - 0.20873786407766984
  - 0.19464605523612027
  - 0.20455637796789386
  - 0.21258472247664403
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.31306148483541757
  - 0.32013646605611273
  - 0.3053298989498712
  - 0.30587001352464993
  - 0.3249553205203328
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.2905248623256553
  - 0.3062793395354129
  - 0.29375424557351715
  - 0.27191022494062383
  - 0.313922047436702
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.2625957705521117
  - 0.26818693968239293
  - 0.2558648249921675
  - 0.24116135683486747
  - 0.2890786563222444
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.2829389782601958
  - 0.29501816301022554
  - 0.2738183283499795
  - 0.26029377699919337
  - 0.30529045737268434
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.42124033582296505
  - 0.4362703245581618
  - 0.4180456769064822
  - 0.3828001735974378
  - 0.43593793088800104
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.4078681229773462
  - 0.374393203883495
  - 0.38533320765387885
  - 0.37287320965106213
  - 0.38981498442938267
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.40786812297734626
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510622
  - 0.38981498442938267
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.4078681229773462
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510621
  - 0.3898149844293826
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.4821492741124048
  - 0.4617177278674226
  - 0.46790778923021553
  - 0.4406985501417526
  - 0.4658311848119068
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.03610436893203884
  - -0.02356391585760518
  - -0.03167122254689414
  - -0.03729693357685283
  - -0.023539109727056237
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.03610436893203883
  - -0.02356391585760518
  - -0.03167122254689415
  - -0.037296933576852834
  - -0.023539109727056237
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.03610436893203883
  - -0.023563915857605176
  - -0.03167122254689414
  - -0.037296933576852834
  - -0.023539109727056234
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.045722833117723155
  - -0.02974178659688909
  - -0.03933231703618637
  - -0.045668366119766095
  - -0.030045118949958986
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.556027508090615
  - -0.6020428802588998
  - -0.5829955697992271
  - -0.5898298567720851
  - -0.5866459058435611
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.5560275080906149
  - -0.6020428802588996
  - -0.5829955697992271
  - -0.589829856772085
  - -0.5866459058435611
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.5560275080906149
  - -0.6020428802588996
  - -0.5829955697992271
  - -0.5898298567720849
  - -0.586645905843561
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.47212789276987194
  - -0.5085404855356882
  - -0.49275989373359796
  - -0.5136330837384814
  - -0.5041236962381341
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.27026069757080756
  - 0.24352586457096143
  - 0.25272087981767205
  - 0.24050850861545622
  - 0.2556987721141676
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.2561773486628978
  - 0.23030981709593132
  - 0.2386456509048453
  - 0.22916051279021682
  - 0.24209328782707623
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.2619860939837597
  - 0.2364777113369696
  - 0.24345693137029134
  - 0.23349917858449512
  - 0.2481901893918041
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.33280973990898194
  - 0.3158511912310877
  - 0.3201715536541463
  - 0.296144739535812
  - 0.3203812467620053
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.2829389782601959
  - 0.29501816301022543
  - 0.27381832834997955
  - 0.2602937769991933
  - 0.3052904573726843
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.07887271441649249
  - 0.09019820451200936
  - 0.07705307090532061
  - 0.03632593644430322
  - 0.10252249405180278
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.11780469849843063
  - 0.12336197017345912
  - 0.10719537495993807
  - 0.07191930853810163
  - 0.14032109330385767
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.12026043660064152
  - 0.11222210616236095
  - 0.1066400517283714
  - 0.07590946755690707
  - 0.1306973802694191
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.08969617352170446
  - 0.09422842953966801
  - 0.08776813008477691
  - 0.035441102166609326
  - 0.10624942251559477
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6330618050093125
  - 0.6421244949572217
  - 0.627840848572722
  - 0.6239882322889677
  - 0.6532507676287936
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -87.73958333333333
  - -88.80208333333333
  - -90.88349514563107
  - -93.22772277227723
  - -89.09433962264151
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.5921318770226538
  - -0.6256067961165049
  - -0.6146667923461211
  - -0.6271267903489378
  - -0.6101850155706173
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.5921318770226537
  - -0.6256067961165048
  - -0.6146667923461212
  - -0.6271267903489378
  - -0.6101850155706173
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.5921318770226537
  - -0.6256067961165047
  - -0.6146667923461212
  - -0.6271267903489378
  - -0.6101850155706172
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.5178507258875951
  - -0.5382822721325774
  - -0.5320922107697844
  - -0.5593014498582475
  - -0.5341688151880932
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.4618333159951002
  - -0.4499998518723866
  - -0.4620975905893304
  - -0.517613663441173
  - -0.4320240507349897
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.4078681229773462
  - 0.374393203883495
  - 0.38533320765387885
  - 0.37287320965106213
  - 0.38981498442938267
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.40786812297734626
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510622
  - 0.38981498442938267
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.4078681229773462
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510621
  - 0.3898149844293826
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.4821492741124048
  - 0.4617177278674226
  - 0.46790778923021553
  - 0.4406985501417526
  - 0.4658311848119068
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.4078681229773462
  - 0.374393203883495
  - 0.38533320765387885
  - 0.37287320965106213
  - 0.38981498442938267
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.40786812297734626
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510622
  - 0.38981498442938267
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.4078681229773462
  - 0.3743932038834951
  - 0.3853332076538788
  - 0.3728732096510621
  - 0.3898149844293826
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.4821492741124048
  - 0.4617177278674226
  - 0.46790778923021553
  - 0.4406985501417526
  - 0.4658311848119068
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5717841060552806
  - 0.6007742347228797
  - 0.5820933699360609
  - 0.5391302324788735
  - 0.6093324170837774
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.5739222439456099
  - 0.5828582108813871
  - 0.5705192686932752
  - 0.518579855326881
  - 0.604269502264229
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.5675704317680724
  - 0.5762337248218502
  - 0.5618027414961112
  - 0.5182337248645699
  - 0.5902597665659792
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5725343059540845
  - 0.6078794980598672
  - 0.5827167467012582
  - 0.5356605672541734
  - 0.60052357675687
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.20944579288025889
  - 0.16605987055016183
  - 0.1906871524177585
  - 0.16879746227049888
  - 0.17741344568602313
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.2094457928802589
  - 0.1660598705501618
  - 0.1906871524177585
  - 0.16879746227049888
  - 0.17741344568602307
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.20944579288025886
  - 0.16605987055016178
  - 0.19068715241775847
  - 0.1687974622704989
  - 0.17741344568602302
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.16911024867040392
  - 0.14221271260357607
  - 0.16213713541687727
  - 0.1355895446175442
  - 0.14133364584554084
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.19842233009708737
  - 0.20833333333333334
  - 0.19464605523612027
  - 0.2040757473805633
  - 0.21240153874335962
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.19842233009708737
  - 0.20833333333333334
  - 0.19464605523612027
  - 0.2040757473805633
  - 0.2124015387433596
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.19842233009708732
  - 0.2083333333333333
  - 0.19464605523612025
  - 0.20407574738056328
  - 0.21240153874335954
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.3130390254420008
  - 0.31950501526384645
  - 0.3057706538133383
  - 0.3051090055242083
  - 0.32449753896636585
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.29612495080347107
  - 0.3053795761437612
  - 0.293176621792781
  - 0.2733792575384124
  - 0.3096301424430502
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.2650034639618012
  - 0.26836575042755295
  - 0.25552314772525414
  - 0.24221839199317707
  - 0.28643763803649924
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.28481957796715857
  - 0.2955402523791493
  - 0.2726505888088012
  - 0.26153825030087585
  - 0.30448021736139325
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.42699349703887535
  - 0.43511389799999806
  - 0.4170093099885737
  - 0.38432152018507487
  - 0.43045667602234533
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.40705906148867316
  - 0.37378640776699024
  - 0.3837307946083515
  - 0.3723925790637315
  - 0.3905477193625206
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.40705906148867316
  - 0.3737864077669903
  - 0.3837307946083514
  - 0.37239257906373163
  - 0.3905477193625206
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.40705906148867316
  - 0.3737864077669902
  - 0.38373079460835147
  - 0.3723925790637315
  - 0.3905477193625207
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.4823064898663217
  - 0.4604820831516208
  - 0.46583745445870056
  - 0.43944071826537506
  - 0.46750849642564185
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.03580097087378641
  - -0.024271844660194174
  - -0.03223678009237439
  - -0.038450446986446216
  - -0.02408866092690969
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.035800970873786406
  - -0.024271844660194174
  - -0.0322367800923744
  - -0.038450446986446216
  - -0.02408866092690969
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.035800970873786406
  - -0.024271844660194174
  - -0.03223678009237439
  - -0.038450446986446216
  - -0.02408866092690969
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.04562850366537301
  - -0.030859318214856813
  - -0.04045644411915747
  - -0.046847337063455445
  - -0.030224569319114027
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.5571399676375405
  - -0.6019417475728157
  - -0.5840324252992742
  - -0.5891569739498222
  - -0.5853636197105697
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.5571399676375405
  - -0.6019417475728155
  - -0.5840324252992742
  - -0.5891569739498221
  - -0.5853636197105697
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.5571399676375405
  - -0.6019417475728156
  - -0.5840324252992742
  - -0.5891569739498222
  - -0.5853636197105696
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.4720650064683051
  - -0.5086585986335224
  - -0.49370610142214194
  - -0.5137119446711695
  - -0.5022669342552443
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.2696977584367212
  - 0.24295829513149514
  - 0.25137278540579944
  - 0.23997958373839412
  - 0.25645431801741814
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.2555393308361374
  - 0.2298507462686567
  - 0.23741762407418207
  - 0.22879754311363099
  - 0.24265877532437968
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.2614117009653694
  - 0.23613050303244046
  - 0.2423535322691556
  - 0.23310280171485412
  - 0.24873334610368666
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.33310435174566877
  - 0.3148323186347913
  - 0.31834700307089275
  - 0.2949683770456196
  - 0.3220633698376683
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.2848195779671586
  - 0.29554025237914944
  - 0.2726505888088011
  - 0.26153825030087585
  - 0.3044802173613933
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.08155271954440488
  - 0.08861144733214767
  - 0.07485289678459918
  - 0.032297534896054976
  - 0.10235974451641477
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.11787765024118721
  - 0.12002129640853865
  - 0.10341045742544859
  - 0.06758133432741326
  - 0.13915887423787537
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.12026636482073379
  - 0.10935181557243807
  - 0.10259695293462891
  - 0.07044528797647433
  - 0.129128891726082
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.09287337714129834
  - 0.0926304129284577
  - 0.08569338778139979
  - 0.029718563879122254
  - 0.11118327973023011
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.6336702074760295
  - 0.6430162939195423
  - 0.6281391525288971
  - 0.6242897403036369
  - 0.6514834770253781
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -87.83333333333333
  - -89.0
  - -90.72815533980582
  - -93.10891089108911
  - -88.82075471698113
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.5929409385113268
  - -0.6262135922330098
  - -0.6162692053916486
  - -0.6276074209362684
  - -0.6094522806374795
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.5929409385113269
  - -0.6262135922330098
  - -0.6162692053916486
  - -0.6276074209362684
  - -0.6094522806374794
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.5929409385113268
  - -0.6262135922330098
  - -0.6162692053916485
  - -0.6276074209362685
  - -0.6094522806374794
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.5176935101336783
  - -0.5395179168483792
  - -0.5341625455412994
  - -0.560559281734625
  - -0.5324915035743581
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.45964576627260434
  - -0.4514550470624739
  - -0.4646938555470334
  - -0.5177030497045666
  - -0.43377198318471055
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.40705906148867316
  - 0.37378640776699024
  - 0.3837307946083515
  - 0.3723925790637315
  - 0.3905477193625206
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.40705906148867316
  - 0.3737864077669903
  - 0.3837307946083514
  - 0.37239257906373163
  - 0.3905477193625206
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.40705906148867316
  - 0.3737864077669902
  - 0.38373079460835147
  - 0.3723925790637315
  - 0.3905477193625207
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.4823064898663217
  - 0.4604820831516208
  - 0.46583745445870056
  - 0.43944071826537506
  - 0.46750849642564185
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.40705906148867316
  - 0.37378640776699024
  - 0.3837307946083515
  - 0.3723925790637315
  - 0.3905477193625206
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.40705906148867316
  - 0.3737864077669903
  - 0.3837307946083514
  - 0.37239257906373163
  - 0.3905477193625206
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.40705906148867316
  - 0.3737864077669902
  - 0.38373079460835147
  - 0.3723925790637315
  - 0.3905477193625207
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.4823064898663217
  - 0.4604820831516208
  - 0.46583745445870056
  - 0.43944071826537506
  - 0.46750849642564185
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5732555892570872
  - 0.6004285278387382
  - 0.5822034507574245
  - 0.5389079680539031
  - 0.6059904353288853
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.575775540035269
  - 0.5816116083899621
  - 0.5698347037824558
  - 0.5189869843847739
  - 0.601420415624893
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.5685179971329002
  - 0.5758107087488435
  - 0.5607898960357445
  - 0.518655893724476
  - 0.5897263670696403
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5761094437566511
  - 0.6060975239528278
  - 0.5822110341200882
  - 0.5354286510081617
  - 0.5970035950570861
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.20833333333333331
  - 0.16616100323624594
  - 0.18965029691771135
  - 0.16947034509276165
  - 0.1786957318190145
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.20833333333333334
  - 0.16616100323624594
  - 0.18965029691771138
  - 0.1694703450927617
  - 0.17869573181901446
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.2083333333333333
  - 0.1661610032362459
  - 0.18965029691771135
  - 0.16947034509276168
  - 0.17869573181901446
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.16917313497197065
  - 0.14209459950574216
  - 0.16119092772833324
  - 0.13551068368485594
  - 0.1431904078284308
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.19872572815533981
  - 0.20762540453074438
  - 0.19408049769064006
  - 0.2029222339709699
  - 0.2118519875435062
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.19872572815533981
  - 0.20762540453074432
  - 0.19408049769064004
  - 0.20292223397096992
  - 0.21185198754350615
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.19872572815533976
  - 0.20762540453074427
  - 0.19408049769063998
  - 0.2029222339709699
  - 0.2118519875435061
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.313133354894351
  - 0.3183874836458787
  - 0.30464652673036724
  - 0.303930034580519
  - 0.32431808859721084
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.2962316241807846
  - 0.304222262604675
  - 0.2906383934481849
  - 0.27177239193587777
  - 0.31236969588513597
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.2669366845471519
  - 0.27062975951903556
  - 0.25424326554970267
  - 0.2427291686134342
  - 0.28451550364232786
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.2857658294378757
  - 0.2971880249962504
  - 0.2711591690972152
  - 0.2624354730598325
  - 0.3014517997749469
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.4266952953602796
  - 0.43358101875595256
  - 0.4153563360171764
  - 0.3825963836747196
  - 0.43403151831269415
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.4082726537216828
  - 0.375101132686084
  - 0.38580450560844576
  - 0.37325771412092656
  - 0.3894486169628137
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.40827265372168287
  - 0.37510113268608414
  - 0.38580450560844565
  - 0.3732577141209267
  - 0.3894486169628137
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.4082726537216828
  - 0.3751011326860841
  - 0.38580450560844576
  - 0.3732577141209267
  - 0.38944861696281363
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.48254006755785545
  - 0.4615859863352233
  - 0.4679846180596273
  - 0.4400361183071714
  - 0.4659703504043128
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.0367111650485437
  - -0.024372977346278316
  - -0.03204826091054764
  - -0.03816206863404787
  - -0.024363436526836417
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.03671116504854369
  - -0.024372977346278316
  - -0.032048260910547646
  - -0.03816206863404787
  - -0.024363436526836417
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.03671116504854369
  - -0.024372977346278316
  - -0.03204826091054764
  - -0.03816206863404787
  - -0.024363436526836414
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.046684095155958026
  - -0.03080480447739498
  - -0.040189565027516846
  - -0.04663441254519717
  - -0.030806867455759987
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.5550161812297735
  - -0.6005258899676377
  - -0.5821472334810066
  - -0.5885802172450255
  - -0.5861879465103499
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.5550161812297735
  - -0.6005258899676376
  - -0.5821472334810067
  - -0.5885802172450255
  - -0.5861879465103499
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.5550161812297735
  - -0.6005258899676374
  - -0.5821472334810066
  - -0.5885802172450255
  - -0.5861879465103499
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.4707758372861865
  - -0.5076092091873818
  - -0.4918258169128558
  - -0.5133294691476314
  - -0.5032227821399273
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.27053035831854894
  - 0.24387658505945328
  - 0.25298414429181004
  - 0.24053999509137972
  - 0.2554891170936158
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.25649660080055914
  - 0.2308458330740026
  - 0.239007299270073
  - 0.22945104295928617
  - 0.24181073703366698
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.2623044867410283
  - 0.23713278471712354
  - 0.2441185299932076
  - 0.23382129105589394
  - 0.24787256030196553
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.33316876891419
  - 0.31567354152577404
  - 0.3200186924510574
  - 0.29530723576815093
  - 0.32067099575119684
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.2857658294378758
  - 0.29718802499625047
  - 0.27115916909721527
  - 0.26243547305983256
  - 0.3014517997749469
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.0796003398610538
  - 0.08934579837184087
  - 0.07828779577358035
  - 0.034779871063031376
  - 0.10028744801951511
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.11630092152393685
  - 0.12116625510947303
  - 0.10641360593164892
  - 0.06960721314476509
  - 0.1369283308188285
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.11977248778669214
  - 0.11127431673348968
  - 0.10571402264596394
  - 0.0726537052055793
  - 0.12666586157405704
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.09049861977971832
  - 0.09390598040828717
  - 0.08893143281283977
  - 0.03125520775971885
  - 0.10882778795507718
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6367971318241438
  - 0.6456004668950525
  - 0.6255261809740739
  - 0.6252483274887565
  - 0.6485553136676092
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -88.09375
  - -88.97916666666667
  - -90.92233009708738
  - -93.12871287128714
  - -88.76415094339623
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.5917273462783172
  - -0.624898867313916
  - -0.6141954943915543
  - -0.6267422858790733
  - -0.6105513830371864
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.5917273462783171
  - -0.6248988673139159
  - -0.6141954943915543
  - -0.6267422858790733
  - -0.6105513830371863
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.5917273462783171
  - -0.6248988673139159
  - -0.6141954943915542
  - -0.6267422858790732
  - -0.6105513830371861
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5174599324421446
  - -0.5384140136647768
  - -0.5320153819403727
  - -0.5599638816928287
  - -0.5340296495956873
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.46575673261692313
  - -0.45232672915014877
  - -0.46744367688276317
  - -0.5165998801838139
  - -0.4344092236402589
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.4082726537216828
  - 0.375101132686084
  - 0.38580450560844576
  - 0.37325771412092656
  - 0.3894486169628137
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.40827265372168287
  - 0.37510113268608414
  - 0.38580450560844565
  - 0.3732577141209267
  - 0.3894486169628137
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.4082726537216828
  - 0.3751011326860841
  - 0.38580450560844576
  - 0.3732577141209267
  - 0.38944861696281363
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.48254006755785545
  - 0.4615859863352233
  - 0.4679846180596273
  - 0.4400361183071714
  - 0.4659703504043128
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.4082726537216828
  - 0.375101132686084
  - 0.38580450560844576
  - 0.37325771412092656
  - 0.3894486169628137
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.40827265372168287
  - 0.37510113268608414
  - 0.38580450560844565
  - 0.3732577141209267
  - 0.3894486169628137
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.4082726537216828
  - 0.3751011326860841
  - 0.38580450560844576
  - 0.3732577141209267
  - 0.38944861696281363
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.48254006755785545
  - 0.4615859863352233
  - 0.4679846180596273
  - 0.4400361183071714
  - 0.4659703504043128
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5747325494052332
  - 0.6018384546416973
  - 0.5821532496273815
  - 0.5397009015262441
  - 0.606781690655805
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.5762326541199717
  - 0.5835668966459733
  - 0.568359116531205
  - 0.5200514845677499
  - 0.600490590717331
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.567948118104908
  - 0.5779928655383743
  - 0.5592026267465707
  - 0.5205912335462404
  - 0.5884363737003936
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5771635741286485
  - 0.6071138501159917
  - 0.5811686754750396
  - 0.5366181428554616
  - 0.5996561800746163
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.21045711974110032
  - 0.1675768608414239
  - 0.19153548873597886
  - 0.17004710179755841
  - 0.17787140501923432
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.21045711974110032
  - 0.16757686084142395
  - 0.1915354887359789
  - 0.1700471017975584
  - 0.1778714050192343
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.21045711974110026
  - 0.1675768608414239
  - 0.19153548873597886
  - 0.1700471017975584
  - 0.17787140501923426
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.1704623041540894
  - 0.14314398895188254
  - 0.16307121223761945
  - 0.13589315920839398
  - 0.1422345599437478
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.19781553398058252
  - 0.20752427184466024
  - 0.19426901687246678
  - 0.2032106123233683
  - 0.21157721194357948
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.19781553398058252
  - 0.20752427184466019
  - 0.19426901687246678
  - 0.20321061232336826
  - 0.2115772119435794
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.1978155339805825
  - 0.20752427184466016
  - 0.19426901687246678
  - 0.20321061232336823
  - 0.2115772119435794
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.31207776340376603
  - 0.31844199738334056
  - 0.3049134058220078
  - 0.30414295909877725
  - 0.32373579046056483
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.29591099990226954
  - 0.30285684777890426
  - 0.29389402869226355
  - 0.2711863446012975
  - 0.31237734565560993
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.2663032936292476
  - 0.26989295572307404
  - 0.2563348997900742
  - 0.24289706705809888
  - 0.2884586768087188
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.2853070005308205
  - 0.29554152663183947
  - 0.2738732681002656
  - 0.26135741047193245
  - 0.3052733230677215
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.4286525488090285
  - 0.43335583556045415
  - 0.4182700269362422
  - 0.38347221182629737
  - 0.433619792567755
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.4072613268608414
  - 0.37398867313915846
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295293
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3842963521538317
  - 0.37239257906373163
  - 0.3892654332295292
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295292
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.48159228115567054
  - 0.46059111062654456
  - 0.4670626721066869
  - 0.4398665673018915
  - 0.46527452244228285
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.03630663430420712
  - -0.023968446601941747
  - -0.03204826091054764
  - -0.038450446986446216
  - -0.023905477193625208
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.03630663430420712
  - -0.023968446601941747
  - -0.032048260910547646
  - -0.038450446986446216
  - -0.023905477193625208
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.036306634304207115
  - -0.023968446601941747
  - -0.03204826091054764
  - -0.038450446986446216
  - -0.023905477193625204
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.046805375880408215
  - -0.030654891699374916
  - -0.04011273619810516
  - -0.04719432516728375
  - -0.030488251494199
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.5564320388349514
  - -0.6020428802588997
  - -0.5836553869356207
  - -0.5891569739498222
  - -0.5868290895768455
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.5564320388349514
  - -0.6020428802588996
  - -0.5836553869356207
  - -0.5891569739498221
  - -0.5868290895768455
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.5564320388349514
  - -0.6020428802588996
  - -0.5836553869356207
  - -0.5891569739498221
  - -0.5868290895768455
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.4716023429639211
  - -0.5087539976740805
  - -0.49282459169520776
  - -0.5129391075308247
  - -0.504237226063518
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.2696187966184802
  - 0.24313028994413258
  - 0.25169143584347214
  - 0.23995539660857731
  - 0.2553424191282473
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.2556987745253667
  - 0.23000373180743874
  - 0.23785076716644304
  - 0.22879754311363099
  - 0.24166950983737062
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.26137363010784564
  - 0.23609242165183408
  - 0.24301355318264728
  - 0.23319645875082493
  - 0.24772370152219236
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.33218224025831766
  - 0.3148208079334729
  - 0.31919706257551983
  - 0.2953136003587451
  - 0.3199808170357646
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.2853070005308206
  - 0.29554152663183947
  - 0.27387326810026547
  - 0.26135741047193256
  - 0.3052733230677214
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.0808680272553664
  - 0.08938916293295598
  - 0.07622769950818532
  - 0.03602296258009838
  - 0.10070811095342357
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.11646784485342088
  - 0.12138477377600325
  - 0.10470830613259605
  - 0.06758133432741326
  - 0.13837457025210484
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.11970297091996147
  - 0.11409531688418688
  - 0.10344142113358916
  - 0.06867293540383138
  - 0.13099403394312084
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.08966187438656546
  - 0.0914860763743652
  - 0.08735568655188157
  - 0.033771654569560536
  - 0.10668729037595656
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.6372530926154857
  - 0.6426862307801823
  - 0.6280805034088528
  - 0.6266787103428012
  - 0.6524374701987211
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -88.08333333333333
  - -88.90625
  - -91.03883495145631
  - -93.35643564356435
  - -88.80188679245283
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.5927386731391586
  - -0.6260113268608415
  - -0.6157036478461684
  - -0.6276074209362684
  - -0.6107345667704708
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.5927386731391586
  - -0.6260113268608414
  - -0.6157036478461684
  - -0.6276074209362684
  - -0.6107345667704708
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.5927386731391585
  - -0.6260113268608415
  - -0.6157036478461683
  - -0.6276074209362684
  - -0.6107345667704708
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.5184077188443295
  - -0.5394088893734554
  - -0.532937327893313
  - -0.5601334326981084
  - -0.5347254775577172
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.46489249067004773
  - -0.4520716537220671
  - -0.4663762816478019
  - -0.518700688790353
  - -0.4329922458335166
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.4072613268608414
  - 0.37398867313915846
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295293
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3842963521538317
  - 0.37239257906373163
  - 0.3892654332295292
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295292
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.48159228115567054
  - 0.46059111062654456
  - 0.4670626721066869
  - 0.4398665673018915
  - 0.46527452244228285
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.4072613268608414
  - 0.37398867313915846
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295293
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3842963521538317
  - 0.37239257906373163
  - 0.3892654332295292
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.38429635215383173
  - 0.3723925790637315
  - 0.3892654332295292
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.48159228115567054
  - 0.46059111062654456
  - 0.4670626721066869
  - 0.4398665673018915
  - 0.46527452244228285
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5750324453872239
  - 0.6004839093053393
  - 0.5826676252466025
  - 0.5396181387710364
  - 0.6081078888982866
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.5756907658397137
  - 0.5829594722122773
  - 0.5696353117568784
  - 0.5200082132282428
  - 0.602927931659149
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.5684183670098921
  - 0.5765470823143206
  - 0.5604941317107411
  - 0.5204795894164037
  - 0.5907245886018418
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5786442906099697
  - 0.6065188152856399
  - 0.5821686758750808
  - 0.5360422830270453
  - 0.6000147357021938
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.2090412621359223
  - 0.16605987055016178
  - 0.19002733528136487
  - 0.16947034509276165
  - 0.1772302619527386
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.20904126213592233
  - 0.1660598705501618
  - 0.19002733528136487
  - 0.1694703450927617
  - 0.1772302619527386
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.20904126213592225
  - 0.16605987055016178
  - 0.19002733528136487
  - 0.16947034509276165
  - 0.17723026195273858
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.16963579847635474
  - 0.14199920046518394
  - 0.16207243745526745
  - 0.1362835208252008
  - 0.14122011602015702
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.19822006472491907
  - 0.20792880258899676
  - 0.19426901687246678
  - 0.20292223397096995
  - 0.21203517127679067
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.1982200647249191
  - 0.20792880258899676
  - 0.19426901687246678
  - 0.20292223397096992
  - 0.2120351712767906
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.19822006472491904
  - 0.2079288025889967
  - 0.19426901687246678
  - 0.20292223397096987
  - 0.21203517127679058
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.3119564826793158
  - 0.3185919101613606
  - 0.30499023465141956
  - 0.30358304647669065
  - 0.32405440642212585
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.2924674954624958
  - 0.30293642439169666
  - 0.2918854472498524
  - 0.2696216589615843
  - 0.31505502532493235
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.26388003212577993
  - 0.2678353762263765
  - 0.25432476190433134
  - 0.24161153187621603
  - 0.28740592649878355
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.2830508509750171
  - 0.29412196497815063
  - 0.2708402305807388
  - 0.26079824386314665
  - 0.30380978277693405
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.4225871740017886
  - 0.43323082414281405
  - 0.4185120041540447
  - 0.38006142440355695
  - 0.4353369310258632
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.40766585760517793
  - 0.3738875404530743
  - 0.3858987651993592
  - 0.37287320965106213
  - 0.3895402088294559
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.38954020882945595
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.3895402088294559
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.4824232787120886
  - 0.46094544992004666
  - 0.4680331415308347
  - 0.4403831064109996
  - 0.466658853861479
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.036003236245954695
  - -0.024170711974110033
  - -0.031954001319634266
  - -0.03796981639911564
  - -0.023630701593698476
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.036003236245954695
  - -0.024170711974110033
  - -0.03195400131963427
  - -0.03796981639911564
  - -0.02363070159369848
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.03600323624595469
  - -0.02417071197411003
  - -0.031954001319634266
  - -0.03796981639911563
  - -0.023630701593698476
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.045722833117723155
  - -0.030191524930949266
  - -0.04005612548169654
  - -0.046129702575992367
  - -0.029583675143560296
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.5563309061488674
  - -0.6019417475728156
  - -0.5821472334810067
  - -0.5891569739498221
  - -0.5868290895768455
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.5563309061488673
  - -0.6019417475728155
  - -0.5821472334810067
  - -0.5891569739498221
  - -0.5868290895768455
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.5563309061488673
  - -0.6019417475728155
  - -0.5821472334810066
  - -0.5891569739498221
  - -0.5868290895768455
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.47185388817018814
  - -0.5088630251490041
  - -0.49191073298746874
  - -0.513487191013008
  - -0.5037574709949607
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.2699508307009673
  - 0.24284938131017864
  - 0.25283813835142904
  - 0.24016578909454678
  - 0.25571986755658965
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.256017783423309
  - 0.22992723428073886
  - 0.2390796542863817
  - 0.22916051279021682
  - 0.24188136267986124
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.26165955282639913
  - 0.23624875769837583
  - 0.24426425738616575
  - 0.23368538068741537
  - 0.24791948965809935
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.33299419185375667
  - 0.31510375666884416
  - 0.3198953334629669
  - 0.2955655687526004
  - 0.3215306881991967
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.283050850975017
  - 0.2941219649781506
  - 0.2708402305807389
  - 0.26079824386314654
  - 0.30380978277693405
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.08025067487275585
  - 0.08543964648295714
  - 0.07913298380645771
  - 0.03713027923091865
  - 0.1015562255131793
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.11790460298124555
  - 0.12051454203671921
  - 0.10684793988732398
  - 0.06974051257363874
  - 0.13967956590142055
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.12099955285721183
  - 0.11013591345114497
  - 0.10524336639837323
  - 0.07126861953047378
  - 0.1310907330399527
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.09017374596475372
  - 0.08813730604417823
  - 0.09017486969015029
  - 0.03624212653240891
  - 0.11083598254663916
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6331448915642922
  - 0.6421243821012169
  - 0.6264738910746895
  - 0.6237287697616742
  - 0.6512618702966144
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -88.14583333333333
  - -88.85416666666667
  - -91.06796116504854
  - -93.29702970297029
  - -88.76415094339623
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.5923341423948221
  - -0.6261124595469256
  - -0.6141012348006409
  - -0.6271267903489378
  - -0.6104597911705442
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.592334142394822
  - -0.6261124595469255
  - -0.6141012348006409
  - -0.6271267903489378
  - -0.610459791170544
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.592334142394822
  - -0.6261124595469255
  - -0.6141012348006408
  - -0.6271267903489378
  - -0.6104597911705439
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.5175767212879114
  - -0.5390545500799534
  - -0.5319668584691652
  - -0.5596168935890006
  - -0.533341146138521
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.4691249531632285
  - -0.4546644971934357
  - -0.4654255562642103
  - -0.5207155952162789
  - -0.43294421908272335
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.40766585760517793
  - 0.3738875404530743
  - 0.3858987651993592
  - 0.37287320965106213
  - 0.3895402088294559
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.38954020882945595
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.3895402088294559
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.4824232787120886
  - 0.46094544992004666
  - 0.4680331415308347
  - 0.4403831064109996
  - 0.466658853861479
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.40766585760517793
  - 0.3738875404530743
  - 0.3858987651993592
  - 0.37287320965106213
  - 0.3895402088294559
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.38954020882945595
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.407665857605178
  - 0.37388754045307443
  - 0.38589876519935906
  - 0.3728732096510622
  - 0.3895402088294559
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.4824232787120886
  - 0.46094544992004666
  - 0.4680331415308347
  - 0.4403831064109996
  - 0.466658853861479
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5722694595179638
  - 0.5985335993914952
  - 0.582148031741601
  - 0.5377146154549693
  - 0.6095065315484909
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.572940133750664
  - 0.5802828943571858
  - 0.568797378122988
  - 0.5183856515366851
  - 0.6022022810562728
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.5655696351511076
  - 0.5736055587958603
  - 0.5589106934795074
  - 0.5187718716788686
  - 0.5899149792772838
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5744115557784226
  - 0.6041009293440842
  - 0.582581981024194
  - 0.5349280889097189
  - 0.6007532573538422
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.20914239482200642
  - 0.1661610032362459
  - 0.19153548873597886
  - 0.16947034509276165
  - 0.17723026195273858
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.20914239482200647
  - 0.16616100323624594
  - 0.1915354887359789
  - 0.1694703450927617
  - 0.1772302619527386
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.20914239482200644
  - 0.1661610032362459
  - 0.1915354887359788
  - 0.16947034509276165
  - 0.17723026195273858
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.1693842532700877
  - 0.14189017299026024
  - 0.16298629616300653
  - 0.13573543734301743
  - 0.1416998710887144
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.1985234627831715
  - 0.2077265372168285
  - 0.19436327646338017
  - 0.20340286455830045
  - 0.21230994687671742
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.1985234627831715
  - 0.2077265372168285
  - 0.19436327646338014
  - 0.20340286455830048
  - 0.21230994687671734
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.19852346278317148
  - 0.20772653721682843
  - 0.19436327646338014
  - 0.20340286455830045
  - 0.21230994687671728
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.31303902544200085
  - 0.31905527692978625
  - 0.3050468453678281
  - 0.3046476690679821
  - 0.3249589827727645
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.29335450439442445
  - 0.2990533467052845
  - 0.2904526715338472
  - 0.26892612601028737
  - 0.3109653020741373
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.26561523764234857
  - 0.26650014331905436
  - 0.2540860234195592
  - 0.24092379074563255
  - 0.2866281188073139
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.28577065218846337
  - 0.2931494633658022
  - 0.27111156325755775
  - 0.26064681433748954
  - 0.30321366310862136
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.4248675952377047
  - 0.42741593323342986
  - 0.4159701511395587
  - 0.37736932244772126
  - 0.4339005870321415
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.4072613268608414
  - 0.3739886731391585
  - 0.38533320765387885
  - 0.3724887051811977
  - 0.38844110642974905
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3853332076538788
  - 0.37248870518119775
  - 0.38844110642974905
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.4072613268608414
  - 0.37398867313915857
  - 0.38533320765387885
  - 0.37248870518119764
  - 0.38844110642974905
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.48147100043122043
  - 0.460659252798372
  - 0.4681908428122587
  - 0.43956689575767616
  - 0.4638901910230868
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.03610436893203884
  - -0.024372977346278316
  - -0.031105665001413887
  - -0.037873690281649525
  - -0.023722293460340722
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.03610436893203883
  - -0.024372977346278316
  - -0.031105665001413894
  - -0.037873690281649525
  - -0.023722293460340722
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.03610436893203883
  - -0.024372977346278316
  - -0.031105665001413887
  - -0.03787369028164952
  - -0.02372229346034072
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.046293301710507405
  - -0.030550407035906387
  - -0.03879451523030453
  - -0.04616913304233649
  - -0.030235556076409237
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.5566343042071198
  - -0.6016383495145633
  - -0.5835611273447073
  - -0.5896376045371527
  - -0.5878366001099102
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.5566343042071198
  - -0.6016383495145631
  - -0.5835611273447073
  - -0.5896376045371527
  - -0.5878366001099102
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.5566343042071198
  - -0.6016383495145631
  - -0.5835611273447073
  - -0.5896376045371529
  - -0.5878366001099102
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.4722356978582722
  - -0.5087903401657218
  - -0.49301464195743666
  - -0.5142639711999873
  - -0.505874252900504
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.2695895451834983
  - 0.24280917045756983
  - 0.25251244133479706
  - 0.23995790531077987
  - 0.25457684136074293
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.2556987745253667
  - 0.23000373180743874
  - 0.2386456509048453
  - 0.2288701198984112
  - 0.2410343847684001
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.26126093362244635
  - 0.23630923932171286
  - 0.2438706119273609
  - 0.23324587113041045
  - 0.24714785780890605
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.3321875344098838
  - 0.3147543066746334
  - 0.3201240039438902
  - 0.294877273529155
  - 0.3187501715117298
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.2857706521884634
  - 0.2931494633658021
  - 0.27111156325755775
  - 0.26064681433748954
  - 0.30321366310862136
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.08030992370060197
  - 0.0871379182049431
  - 0.08092092191806663
  - 0.03657420302545365
  - 0.10232003889005631
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.11712212143785587
  - 0.11987983042825162
  - 0.10917332593707318
  - 0.06956368522305399
  - 0.1381070450605475
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.11968692855305492
  - 0.11142513028131033
  - 0.10541188524101364
  - 0.07154695003833662
  - 0.1301712176839274
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.08930848121511473
  - 0.08954106733611443
  - 0.09211275929411218
  - 0.03516031499789252
  - 0.10721864288473253
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.638245070912955
  - 0.6397199889977058
  - 0.625569580384518
  - 0.6245427540879892
  - 0.6492654667208092
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -88.28125
  - -89.01041666666667
  - -91.2621359223301
  - -93.38613861386139
  - -88.75471698113208
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.5927386731391586
  - -0.6260113268608414
  - -0.6146667923461212
  - -0.6275112948188023
  - -0.611558893570251
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.5927386731391586
  - -0.6260113268608414
  - -0.6146667923461212
  - -0.6275112948188023
  - -0.611558893570251
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.5927386731391585
  - -0.6260113268608415
  - -0.6146667923461211
  - -0.6275112948188023
  - -0.6115588935702508
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5185289995687795
  - -0.5393407472016281
  - -0.5318091571877412
  - -0.560433104242324
  - -0.5361098089769132
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.4668459967203182
  - -0.4558367411032321
  - -0.4676339096931543
  - -0.5187978490887282
  - -0.43240750817149115
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.4072613268608414
  - 0.3739886731391585
  - 0.38533320765387885
  - 0.3724887051811977
  - 0.38844110642974905
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3853332076538788
  - 0.37248870518119775
  - 0.38844110642974905
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.4072613268608414
  - 0.37398867313915857
  - 0.38533320765387885
  - 0.37248870518119764
  - 0.38844110642974905
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.48147100043122043
  - 0.460659252798372
  - 0.4681908428122587
  - 0.43956689575767616
  - 0.4638901910230868
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.4072613268608414
  - 0.3739886731391585
  - 0.38533320765387885
  - 0.3724887051811977
  - 0.38844110642974905
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.40726132686084143
  - 0.37398867313915857
  - 0.3853332076538788
  - 0.37248870518119775
  - 0.38844110642974905
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.4072613268608414
  - 0.37398867313915857
  - 0.38533320765387885
  - 0.37248870518119764
  - 0.38844110642974905
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.48147100043122043
  - 0.460659252798372
  - 0.4681908428122587
  - 0.43956689575767616
  - 0.4638901910230868
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5714599531914327
  - 0.5953275699019213
  - 0.5820882884084725
  - 0.5363691222104647
  - 0.6069619708327628
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.5740188398115802
  - 0.5798636374206985
  - 0.5687217466650104
  - 0.5176234956460202
  - 0.601573749946019
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.5672392626283038
  - 0.5739193773810679
  - 0.5594828347462042
  - 0.5189838736126469
  - 0.590713446850443
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5759523574841703
  - 0.6005572049452959
  - 0.5811213874944061
  - 0.5314145429263589
  - 0.5999917562967105
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.20883899676375403
  - 0.16646440129449833
  - 0.1901215948722782
  - 0.1689897145054311
  - 0.17622275141967395
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.20883899676375406
  - 0.16646440129449838
  - 0.19012159487227825
  - 0.16898971450543113
  - 0.17622275141967395
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.20883899676375398
  - 0.16646440129449835
  - 0.1901215948722782
  - 0.1689897145054311
  - 0.17622275141967392
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.16900244358200375
  - 0.1419628579735427
  - 0.16188238719303852
  - 0.1349586571560382
  - 0.1395830891831712
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.1984223300970874
  - 0.20752427184466024
  - 0.19521161278160054
  - 0.2034989906757666
  - 0.2122183550100752
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.19842233009708737
  - 0.20752427184466019
  - 0.19521161278160054
  - 0.2034989906757666
  - 0.2122183550100751
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.19842233009708732
  - 0.20752427184466016
  - 0.1952116127816005
  - 0.2034989906757666
  - 0.21221835501007505
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.31246855684921665
  - 0.31869639482482914
  - 0.30630845561922015
  - 0.3046082386016379
  - 0.32430710183991557
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.6955918463583582
  - 0.6866859341042028
  - 0.7067753424429635
  - 0.6937263275056716
  - 0.6918538936400704
  train_level0__average_precision_macro_masked:
  - 0.22205857932788126
  - 0.21879614161289282
  - 0.2349765856047118
  - 0.22777451871055063
  - 0.21979711850227157
  train_level0__average_precision_macro_oob:
  - 0.27018332738657175
  - 0.27190390892917093
  - 0.2755202535550784
  - 0.2824790546664714
  - 0.26665292124505674
  train_level0__average_precision_micro:
  - 0.6421845663878203
  - 0.6408246800215008
  - 0.6438526529664714
  - 0.6470999493443347
  - 0.639508074861554
  train_level0__average_precision_micro_masked:
  - 0.3690260608746019
  - 0.37331181574365824
  - 0.3737867010489716
  - 0.3802037686585397
  - 0.3700963147642056
  train_level0__average_precision_micro_oob:
  - 0.4943293351485829
  - 0.4982260703520002
  - 0.49849840345933716
  - 0.5066019677666022
  - 0.4938579731783192
  train_level0__average_precision_samples:
  - 0.6570322213500546
  - 0.6548320636661339
  - 0.6573644623283826
  - 0.6597087885943582
  - 0.6531595213880147
  train_level0__average_precision_samples_masked:
  - 0.4268364135695654
  - 0.4309922183011511
  - 0.428287745592953
  - 0.43711905240525184
  - 0.42585494826807396
  train_level0__average_precision_samples_oob:
  - 0.5286227641560671
  - 0.5308691580891672
  - 0.5319018851019403
  - 0.5388754776606337
  - 0.5273446704678484
  train_level0__average_precision_weighted:
  - 0.7477047825752167
  - 0.745485555373204
  - 0.7586178814314746
  - 0.7506133562973657
  - 0.7463483108274654
  train_level0__average_precision_weighted_masked:
  - 0.3150089445766211
  - 0.3198074843560885
  - 0.32860456479026684
  - 0.3291476475935888
  - 0.3164177599389032
  train_level0__average_precision_weighted_oob:
  - 0.3841610656494396
  - 0.38954174788903234
  - 0.3890298728531065
  - 0.40263754555049264
  - 0.3815805598579335
  train_level0__f1_macro:
  - 0.7674685542111054
  - 0.766798986082548
  - 0.7655059980047203
  - 0.7686850834079849
  - 0.7677012846915761
  train_level0__f1_macro_masked:
  - 0.8568490747984611
  - 0.8563738766866403
  - 0.8554129910863367
  - 0.8579157149900122
  - 0.8571305332614076
  train_level0__f1_macro_oob:
  - 0.7665837677555122
  - 0.7659620259218518
  - 0.7641433681290604
  - 0.7679103212841683
  - 0.7668186721584781
  train_level0__f1_micro:
  - 0.7674685542111053
  - 0.7667989860825482
  - 0.7655059980047205
  - 0.7686850834079849
  - 0.767701284691576
  train_level0__f1_micro_masked:
  - 0.8681137034929409
  - 0.867816091954023
  - 0.8668249454766309
  - 0.8694007346894018
  - 0.8683962002110994
  train_level0__f1_micro_oob:
  - 0.766583767755512
  - 0.7659620259218518
  - 0.7641433681290605
  - 0.7679103212841683
  - 0.766818672158478
  train_level0__f1_samples:
  - 0.7674685542111052
  - 0.7667989860825483
  - 0.7655059980047205
  - 0.7686850834079848
  - 0.7677012846915761
  train_level0__f1_samples_masked:
  - 0.867816560411096
  - 0.8675389945149833
  - 0.8666254939072856
  - 0.8691089552965645
  - 0.8680503065564664
  train_level0__f1_samples_oob:
  - 0.7665837677555121
  - 0.7659620259218519
  - 0.7641433681290605
  - 0.7679103212841681
  - 0.766818672158478
  train_level0__f1_weighted:
  - 0.6596978760973697
  - 0.6566594887234967
  - 0.65754653672019
  - 0.6563006395784448
  - 0.6587682261506286
  train_level0__f1_weighted_masked:
  - 0.7712396940369771
  - 0.7696700033217554
  - 0.7698293564298089
  - 0.7698113606642454
  - 0.7718188127225727
  train_level0__f1_weighted_oob:
  - 0.6563436299289412
  - 0.6535125458290827
  - 0.6525365894373009
  - 0.653337976364751
  - 0.6554560196674855
  train_level0__fn_macro:
  - -0.23250753264144625
  - -0.23320101391745185
  - -0.2344940019952794
  - -0.23131491659201506
  - -0.23229871530842397
  train_level0__fn_macro_masked:
  - -0.14310796618444124
  - -0.1436261233133597
  - -0.14458700891366322
  - -0.14208428500998763
  - -0.14286946673859208
  train_level0__fn_macro_oob:
  - -0.23332057965469416
  - -0.23399014778325125
  - -0.2358322991945883
  - -0.23208967871583172
  - -0.2331322938119054
  train_level0__fn_micro:
  - -0.23250753264144627
  - -0.23320101391745182
  - -0.23449400199527945
  - -0.2313149165920151
  - -0.23229871530842405
  train_level0__fn_micro_masked:
  - -0.13185919843915128
  - -0.13218390804597702
  - -0.13317505452336914
  - -0.13059926531059818
  - -0.1316037997889006
  train_level0__fn_micro_oob:
  - -0.23332057965469416
  - -0.23399014778325122
  - -0.23583229919458842
  - -0.23208967871583178
  - -0.23313229381190545
  train_level0__fn_samples:
  - -0.23250753264144622
  - -0.23320101391745177
  - -0.23449400199527942
  - -0.23131491659201503
  - -0.232298715308424
  train_level0__fn_samples_masked:
  - -0.13215804727769573
  - -0.1324610054850168
  - -0.1333745060927144
  - -0.13089104470343543
  - -0.1319496934435335
  train_level0__fn_samples_oob:
  - -0.23332057965469408
  - -0.23399014778325117
  - -0.23583229919458834
  - -0.23208967871583172
  - -0.23313229381190537
  train_level0__fn_weighted:
  - -0.3402114686007807
  - -0.3433405112765035
  - -0.3424534632798099
  - -0.34369936042155536
  - -0.34123177384937153
  train_level0__fn_weighted_masked:
  - -0.22859662734054229
  - -0.2303299966782446
  - -0.23017064357019118
  - -0.23018863933575445
  - -0.2281811872774273
  train_level0__fn_weighted_oob:
  - -0.34329374886366093
  - -0.34630762886266514
  - -0.34739700059510564
  - -0.3466620236352491
  - -0.3443599688612289
  train_level0__fp_macro:
  - -2.391314744846717e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_masked:
  - -4.2959017097688804e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_macro_oob:
  - -9.565258979386868e-05
  - -4.782629489693434e-05
  - -2.4332676351071852e-05
  - -0.0
  - -4.903402961655389e-05
  train_level0__fp_micro:
  - -2.3913147448467166e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_masked:
  - -2.7098067907758176e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_micro_oob:
  - -9.565258979386866e-05
  - -4.782629489693433e-05
  - -2.4332676351071856e-05
  - -0.0
  - -4.903402961655389e-05
  train_level0__fp_samples:
  - -2.3913147448467166e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_masked:
  - -2.5392311208166168e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_samples_oob:
  - -9.565258979386866e-05
  - -4.782629489693433e-05
  - -2.4332676351071852e-05
  - -0.0
  - -4.9034029616553884e-05
  train_level0__fp_weighted:
  - -9.065530184941853e-05
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_masked:
  - -0.00016367862248071322
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  train_level0__fp_weighted_oob:
  - -0.0003626212073976741
  - -0.0001798253082522236
  - -6.640996759348623e-05
  - -0.0
  - -0.00018401147128572581
  train_level0__jaccard_macro:
  - 0.6462205127517295
  - 0.6459947197609852
  - 0.6438321414886098
  - 0.648720271821228
  - 0.6468184031704863
  train_level0__jaccard_macro_masked:
  - 0.7669989248607708
  - 0.7665052972049958
  - 0.7649263072485974
  - 0.7689934145219479
  - 0.7673594740572741
  train_level0__jaccard_macro_oob:
  - 0.645669025514885
  - 0.6454716402872127
  - 0.6429817783027221
  - 0.6482625742809743
  - 0.6462720063958217
  train_level0__jaccard_micro:
  - 0.6226766520507547
  - 0.621795617607136
  - 0.6200969763866441
  - 0.6242798434827064
  - 0.6229831088474623
  train_level0__jaccard_micro_masked:
  - 0.7669619344026813
  - 0.766497461928934
  - 0.7649523716714985
  - 0.7689733766548664
  - 0.7674030436917035
  train_level0__jaccard_micro_oob:
  - 0.6215126311095601
  - 0.6206956690243194
  - 0.6183106910809214
  - 0.6232584645011692
  - 0.6218215073858328
  train_level0__jaccard_samples:
  - 0.6252737453634268
  - 0.6246323157518561
  - 0.6229349443567336
  - 0.626902904839876
  - 0.6256595788320385
  train_level0__jaccard_samples_masked:
  - 0.7685128969103354
  - 0.7685539755319122
  - 0.7671956685682176
  - 0.7707410070792151
  - 0.7690695310583707
  train_level0__jaccard_samples_oob:
  - 0.6241000858953679
  - 0.6235562121539027
  - 0.6211023430161438
  - 0.625870823296488
  - 0.6245008046153815
  train_level0__jaccard_weighted:
  - 0.519234359958905
  - 0.515935855610734
  - 0.5165294040119733
  - 0.5171326237679953
  - 0.5184261108609359
  train_level0__jaccard_weighted_masked:
  - 0.6545630671920999
  - 0.6519005895700161
  - 0.6523100185774987
  - 0.6532088204132824
  - 0.6547038422871306
  train_level0__jaccard_weighted_oob:
  - 0.5171436589322009
  - 0.5139690938573042
  - 0.5134179974087507
  - 0.5153824044118553
  - 0.5163756313225814
  train_level0__label_ranking_average_precision_score:
  - 0.6570322213500547
  - 0.6548320636661341
  - 0.6573644623283834
  - 0.6597087885943581
  - 0.6531595213880143
  train_level0__label_ranking_average_precision_score_oob:
  - 0.5286227641560671
  - 0.5308691580891671
  - 0.5319018851019399
  - 0.5388754776606337
  - 0.5273446704678486
  train_level0__matthews_corrcoef_macro:
  - 0.0012169638294466946
  - 0.001407244847402117
  - 0.0024034933342951363
  - 0.0010674253503443667
  - 0.001370974511065723
  train_level0__matthews_corrcoef_macro_masked:
  - -0.001280350433778227
  - 0.0003344280210252996
  - 0.0003263556531324341
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_macro_oob:
  - -0.0002464035558663045
  - 0.0002629918305672271
  - -0.0001979494514778488
  - 0.0002996837017271136
  - 3.8031178982528806e-05
  train_level0__matthews_corrcoef_micro:
  - 0.06652258779063579
  - 0.06556424035173399
  - 0.06993686147381913
  - 0.052962217788055356
  - 0.06283555212093249
  train_level0__matthews_corrcoef_micro_masked:
  - -0.002028781048910196
  - 0.013339408581279086
  - 0.013403435247874585
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_micro_oob:
  - 0.038110942049201436
  - 0.03858107803845008
  - 0.020997951479850972
  - 0.015499741426729146
  - 0.031318104570908174
  train_level0__matthews_corrcoef_samples:
  - 0.025619837565530608
  - 0.02368019396611733
  - 0.028614213589673556
  - 0.01597055467307083
  - 0.022325085249237278
  train_level0__matthews_corrcoef_samples_masked:
  - -8.990533567150382e-05
  - 0.0005812300350943836
  - 0.0006453962438904821
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_samples_oob:
  - 0.01017416817770209
  - 0.009575987552848894
  - 0.0029728345477297857
  - 0.001346889064202812
  - 0.006916507070169987
  train_level0__matthews_corrcoef_weighted:
  - 0.0046135383698889115
  - 0.005291194708178409
  - 0.00801902859683806
  - 0.004081797136972284
  - 0.005144897102057959
  train_level0__matthews_corrcoef_weighted_masked:
  - -0.004878277238439854
  - 0.001264270950101179
  - 0.0012331170802606024
  - 0.0
  - 0.0
  train_level0__matthews_corrcoef_weighted_oob:
  - -0.0009341216492712985
  - 0.000988840701573971
  - -6.489950479431067e-05
  - 0.00114597997444257
  - 0.0001427207442266445
  train_level0__ndcg:
  - 0.8847008238585357
  - 0.8831438503561951
  - 0.8847285758449742
  - 0.8854788906861532
  - 0.8835064548160524
  train_level0__ndcg_oob:
  - 0.8251012757008644
  - 0.8252646829386324
  - 0.8273613598943442
  - 0.8297873282677782
  - 0.8241604373172852
  train_level0__neg_coverage_error:
  - -79.83251231527093
  - -78.61576354679804
  - -79.16791979949875
  - -78.83042394014963
  - -79.51262626262626
  train_level0__neg_coverage_error_oob:
  - -89.51477832512315
  - -89.05665024630542
  - -89.72431077694236
  - -88.6359102244389
  - -89.67676767676768
  train_level0__neg_hamming_loss_macro:
  - -0.23253144578889476
  - -0.23320101391745185
  - -0.2344940019952794
  - -0.23131491659201506
  - -0.23229871530842397
  train_level0__neg_hamming_loss_macro_masked:
  - -0.14315092520153894
  - -0.1436261233133597
  - -0.14458700891366322
  - -0.14208428500998763
  - -0.14286946673859208
  train_level0__neg_hamming_loss_macro_oob:
  - -0.23341623224448801
  - -0.2340379740781482
  - -0.23585663187093944
  - -0.23208967871583172
  - -0.23318132784152196
  train_level0__neg_hamming_loss_micro:
  - -0.23253144578889473
  - -0.23320101391745182
  - -0.23449400199527945
  - -0.2313149165920151
  - -0.23229871530842405
  train_level0__neg_hamming_loss_micro_masked:
  - -0.13188629650705905
  - -0.13218390804597702
  - -0.13317505452336914
  - -0.13059926531059818
  - -0.1316037997889006
  train_level0__neg_hamming_loss_micro_oob:
  - -0.23341623224448801
  - -0.23403797407814816
  - -0.2358566318709395
  - -0.23208967871583178
  - -0.233181327841522
  train_level0__neg_hamming_loss_samples:
  - -0.23253144578889468
  - -0.23320101391745177
  - -0.23449400199527942
  - -0.23131491659201503
  - -0.232298715308424
  train_level0__neg_hamming_loss_samples_masked:
  - -0.1321834395889039
  - -0.1324610054850168
  - -0.1333745060927144
  - -0.13089104470343543
  - -0.1319496934435335
  train_level0__neg_hamming_loss_samples_oob:
  - -0.233416232244488
  - -0.23403797407814808
  - -0.23585663187093941
  - -0.23208967871583172
  - -0.23318132784152196
  train_level0__neg_hamming_loss_weighted:
  - -0.3403021239026301
  - -0.3433405112765035
  - -0.3424534632798099
  - -0.34369936042155536
  - -0.34123177384937153
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.228760305963023
  - -0.2303299966782446
  - -0.23017064357019118
  - -0.23018863933575445
  - -0.2281811872774273
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.34365637007105865
  - -0.3464874541709174
  - -0.34746341056269914
  - -0.3466620236352491
  - -0.3445439803325146
  train_level0__neg_label_ranking_loss:
  - -0.16263165192671483
  - -0.1635291512780052
  - -0.16325215224678008
  - -0.15930383337292686
  - -0.16410878073608243
  train_level0__neg_label_ranking_loss_oob:
  - -0.2539707912709631
  - -0.2506508141781224
  - -0.2523002884343827
  - -0.244867496905122
  - -0.2551758420570615
  train_level0__precision_macro:
  - 0.7674685542111054
  - 0.766798986082548
  - 0.7655059980047203
  - 0.7686850834079849
  - 0.7677012846915761
  train_level0__precision_macro_masked:
  - 0.8568490747984611
  - 0.8563738766866403
  - 0.8554129910863367
  - 0.8579157149900122
  - 0.8571305332614076
  train_level0__precision_macro_oob:
  - 0.7665837677555122
  - 0.7659620259218518
  - 0.7641433681290604
  - 0.7679103212841683
  - 0.7668186721584781
  train_level0__precision_micro:
  - 0.7674685542111053
  - 0.7667989860825482
  - 0.7655059980047205
  - 0.7686850834079849
  - 0.767701284691576
  train_level0__precision_micro_masked:
  - 0.8681137034929409
  - 0.867816091954023
  - 0.8668249454766309
  - 0.8694007346894018
  - 0.8683962002110994
  train_level0__precision_micro_oob:
  - 0.766583767755512
  - 0.7659620259218518
  - 0.7641433681290605
  - 0.7679103212841683
  - 0.766818672158478
  train_level0__precision_samples:
  - 0.7674685542111052
  - 0.7667989860825483
  - 0.7655059980047205
  - 0.7686850834079848
  - 0.7677012846915761
  train_level0__precision_samples_masked:
  - 0.867816560411096
  - 0.8675389945149833
  - 0.8666254939072856
  - 0.8691089552965645
  - 0.8680503065564664
  train_level0__precision_samples_oob:
  - 0.7665837677555121
  - 0.7659620259218519
  - 0.7641433681290605
  - 0.7679103212841681
  - 0.766818672158478
  train_level0__precision_weighted:
  - 0.6596978760973697
  - 0.6566594887234967
  - 0.65754653672019
  - 0.6563006395784448
  - 0.6587682261506286
  train_level0__precision_weighted_masked:
  - 0.7712396940369771
  - 0.7696700033217554
  - 0.7698293564298089
  - 0.7698113606642454
  - 0.7718188127225727
  train_level0__precision_weighted_oob:
  - 0.6563436299289412
  - 0.6535125458290827
  - 0.6525365894373009
  - 0.653337976364751
  - 0.6554560196674855
  train_level0__recall_macro:
  - 0.7674685542111054
  - 0.766798986082548
  - 0.7655059980047203
  - 0.7686850834079849
  - 0.7677012846915761
  train_level0__recall_macro_masked:
  - 0.8568490747984611
  - 0.8563738766866403
  - 0.8554129910863367
  - 0.8579157149900122
  - 0.8571305332614076
  train_level0__recall_macro_oob:
  - 0.7665837677555122
  - 0.7659620259218518
  - 0.7641433681290604
  - 0.7679103212841683
  - 0.7668186721584781
  train_level0__recall_micro:
  - 0.7674685542111053
  - 0.7667989860825482
  - 0.7655059980047205
  - 0.7686850834079849
  - 0.767701284691576
  train_level0__recall_micro_masked:
  - 0.8681137034929409
  - 0.867816091954023
  - 0.8668249454766309
  - 0.8694007346894018
  - 0.8683962002110994
  train_level0__recall_micro_oob:
  - 0.766583767755512
  - 0.7659620259218518
  - 0.7641433681290605
  - 0.7679103212841683
  - 0.766818672158478
  train_level0__recall_samples:
  - 0.7674685542111052
  - 0.7667989860825483
  - 0.7655059980047205
  - 0.7686850834079848
  - 0.7677012846915761
  train_level0__recall_samples_masked:
  - 0.867816560411096
  - 0.8675389945149833
  - 0.8666254939072856
  - 0.8691089552965645
  - 0.8680503065564664
  train_level0__recall_samples_oob:
  - 0.7665837677555121
  - 0.7659620259218519
  - 0.7641433681290605
  - 0.7679103212841681
  - 0.766818672158478
  train_level0__recall_weighted:
  - 0.6596978760973697
  - 0.6566594887234967
  - 0.65754653672019
  - 0.6563006395784448
  - 0.6587682261506286
  train_level0__recall_weighted_masked:
  - 0.7712396940369771
  - 0.7696700033217554
  - 0.7698293564298089
  - 0.7698113606642454
  - 0.7718188127225727
  train_level0__recall_weighted_oob:
  - 0.6563436299289412
  - 0.6535125458290827
  - 0.6525365894373009
  - 0.653337976364751
  - 0.6554560196674855
  train_level0__roc_auc_macro:
  - 0.8026548939719471
  - 0.8038217258035576
  - 0.8107503679155746
  - 0.8074596302074608
  - 0.798252854697854
  train_level0__roc_auc_macro_masked:
  - 0.6200952599741512
  - 0.6222054181275763
  - 0.6334858801693594
  - 0.6303521062364492
  - 0.6115682519244745
  train_level0__roc_auc_macro_oob:
  - 0.5489466790956145
  - 0.5446347332360507
  - 0.5521644517383615
  - 0.5670508043020428
  - 0.5387001197441816
  train_level0__roc_auc_micro:
  - 0.8366105528280697
  - 0.8356463367369349
  - 0.8364927840319234
  - 0.8403775345813653
  - 0.8349685598726613
  train_level0__roc_auc_micro_masked:
  - 0.7633234318657524
  - 0.7651324324661388
  - 0.7654299620417392
  - 0.7708752698538316
  - 0.7616245634070752
  train_level0__roc_auc_micro_oob:
  - 0.7424461039972323
  - 0.745643966573041
  - 0.7442359271673394
  - 0.7522813247213846
  - 0.7412933252018173
  train_level0__roc_auc_samples:
  - 0.8373683480732852
  - 0.8364708487219946
  - 0.8367478477532199
  - 0.840696166627073
  - 0.8358912192639176
  train_level0__roc_auc_samples_masked:
  - 0.7666950996869834
  - 0.7694091508495564
  - 0.7672337591282565
  - 0.7738494940177043
  - 0.7650425261314415
  train_level0__roc_auc_samples_oob:
  - 0.7460292087290368
  - 0.7493491858218777
  - 0.7476997115656173
  - 0.7551325030948779
  - 0.7448241579429385
  train_level0__roc_auc_weighted:
  - 0.7934534533742754
  - 0.7985380145192924
  - 0.8023411312613716
  - 0.8010021594962581
  - 0.7930115734055591
  train_level0__roc_auc_weighted_masked:
  - 0.6119269073043422
  - 0.6217413583117785
  - 0.6261463971017419
  - 0.6282626319786816
  - 0.611803684923812
  train_level0__roc_auc_weighted_oob:
  - 0.5487881446466467
  - 0.5476543552658919
  - 0.5504676957028418
  - 0.5670669362862024
  - 0.5421042141362883
  train_level0__tn_macro:
  - 0.7660815916590942
  - 0.7654837629728822
  - 0.7639973720709539
  - 0.7678376873350605
  - 0.7664999509659703
  train_level0__tn_macro_masked:
  - 0.8568490747984611
  - 0.8563311069163141
  - 0.8553690601457754
  - 0.8579157149900122
  - 0.8571305332614076
  train_level0__tn_macro_oob:
  - 0.7660098522167489
  - 0.7654359366779854
  - 0.7639730393946029
  - 0.7678376873350605
  - 0.7664509169363538
  train_level0__tn_micro:
  - 0.7660815916590942
  - 0.7654837629728825
  - 0.7639973720709541
  - 0.7678376873350604
  - 0.7664999509659703
  train_level0__tn_micro_masked:
  - 0.8681137034929409
  - 0.8677889828670571
  - 0.866797338707451
  - 0.8694007346894018
  - 0.8683962002110994
  train_level0__tn_micro_oob:
  - 0.7660098522167488
  - 0.7654359366779856
  - 0.763973039394603
  - 0.7678376873350604
  - 0.7664509169363538
  train_level0__tn_samples:
  - 0.7660815916590942
  - 0.7654837629728823
  - 0.7639973720709542
  - 0.7678376873350603
  - 0.7664999509659703
  train_level0__tn_samples_masked:
  - 0.867816560411096
  - 0.8675103543500159
  - 0.8665970136156474
  - 0.8691089552965645
  - 0.8680503065564664
  train_level0__tn_samples_oob:
  - 0.7660098522167488
  - 0.7654359366779855
  - 0.7639730393946029
  - 0.7678376873350603
  - 0.7664509169363538
  train_level0__tn_weighted:
  - 0.6544398685901035
  - 0.6517142927465605
  - 0.6519608641151287
  - 0.6530602266884672
  - 0.6542599451041283
  train_level0__tn_weighted_masked:
  - 0.7712396940369771
  - 0.7695083165767264
  - 0.7696633657609228
  - 0.7698113606642454
  - 0.7718188127225727
  train_level0__tn_weighted_oob:
  - 0.6541679026845552
  - 0.6515344674383082
  - 0.6518944541475351
  - 0.6530602266884672
  - 0.6540759336328426
  train_level0__tp_macro:
  - 0.0013869625520110955
  - 0.0013152231096656942
  - 0.001508625933766455
  - 0.000847396072924485
  - 0.0012013337256055704
  train_level0__tp_macro_masked:
  - 0.0
  - 4.276977032633335e-05
  - 4.3930940561437425e-05
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 0.000573915538763212
  - 0.0005260892438662777
  - 0.00017032873445750298
  - 7.263394910781299e-05
  - 0.0003677552221241542
  train_level0__tp_micro:
  - 0.0013869625520110957
  - 0.0013152231096656942
  - 0.001508625933766455
  - 0.0008473960729244849
  - 0.0012013337256055702
  train_level0__tp_micro_masked:
  - 0.0
  - 2.7109086965950985e-05
  - 2.760676917980289e-05
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 0.000573915538763212
  - 0.0005260892438662776
  - 0.00017032873445750298
  - 7.263394910781299e-05
  - 0.0003677552221241542
  train_level0__tp_samples:
  - 0.0013869625520110957
  - 0.0013152231096656942
  - 0.0015086259337664548
  - 0.0008473960729244849
  - 0.0012013337256055702
  train_level0__tp_samples_masked:
  - 0.0
  - 2.8640164967350212e-05
  - 2.8480291638186377e-05
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 0.000573915538763212
  - 0.0005260892438662776
  - 0.00017032873445750298
  - 7.263394910781298e-05
  - 0.00036775522212415413
  train_level0__tp_weighted:
  - 0.0052580075072662736
  - 0.004945195976936149
  - 0.005585672605061473
  - 0.00324041288997758
  - 0.004508281046500283
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.00016168674502903588
  - 0.00016599066888612759
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0021757272443860445
  - 0.0019780783907744595
  - 0.0006421352897658105
  - 0.0002777496762837925
  - 0.0013800860346429437
  train_level10__average_precision_macro:
  - 0.3445697204536549
  - 0.34566255818479336
  - 0.36719551924746535
  - 0.3370706805181086
  - 0.36192470737755705
  train_level10__average_precision_macro_masked:
  - 0.21927870002680705
  - 0.2217808013405649
  - 0.2414981600762386
  - 0.21724458508908379
  - 0.2355184619610304
  train_level10__average_precision_macro_oob:
  - 0.3409300462124218
  - 0.34037608041741046
  - 0.3627388543555632
  - 0.33390911612121027
  - 0.3574424836017842
  train_level10__average_precision_micro:
  - 0.30987916310018493
  - 0.30063764034144314
  - 0.3196068155272123
  - 0.2977368902246518
  - 0.33864267839470674
  train_level10__average_precision_micro_masked:
  - 0.17501817384117135
  - 0.16930461931176516
  - 0.1827812294344487
  - 0.1686251432050538
  - 0.19530804167898472
  train_level10__average_precision_micro_oob:
  - 0.3093493235098654
  - 0.29962550638994034
  - 0.32009265527328623
  - 0.29722881730958545
  - 0.3381014519158724
  train_level10__average_precision_samples:
  - 0.3205852953986004
  - 0.3134353670192429
  - 0.3282863120702624
  - 0.3069442500463911
  - 0.3501578229411941
  train_level10__average_precision_samples_masked:
  - 0.19330212146159964
  - 0.19008552127498568
  - 0.20060964866944223
  - 0.18371917678233657
  - 0.21668956102630801
  train_level10__average_precision_samples_oob:
  - 0.32029482644636276
  - 0.3125195445670088
  - 0.3290684973686075
  - 0.30670880305202997
  - 0.3497430201269695
  train_level10__average_precision_weighted:
  - 0.47082909432348824
  - 0.4777443654347931
  - 0.49567788475582625
  - 0.4677608467237944
  - 0.4898322952351741
  train_level10__average_precision_weighted_masked:
  - 0.3212847902565132
  - 0.33024228203579264
  - 0.347535478117596
  - 0.32535612760384536
  - 0.3404285498528542
  train_level10__average_precision_weighted_oob:
  - 0.4667754225412907
  - 0.4710775849008631
  - 0.49025237799254456
  - 0.4635035452396963
  - 0.48468012976721014
  train_level10__f1_macro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.4416624084483052
  - 0.4330436045807811
  - 0.4319407668922233
  train_level10__f1_macro_masked:
  - 0.381779176111807
  - 0.3570696253531
  - 0.38203843978139435
  - 0.3727723974814569
  - 0.3704743163358517
  train_level10__f1_macro_oob:
  - 0.4396432158400688
  - 0.4167822468793343
  - 0.43961846363481516
  - 0.4312519671694551
  - 0.4302000588408356
  train_level10__f1_micro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.44166240844830523
  - 0.43304360458078106
  - 0.4319407668922232
  train_level10__f1_micro_masked:
  - 0.37408882746660166
  - 0.3487855129039254
  - 0.37354719377191287
  - 0.36504194308898513
  - 0.36259096716849065
  train_level10__f1_micro_oob:
  - 0.4396432158400689
  - 0.41678224687933424
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__f1_samples:
  - 0.441293223014013
  - 0.4202496532593619
  - 0.4416624084483052
  - 0.433043604580781
  - 0.43194076689222327
  train_level10__f1_samples_masked:
  - 0.375257627802132
  - 0.35008003907639085
  - 0.3747200621653963
  - 0.3662069530783105
  - 0.36374651716050893
  train_level10__f1_samples_oob:
  - 0.4396432158400688
  - 0.4167822468793342
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__f1_weighted:
  - 0.5204828099920273
  - 0.5051137194152563
  - 0.5251408240159113
  - 0.5133482385391197
  - 0.5124626674133183
  train_level10__f1_weighted_masked:
  - 0.4398950413442752
  - 0.41984524031695214
  - 0.4457797779843302
  - 0.432104513325929
  - 0.4299468723133194
  train_level10__f1_weighted_oob:
  - 0.5180242885699277
  - 0.5015978332557269
  - 0.5227663446687654
  - 0.510799599187452
  - 0.509767191019816
  train_level10__fn_macro:
  - -0.016763116361375487
  - -0.014276149026734897
  - -0.016692215976835293
  - -0.01641527249836574
  - -0.015347651269981366
  train_level10__fn_macro_masked:
  - -0.01246337515869326
  - -0.010585936574321176
  - -0.01263756337655806
  - -0.012210773486096421
  - -0.011800588287323274
  train_level10__fn_macro_oob:
  - -0.017408771342484104
  - -0.015137022334879718
  - -0.017397863591016374
  - -0.01699634409122824
  - -0.01600961066980484
  train_level10__fn_micro:
  - -0.016763116361375483
  - -0.0142761490267349
  - -0.016692215976835293
  - -0.016415272498365736
  - -0.015347651269981367
  train_level10__fn_micro_masked:
  - -0.011787659539874807
  - -0.01016590761223162
  - -0.011926124285674848
  - -0.011596030484127419
  - -0.011221598800066663
  train_level10__fn_micro_oob:
  - -0.017408771342484097
  - -0.015137022334879718
  - -0.017397863591016374
  - -0.01699634409122824
  - -0.016009610669804844
  train_level10__fn_samples:
  - -0.016763116361375483
  - -0.014276149026734897
  - -0.016692215976835293
  - -0.016415272498365736
  - -0.015347651269981367
  train_level10__fn_samples_masked:
  - -0.011687622075685853
  - -0.010113582619199838
  - -0.011885213129303374
  - -0.01154861096624922
  - -0.011153383419889227
  train_level10__fn_samples_oob:
  - -0.017408771342484093
  - -0.015137022334879716
  - -0.017397863591016374
  - -0.01699634409122824
  - -0.016009610669804844
  train_level10__fn_weighted:
  - -0.021915919222096927
  - -0.01779165479970324
  - -0.02223958700752293
  - -0.021421053685527547
  - -0.019706196785155207
  train_level10__fn_weighted_masked:
  - -0.01758232217912455
  - -0.013771596174265792
  - -0.017958767746377217
  - -0.016903091751227478
  - -0.016176995736993362
  train_level10__fn_weighted_oob:
  - -0.022975578972603463
  - -0.018787977422380014
  - -0.023210412876195022
  - -0.022313337523851232
  - -0.020616178585519195
  train_level10__fp_macro:
  - -0.5419436606246114
  - -0.5654741977139032
  - -0.5416453755748596
  - -0.5505411229208531
  - -0.5527115818377953
  train_level10__fp_macro_masked:
  - -0.6057574487294998
  - -0.6323444380725788
  - -0.6053239968420475
  - -0.6150168290324466
  - -0.617725095376825
  train_level10__fp_macro_oob:
  - -0.542948012817447
  - -0.568080730785786
  - -0.5429836727741685
  - -0.5517516887393167
  - -0.5537903304893597
  train_level10__fp_micro:
  - -0.5419436606246114
  - -0.5654741977139031
  - -0.5416453755748595
  - -0.5505411229208532
  - -0.5527115818377955
  train_level10__fp_micro_masked:
  - -0.6141235129935235
  - -0.641048579483843
  - -0.6145266819424123
  - -0.6233620264268874
  - -0.6261874340314427
  train_level10__fp_micro_oob:
  - -0.542948012817447
  - -0.568080730785786
  - -0.5429836727741685
  - -0.5517516887393168
  - -0.5537903304893597
  train_level10__fp_samples:
  - -0.5419436606246114
  - -0.5654741977139031
  - -0.5416453755748595
  - -0.5505411229208532
  - -0.5527115818377953
  train_level10__fp_samples_masked:
  - -0.6130547501221822
  - -0.6398063783044092
  - -0.6133947247053003
  - -0.6222444359554402
  - -0.6251000994196019
  train_level10__fp_samples_oob:
  - -0.542948012817447
  - -0.568080730785786
  - -0.5429836727741685
  - -0.5517516887393168
  - -0.5537903304893596
  train_level10__fp_weighted:
  - -0.4576012707858757
  - -0.4770946257850405
  - -0.4526195889765655
  - -0.46523070777535264
  - -0.4678311358015264
  train_level10__fp_weighted_masked:
  - -0.5425226364766004
  - -0.566383163508782
  - -0.5362614542692925
  - -0.5509923949228434
  - -0.5538761319496873
  train_level10__fp_weighted_oob:
  - -0.45900013245746896
  - -0.479614189321893
  - -0.4540232424550396
  - -0.4668870632886967
  - -0.46961663039466484
  train_level10__jaccard_macro:
  - 0.2990052014231653
  - 0.28026213194044725
  - 0.30089190882863104
  - 0.29282377199666687
  - 0.29050198173407743
  train_level10__jaccard_macro_masked:
  - 0.24909030198460616
  - 0.22819605362685794
  - 0.2506748133328713
  - 0.24311709244150467
  - 0.23950947868222588
  train_level10__jaccard_macro_oob:
  - 0.29746760597665545
  - 0.2775815946163113
  - 0.2991008952549735
  - 0.29125647798694493
  - 0.28897674053212047
  train_level10__jaccard_micro:
  - 0.28311497039059863
  - 0.2660228270412643
  - 0.28341895289102637
  - 0.27635970333745363
  - 0.27546202195190594
  train_level10__jaccard_micro_masked:
  - 0.2300794986750221
  - 0.21122968313905763
  - 0.22966986336247136
  - 0.2232729711602951
  - 0.22144189991518234
  train_level10__jaccard_micro_oob:
  - 0.28175813397495825
  - 0.26325010950503724
  - 0.2817378015500491
  - 0.2749019970984968
  - 0.2740476971372347
  train_level10__jaccard_samples:
  - 0.2898267922247938
  - 0.27267190658444984
  - 0.29012759656298
  - 0.28403258764433037
  - 0.28303143508402884
  train_level10__jaccard_samples_masked:
  - 0.23750796456022702
  - 0.21855394197327555
  - 0.23705259904107948
  - 0.2318934344799881
  - 0.22976368244098735
  train_level10__jaccard_samples_oob:
  - 0.28844591660185515
  - 0.26977123444492446
  - 0.2884034527099299
  - 0.2826189117925237
  - 0.28141556788057914
  train_level10__jaccard_weighted:
  - 0.3671744313298198
  - 0.35268926605000744
  - 0.3728555099006693
  - 0.36197745474256277
  - 0.3605211614890372
  train_level10__jaccard_weighted_masked:
  - 0.29421013249059297
  - 0.27648819956500476
  - 0.3000690900516603
  - 0.2890864868504042
  - 0.285945621478515
  train_level10__jaccard_weighted_oob:
  - 0.3647115208792074
  - 0.3496380540894931
  - 0.3705960069749481
  - 0.35962957281357105
  - 0.3579182123956851
  train_level10__label_ranking_average_precision_score:
  - 0.32058529539860026
  - 0.31343536701924285
  - 0.3282863120702622
  - 0.3069442500463912
  - 0.3501578229411939
  train_level10__label_ranking_average_precision_score_oob:
  - 0.32029482644636287
  - 0.312519544567009
  - 0.3290684973686072
  - 0.3067088030520298
  - 0.34974302012696945
  train_level10__matthews_corrcoef_macro:
  - 0.19227408449114053
  - 0.17697371089286987
  - 0.19840986219168988
  - 0.1798551702234039
  - 0.1864624082344676
  train_level10__matthews_corrcoef_macro_masked:
  - 0.138897727054757
  - 0.12625949812063397
  - 0.14420182974275883
  - 0.1277147604097674
  - 0.1319892111677714
  train_level10__matthews_corrcoef_macro_oob:
  - 0.1879549181102532
  - 0.16852740000503413
  - 0.19342627067286391
  - 0.17533847986745796
  - 0.18070105062227237
  train_level10__matthews_corrcoef_micro:
  - 0.21868801432598123
  - 0.20694052639490076
  - 0.21933966697096027
  - 0.21180092145992893
  - 0.2145968832260579
  train_level10__matthews_corrcoef_micro_masked:
  - 0.15563022965237908
  - 0.14689587754526018
  - 0.15529384151547648
  - 0.1496354414897446
  - 0.15050102592283113
  train_level10__matthews_corrcoef_micro_oob:
  - 0.21476712200884565
  - 0.2002298813412323
  - 0.21481411015918353
  - 0.2079258377641549
  - 0.21046116258074238
  train_level10__matthews_corrcoef_samples:
  - 0.2171346385509086
  - 0.204464649648101
  - 0.2170872101618054
  - 0.20890367376055838
  - 0.210568692788731
  train_level10__matthews_corrcoef_samples_masked:
  - 0.1563291503655668
  - 0.14598757842834287
  - 0.1520871097103953
  - 0.14757223244390527
  - 0.1479759320417611
  train_level10__matthews_corrcoef_samples_oob:
  - 0.21335515044540518
  - 0.19776190522562023
  - 0.21270454606064065
  - 0.2048505297231205
  - 0.20667433665878893
  train_level10__matthews_corrcoef_weighted:
  - 0.21163939012488042
  - 0.19571105407654601
  - 0.22354348199732552
  - 0.19915308268035858
  - 0.21281510062765915
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.1569886255347591
  - 0.14557956871015482
  - 0.16665834374284272
  - 0.14766433724121547
  - 0.1566830817600803
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.204809347832913
  - 0.18500131415034987
  - 0.21583327884490366
  - 0.19238157718927082
  - 0.204186554197875
  train_level10__ndcg:
  - 0.6690806296579899
  - 0.6624253165179053
  - 0.6730573636057962
  - 0.6625298548243359
  - 0.6911517886774083
  train_level10__ndcg_oob:
  - 0.6695248332975284
  - 0.6622162522927785
  - 0.6753729935136268
  - 0.6629025798187673
  - 0.6920954635867952
  train_level10__neg_coverage_error:
  - -83.23891625615764
  - -84.60591133004927
  - -83.17543859649123
  - -84.0498753117207
  - -83.60606060606061
  train_level10__neg_coverage_error_oob:
  - -84.0935960591133
  - -85.41625615763547
  - -83.95238095238095
  - -84.93516209476309
  - -84.40151515151516
  train_level10__neg_hamming_loss_macro:
  - -0.5587067769859869
  - -0.579750346740638
  - -0.5583375915516948
  - -0.5669563954192189
  - -0.5680592331077766
  train_level10__neg_hamming_loss_macro_masked:
  - -0.6182208238881929
  - -0.6429303746469
  - -0.6179615602186057
  - -0.627227602518543
  - -0.6295256836641483
  train_level10__neg_hamming_loss_macro_oob:
  - -0.5603567841599312
  - -0.5832177531206658
  - -0.5603815363651848
  - -0.568748032830545
  - -0.5697999411591643
  train_level10__neg_hamming_loss_micro:
  - -0.5587067769859869
  - -0.579750346740638
  - -0.5583375915516948
  - -0.5669563954192189
  - -0.5680592331077768
  train_level10__neg_hamming_loss_micro_masked:
  - -0.6259111725333983
  - -0.6512144870960747
  - -0.6264528062280871
  - -0.6349580569110148
  - -0.6374090328315094
  train_level10__neg_hamming_loss_micro_oob:
  - -0.5603567841599312
  - -0.5832177531206657
  - -0.5603815363651848
  - -0.568748032830545
  - -0.5697999411591644
  train_level10__neg_hamming_loss_samples:
  - -0.5587067769859869
  - -0.579750346740638
  - -0.5583375915516947
  - -0.566956395419219
  - -0.5680592331077767
  train_level10__neg_hamming_loss_samples_masked:
  - -0.624742372197868
  - -0.6499199609236092
  - -0.6252799378346037
  - -0.6337930469216895
  - -0.6362534828394911
  train_level10__neg_hamming_loss_samples_oob:
  - -0.5603567841599311
  - -0.5832177531206657
  - -0.5603815363651847
  - -0.568748032830545
  - -0.5697999411591644
  train_level10__neg_hamming_loss_weighted:
  - -0.4795171900079727
  - -0.4948862805847436
  - -0.47485917598408844
  - -0.48665176146088013
  - -0.48753733258668164
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.5601049586557248
  - -0.580154759683048
  - -0.5542202220156698
  - -0.5678954866740711
  - -0.5700531276866806
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.4819757114300724
  - -0.4984021667442729
  - -0.4772336553312346
  - -0.48920040081254795
  - -0.49023280898018395
  train_level10__neg_label_ranking_loss:
  - -0.4056520120086786
  - -0.4147815052105096
  - -0.3972539478487763
  - -0.43413506148883135
  - -0.36929458702688556
  train_level10__neg_label_ranking_loss_oob:
  - -0.41097633030529007
  - -0.4196444186689195
  - -0.4026453034905521
  - -0.43884863910754734
  - -0.3749186362256804
  train_level10__precision_macro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.4416624084483052
  - 0.4330436045807811
  - 0.4319407668922233
  train_level10__precision_macro_masked:
  - 0.381779176111807
  - 0.3570696253531
  - 0.38203843978139435
  - 0.3727723974814569
  - 0.3704743163358517
  train_level10__precision_macro_oob:
  - 0.4396432158400688
  - 0.4167822468793343
  - 0.43961846363481516
  - 0.4312519671694551
  - 0.4302000588408356
  train_level10__precision_micro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.44166240844830523
  - 0.43304360458078106
  - 0.4319407668922232
  train_level10__precision_micro_masked:
  - 0.37408882746660166
  - 0.3487855129039254
  - 0.37354719377191287
  - 0.36504194308898513
  - 0.36259096716849065
  train_level10__precision_micro_oob:
  - 0.4396432158400689
  - 0.41678224687933424
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__precision_samples:
  - 0.441293223014013
  - 0.4202496532593619
  - 0.4416624084483052
  - 0.433043604580781
  - 0.43194076689222327
  train_level10__precision_samples_masked:
  - 0.375257627802132
  - 0.35008003907639085
  - 0.3747200621653963
  - 0.3662069530783105
  - 0.36374651716050893
  train_level10__precision_samples_oob:
  - 0.4396432158400688
  - 0.4167822468793342
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__precision_weighted:
  - 0.5204828099920273
  - 0.5051137194152563
  - 0.5251408240159113
  - 0.5133482385391197
  - 0.5124626674133183
  train_level10__precision_weighted_masked:
  - 0.4398950413442752
  - 0.41984524031695214
  - 0.4457797779843302
  - 0.432104513325929
  - 0.4299468723133194
  train_level10__precision_weighted_oob:
  - 0.5180242885699277
  - 0.5015978332557269
  - 0.5227663446687654
  - 0.510799599187452
  - 0.509767191019816
  train_level10__recall_macro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.4416624084483052
  - 0.4330436045807811
  - 0.4319407668922233
  train_level10__recall_macro_masked:
  - 0.381779176111807
  - 0.3570696253531
  - 0.38203843978139435
  - 0.3727723974814569
  - 0.3704743163358517
  train_level10__recall_macro_oob:
  - 0.4396432158400688
  - 0.4167822468793343
  - 0.43961846363481516
  - 0.4312519671694551
  - 0.4302000588408356
  train_level10__recall_micro:
  - 0.4412932230140131
  - 0.420249653259362
  - 0.44166240844830523
  - 0.43304360458078106
  - 0.4319407668922232
  train_level10__recall_micro_masked:
  - 0.37408882746660166
  - 0.3487855129039254
  - 0.37354719377191287
  - 0.36504194308898513
  - 0.36259096716849065
  train_level10__recall_micro_oob:
  - 0.4396432158400689
  - 0.41678224687933424
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__recall_samples:
  - 0.441293223014013
  - 0.4202496532593619
  - 0.4416624084483052
  - 0.433043604580781
  - 0.43194076689222327
  train_level10__recall_samples_masked:
  - 0.375257627802132
  - 0.35008003907639085
  - 0.3747200621653963
  - 0.3662069530783105
  - 0.36374651716050893
  train_level10__recall_samples_oob:
  - 0.4396432158400688
  - 0.4167822468793342
  - 0.4396184636348152
  - 0.431251967169455
  - 0.43020005884083556
  train_level10__recall_weighted:
  - 0.5204828099920273
  - 0.5051137194152563
  - 0.5251408240159113
  - 0.5133482385391197
  - 0.5124626674133183
  train_level10__recall_weighted_masked:
  - 0.4398950413442752
  - 0.41984524031695214
  - 0.4457797779843302
  - 0.432104513325929
  - 0.4299468723133194
  train_level10__recall_weighted_oob:
  - 0.5180242885699277
  - 0.5015978332557269
  - 0.5227663446687654
  - 0.510799599187452
  - 0.509767191019816
  train_level10__roc_auc_macro:
  - 0.6790661837369908
  - 0.6767130468662109
  - 0.694178112580896
  - 0.6690848349546171
  - 0.6921541527692174
  train_level10__roc_auc_macro_masked:
  - 0.6589547250958622
  - 0.656631511056812
  - 0.6783128371746142
  - 0.6480600104522669
  - 0.6719069178967262
  train_level10__roc_auc_macro_oob:
  - 0.6725150763186236
  - 0.6699318886231992
  - 0.6873588274722577
  - 0.6621266437052804
  - 0.6852314208748619
  train_level10__roc_auc_micro:
  - 0.6506043245410794
  - 0.6377235641476446
  - 0.6588891859375772
  - 0.6374287350221493
  - 0.6773905315618098
  train_level10__roc_auc_micro_masked:
  - 0.6332511027086296
  - 0.621566353097802
  - 0.6431040391668787
  - 0.6230878210837657
  - 0.6601117870152383
  train_level10__roc_auc_micro_oob:
  - 0.6486131541552203
  - 0.6351926567813947
  - 0.6570433662384865
  - 0.635500790899749
  - 0.6748636031469494
  train_level10__roc_auc_samples:
  - 0.6394067068066797
  - 0.6261659207802642
  - 0.6450758387076992
  - 0.6236372884260584
  - 0.6673980588600836
  train_level10__roc_auc_samples_masked:
  - 0.6251854082173556
  - 0.6114382557846886
  - 0.629676981067315
  - 0.6091686471233114
  - 0.6514459195201576
  train_level10__roc_auc_samples_oob:
  - 0.6376613780416245
  - 0.6236657514138789
  - 0.6440873511287691
  - 0.6221302992741348
  - 0.6654599844790848
  train_level10__roc_auc_weighted:
  - 0.678267645704102
  - 0.6787965074997445
  - 0.6947554864604779
  - 0.6735494245269293
  - 0.6936272229617191
  train_level10__roc_auc_weighted_masked:
  - 0.6573955179124463
  - 0.6579748235971418
  - 0.6760838264894395
  - 0.6545428926699924
  - 0.6733759889941111
  train_level10__roc_auc_weighted_oob:
  - 0.6709073547158968
  - 0.670843025493987
  - 0.6862559384894477
  - 0.6659625108764002
  - 0.6860587961166787
  train_level10__tn_macro:
  - 0.22416184418193125
  - 0.20000956525897937
  - 0.2223519964960946
  - 0.21729656441420725
  - 0.213788369128175
  train_level10__tn_macro_masked:
  - 0.251134585086059
  - 0.22398666884373516
  - 0.2500450633037279
  - 0.2428988859575657
  - 0.2394054378845829
  train_level10__tn_macro_oob:
  - 0.2231574919890956
  - 0.1974030321870965
  - 0.2210136992967857
  - 0.21608599859574365
  - 0.21270962047661077
  train_level10__tn_micro:
  - 0.22416184418193122
  - 0.2000095652589794
  - 0.2223519964960946
  - 0.2172965644142072
  - 0.21378836912817495
  train_level10__tn_micro_masked:
  - 0.25401728856732514
  - 0.22674040338321405
  - 0.2522706567650388
  - 0.2460387082625144
  - 0.2422087661796567
  train_level10__tn_micro_oob:
  - 0.2231574919890956
  - 0.19740303218709646
  - 0.22101369929678566
  - 0.21608599859574365
  - 0.21270962047661077
  train_level10__tn_samples:
  - 0.2241618441819312
  - 0.20000956525897937
  - 0.22235199649609458
  - 0.21729656441420714
  - 0.21378836912817492
  train_level10__tn_samples_masked:
  - 0.2547872026001221
  - 0.22770397604560644
  - 0.253202288910347
  - 0.24686451934112427
  - 0.2429502071368647
  train_level10__tn_samples_oob:
  - 0.22315749198909554
  - 0.19740303218709643
  - 0.22101369929678563
  - 0.2160859985957436
  - 0.21270962047661074
  train_level10__tn_weighted:
  - 0.19692925310607726
  - 0.1746196669615199
  - 0.19934127513856298
  - 0.18782951891311458
  - 0.1864288093026018
  train_level10__tn_weighted_masked:
  - 0.22888073618285748
  - 0.20312515306794438
  - 0.23340191149163017
  - 0.21881896574140194
  - 0.21794268077288556
  train_level10__tn_weighted_oob:
  - 0.19553039143448417
  - 0.1721001034246675
  - 0.19793762166008894
  - 0.18617316339977044
  - 0.18464331470946338
  train_level10__tp_macro:
  - 0.2171313788320819
  - 0.2202400880003826
  - 0.2193104119522106
  - 0.21574704016657378
  - 0.2181523977640482
  train_level10__tp_macro_masked:
  - 0.130644591025748
  - 0.13308295650936483
  - 0.13199337647766657
  - 0.12987351152389123
  - 0.13106887845126883
  train_level10__tp_macro_oob:
  - 0.21648572385097328
  - 0.2193792146922378
  - 0.21860476433802953
  - 0.21516596857371126
  - 0.21749043836422474
  train_level10__tp_micro:
  - 0.2171313788320819
  - 0.2202400880003826
  - 0.21931041195221063
  - 0.21574704016657387
  - 0.21815239776404824
  train_level10__tp_micro_masked:
  - 0.12007153889927648
  - 0.12204510952071135
  - 0.12127653700687409
  - 0.11900323482647075
  - 0.12038220098883395
  train_level10__tp_micro_oob:
  - 0.21648572385097326
  - 0.21937921469223778
  - 0.21860476433802953
  - 0.21516596857371134
  - 0.21749043836422477
  train_level10__tp_samples:
  - 0.21713137883208178
  - 0.22024008800038258
  - 0.2193104119522106
  - 0.2157470401665738
  - 0.21815239776404816
  train_level10__tp_samples_masked:
  - 0.1204704252020099
  - 0.12237606303078431
  - 0.12151777325504923
  - 0.11934243373718621
  - 0.12079631002364426
  train_level10__tp_samples_oob:
  - 0.21648572385097323
  - 0.21937921469223776
  - 0.2186047643380295
  - 0.2151659685737113
  - 0.21749043836422471
  train_level10__tp_weighted:
  - 0.3235535568859501
  - 0.33049405245373636
  - 0.3257995488773485
  - 0.3255187196260054
  - 0.32603385811071656
  train_level10__tp_weighted_masked:
  - 0.21101430516141773
  - 0.21672008724900782
  - 0.2123778664927001
  - 0.21328554758452697
  - 0.21200419154043393
  train_level10__tp_weighted_oob:
  - 0.3224938971354435
  - 0.3294977298310596
  - 0.32482872300867643
  - 0.3246264357876817
  - 0.32512387631035267
  train_level1__average_precision_macro:
  - 0.39394961405874424
  - 0.38673157769582883
  - 0.40743798025573136
  - 0.3790604266953853
  - 0.39412774812814055
  train_level1__average_precision_macro_masked:
  - 0.2660384924145112
  - 0.2559135369115844
  - 0.2785601032690965
  - 0.25680008701570367
  - 0.2668853359318843
  train_level1__average_precision_macro_oob:
  - 0.385666262556778
  - 0.37610775916657696
  - 0.39813580598571596
  - 0.3706286568997095
  - 0.3830111273241593
  train_level1__average_precision_micro:
  - 0.33416143886724897
  - 0.31333141654999414
  - 0.310909337284092
  - 0.3091056015847216
  - 0.3449325216821994
  train_level1__average_precision_micro_masked:
  - 0.19148505112945052
  - 0.17715402229689625
  - 0.17777854387829353
  - 0.17618644324833327
  - 0.20040711610225298
  train_level1__average_precision_micro_oob:
  - 0.32794820831602356
  - 0.30667088664265835
  - 0.30484708479581346
  - 0.30461450930702433
  - 0.3368786556489377
  train_level1__average_precision_samples:
  - 0.35657114587250843
  - 0.33447655953184374
  - 0.3302413055613506
  - 0.32718793686592484
  - 0.37417771121516363
  train_level1__average_precision_samples_masked:
  - 0.22830866480057943
  - 0.21150919934508758
  - 0.20865803967185212
  - 0.2063550235127971
  - 0.24610527626172263
  train_level1__average_precision_samples_oob:
  - 0.3511830098931495
  - 0.3281570369089229
  - 0.3244741442545454
  - 0.3224684357618405
  - 0.36577172480094183
  train_level1__average_precision_weighted:
  - 0.5178907122181775
  - 0.5115187562448199
  - 0.5327773006584067
  - 0.5073981734040284
  - 0.5188472370933898
  train_level1__average_precision_weighted_masked:
  - 0.36909687136311525
  - 0.3607429994433922
  - 0.38552243267264247
  - 0.36440431287424846
  - 0.37359360912007805
  train_level1__average_precision_weighted_oob:
  - 0.5092721946568646
  - 0.49957641850113704
  - 0.5221995083750817
  - 0.4976186842191077
  - 0.5074221732956693
  train_level1__f1_macro:
  - 0.43734755368501604
  - 0.39492563011143517
  - 0.43772051487943153
  - 0.4388543205094061
  - 0.4130626654898499
  train_level1__f1_macro_masked:
  - 0.3747319501150149
  - 0.3258874831069209
  - 0.37563371861278416
  - 0.37852011522258844
  - 0.3469490247349975
  train_level1__f1_macro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.4197629997323406
  - 0.4257075757208921
  - 0.3948220064724918
  train_level1__f1_micro:
  - 0.43734755368501604
  - 0.3949256301114353
  - 0.4377205148794316
  - 0.4388543205094061
  - 0.41306266548984993
  train_level1__f1_micro_masked:
  - 0.3683982332059724
  - 0.31839622641509435
  - 0.36843994147364934
  - 0.3721146992707934
  - 0.3402310982723182
  train_level1__f1_micro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.41976299973234055
  - 0.42570757572089196
  - 0.3948220064724919
  train_level1__f1_samples:
  - 0.43734755368501593
  - 0.3949256301114352
  - 0.43772051487943153
  - 0.43885432050940604
  - 0.4130626654898499
  train_level1__f1_samples_masked:
  - 0.36944723812888225
  - 0.31958913407866113
  - 0.36949978196859273
  - 0.3731471461392185
  - 0.3411684398692828
  train_level1__f1_samples_oob:
  - 0.42075182935577976
  - 0.3777559902434358
  - 0.41976299973234055
  - 0.4257075757208919
  - 0.3948220064724919
  train_level1__f1_weighted:
  - 0.5097444376676808
  - 0.4767615973510426
  - 0.5148015414347809
  - 0.5115951387565083
  - 0.4882484547278752
  train_level1__f1_weighted_masked:
  - 0.4224648834414835
  - 0.38264905181643005
  - 0.42965062517779495
  - 0.4278234791735913
  - 0.39759034847418384
  train_level1__f1_weighted_oob:
  - 0.4922149759536812
  - 0.45883532472281546
  - 0.4955281801782526
  - 0.4980233741436376
  - 0.4684367297502534
  train_level1__fn_macro:
  - -0.014754411975704243
  - -0.011071787268640297
  - -0.01579190695184563
  - -0.01716582330581314
  - -0.01345984112974404
  train_level1__fn_macro_masked:
  - -0.010978961871491156
  - -0.008381102901062155
  - -0.011899650547947936
  - -0.012297914760532436
  - -0.010345282746158192
  train_level1__fn_macro_oob:
  - -0.015926156200679133
  - -0.012745707590033
  - -0.017592525001824948
  - -0.01910272861535482
  - -0.014783759929390997
  train_level1__fn_micro:
  - -0.014754411975704242
  - -0.011071787268640299
  - -0.015791906951845635
  - -0.017165823305813135
  - -0.013459841129744042
  train_level1__fn_micro_masked:
  - -0.010730834891472238
  - -0.008214053350683148
  - -0.011539629517157608
  - -0.011952409671582872
  - -0.010054996944614187
  train_level1__fn_micro_oob:
  - -0.015926156200679133
  - -0.012745707590033
  - -0.01759252500182495
  - -0.01910272861535482
  - -0.014783759929390997
  train_level1__fn_samples:
  - -0.014754411975704242
  - -0.011071787268640297
  - -0.01579190695184563
  - -0.01716582330581314
  - -0.01345984112974404
  train_level1__fn_samples_masked:
  - -0.010639795437932068
  - -0.008187416310462239
  - -0.01152276289946505
  - -0.011902847866905772
  - -0.010015530312919853
  train_level1__fn_samples_oob:
  - -0.015926156200679133
  - -0.012745707590033
  - -0.017592525001824948
  - -0.019102728615354815
  - -0.014783759929390997
  train_level1__fn_weighted:
  - -0.015924359230699108
  - -0.012100535407251582
  - -0.018187286961604442
  - -0.019416730881108835
  - -0.015138257840903786
  train_level1__fn_weighted_masked:
  - -0.01283441923960795
  - -0.009646446697745984
  - -0.014590081296934648
  - -0.014929913682252875
  - -0.012529640886856394
  train_level1__fn_weighted_oob:
  - -0.01634364000175267
  - -0.013623525168762033
  - -0.019398687459963444
  - -0.02136383933273501
  - -0.016118503387508004
  train_level1__fp_macro:
  - -0.5478980343392796
  - -0.5940025826199244
  - -0.5464875781687228
  - -0.5439798561847808
  - -0.573477493380406
  train_level1__fp_macro_masked:
  - -0.614289088013494
  - -0.6657314139920167
  - -0.612466630839268
  - -0.6091819700168791
  - -0.6427056925188442
  train_level1__fp_macro_oob:
  - -0.563322014443541
  - -0.6094983021665311
  - -0.5626444752658345
  - -0.5551896956637533
  - -0.5903942335981172
  train_level1__fp_micro:
  - -0.5478980343392797
  - -0.5940025826199244
  - -0.5464875781687227
  - -0.5439798561847807
  - -0.573477493380406
  train_level1__fp_micro_masked:
  - -0.6208709319025554
  - -0.6733897202342225
  - -0.6200204290091931
  - -0.6159328910576237
  - -0.6497139047830676
  train_level1__fp_micro_oob:
  - -0.563322014443541
  - -0.6094983021665311
  - -0.5626444752658345
  - -0.5551896956637532
  - -0.590394233598117
  train_level1__fp_samples:
  - -0.5478980343392797
  - -0.5940025826199243
  - -0.5464875781687228
  - -0.5439798561847807
  - -0.573477493380406
  train_level1__fp_samples_masked:
  - -0.6199129664331856
  - -0.6722234496108765
  - -0.6189774551319422
  - -0.6149500059938757
  - -0.6488160298177974
  train_level1__fp_samples_oob:
  - -0.563322014443541
  - -0.6094983021665311
  - -0.5626444752658345
  - -0.5551896956637533
  - -0.590394233598117
  train_level1__fp_weighted:
  - -0.47433120310162
  - -0.5111378672417057
  - -0.4670111716036147
  - -0.46898813036238285
  - -0.4966132874312212
  train_level1__fp_weighted_masked:
  - -0.5647006973189085
  - -0.607704501485824
  - -0.5557592935252703
  - -0.5572466071441556
  - -0.5898800106389597
  train_level1__fp_weighted_oob:
  - -0.4914413840445661
  - -0.5275411501084226
  - -0.48507313236178395
  - -0.48061278652362743
  - -0.5154447668622387
  train_level1__jaccard_macro:
  - 0.30065833320717594
  - 0.26460828934411695
  - 0.30444689227123484
  - 0.30343075716639734
  - 0.28052270222428166
  train_level1__jaccard_macro_masked:
  - 0.2501955710794665
  - 0.2107619582059516
  - 0.2542063207965966
  - 0.25502618284910866
  - 0.2284977609575013
  train_level1__jaccard_macro_oob:
  - 0.28681515124975787
  - 0.2510666208881434
  - 0.2899491752914958
  - 0.29241376445008704
  - 0.2657530396252262
  train_level1__jaccard_micro:
  - 0.27987512816196614
  - 0.24604818164210904
  - 0.2801806712872829
  - 0.2811104218362283
  - 0.26028921023359286
  train_level1__jaccard_micro_masked:
  - 0.22578930760160104
  - 0.18934081346423562
  - 0.2258206429780034
  - 0.22858778754504733
  - 0.20498703037402727
  train_level1__jaccard_micro_oob:
  - 0.26642540240153845
  - 0.23286015418859357
  - 0.2656329396547742
  - 0.2704120080586869
  - 0.24596774193548387
  train_level1__jaccard_samples:
  - 0.28537928359562603
  - 0.25081621835991735
  - 0.28512029446418746
  - 0.28672467605238844
  - 0.2652901283900851
  train_level1__jaccard_samples_masked:
  - 0.23170013520407817
  - 0.19439984704960028
  - 0.23108859708167975
  - 0.2346980290715419
  - 0.21035023896581442
  train_level1__jaccard_samples_oob:
  - 0.27145188965274103
  - 0.2373925417123604
  - 0.2700493756495793
  - 0.27561511615230805
  - 0.25045200197383666
  train_level1__jaccard_weighted:
  - 0.3606372384582842
  - 0.3316432921161889
  - 0.3669145083166801
  - 0.3642230524173007
  - 0.34226139295036734
  train_level1__jaccard_weighted_masked:
  - 0.28449056244354276
  - 0.25162904777008205
  - 0.29166944167502296
  - 0.29069701473353576
  - 0.26437001042853775
  train_level1__jaccard_weighted_oob:
  - 0.34514693092798293
  - 0.3165926533868733
  - 0.3501683283506939
  - 0.3521772937607389
  - 0.32522467398286986
  train_level1__label_ranking_average_precision_score:
  - 0.35657114587250843
  - 0.33447655953184374
  - 0.33024130556135073
  - 0.3271879368659249
  - 0.37417771121516386
  train_level1__label_ranking_average_precision_score_oob:
  - 0.3511830098931494
  - 0.3281570369089229
  - 0.32447414425454535
  - 0.3224684357618405
  - 0.36577172480094156
  train_level1__matthews_corrcoef_macro:
  - 0.18283053613528627
  - 0.15167893282461675
  - 0.1854963703008089
  - 0.17090322135625297
  - 0.16022279526974129
  train_level1__matthews_corrcoef_macro_masked:
  - 0.12905898529199386
  - 0.10604555245980422
  - 0.1317683597443024
  - 0.12094249607892033
  - 0.11057919311952735
  train_level1__matthews_corrcoef_macro_oob:
  - 0.1546711652565759
  - 0.11973031390189631
  - 0.1549914181459339
  - 0.14725194585817725
  - 0.129558294081038
  train_level1__matthews_corrcoef_micro:
  - 0.22205372948215646
  - 0.19392157500665994
  - 0.21865640609161624
  - 0.21480977966382603
  - 0.20294709670671182
  train_level1__matthews_corrcoef_micro_masked:
  - 0.15732113316286603
  - 0.13642315927847135
  - 0.15375991663030134
  - 0.152642245536882
  - 0.14118928090800226
  train_level1__matthews_corrcoef_micro_oob:
  - 0.20132776879237793
  - 0.1690474546267146
  - 0.1940778760275249
  - 0.1947827410763962
  - 0.17916806839189897
  train_level1__matthews_corrcoef_samples:
  - 0.21927670920825112
  - 0.19113199963306426
  - 0.21722776979497493
  - 0.2137161768849068
  - 0.20051827910982498
  train_level1__matthews_corrcoef_samples_masked:
  - 0.1560406848688262
  - 0.1342201753711527
  - 0.15009262213953536
  - 0.15174086675745158
  - 0.13943019055036812
  train_level1__matthews_corrcoef_samples_oob:
  - 0.19760157948630158
  - 0.16578249332536035
  - 0.19228918135797834
  - 0.19355921873691512
  - 0.17667989443820714
  train_level1__matthews_corrcoef_weighted:
  - 0.1963373685314593
  - 0.16317163133715004
  - 0.20010239623199036
  - 0.1858276237641677
  - 0.17413979967242352
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.14189150698381348
  - 0.11813641007233379
  - 0.14600174781833355
  - 0.1376785842178011
  - 0.12405066427526315
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.16134701691549053
  - 0.12456786335752681
  - 0.16452128388747106
  - 0.1592853937195951
  - 0.1357166087655014
  train_level1__ndcg:
  - 0.6680694472906893
  - 0.6496940826213022
  - 0.6415691185807498
  - 0.6476648307599853
  - 0.6821688812747664
  train_level1__ndcg_oob:
  - 0.6660442174668476
  - 0.6466229971755699
  - 0.639685153756071
  - 0.6462218883033681
  - 0.6787994177098534
  train_level1__neg_coverage_error:
  - -83.38669950738917
  - -84.0320197044335
  - -83.7218045112782
  - -83.88029925187033
  - -83.8030303030303
  train_level1__neg_coverage_error_oob:
  - -85.35960591133005
  - -85.9039408866995
  - -85.67167919799499
  - -85.36907730673316
  - -85.92171717171718
  train_level1__neg_hamming_loss_macro:
  - -0.562652446314984
  - -0.6050743698885649
  - -0.5622794851205685
  - -0.5611456794905939
  - -0.5869373345101501
  train_level1__neg_hamming_loss_macro_masked:
  - -0.6252680498849851
  - -0.674112516893079
  - -0.6243662813872158
  - -0.6214798847774115
  - -0.6530509752650026
  train_level1__neg_hamming_loss_macro_oob:
  - -0.5792481706442202
  - -0.6222440097565641
  - -0.5802370002676595
  - -0.5742924242791079
  - -0.6051779935275081
  train_level1__neg_hamming_loss_micro:
  - -0.562652446314984
  - -0.6050743698885648
  - -0.5622794851205684
  - -0.5611456794905939
  - -0.5869373345101501
  train_level1__neg_hamming_loss_micro_masked:
  - -0.6316017667940276
  - -0.6816037735849056
  - -0.6315600585263507
  - -0.6278853007292067
  - -0.6597689017276818
  train_level1__neg_hamming_loss_micro_oob:
  - -0.5792481706442202
  - -0.6222440097565641
  - -0.5802370002676595
  - -0.5742924242791081
  - -0.6051779935275081
  train_level1__neg_hamming_loss_samples:
  - -0.5626524463149839
  - -0.6050743698885647
  - -0.5622794851205684
  - -0.5611456794905939
  - -0.5869373345101501
  train_level1__neg_hamming_loss_samples_masked:
  - -0.6305527618711176
  - -0.6804108659213389
  - -0.6305002180314073
  - -0.6268528538607815
  - -0.6588315601307172
  train_level1__neg_hamming_loss_samples_oob:
  - -0.5792481706442202
  - -0.6222440097565641
  - -0.5802370002676593
  - -0.5742924242791081
  - -0.605177993527508
  train_level1__neg_hamming_loss_weighted:
  - -0.4902555623323192
  - -0.5232384026489574
  - -0.4851984585652192
  - -0.48840486124349164
  - -0.5117515452721249
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.5775351165585164
  - -0.6173509481835701
  - -0.570349374822205
  - -0.5721765208264085
  - -0.602409651525816
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.5077850240463189
  - -0.5411646752771846
  - -0.5044718198217474
  - -0.5019766258563625
  - -0.5315632702497466
  train_level1__neg_label_ranking_loss:
  - -0.32615255169571383
  - -0.3433944328406969
  - -0.34465959653974765
  - -0.348001466202526
  - -0.3207990322580689
  train_level1__neg_label_ranking_loss_oob:
  - -0.3369629730411196
  - -0.3558506182866158
  - -0.35660254741017944
  - -0.3578916237252849
  - -0.33517081551696054
  train_level1__precision_macro:
  - 0.43734755368501604
  - 0.39492563011143517
  - 0.43772051487943153
  - 0.4388543205094061
  - 0.4130626654898499
  train_level1__precision_macro_masked:
  - 0.3747319501150149
  - 0.3258874831069209
  - 0.37563371861278416
  - 0.37852011522258844
  - 0.3469490247349975
  train_level1__precision_macro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.4197629997323406
  - 0.4257075757208921
  - 0.3948220064724918
  train_level1__precision_micro:
  - 0.43734755368501604
  - 0.3949256301114353
  - 0.4377205148794316
  - 0.4388543205094061
  - 0.41306266548984993
  train_level1__precision_micro_masked:
  - 0.3683982332059724
  - 0.31839622641509435
  - 0.36843994147364934
  - 0.3721146992707934
  - 0.3402310982723182
  train_level1__precision_micro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.41976299973234055
  - 0.42570757572089196
  - 0.3948220064724919
  train_level1__precision_samples:
  - 0.43734755368501593
  - 0.3949256301114352
  - 0.43772051487943153
  - 0.43885432050940604
  - 0.4130626654898499
  train_level1__precision_samples_masked:
  - 0.36944723812888225
  - 0.31958913407866113
  - 0.36949978196859273
  - 0.3731471461392185
  - 0.3411684398692828
  train_level1__precision_samples_oob:
  - 0.42075182935577976
  - 0.3777559902434358
  - 0.41976299973234055
  - 0.4257075757208919
  - 0.3948220064724919
  train_level1__precision_weighted:
  - 0.5097444376676808
  - 0.4767615973510426
  - 0.5148015414347809
  - 0.5115951387565083
  - 0.4882484547278752
  train_level1__precision_weighted_masked:
  - 0.4224648834414835
  - 0.38264905181643005
  - 0.42965062517779495
  - 0.4278234791735913
  - 0.39759034847418384
  train_level1__precision_weighted_oob:
  - 0.4922149759536812
  - 0.45883532472281546
  - 0.4955281801782526
  - 0.4980233741436376
  - 0.4684367297502534
  train_level1__recall_macro:
  - 0.43734755368501604
  - 0.39492563011143517
  - 0.43772051487943153
  - 0.4388543205094061
  - 0.4130626654898499
  train_level1__recall_macro_masked:
  - 0.3747319501150149
  - 0.3258874831069209
  - 0.37563371861278416
  - 0.37852011522258844
  - 0.3469490247349975
  train_level1__recall_macro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.4197629997323406
  - 0.4257075757208921
  - 0.3948220064724918
  train_level1__recall_micro:
  - 0.43734755368501604
  - 0.3949256301114353
  - 0.4377205148794316
  - 0.4388543205094061
  - 0.41306266548984993
  train_level1__recall_micro_masked:
  - 0.3683982332059724
  - 0.31839622641509435
  - 0.36843994147364934
  - 0.3721146992707934
  - 0.3402310982723182
  train_level1__recall_micro_oob:
  - 0.4207518293557798
  - 0.37775599024343587
  - 0.41976299973234055
  - 0.42570757572089196
  - 0.3948220064724919
  train_level1__recall_samples:
  - 0.43734755368501593
  - 0.3949256301114352
  - 0.43772051487943153
  - 0.43885432050940604
  - 0.4130626654898499
  train_level1__recall_samples_masked:
  - 0.36944723812888225
  - 0.31958913407866113
  - 0.36949978196859273
  - 0.3731471461392185
  - 0.3411684398692828
  train_level1__recall_samples_oob:
  - 0.42075182935577976
  - 0.3777559902434358
  - 0.41976299973234055
  - 0.4257075757208919
  - 0.3948220064724919
  train_level1__recall_weighted:
  - 0.5097444376676808
  - 0.4767615973510426
  - 0.5148015414347809
  - 0.5115951387565083
  - 0.4882484547278752
  train_level1__recall_weighted_masked:
  - 0.4224648834414835
  - 0.38264905181643005
  - 0.42965062517779495
  - 0.4278234791735913
  - 0.39759034847418384
  train_level1__recall_weighted_oob:
  - 0.4922149759536812
  - 0.45883532472281546
  - 0.4955281801782526
  - 0.4980233741436376
  - 0.4684367297502534
  train_level1__roc_auc_macro:
  - 0.6993313149969448
  - 0.6884848501977731
  - 0.7069559640144781
  - 0.6872913475186259
  - 0.699619230677957
  train_level1__roc_auc_macro_masked:
  - 0.6739042970742258
  - 0.6630232326497186
  - 0.6881626330916094
  - 0.6617876573662689
  - 0.6743489935859897
  train_level1__roc_auc_macro_oob:
  - 0.6854636856028615
  - 0.671334982911553
  - 0.6904726423629471
  - 0.6723981230421369
  - 0.6811029138118766
  train_level1__roc_auc_micro:
  - 0.6837102092909346
  - 0.663973063175104
  - 0.6669378557659636
  - 0.6631641683377915
  - 0.6849852190200311
  train_level1__roc_auc_micro_masked:
  - 0.6658961173912905
  - 0.6459702982840884
  - 0.6507755881616168
  - 0.648181550133707
  - 0.6685726955573376
  train_level1__roc_auc_micro_oob:
  - 0.6727013658298304
  - 0.6512561226778509
  - 0.6545529022861984
  - 0.653609398494824
  - 0.6709313975344086
  train_level1__roc_auc_samples:
  - 0.6738843070818815
  - 0.6567479290993176
  - 0.6553983768506159
  - 0.6525884664871937
  - 0.6792792064830103
  train_level1__roc_auc_samples_masked:
  - 0.6583142354607536
  - 0.6430221817825549
  - 0.6379596615254202
  - 0.6373136425511052
  - 0.6645165474008058
  train_level1__roc_auc_samples_oob:
  - 0.6630975959773904
  - 0.6443438838021371
  - 0.6435007359425424
  - 0.6429103496164644
  - 0.6649515195388946
  train_level1__roc_auc_weighted:
  - 0.6949985163145257
  - 0.6880748572659104
  - 0.7042147511794586
  - 0.6895398312196361
  - 0.699284014522727
  train_level1__roc_auc_weighted_masked:
  - 0.6712914405436403
  - 0.6636906799039938
  - 0.6828574787036519
  - 0.6674507633340985
  - 0.6767716403511473
  train_level1__roc_auc_weighted_oob:
  - 0.6809126810880693
  - 0.6706816565536767
  - 0.6862964970755943
  - 0.6737486048204513
  - 0.6812959882925257
  train_level1__tn_macro:
  - 0.21820747046726294
  - 0.17148118035295806
  - 0.21750979390223127
  - 0.22385783115027963
  - 0.19302245758556438
  train_level1__tn_macro_masked:
  - 0.24260294580206468
  - 0.19059969292429704
  - 0.2429024293065075
  - 0.24873374497313325
  - 0.21442484074256357
  train_level1__tn_macro_oob:
  - 0.20278349036300158
  - 0.15598546080635134
  - 0.2013528968051196
  - 0.21264799167130716
  - 0.17610571736785327
  train_level1__tn_micro:
  - 0.2182074704672629
  - 0.17148118035295806
  - 0.2175097939022313
  - 0.22385783115027963
  - 0.19302245758556438
  train_level1__tn_micro_masked:
  - 0.24726986965829337
  - 0.19439926263283452
  - 0.24677690969825802
  - 0.25346784363177804
  - 0.21868229542803178
  train_level1__tn_micro_oob:
  - 0.20278349036300158
  - 0.15598546080635134
  - 0.20135289680511959
  - 0.21264799167130716
  - 0.1761057173678533
  train_level1__tn_samples:
  - 0.21820747046726285
  - 0.171481180352958
  - 0.21750979390223124
  - 0.2238578311502796
  - 0.19302245758556433
  train_level1__tn_samples_masked:
  - 0.24792898628911858
  - 0.19528690473913918
  - 0.24761955848370512
  - 0.2541589493026889
  - 0.21923427673866913
  train_level1__tn_samples_oob:
  - 0.20278349036300153
  - 0.1559854608063513
  - 0.20135289680511953
  - 0.21264799167130713
  - 0.17610571736785324
  train_level1__tn_weighted:
  - 0.18019932079033293
  - 0.14057642550485455
  - 0.18494969251151386
  - 0.1840720963260844
  - 0.15764665767290711
  train_level1__tn_weighted_masked:
  - 0.2067026753405492
  - 0.1618038150909025
  - 0.2139040722356523
  - 0.21256475352008986
  - 0.18193880208361307
  train_level1__tn_weighted_oob:
  - 0.16308913984738682
  - 0.12417314263813775
  - 0.16688773175334462
  - 0.17244744016483973
  - 0.13881517824188971
  train_level1__tp_macro:
  - 0.21914008321775313
  - 0.22344444975847724
  - 0.22021072097720026
  - 0.2149964893591264
  - 0.22004020790428555
  train_level1__tp_macro_masked:
  - 0.13212900431295008
  - 0.13528779018262388
  - 0.13273128930627667
  - 0.12978637024945522
  - 0.1325241839924339
  train_level1__tp_macro_oob:
  - 0.21796833899277823
  - 0.22177052943708456
  - 0.21841010292722093
  - 0.21305958404958472
  - 0.21871628910463858
  train_level1__tp_micro:
  - 0.21914008321775313
  - 0.22344444975847721
  - 0.2202107209772003
  - 0.21499648935912646
  - 0.22004020790428558
  train_level1__tp_micro_masked:
  - 0.12112836354767904
  - 0.12399696378225981
  - 0.12166303177539133
  - 0.1186468556390153
  - 0.12154880284428643
  train_level1__tp_micro_oob:
  - 0.21796833899277823
  - 0.2217705294370845
  - 0.21841010292722096
  - 0.21305958404958478
  - 0.2187162891046386
  train_level1__tp_samples:
  - 0.21914008321775305
  - 0.22344444975847716
  - 0.22021072097720024
  - 0.21499648935912638
  - 0.2200402079042855
  train_level1__tp_samples_masked:
  - 0.12151825183976368
  - 0.12430222933952191
  - 0.12188022348488754
  - 0.11898819683652964
  - 0.12193416313061364
  train_level1__tp_samples_oob:
  - 0.21796833899277818
  - 0.22177052943708447
  - 0.21841010292722093
  - 0.21305958404958472
  - 0.21871628910463856
  train_level1__tp_weighted:
  - 0.32954511687734783
  - 0.33618517184618807
  - 0.3298518489232671
  - 0.327523042430424
  - 0.330601797054968
  train_level1__tp_weighted_masked:
  - 0.21576220810093433
  - 0.22084523672552756
  - 0.21574655294214268
  - 0.21525872565350154
  - 0.21565154639057085
  train_level1__tp_weighted_oob:
  - 0.3291258361062943
  - 0.33466218208467763
  - 0.328640448424908
  - 0.3255759339787979
  - 0.32962155150836375
  train_level2__average_precision_macro:
  - 0.3563110813791033
  - 0.35141880068358355
  - 0.37920969277537403
  - 0.3473530060843365
  - 0.3662241276752332
  train_level2__average_precision_macro_masked:
  - 0.22863879633582682
  - 0.22666935778101896
  - 0.2501616713595796
  - 0.22679844107591068
  - 0.240390736483894
  train_level2__average_precision_macro_oob:
  - 0.3516694606779842
  - 0.3470593577770385
  - 0.37430530551984353
  - 0.34167349921686135
  - 0.36045113072268287
  train_level2__average_precision_micro:
  - 0.3098905025138927
  - 0.29576249917838815
  - 0.3180538535604387
  - 0.29880573430244867
  - 0.3342606359448543
  train_level2__average_precision_micro_masked:
  - 0.17512763056764624
  - 0.16615568351154153
  - 0.1816371329902295
  - 0.16895801602027555
  - 0.19250712800949724
  train_level2__average_precision_micro_oob:
  - 0.30892756232028784
  - 0.2955279772219252
  - 0.31717051948609065
  - 0.2972730849437544
  - 0.33244109737688654
  train_level2__average_precision_samples:
  - 0.3218089331143057
  - 0.3108322206922705
  - 0.32782956150881193
  - 0.30817663749961977
  - 0.34851568842670744
  train_level2__average_precision_samples_masked:
  - 0.19579882065470558
  - 0.1897007750325622
  - 0.20186152404680485
  - 0.1854623983323386
  - 0.21819663777310525
  train_level2__average_precision_samples_oob:
  - 0.32100171307149145
  - 0.31047980776410744
  - 0.3272381862175013
  - 0.30711641129165074
  - 0.34731477021957496
  train_level2__average_precision_weighted:
  - 0.4822468173205217
  - 0.4830492153218577
  - 0.5073072847675755
  - 0.4764575742411725
  - 0.49329847258625525
  train_level2__average_precision_weighted_masked:
  - 0.3322158990049773
  - 0.334752885485241
  - 0.35752948091457976
  - 0.33352247332934015
  - 0.3447718040874693
  train_level2__average_precision_weighted_oob:
  - 0.4771636673667127
  - 0.4777409280994406
  - 0.5014863333972968
  - 0.469875188181425
  - 0.48727719745960896
  train_level2__f1_macro:
  - 0.4354584150365872
  - 0.4086756898943039
  - 0.4374528554395699
  - 0.42791080551049565
  - 0.42340884573894294
  train_level2__f1_macro_masked:
  - 0.3753361452828953
  - 0.34376354912161294
  - 0.3775338003128264
  - 0.36720157540435144
  - 0.360717234560069
  train_level2__f1_macro_oob:
  - 0.43160839829738396
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.42173691983633155
  - 0.4187015788957537
  train_level2__f1_micro:
  - 0.4354584150365871
  - 0.40867568989430386
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__f1_micro_masked:
  - 0.3677478795761862
  - 0.3354478421166775
  - 0.3689920768572454
  - 0.3593947036569987
  - 0.3528415088050664
  train_level2__f1_micro_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.4217369198363315
  - 0.41870157889575366
  train_level2__f1_samples:
  - 0.43545841503658705
  - 0.4086756898943038
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__f1_samples_masked:
  - 0.3689607346713227
  - 0.33671198466324354
  - 0.37019389433452515
  - 0.36054160824491627
  - 0.3539925932140471
  train_level2__f1_samples_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.4339732827213665
  - 0.42173691983633144
  - 0.41870157889575366
  train_level2__f1_weighted:
  - 0.5142573089578016
  - 0.4943392700800323
  - 0.521579234197464
  - 0.5088948813699404
  - 0.5045061598768025
  train_level2__f1_weighted_masked:
  - 0.4326505471999876
  - 0.406779424443456
  - 0.44162256431201447
  - 0.42713843410736746
  - 0.42010839113670245
  train_level2__f1_weighted_oob:
  - 0.509889234330357
  - 0.48785752209766714
  - 0.5173889461254951
  - 0.50207128960371
  - 0.49959034910210887
  train_level2__fn_macro:
  - -0.017026160983308624
  - -0.013630494045626286
  - -0.016789546682239576
  - -0.016512117763842822
  - -0.01490634500343238
  train_level2__fn_macro_masked:
  - -0.01238580094789001
  - -0.01005057990383075
  - -0.012504400633319535
  - -0.012132530322902802
  - -0.011339417058986749
  train_level2__fn_macro_oob:
  - -0.017671815964417237
  - -0.014491367353771104
  - -0.018079178528846388
  - -0.01765004963319856
  - -0.015690889477297243
  train_level2__fn_micro:
  - -0.017026160983308624
  - -0.013630494045626286
  - -0.01678954668223958
  - -0.01651211776384282
  - -0.014906345003432383
  train_level2__fn_micro_masked:
  - -0.011814757607782564
  - -0.009650834959878552
  - -0.011815697208955636
  - -0.01154120291682658
  - -0.010804955280262207
  train_level2__fn_micro_oob:
  - -0.017671815964417237
  - -0.014491367353771104
  - -0.018079178528846388
  - -0.017650049633198557
  - -0.015690889477297243
  train_level2__fn_samples:
  - -0.01702616098330862
  - -0.013630494045626286
  - -0.01678954668223958
  - -0.01651211776384282
  - -0.01490634500343238
  train_level2__fn_samples_masked:
  - -0.011706017383873403
  - -0.0096194177588157
  - -0.011792454865457668
  - -0.011501413316324788
  - -0.0107422591472441
  train_level2__fn_samples_oob:
  - -0.017671815964417234
  - -0.014491367353771104
  - -0.018079178528846385
  - -0.017650049633198557
  - -0.015690889477297243
  train_level2__fn_weighted:
  - -0.02155783077979172
  - -0.016979929385916668
  - -0.022257675325544502
  - -0.021334972091098775
  - -0.01886859990072926
  train_level2__fn_weighted_masked:
  - -0.016707018521567165
  - -0.013079513495640408
  - -0.01766017292539405
  - -0.016640881223828455
  - -0.015371276134243031
  train_level2__fn_weighted_oob:
  - -0.02224152284790609
  - -0.018211330903180147
  - -0.023721795467119184
  - -0.022898484313774947
  - -0.01977486965412207
  train_level2__fp_macro:
  - -0.5475154239801042
  - -0.5776938160600699
  - -0.5457575978781906
  - -0.5555770767256616
  - -0.5616848092576247
  train_level2__fp_macro_masked:
  - -0.6122780537692147
  - -0.6461858709745563
  - -0.6099617990538541
  - -0.6206658942727459
  - -0.6279433483809441
  train_level2__fp_macro_oob:
  - -0.5507197857381988
  - -0.5828829690563874
  - -0.547947538749787
  - -0.5606130305304698
  - -0.565607531626949
  train_level2__fp_micro:
  - -0.5475154239801042
  - -0.5776938160600699
  - -0.5457575978781907
  - -0.5555770767256616
  - -0.5616848092576248
  train_level2__fp_micro_masked:
  - -0.6204373628160312
  - -0.6549013229234439
  - -0.619192225933799
  - -0.6290640934261746
  - -0.6363535359146714
  train_level2__fp_micro_oob:
  - -0.5507197857381989
  - -0.5828829690563873
  - -0.5479475387497871
  - -0.56061303053047
  - -0.5656075316269491
  train_level2__fp_samples:
  - -0.5475154239801043
  - -0.5776938160600699
  - -0.5457575978781907
  - -0.5555770767256615
  - -0.5616848092576248
  train_level2__fp_samples_masked:
  - -0.6193332479448039
  - -0.6536685975779406
  - -0.6180136508000171
  - -0.627956978438759
  - -0.6352651476387088
  train_level2__fp_samples_oob:
  - -0.5507197857381989
  - -0.5828829690563873
  - -0.5479475387497871
  - -0.56061303053047
  - -0.5656075316269491
  train_level2__fp_weighted:
  - -0.4641848602624067
  - -0.4886808005340511
  - -0.4561630904769916
  - -0.4697701465389609
  - -0.47662524022246827
  train_level2__fp_weighted_masked:
  - -0.5506424342784453
  - -0.5801410620609039
  - -0.5407172627625914
  - -0.5562206846688041
  - -0.5645203327290546
  train_level2__fp_weighted_oob:
  - -0.46786924282173686
  - -0.4939311469991527
  - -0.4588892584073857
  - -0.4750302260825153
  - -0.480634781243769
  train_level2__jaccard_macro:
  - 0.2940214413000086
  - 0.27126656773732216
  - 0.29770236228032426
  - 0.2888198563008918
  - 0.28381519400569627
  train_level2__jaccard_macro_masked:
  - 0.24407726389294024
  - 0.21864357846834456
  - 0.24757250194609012
  - 0.23908076162312877
  - 0.23240656189566836
  train_level2__jaccard_macro_oob:
  - 0.29072647827575915
  - 0.2663822734106943
  - 0.2947118670459121
  - 0.2836302183368163
  - 0.27998304526068746
  train_level2__jaccard_micro:
  - 0.2783297160150399
  - 0.2568148348510805
  - 0.27996138034134793
  - 0.2721924474835212
  - 0.26855969893944576
  train_level2__jaccard_micro_masked:
  - 0.22530090478957418
  - 0.20152438031334485
  - 0.22623561272850373
  - 0.21906225980015373
  - 0.21421223925397548
  train_level2__jaccard_micro_oob:
  - 0.2751917300684587
  - 0.2520546714771179
  - 0.2771174194751317
  - 0.2672158559221931
  - 0.2647834041365624
  train_level2__jaccard_samples:
  - 0.285410671505956
  - 0.2632405463174633
  - 0.28647568159136644
  - 0.27996490608258245
  - 0.27580182319386004
  train_level2__jaccard_samples_masked:
  - 0.2331923973145434
  - 0.20855701468677768
  - 0.23336704568450914
  - 0.22783530424939435
  - 0.22217054225606958
  train_level2__jaccard_samples_oob:
  - 0.28204691376175584
  - 0.25838537062310046
  - 0.2834974598641879
  - 0.27505332933401255
  - 0.2718673098369751
  train_level2__jaccard_weighted:
  - 0.36149625782375056
  - 0.343486086724609
  - 0.3696173202943147
  - 0.3584404097147228
  - 0.3535733380529672
  train_level2__jaccard_weighted_masked:
  - 0.28834192136807363
  - 0.2663891855036003
  - 0.2967525535139013
  - 0.2854212670932323
  - 0.27815642022953135
  train_level2__jaccard_weighted_oob:
  - 0.3574831883904498
  - 0.3378780689821523
  - 0.3657651681743656
  - 0.35229204399187203
  - 0.3490515588003114
  train_level2__label_ranking_average_precision_score:
  - 0.3218089331143058
  - 0.3108322206922701
  - 0.32782956150881193
  - 0.3081766374996199
  - 0.3485156884267074
  train_level2__label_ranking_average_precision_score_oob:
  - 0.3210017130714914
  - 0.3104798077641072
  - 0.3272381862175014
  - 0.30711641129165057
  - 0.3473147702195748
  train_level2__matthews_corrcoef_macro:
  - 0.18256835404707147
  - 0.16692949737799664
  - 0.19306444098196768
  - 0.17442372770473955
  - 0.17592515485536236
  train_level2__matthews_corrcoef_macro_masked:
  - 0.13129544834415052
  - 0.1185033311145211
  - 0.14070187440407836
  - 0.123943622532318
  - 0.12371539330647606
  train_level2__matthews_corrcoef_macro_oob:
  - 0.17522935951753335
  - 0.15742907444692167
  - 0.18345965586623694
  - 0.16275708227731467
  - 0.16898063602284066
  train_level2__matthews_corrcoef_micro:
  - 0.21199254420952532
  - 0.19776517813354155
  - 0.2148207038448435
  - 0.2063766763699734
  - 0.20778989820417224
  train_level2__matthews_corrcoef_micro_masked:
  - 0.15106211364532018
  - 0.14032991007314508
  - 0.15268068802267748
  - 0.14598719017563017
  - 0.14593364157428484
  train_level2__matthews_corrcoef_micro_oob:
  - 0.20584544639908608
  - 0.1882553553773567
  - 0.2067528581157729
  - 0.19604420315695267
  - 0.20016332289536876
  train_level2__matthews_corrcoef_samples:
  - 0.20974211140721685
  - 0.19464715617211656
  - 0.21313069469550572
  - 0.20392673043968707
  - 0.20507597922721843
  train_level2__matthews_corrcoef_samples_masked:
  - 0.15104719426496216
  - 0.13869462040930935
  - 0.14952718685603034
  - 0.14409010749017756
  - 0.14423794667326778
  train_level2__matthews_corrcoef_samples_oob:
  - 0.20388029887646789
  - 0.18534800794847223
  - 0.2060722531062118
  - 0.19243688226752514
  - 0.19699609310544183
  train_level2__matthews_corrcoef_weighted:
  - 0.20106266711444315
  - 0.18314355998882081
  - 0.21576879053317585
  - 0.19388974161789324
  - 0.20017872856645577
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.14950510217040722
  - 0.13504248342019534
  - 0.16097683629036952
  - 0.14398252759362687
  - 0.14694332256892223
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.19145127463915187
  - 0.17108001700888872
  - 0.20301020584384552
  - 0.17861014122626856
  - 0.19005088891417918
  train_level2__ndcg:
  - 0.6626741701708674
  - 0.6531519115889332
  - 0.6677926480917652
  - 0.6599332853739218
  - 0.6852599172838395
  train_level2__ndcg_oob:
  - 0.663412852388029
  - 0.6542815686722266
  - 0.6684594665342151
  - 0.6597316382717888
  - 0.6856969482089457
  train_level2__neg_coverage_error:
  - -83.4384236453202
  - -84.19211822660098
  - -83.39598997493734
  - -83.78054862842893
  - -83.44949494949495
  train_level2__neg_coverage_error_oob:
  - -84.32512315270937
  - -85.04433497536945
  - -84.17042606516291
  - -84.79052369077307
  - -84.28535353535354
  train_level2__neg_hamming_loss_macro:
  - -0.5645415849634128
  - -0.5913243101056962
  - -0.5625471445604301
  - -0.5720891944895045
  - -0.5765911542610571
  train_level2__neg_hamming_loss_macro_masked:
  - -0.6246638547171047
  - -0.6562364508783868
  - -0.6224661996871736
  - -0.6327984245956485
  - -0.6392827654399309
  train_level2__neg_hamming_loss_macro_oob:
  - -0.568391601702616
  - -0.5973743364101584
  - -0.5660267172786335
  - -0.5782630801636685
  - -0.5812984211042463
  train_level2__neg_hamming_loss_micro:
  - -0.5645415849634129
  - -0.5913243101056961
  - -0.5625471445604302
  - -0.5720891944895043
  - -0.5765911542610572
  train_level2__neg_hamming_loss_micro_masked:
  - -0.6322521204238137
  - -0.6645521578833224
  - -0.6310079231427546
  - -0.6406052963430012
  - -0.6471584911949336
  train_level2__neg_hamming_loss_micro_oob:
  - -0.568391601702616
  - -0.5973743364101584
  - -0.5660267172786335
  - -0.5782630801636685
  - -0.5812984211042463
  train_level2__neg_hamming_loss_samples:
  - -0.5645415849634128
  - -0.5913243101056961
  - -0.5625471445604302
  - -0.5720891944895043
  - -0.5765911542610571
  train_level2__neg_hamming_loss_samples_masked:
  - -0.6310392653286773
  - -0.6632880153367563
  - -0.6298061056654749
  - -0.6394583917550838
  - -0.6460074067859528
  train_level2__neg_hamming_loss_samples_oob:
  - -0.568391601702616
  - -0.5973743364101582
  - -0.5660267172786335
  - -0.5782630801636685
  - -0.5812984211042463
  train_level2__neg_hamming_loss_weighted:
  - -0.4857426910421983
  - -0.5056607299199677
  - -0.478420765802536
  - -0.4911051186300596
  - -0.4954938401231975
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.5673494528000125
  - -0.5932205755565441
  - -0.5583774356879855
  - -0.5728615658926324
  - -0.5798916088632975
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.490110765669643
  - -0.5121424779023329
  - -0.48261105387450487
  - -0.4979287103962901
  - -0.5004096508978911
  train_level2__neg_label_ranking_loss:
  - -0.3834863969511807
  - -0.39910631220693427
  - -0.3785925540367244
  - -0.41798815045924964
  - -0.35770964239693875
  train_level2__neg_label_ranking_loss_oob:
  - -0.38849352010880256
  - -0.40368592827771954
  - -0.38289712651583035
  - -0.42290354330127855
  - -0.36299587020875246
  train_level2__precision_macro:
  - 0.4354584150365872
  - 0.4086756898943039
  - 0.4374528554395699
  - 0.42791080551049565
  - 0.42340884573894294
  train_level2__precision_macro_masked:
  - 0.3753361452828953
  - 0.34376354912161294
  - 0.3775338003128264
  - 0.36720157540435144
  - 0.360717234560069
  train_level2__precision_macro_oob:
  - 0.43160839829738396
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.42173691983633155
  - 0.4187015788957537
  train_level2__precision_micro:
  - 0.4354584150365871
  - 0.40867568989430386
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__precision_micro_masked:
  - 0.3677478795761862
  - 0.3354478421166775
  - 0.3689920768572454
  - 0.3593947036569987
  - 0.3528415088050664
  train_level2__precision_micro_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.4217369198363315
  - 0.41870157889575366
  train_level2__precision_samples:
  - 0.43545841503658705
  - 0.4086756898943038
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__precision_samples_masked:
  - 0.3689607346713227
  - 0.33671198466324354
  - 0.37019389433452515
  - 0.36054160824491627
  - 0.3539925932140471
  train_level2__precision_samples_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.4339732827213665
  - 0.42173691983633144
  - 0.41870157889575366
  train_level2__precision_weighted:
  - 0.5142573089578016
  - 0.4943392700800323
  - 0.521579234197464
  - 0.5088948813699404
  - 0.5045061598768025
  train_level2__precision_weighted_masked:
  - 0.4326505471999876
  - 0.406779424443456
  - 0.44162256431201447
  - 0.42713843410736746
  - 0.42010839113670245
  train_level2__precision_weighted_oob:
  - 0.509889234330357
  - 0.48785752209766714
  - 0.5173889461254951
  - 0.50207128960371
  - 0.49959034910210887
  train_level2__recall_macro:
  - 0.4354584150365872
  - 0.4086756898943039
  - 0.4374528554395699
  - 0.42791080551049565
  - 0.42340884573894294
  train_level2__recall_macro_masked:
  - 0.3753361452828953
  - 0.34376354912161294
  - 0.3775338003128264
  - 0.36720157540435144
  - 0.360717234560069
  train_level2__recall_macro_oob:
  - 0.43160839829738396
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.42173691983633155
  - 0.4187015788957537
  train_level2__recall_micro:
  - 0.4354584150365871
  - 0.40867568989430386
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__recall_micro_masked:
  - 0.3677478795761862
  - 0.3354478421166775
  - 0.3689920768572454
  - 0.3593947036569987
  - 0.3528415088050664
  train_level2__recall_micro_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.43397328272136654
  - 0.4217369198363315
  - 0.41870157889575366
  train_level2__recall_samples:
  - 0.43545841503658705
  - 0.4086756898943038
  - 0.4374528554395698
  - 0.4279108055104956
  - 0.42340884573894283
  train_level2__recall_samples_masked:
  - 0.3689607346713227
  - 0.33671198466324354
  - 0.37019389433452515
  - 0.36054160824491627
  - 0.3539925932140471
  train_level2__recall_samples_oob:
  - 0.4316083982973839
  - 0.4026256635898417
  - 0.4339732827213665
  - 0.42173691983633144
  - 0.41870157889575366
  train_level2__recall_weighted:
  - 0.5142573089578016
  - 0.4943392700800323
  - 0.521579234197464
  - 0.5088948813699404
  - 0.5045061598768025
  train_level2__recall_weighted_masked:
  - 0.4326505471999876
  - 0.406779424443456
  - 0.44162256431201447
  - 0.42713843410736746
  - 0.42010839113670245
  train_level2__recall_weighted_oob:
  - 0.509889234330357
  - 0.48785752209766714
  - 0.5173889461254951
  - 0.50207128960371
  - 0.49959034910210887
  train_level2__roc_auc_macro:
  - 0.6834264681192952
  - 0.6771139943963779
  - 0.69763170570519
  - 0.6723366960416904
  - 0.6904266422119126
  train_level2__roc_auc_macro_masked:
  - 0.661641246066368
  - 0.6561245960806671
  - 0.682292624855459
  - 0.6510099700664904
  - 0.6695020420504919
  train_level2__roc_auc_macro_oob:
  - 0.6771571015641704
  - 0.6697131940460177
  - 0.6903361043393458
  - 0.6632074572387192
  - 0.6831953552799512
  train_level2__roc_auc_micro:
  - 0.6544158791808483
  - 0.6355541874455776
  - 0.6593004519152813
  - 0.6395555097834356
  - 0.6739485842639852
  train_level2__roc_auc_micro_masked:
  - 0.6366631691180233
  - 0.6196582920571433
  - 0.6432143131785892
  - 0.6248664497881385
  - 0.6563859323484034
  train_level2__roc_auc_micro_oob:
  - 0.6516451397443447
  - 0.6323856640401
  - 0.6562596926254711
  - 0.6360997128937596
  - 0.6699486609839196
  train_level2__roc_auc_samples:
  - 0.642368648084288
  - 0.6252478549450412
  - 0.6456900008962693
  - 0.6264320222434
  - 0.6646110502466519
  train_level2__roc_auc_samples_masked:
  - 0.6276493579046114
  - 0.6111894236290512
  - 0.6298510478008249
  - 0.6112977178763308
  - 0.6486139099737226
  train_level2__roc_auc_samples_oob:
  - 0.640059427668937
  - 0.6226498415584047
  - 0.6434688256025084
  - 0.623400698805139
  - 0.6615485441764285
  train_level2__roc_auc_weighted:
  - 0.6821564374151906
  - 0.6801849446011242
  - 0.6961007231615292
  - 0.6760489273222547
  - 0.6921434422586096
  train_level2__roc_auc_weighted_masked:
  - 0.6604230776820336
  - 0.6590363381167587
  - 0.6771481508855686
  - 0.6564467326136473
  - 0.6715335765318279
  train_level2__roc_auc_weighted_oob:
  - 0.675209182698474
  - 0.6713453317421331
  - 0.6873836102578933
  - 0.6654560100220591
  - 0.6840625656692934
  train_level2__tn_macro:
  - 0.2185900808264384
  - 0.18778994691281267
  - 0.2182397741927635
  - 0.21226061060939883
  - 0.20481514170834558
  train_level2__tn_macro_masked:
  - 0.24461398004634405
  - 0.2101452359417577
  - 0.24540726109192126
  - 0.23724982071726655
  - 0.22918718488046372
  train_level2__tn_macro_oob:
  - 0.21538571906834378
  - 0.18260079391649528
  - 0.21604983332116698
  - 0.20722465680459043
  - 0.2008924193390213
  train_level2__tn_micro:
  - 0.21859008082643838
  - 0.18778994691281267
  - 0.21823977419276347
  - 0.21226061060939883
  - 0.20481514170834558
  train_level2__tn_micro_masked:
  - 0.24770343874481748
  - 0.2128876599436131
  - 0.2476051127736521
  - 0.24033664126322715
  - 0.23204266429642798
  train_level2__tn_micro_oob:
  - 0.21538571906834378
  - 0.18260079391649528
  - 0.216049833321167
  - 0.20722465680459046
  - 0.20089241933902127
  train_level2__tn_samples:
  - 0.21859008082643835
  - 0.1877899469128126
  - 0.2182397741927634
  - 0.2122606106093988
  - 0.20481514170834558
  train_level2__tn_samples_masked:
  - 0.2485087047775003
  - 0.21384175677207512
  - 0.2485833628156303
  - 0.24115197685780565
  - 0.2327851589177577
  train_level2__tn_samples_oob:
  - 0.21538571906834375
  - 0.18260079391649525
  - 0.21604983332116695
  - 0.20722465680459043
  - 0.20089241933902124
  train_level2__tn_weighted:
  - 0.1903456636295462
  - 0.16303349221250932
  - 0.19579777363813697
  - 0.18329008014950632
  - 0.17763470488165994
  train_level2__tn_weighted_masked:
  - 0.22076093838101252
  - 0.18936725451582276
  - 0.2289461029983313
  - 0.21359067599544146
  - 0.20729847999351822
  train_level2__tn_weighted_oob:
  - 0.186661281070216
  - 0.15778314574740776
  - 0.1930716057077429
  - 0.178030000605952
  - 0.17362516386035914
  train_level2__tp_macro:
  - 0.21686833421014878
  - 0.22088574298149125
  - 0.21921308124680636
  - 0.21565019490109674
  - 0.2185937040305972
  train_level2__tp_macro_masked:
  - 0.13072216523655122
  - 0.13361831317985529
  - 0.1321265392209051
  - 0.12995175468708486
  - 0.13153004967960535
  train_level2__tp_macro_oob:
  - 0.21622267922904018
  - 0.22002486967334645
  - 0.21792344940019948
  - 0.21451226303174098
  - 0.21780915955673233
  train_level2__tp_micro:
  - 0.21686833421014873
  - 0.22088574298149122
  - 0.21921308124680633
  - 0.21565019490109677
  - 0.21859370403059725
  train_level2__tp_micro_masked:
  - 0.12004444083136873
  - 0.12256018217306441
  - 0.1213869640835933
  - 0.11905806239377159
  - 0.12079884450863841
  train_level2__tp_micro_oob:
  - 0.21622267922904012
  - 0.22002486967334642
  - 0.21792344940019953
  - 0.21451226303174104
  - 0.21780915955673238
  train_level2__tp_samples:
  - 0.2168683342101487
  - 0.22088574298149116
  - 0.21921308124680627
  - 0.21565019490109674
  - 0.21859370403059716
  train_level2__tp_samples_masked:
  - 0.12045202989382234
  - 0.12287022789116846
  - 0.12161053151889493
  - 0.11938963138711065
  - 0.1212074342962894
  train_level2__tp_samples_oob:
  - 0.2162226792290401
  - 0.22002486967334636
  - 0.21792344940019948
  - 0.21451226303174095
  - 0.2178091595567323
  train_level2__tp_weighted:
  - 0.3239116453282552
  - 0.331305777867523
  - 0.32578146055932694
  - 0.3256048012204341
  - 0.32687145499514253
  train_level2__tp_weighted_masked:
  - 0.21188960881897514
  - 0.21741216992763318
  - 0.21267646131368326
  - 0.21354775811192597
  - 0.2128099111431842
  train_level2__tp_weighted_oob:
  - 0.32322795326014087
  - 0.3300743763502595
  - 0.3243173404177523
  - 0.32404128899775797
  - 0.32596518524174967
  train_level3__average_precision_macro:
  - 0.35021030161072325
  - 0.35019879142223037
  - 0.3731370914342321
  - 0.34222779862151903
  - 0.3641082809423181
  train_level3__average_precision_macro_masked:
  - 0.22407924935707246
  - 0.22626281415486973
  - 0.24441235343488235
  - 0.22081712053681413
  - 0.23770927796348332
  train_level3__average_precision_macro_oob:
  - 0.3465019811956565
  - 0.3448808750432695
  - 0.36725636022485825
  - 0.33782815281954504
  - 0.3578081166991103
  train_level3__average_precision_micro:
  - 0.30996724924003005
  - 0.29925146644239287
  - 0.31879641377046963
  - 0.29946792978869796
  - 0.3354988177449691
  train_level3__average_precision_micro_masked:
  - 0.17567154340226654
  - 0.16860250987322856
  - 0.18109383172757137
  - 0.16951408569708054
  - 0.19263802120425483
  train_level3__average_precision_micro_oob:
  - 0.30997304678810667
  - 0.2980805907083317
  - 0.3181344523242612
  - 0.2980430339711251
  - 0.33395367656468
  train_level3__average_precision_samples:
  - 0.3221279403485137
  - 0.3130693796411864
  - 0.32847822675096994
  - 0.30915940739361747
  - 0.34823419817634577
  train_level3__average_precision_samples_masked:
  - 0.19594908451696413
  - 0.1908385967828839
  - 0.20039169100609502
  - 0.18569573935153308
  - 0.21662842472637767
  train_level3__average_precision_samples_oob:
  - 0.32164503996374416
  - 0.312335544917675
  - 0.32776533843156175
  - 0.30793057493461395
  - 0.34715246631371743
  train_level3__average_precision_weighted:
  - 0.4757474606469327
  - 0.48212159622172246
  - 0.5014196802883646
  - 0.47116637292460734
  - 0.49267591960454343
  train_level3__average_precision_weighted_masked:
  - 0.32631347707375574
  - 0.33483459595999265
  - 0.3513631854317748
  - 0.3273793369068746
  - 0.3441649527698812
  train_level3__average_precision_weighted_oob:
  - 0.471293957743183
  - 0.47544401662017377
  - 0.4944503764106292
  - 0.46569658719004686
  - 0.48687994758409536
  train_level3__f1_macro:
  - 0.43842364532019706
  - 0.4138170165957244
  - 0.43986179039832585
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__f1_macro_masked:
  - 0.3787284788535116
  - 0.3497174421969452
  - 0.38019030129695913
  - 0.3706615064746296
  - 0.364994083302956
  train_level3__f1_macro_oob:
  - 0.43574537280596864
  - 0.4095604763498972
  - 0.4369662019125484
  - 0.42808028472508053
  - 0.4243159752868492
  train_level3__f1_micro:
  - 0.43842364532019706
  - 0.41381701659572434
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.4271354319898009
  train_level3__f1_micro_masked:
  - 0.371135138064656
  - 0.3413305139882889
  - 0.3716423266985065
  - 0.36290366796425244
  - 0.35711904894172547
  train_level3__f1_micro_oob:
  - 0.4357453728059687
  - 0.4095604763498972
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__f1_samples:
  - 0.43842364532019706
  - 0.4138170165957243
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__f1_samples_masked:
  - 0.37236753859836685
  - 0.3426062136247649
  - 0.3728159297830679
  - 0.3640541138011755
  - 0.3582265295854786
  train_level3__f1_samples_oob:
  - 0.4357453728059687
  - 0.4095604763498971
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__f1_weighted:
  - 0.5168795135637958
  - 0.4996461258947942
  - 0.5237009939013942
  - 0.5117610603796069
  - 0.5079085160721026
  train_level3__f1_weighted_masked:
  - 0.43608902664143073
  - 0.41327346012438165
  - 0.44434423798552836
  - 0.430213143442031
  - 0.424391372192132
  train_level3__f1_weighted_oob:
  - 0.5138377763664651
  - 0.49452135576227096
  - 0.5204474222983999
  - 0.5082572014015435
  - 0.5045644920434924
  train_level3__fn_macro:
  - -0.017026160983308627
  - -0.013917451815007892
  - -0.016862544711292796
  - -0.01651211776384282
  - -0.015200549181131704
  train_level3__fn_macro_masked:
  - -0.012364480224550929
  - -0.01035049549824094
  - -0.012678544299032096
  - -0.012252061253667679
  - -0.0116321122626531
  train_level3__fn_macro_oob:
  - -0.017863121144004977
  - -0.015184848629776652
  - -0.01783585176533567
  - -0.017286879887659493
  - -0.01603412768461312
  train_level3__fn_micro:
  - -0.017026160983308624
  - -0.013917451815007892
  - -0.016862544711292796
  - -0.01651211776384282
  - -0.015200549181131706
  train_level3__fn_micro_masked:
  - -0.011787659539874807
  - -0.009921925829538061
  - -0.011981337824034453
  - -0.011650858051428258
  - -0.011082717626798511
  train_level3__fn_micro_oob:
  - -0.017863121144004974
  - -0.015184848629776652
  - -0.01783585176533567
  - -0.017286879887659493
  - -0.016034127684613122
  train_level3__fn_samples:
  - -0.01702616098330862
  - -0.013917451815007892
  - -0.016862544711292796
  - -0.01651211776384282
  - -0.015200549181131702
  train_level3__fn_samples_masked:
  - -0.011686382780135231
  - -0.009885335118981774
  - -0.011957185444207909
  - -0.011616250429775751
  - -0.011023904190240994
  train_level3__fn_samples_oob:
  - -0.01786312114400497
  - -0.01518484862977665
  - -0.01783585176533567
  - -0.017286879887659493
  - -0.016034127684613122
  train_level3__fn_weighted:
  - -0.021834077630149534
  - -0.017488764685524214
  - -0.02251427103690766
  - -0.02133315163441901
  - -0.019354878053954073
  train_level3__fn_weighted_masked:
  - -0.016730847445261463
  - -0.013598343785003313
  - -0.017896910929447913
  - -0.016837193221489022
  - -0.01578079129251909
  train_level3__fn_weighted_oob:
  - -0.02284765426888262
  - -0.019115731650409556
  - -0.023550214850457413
  - -0.022667546380685057
  - -0.02031974512024911
  train_level3__fp_macro:
  - -0.5445501936964944
  - -0.5722655315892677
  - -0.5432756648903813
  - -0.5523811829649177
  - -0.5576640188290674
  train_level3__fp_macro_masked:
  - -0.6089070409219374
  - -0.6399320623048137
  - -0.6071311544040088
  - -0.6170864322717028
  - -0.6233738044343909
  train_level3__fp_macro_oob:
  - -0.5463915060500263
  - -0.5752546750203262
  - -0.5451979463221159
  - -0.5546328353872599
  - -0.5596498970285377
  train_level3__fp_micro:
  - -0.5445501936964944
  - -0.5722655315892677
  - -0.5432756648903813
  - -0.5523811829649178
  - -0.5576640188290674
  train_level3__fp_micro_masked:
  - -0.6170772023954691
  - -0.648747560182173
  - -0.6163763354774591
  - -0.6254454739843193
  - -0.631798233431476
  train_level3__fp_micro_oob:
  - -0.5463915060500263
  - -0.5752546750203261
  - -0.5451979463221159
  - -0.55463283538726
  - -0.5596498970285378
  train_level3__fp_samples:
  - -0.5445501936964944
  - -0.5722655315892677
  - -0.5432756648903814
  - -0.5523811829649177
  - -0.5576640188290674
  train_level3__fp_samples_masked:
  - -0.6159460786214979
  - -0.6475084512562534
  - -0.6152268847727242
  - -0.6243296357690488
  - -0.6307495662242804
  train_level3__fp_samples_oob:
  - -0.5463915060500263
  - -0.5752546750203261
  - -0.5451979463221159
  - -0.5546328353872599
  - -0.5596498970285378
  train_level3__fp_weighted:
  - -0.4612864088060546
  - -0.48286510941968164
  - -0.45378473506169803
  - -0.4669057879859744
  - -0.47273660587394317
  train_level3__fp_weighted_masked:
  - -0.5471801259133078
  - -0.573128196090615
  - -0.5377588510850237
  - -0.5529496633364799
  - -0.559827836515349
  train_level3__fp_weighted_oob:
  - -0.4633145693646524
  - -0.4863629125873195
  - -0.45600236285114265
  - -0.4690752522177715
  - -0.47511576283625845
  train_level3__jaccard_macro:
  - 0.29635187820331504
  - 0.27537125779049765
  - 0.2995926864421663
  - 0.2912575660204948
  - 0.286588979553597
  train_level3__jaccard_macro_masked:
  - 0.2465381105892399
  - 0.2229900502471086
  - 0.24950963458122816
  - 0.24149425871447153
  - 0.23536786685050598
  train_level3__jaccard_macro_oob:
  - 0.29411419391616594
  - 0.2717961475041613
  - 0.2971448440100844
  - 0.28866776692818097
  - 0.2842990224548417
  train_level3__jaccard_micro:
  - 0.2807570977917981
  - 0.26088857396993864
  - 0.2819377076282421
  - 0.27478395061728395
  - 0.2715652960064844
  train_level3__jaccard_micro_masked:
  - 0.22784894360339378
  - 0.20578573179700907
  - 0.22823138478231383
  - 0.22167520680531833
  - 0.2173736622313896
  train_level3__jaccard_micro_oob:
  - 0.27856422172623596
  - 0.2575140206588582
  - 0.27956286194657204
  - 0.2723296110897189
  - 0.26929001540400505
  train_level3__jaccard_samples:
  - 0.28778089585702166
  - 0.2673349728760785
  - 0.288382353348344
  - 0.2825255874731714
  - 0.278968360834356
  train_level3__jaccard_samples_masked:
  - 0.23569992715776833
  - 0.2128522771135784
  - 0.23526849147089746
  - 0.2303961277749569
  - 0.2255009150143116
  train_level3__jaccard_samples_oob:
  - 0.2853642146600227
  - 0.26388350285691164
  - 0.2858936117485952
  - 0.28020745744066905
  - 0.27646797995168815
  train_level3__jaccard_weighted:
  - 0.3637312420121344
  - 0.34809649934058956
  - 0.37153145991934877
  - 0.36070871043231495
  - 0.3564402546936758
  train_level3__jaccard_weighted_masked:
  - 0.29100475544847565
  - 0.2714578519801228
  - 0.2989623724930607
  - 0.28761201336558434
  - 0.28145360107386974
  train_level3__jaccard_weighted_oob:
  - 0.36093375166991815
  - 0.34338372289686336
  - 0.3685019066522074
  - 0.35744481632604325
  - 0.3534034507571844
  train_level3__label_ranking_average_precision_score:
  - 0.3221279403485139
  - 0.31306937964118625
  - 0.32847822675097027
  - 0.3091594073936173
  - 0.3482341981763458
  train_level3__label_ranking_average_precision_score_oob:
  - 0.32164503996374416
  - 0.3123355449176747
  - 0.327765338431562
  - 0.3079305749346138
  - 0.3471524663137174
  train_level3__matthews_corrcoef_macro:
  - 0.18668019369550093
  - 0.17191754161601377
  - 0.19584347251107503
  - 0.17743967158887242
  - 0.1803500439331309
  train_level3__matthews_corrcoef_macro_masked:
  - 0.13462050921279145
  - 0.12199922892485732
  - 0.14182716158944644
  - 0.1257842967341087
  - 0.126756425978436
  train_level3__matthews_corrcoef_macro_oob:
  - 0.18034555340672587
  - 0.16172170568009245
  - 0.18741951304311433
  - 0.172238397927827
  - 0.17343215765751435
  train_level3__matthews_corrcoef_micro:
  - 0.2149249508271101
  - 0.20185408955108483
  - 0.21695275752519813
  - 0.20953947564621078
  - 0.21039458137493683
  train_level3__matthews_corrcoef_micro_masked:
  - 0.15357321977312002
  - 0.1429859793550362
  - 0.15366597293669218
  - 0.14784770478517756
  - 0.14742144428743115
  train_level3__matthews_corrcoef_micro_oob:
  - 0.20928724768998613
  - 0.1927155828756434
  - 0.2106180936584603
  - 0.20372243957832314
  - 0.20451873852552604
  train_level3__matthews_corrcoef_samples:
  - 0.21359445994603343
  - 0.1996163941589306
  - 0.21537070856391774
  - 0.20660026360084785
  - 0.20726157563013242
  train_level3__matthews_corrcoef_samples_masked:
  - 0.15404912973546234
  - 0.1418619890732077
  - 0.15125455859006298
  - 0.14537365559703286
  - 0.14508614945877107
  train_level3__matthews_corrcoef_samples_oob:
  - 0.20786325227791053
  - 0.1905835033434331
  - 0.2093965388458024
  - 0.20057989359075545
  - 0.20121365565094962
  train_level3__matthews_corrcoef_weighted:
  - 0.20519554704096127
  - 0.18918989457305804
  - 0.2194399169344307
  - 0.19708725888901207
  - 0.20471956558189192
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.15363777010078392
  - 0.13938509387767142
  - 0.16362015938606878
  - 0.14578348643264502
  - 0.15010752446438402
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.19674832492019556
  - 0.17612890732717235
  - 0.20675888498588602
  - 0.18982295430890977
  - 0.1946856479413383
  train_level3__ndcg:
  - 0.6646207293396867
  - 0.6571634981933343
  - 0.6704655546745605
  - 0.6616580874884305
  - 0.6849537394238265
  train_level3__ndcg_oob:
  - 0.6660182671462461
  - 0.6579911678818837
  - 0.6711274405547778
  - 0.6610257748392544
  - 0.6854438270356084
  train_level3__neg_coverage_error:
  - -83.33497536945812
  - -84.2487684729064
  - -83.41102756892231
  - -83.73067331670823
  - -83.47474747474747
  train_level3__neg_coverage_error_oob:
  - -84.14532019704434
  - -85.10344827586206
  - -84.0701754385965
  - -84.70573566084788
  - -84.13636363636364
  train_level3__neg_hamming_loss_macro:
  - -0.5615763546798029
  - -0.5861829834042755
  - -0.5601382096016742
  - -0.5688933007287607
  - -0.5728645680101989
  train_level3__neg_hamming_loss_macro_masked:
  - -0.6212715211464884
  - -0.6502825578030548
  - -0.6198096987030409
  - -0.6293384935253704
  - -0.635005916697044
  train_level3__neg_hamming_loss_macro_oob:
  - -0.5642546271940312
  - -0.5904395236501029
  - -0.5630337980874516
  - -0.5719197152749195
  - -0.5756840247131508
  train_level3__neg_hamming_loss_micro:
  - -0.5615763546798029
  - -0.5861829834042757
  - -0.560138209601674
  - -0.5688933007287607
  - -0.572864568010199
  train_level3__neg_hamming_loss_micro_masked:
  - -0.628864861935344
  - -0.6586694860117112
  - -0.6283576733014935
  - -0.6370963320357476
  - -0.6428809510582746
  train_level3__neg_hamming_loss_micro_oob:
  - -0.5642546271940313
  - -0.5904395236501028
  - -0.5630337980874517
  - -0.5719197152749195
  - -0.5756840247131509
  train_level3__neg_hamming_loss_samples:
  - -0.5615763546798029
  - -0.5861829834042757
  - -0.560138209601674
  - -0.5688933007287607
  - -0.572864568010199
  train_level3__neg_hamming_loss_samples_masked:
  - -0.6276324614016332
  - -0.6573937863752352
  - -0.6271840702169322
  - -0.6359458861988245
  - -0.6417734704145213
  train_level3__neg_hamming_loss_samples_oob:
  - -0.5642546271940312
  - -0.5904395236501029
  - -0.5630337980874517
  - -0.5719197152749195
  - -0.5756840247131509
  train_level3__neg_hamming_loss_weighted:
  - -0.48312048643620403
  - -0.5003538741052058
  - -0.4762990060986057
  - -0.48823893962039305
  - -0.4920914839278973
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.5639109733585691
  - -0.5867265398756185
  - -0.5556557620144716
  - -0.5697868565579689
  - -0.5756086278078679
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.4861622236335349
  - -0.505478644237729
  - -0.47955257770160015
  - -0.4917427985984565
  - -0.4954355079565076
  train_level3__neg_label_ranking_loss:
  - -0.39037959910327913
  - -0.40410258548456995
  - -0.3837822891880465
  - -0.42153321301644586
  - -0.36008562810956685
  train_level3__neg_label_ranking_loss_oob:
  - -0.3959734208441504
  - -0.4086203806862464
  - -0.38927075687190393
  - -0.4267317981450012
  - -0.3659238070474346
  train_level3__precision_macro:
  - 0.43842364532019706
  - 0.4138170165957244
  - 0.43986179039832585
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__precision_macro_masked:
  - 0.3787284788535116
  - 0.3497174421969452
  - 0.38019030129695913
  - 0.3706615064746296
  - 0.364994083302956
  train_level3__precision_macro_oob:
  - 0.43574537280596864
  - 0.4095604763498972
  - 0.4369662019125484
  - 0.42808028472508053
  - 0.4243159752868492
  train_level3__precision_micro:
  - 0.43842364532019706
  - 0.41381701659572434
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.4271354319898009
  train_level3__precision_micro_masked:
  - 0.371135138064656
  - 0.3413305139882889
  - 0.3716423266985065
  - 0.36290366796425244
  - 0.35711904894172547
  train_level3__precision_micro_oob:
  - 0.4357453728059687
  - 0.4095604763498972
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__precision_samples:
  - 0.43842364532019706
  - 0.4138170165957243
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__precision_samples_masked:
  - 0.37236753859836685
  - 0.3426062136247649
  - 0.3728159297830679
  - 0.3640541138011755
  - 0.3582265295854786
  train_level3__precision_samples_oob:
  - 0.4357453728059687
  - 0.4095604763498971
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__precision_weighted:
  - 0.5168795135637958
  - 0.4996461258947942
  - 0.5237009939013942
  - 0.5117610603796069
  - 0.5079085160721026
  train_level3__precision_weighted_masked:
  - 0.43608902664143073
  - 0.41327346012438165
  - 0.44434423798552836
  - 0.430213143442031
  - 0.424391372192132
  train_level3__precision_weighted_oob:
  - 0.5138377763664651
  - 0.49452135576227096
  - 0.5204474222983999
  - 0.5082572014015435
  - 0.5045644920434924
  train_level3__recall_macro:
  - 0.43842364532019706
  - 0.4138170165957244
  - 0.43986179039832585
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__recall_macro_masked:
  - 0.3787284788535116
  - 0.3497174421969452
  - 0.38019030129695913
  - 0.3706615064746296
  - 0.364994083302956
  train_level3__recall_macro_oob:
  - 0.43574537280596864
  - 0.4095604763498972
  - 0.4369662019125484
  - 0.42808028472508053
  - 0.4243159752868492
  train_level3__recall_micro:
  - 0.43842364532019706
  - 0.41381701659572434
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.4271354319898009
  train_level3__recall_micro_masked:
  - 0.371135138064656
  - 0.3413305139882889
  - 0.3716423266985065
  - 0.36290366796425244
  - 0.35711904894172547
  train_level3__recall_micro_oob:
  - 0.4357453728059687
  - 0.4095604763498972
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__recall_samples:
  - 0.43842364532019706
  - 0.4138170165957243
  - 0.4398617903983259
  - 0.4311066992712394
  - 0.427135431989801
  train_level3__recall_samples_masked:
  - 0.37236753859836685
  - 0.3426062136247649
  - 0.3728159297830679
  - 0.3640541138011755
  - 0.3582265295854786
  train_level3__recall_samples_oob:
  - 0.4357453728059687
  - 0.4095604763498971
  - 0.43696620191254837
  - 0.42808028472508053
  - 0.42431597528684906
  train_level3__recall_weighted:
  - 0.5168795135637958
  - 0.4996461258947942
  - 0.5237009939013942
  - 0.5117610603796069
  - 0.5079085160721026
  train_level3__recall_weighted_masked:
  - 0.43608902664143073
  - 0.41327346012438165
  - 0.44434423798552836
  - 0.430213143442031
  - 0.424391372192132
  train_level3__recall_weighted_oob:
  - 0.5138377763664651
  - 0.49452135576227096
  - 0.5204474222983999
  - 0.5082572014015435
  - 0.5045644920434924
  train_level3__roc_auc_macro:
  - 0.6816315275302282
  - 0.6780758692095882
  - 0.6943821126893119
  - 0.671101083110404
  - 0.6921027137337294
  train_level3__roc_auc_macro_masked:
  - 0.6612329773561986
  - 0.6582984110531925
  - 0.6788160454492391
  - 0.6508387612795121
  - 0.6708449011920207
  train_level3__roc_auc_macro_oob:
  - 0.6753703744599595
  - 0.6704891847345882
  - 0.6876237066804562
  - 0.6630961176510017
  - 0.6842847963346104
  train_level3__roc_auc_micro:
  - 0.6534410117771727
  - 0.6378074820353462
  - 0.6589285614717502
  - 0.6393127914214363
  - 0.6761608682552552
  train_level3__roc_auc_micro_masked:
  - 0.6363329117210486
  - 0.6221598350121176
  - 0.6422785121787566
  - 0.6249351526105458
  - 0.6585299376423897
  train_level3__roc_auc_micro_oob:
  - 0.6513326400405355
  - 0.6346665060076075
  - 0.656352255177157
  - 0.6363747506268761
  - 0.6727753526269034
  train_level3__roc_auc_samples:
  - 0.6422325829702903
  - 0.6263673485400646
  - 0.6454679401072161
  - 0.626483233746128
  - 0.6664231100765401
  train_level3__roc_auc_samples_masked:
  - 0.6278508937586793
  - 0.6124810995067665
  - 0.6288625763165421
  - 0.6116627621614994
  - 0.6502506911881644
  train_level3__roc_auc_samples_oob:
  - 0.6403637517377473
  - 0.6238439522642707
  - 0.6435495339497138
  - 0.62376478471193
  - 0.6638430386077172
  train_level3__roc_auc_weighted:
  - 0.6793857993289569
  - 0.6807688853888489
  - 0.6938437152432269
  - 0.6739989892303887
  - 0.6937563925355564
  train_level3__roc_auc_weighted_masked:
  - 0.6585701709125165
  - 0.6604350980264285
  - 0.6750812912730371
  - 0.6548759743687746
  - 0.673146830712642
  train_level3__roc_auc_weighted_oob:
  - 0.6722527363319347
  - 0.6720057892904129
  - 0.6852852038093274
  - 0.6650567522373881
  - 0.6858849664911275
  train_level3__tn_macro:
  - 0.22155531111004834
  - 0.19321823138361469
  - 0.22072170718057277
  - 0.2154565043701426
  - 0.208835932136903
  train_level3__tn_macro_masked:
  - 0.24798499289362125
  - 0.2163990446115001
  - 0.2482379057417666
  - 0.24082928271830956
  - 0.23375672882701695
  train_level3__tn_macro_oob:
  - 0.21971399875651637
  - 0.1902290879525563
  - 0.2187994257488381
  - 0.21320485194780037
  - 0.20685005393743255
  train_level3__tn_micro:
  - 0.2215553111100483
  - 0.1932182313836147
  - 0.2207217071805728
  - 0.2154565043701426
  - 0.20883593213690302
  train_level3__tn_micro_masked:
  - 0.2510635991653795
  - 0.21904142268488397
  - 0.250421003229992
  - 0.24395526070508253
  - 0.23659796677962336
  train_level3__tn_micro_oob:
  - 0.21971399875651634
  - 0.1902290879525563
  - 0.21879942574883812
  - 0.2132048519478004
  - 0.20685005393743258
  train_level3__tn_samples:
  - 0.22155531111004825
  - 0.19321823138361469
  - 0.22072170718057277
  - 0.21545650437014255
  - 0.20883593213690296
  train_level3__tn_samples_masked:
  - 0.2518958741008063
  - 0.22000190309376244
  - 0.2513701288429232
  - 0.24477931952751583
  - 0.23730074033218612
  train_level3__tn_samples_oob:
  - 0.2197139987565163
  - 0.1902290879525563
  - 0.21879942574883807
  - 0.21320485194780037
  - 0.20685005393743255
  train_level3__tn_weighted:
  - 0.19324411508589845
  - 0.1688491833268787
  - 0.19817612905343057
  - 0.1861544387024929
  - 0.1815233392301851
  train_level3__tn_weighted_masked:
  - 0.22422324674615005
  - 0.19638012048611136
  - 0.23190451467589904
  - 0.21686169732776553
  - 0.21199097620722387
  train_level3__tn_weighted_oob:
  - 0.19121595452730059
  - 0.16535138015924086
  - 0.1959585012639858
  - 0.18398497447069567
  - 0.17914418226786977
  train_level3__tp_macro:
  - 0.21686833421014873
  - 0.22059878521210963
  - 0.2191400832177531
  - 0.21565019490109671
  - 0.2182994998528979
  train_level3__tp_macro_masked:
  - 0.13074348595989033
  - 0.1333183975854451
  - 0.13195239555519253
  - 0.12983222375631998
  - 0.13123735447593898
  train_level3__tp_macro_oob:
  - 0.2160313740494524
  - 0.21933138839734087
  - 0.21816677616371025
  - 0.21487543277728
  - 0.21746592134941647
  train_level3__tp_micro:
  - 0.21686833421014873
  - 0.22059878521210963
  - 0.21914008321775313
  - 0.21565019490109677
  - 0.2182994998528979
  train_level3__tp_micro_masked:
  - 0.12007153889927648
  - 0.1222890913034049
  - 0.12122132346851448
  - 0.11894840725916991
  - 0.12052108216210211
  train_level3__tp_micro_oob:
  - 0.21603137404945238
  - 0.21933138839734087
  - 0.21816677616371025
  - 0.2148754327772801
  - 0.2174659213494165
  train_level3__tp_samples:
  - 0.2168683342101487
  - 0.22059878521210957
  - 0.21914008321775305
  - 0.21565019490109671
  - 0.21829949985289787
  train_level3__tp_samples_masked:
  - 0.12047166449756051
  - 0.12260431053100238
  - 0.1214458009401447
  - 0.11927479427365968
  - 0.1209257892532925
  train_level3__tp_samples_oob:
  - 0.21603137404945233
  - 0.21933138839734082
  - 0.21816677616371022
  - 0.21487543277728005
  - 0.21746592134941645
  train_level3__tp_weighted:
  - 0.3236353984778974
  - 0.33079694256791536
  - 0.3255248648479638
  - 0.3256066216771139
  - 0.3263851768419177
  train_level3__tp_weighted_masked:
  - 0.21186577989528083
  - 0.21689333963827026
  - 0.2124397233096294
  - 0.21335144611426543
  - 0.21240039598490817
  train_level3__tp_weighted_oob:
  - 0.3226218218391643
  - 0.32916997560303013
  - 0.32448892103441407
  - 0.32427222693084784
  - 0.32542030977562264
  train_level4__average_precision_macro:
  - 0.3504856276628191
  - 0.3470634731166254
  - 0.37056262014752417
  - 0.33949005643867214
  - 0.36404368391184144
  train_level4__average_precision_macro_masked:
  - 0.22414414376981864
  - 0.22268541478828752
  - 0.2429964644672429
  - 0.21922372091440082
  - 0.23634801066355027
  train_level4__average_precision_macro_oob:
  - 0.3466828703550359
  - 0.3430280460908298
  - 0.36539708436867463
  - 0.33545688459268397
  - 0.3588654455543679
  train_level4__average_precision_micro:
  - 0.31126869817794406
  - 0.29846853881669155
  - 0.3204539105493911
  - 0.29924766650458723
  - 0.3397636287644199
  train_level4__average_precision_micro_masked:
  - 0.17586856611258972
  - 0.1678733821472066
  - 0.18281197413111025
  - 0.1692496277256583
  - 0.19561030178723582
  train_level4__average_precision_micro_oob:
  - 0.3112139147860784
  - 0.2980883707851786
  - 0.3197835036448924
  - 0.2980426019182234
  - 0.33802754477715846
  train_level4__average_precision_samples:
  - 0.32247938902973977
  - 0.3119072371264296
  - 0.32976284128335337
  - 0.3082975732052918
  - 0.35030493335808915
  train_level4__average_precision_samples_masked:
  - 0.19537730850172094
  - 0.1894729955131002
  - 0.20186281935414635
  - 0.18509334433675714
  - 0.21737395283122382
  train_level4__average_precision_samples_oob:
  - 0.322191532244092
  - 0.3116805421669286
  - 0.3290621556452246
  - 0.30721229683281454
  - 0.3485918362095673
  train_level4__average_precision_weighted:
  - 0.4751241243572324
  - 0.4783332182665309
  - 0.499586035899269
  - 0.4707720931177466
  - 0.4917357990348862
  train_level4__average_precision_weighted_masked:
  - 0.32518774677900253
  - 0.33057398096563745
  - 0.35070722210364275
  - 0.3275791688222786
  - 0.34178388907486923
  train_level4__average_precision_weighted_oob:
  - 0.4708607527721248
  - 0.47292385724583097
  - 0.4934389836970783
  - 0.46535390553132716
  - 0.48633842691610585
  train_level4__f1_macro:
  - 0.43892582141661474
  - 0.4159931130135348
  - 0.4403484439253473
  - 0.432317265089703
  - 0.42816514661174865
  train_level4__f1_macro_masked:
  - 0.3792119518733779
  - 0.3522642168691406
  - 0.38060809476689933
  - 0.3720301595667333
  - 0.3660314732774773
  train_level4__f1_macro_oob:
  - 0.43698885647328894
  - 0.4123344014539193
  - 0.4378665109375381
  - 0.42909716001258996
  - 0.425100519760714
  train_level4__f1_micro:
  - 0.43892582141661485
  - 0.41599311301353487
  - 0.44034844392534733
  - 0.4323172650897029
  - 0.42816514661174854
  train_level4__f1_micro_masked:
  - 0.3715687071511801
  - 0.3439329863370202
  - 0.37211164177456313
  - 0.3642743571467734
  - 0.3581745458585634
  train_level4__f1_micro_oob:
  - 0.436988856473289
  - 0.41233440145391936
  - 0.43786651093753803
  - 0.4290971600125899
  - 0.42510051976071395
  train_level4__f1_samples:
  - 0.43892582141661485
  - 0.41599311301353475
  - 0.44034844392534733
  - 0.432317265089703
  - 0.42816514661174854
  train_level4__f1_samples_masked:
  - 0.3727788989726921
  - 0.3452080578692358
  - 0.37326757577167663
  - 0.3654243027442353
  - 0.359283033451097
  train_level4__f1_samples_oob:
  - 0.43698885647328906
  - 0.4123344014539193
  - 0.43786651093753803
  - 0.42909716001258985
  - 0.4251005197607139
  train_level4__f1_weighted:
  - 0.5177936211907775
  - 0.5013959065129413
  - 0.5239490622628331
  - 0.5127649122058758
  - 0.5087312647686439
  train_level4__f1_weighted_masked:
  - 0.4369542905913261
  - 0.4153996806918763
  - 0.4443820245441435
  - 0.43156951986633224
  - 0.425293171178182
  train_level4__f1_weighted_oob:
  - 0.5155556943365115
  - 0.4966403307981984
  - 0.5209655234074464
  - 0.5089765418552898
  - 0.5051623967520649
  train_level4__fn_macro:
  - -0.01697833468841169
  - -0.014228322731837963
  - -0.016838212034941725
  - -0.01629421591651938
  - -0.015274100225556532
  train_level4__fn_macro_masked:
  - -0.012469968006209014
  - -0.0105947548309637
  - -0.012729850393446355
  - -0.012013928376466037
  - -0.011842494413008308
  train_level4__fn_macro_oob:
  - -0.01783920799655651
  - -0.015471806399158258
  - -0.01771418838358031
  - -0.0173595138367673
  - -0.01593605962538001
  train_level4__fn_micro:
  - -0.01697833468841169
  - -0.014228322731837965
  - -0.016838212034941725
  - -0.016294215916519382
  - -0.015274100225556536
  train_level4__fn_micro_masked:
  - -0.011868953743598082
  - -0.010138798525265669
  - -0.012036551362394059
  - -0.011404133998574484
  - -0.011277151269373923
  train_level4__fn_micro_oob:
  - -0.017839207996556507
  - -0.015471806399158258
  - -0.01771418838358031
  - -0.017359513836767305
  - -0.015936059625380014
  train_level4__fn_samples:
  - -0.016978334688411686
  - -0.014228322731837963
  - -0.01683821203494172
  - -0.01629421591651938
  - -0.015274100225556536
  train_level4__fn_samples_masked:
  - -0.011766851465225646
  - -0.010101805890325615
  - -0.012009815266810227
  - -0.011363361709127343
  - -0.0112175489444844
  train_level4__fn_samples_oob:
  - -0.017839207996556503
  - -0.015471806399158256
  - -0.01771418838358031
  - -0.017359513836767305
  - -0.015936059625380014
  train_level4__fn_weighted:
  - -0.021841884058919903
  - -0.017944355620118535
  - -0.02235095936562718
  - -0.02130064347942325
  - -0.019550025666153343
  train_level4__fn_weighted_masked:
  - -0.017020389722116062
  - -0.01404808914773847
  - -0.01791670619166315
  - -0.016665063129742183
  - -0.01611063806145434
  train_level4__fn_weighted_oob:
  - -0.022923452174040047
  - -0.01967329056705751
  - -0.023333155034198548
  - -0.02292683142493126
  - -0.02019167949974334
  train_level4__fp_macro:
  - -0.5440958438949735
  - -0.5697785642546271
  - -0.5428133440397108
  - -0.5513885189937776
  - -0.5565607531626949
  train_level4__fp_macro_masked:
  - -0.608318080120413
  - -0.6371410282998956
  - -0.6066620548396544
  - -0.6159559120568007
  - -0.6221260323095145
  train_level4__fp_macro_oob:
  - -0.5451719355301545
  - -0.5721937921469223
  - -0.5444193006788816
  - -0.5535433261506427
  - -0.558963420613906
  train_level4__fp_micro:
  - -0.5440958438949735
  - -0.5697785642546271
  - -0.5428133440397109
  - -0.5513885189937777
  - -0.5565607531626949
  train_level4__fp_micro_masked:
  - -0.6165623391052218
  - -0.6459282151377141
  - -0.6158518068630429
  - -0.6243215088546521
  - -0.6305483028720626
  train_level4__fp_micro_oob:
  - -0.5451719355301545
  - -0.5721937921469223
  - -0.5444193006788817
  - -0.5535433261506428
  - -0.558963420613906
  train_level4__fp_samples:
  - -0.5440958438949735
  - -0.5697785642546271
  - -0.5428133440397109
  - -0.5513885189937776
  - -0.5565607531626949
  train_level4__fp_samples_masked:
  - -0.6154542495620821
  - -0.6446901362404387
  - -0.6147226089615132
  - -0.6232123355466372
  - -0.6294994176044185
  train_level4__fp_samples_oob:
  - -0.5451719355301544
  - -0.5721937921469223
  - -0.5444193006788817
  - -0.5535433261506428
  - -0.558963420613906
  train_level4__fp_weighted:
  - -0.46036449475030256
  - -0.4806597378669403
  - -0.45369997837153986
  - -0.4659344443147008
  - -0.47171870956520257
  train_level4__fp_weighted_masked:
  - -0.5460253196865578
  - -0.5705522301603854
  - -0.5377012692641934
  - -0.5517654170039255
  - -0.5585961907603639
  train_level4__fp_weighted_oob:
  - -0.4615208534894484
  - -0.48368637863474423
  - -0.45570132155835524
  - -0.46809662671977903
  - -0.47464592374819176
  train_level4__jaccard_macro:
  - 0.29680915630408156
  - 0.27698359479368834
  - 0.29990352355056776
  - 0.2922288522595948
  - 0.2874885235063493
  train_level4__jaccard_macro_masked:
  - 0.24691671184332747
  - 0.22474138030697954
  - 0.24973133282977927
  - 0.2425133445696205
  - 0.23620244057120982
  train_level4__jaccard_macro_oob:
  - 0.2952077584091025
  - 0.27388347714475864
  - 0.2978037628305095
  - 0.2895048149990543
  - 0.2849186778378079
  train_level4__jaccard_micro:
  - 0.2811690997380555
  - 0.2626207729468599
  - 0.28233770691296006
  - 0.27576833976833975
  - 0.27239830296980283
  train_level4__jaccard_micro_masked:
  - 0.22817585782274435
  - 0.20768059716151843
  - 0.22858548001424525
  - 0.22269893410203123
  - 0.21815628753658495
  train_level4__jaccard_micro_oob:
  - 0.2795814081576451
  - 0.25971111412347686
  - 0.28030031620430224
  - 0.2731532142471834
  - 0.2699223189127761
  train_level4__jaccard_samples:
  - 0.28806189377603825
  - 0.2691007075886205
  - 0.2887810987684054
  - 0.28346553663925883
  - 0.27976366671445513
  train_level4__jaccard_samples_masked:
  - 0.2358221845237716
  - 0.21480698221396918
  - 0.23562921191004652
  - 0.23138323679008127
  - 0.22623431543602063
  train_level4__jaccard_samples_oob:
  - 0.2863485284533041
  - 0.26604033459742654
  - 0.2867250296089602
  - 0.280787040312794
  - 0.2770063174693455
  train_level4__jaccard_weighted:
  - 0.36457654460653316
  - 0.3494674999276334
  - 0.3717297431977104
  - 0.3615500461810572
  - 0.35720125172863254
  train_level4__jaccard_weighted_masked:
  - 0.2917117562576365
  - 0.27297512259333456
  - 0.29894657119670526
  - 0.2886753126741014
  - 0.2821889015884423
  train_level4__jaccard_weighted_oob:
  - 0.36251045443187385
  - 0.34508661191776785
  - 0.3689777166339696
  - 0.3581072113935442
  - 0.35391106854117516
  train_level4__label_ranking_average_precision_score:
  - 0.3224793890297399
  - 0.3119072371264294
  - 0.3297628412833536
  - 0.3082975732052919
  - 0.3503049333580888
  train_level4__label_ranking_average_precision_score_oob:
  - 0.32219153224409236
  - 0.3116805421669288
  - 0.32906215564522484
  - 0.3072122968328145
  - 0.34859183620956724
  train_level4__matthews_corrcoef_macro:
  - 0.1875570900739564
  - 0.17307341438303905
  - 0.1958524827822036
  - 0.17996006272116977
  - 0.18097763490141633
  train_level4__matthews_corrcoef_macro_masked:
  - 0.1347792237235889
  - 0.12283691959262102
  - 0.1412973765359236
  - 0.1287165574334742
  - 0.1262117594443416
  train_level4__matthews_corrcoef_macro_oob:
  - 0.1830155821050544
  - 0.16329253710782216
  - 0.18818480459612683
  - 0.17290237193311947
  - 0.17488988942599992
  train_level4__matthews_corrcoef_micro:
  - 0.2155910594490888
  - 0.20286011855814715
  - 0.21752150340176882
  - 0.21152545291765656
  - 0.21114219547623395
  train_level4__matthews_corrcoef_micro_masked:
  - 0.15344340974488993
  - 0.14361852644672438
  - 0.15370398863582174
  - 0.15013697863507036
  - 0.1471050254886159
  train_level4__matthews_corrcoef_micro_oob:
  - 0.21060858990598177
  - 0.1944610177516547
  - 0.21194870003628732
  - 0.20447133023939282
  - 0.2056627509870887
  train_level4__matthews_corrcoef_samples:
  - 0.2141778913087618
  - 0.20052011820622964
  - 0.21606719678178088
  - 0.20874074231939543
  - 0.2083280601372444
  train_level4__matthews_corrcoef_samples_masked:
  - 0.15414244213938713
  - 0.1422536435497254
  - 0.15145677245680958
  - 0.14777463270712737
  - 0.14508915306769826
  train_level4__matthews_corrcoef_samples_oob:
  - 0.2091798721286416
  - 0.19283005509063442
  - 0.21063375779085877
  - 0.20192605349852163
  - 0.20213270189807706
  train_level4__matthews_corrcoef_weighted:
  - 0.2059123325277766
  - 0.18991171782772281
  - 0.21983739664931545
  - 0.19923451676092604
  - 0.205084554854307
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.1531288587483249
  - 0.13927891710690163
  - 0.16306067539077373
  - 0.148624191786735
  - 0.14957983566295016
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.20113366498339863
  - 0.1765647352187513
  - 0.20838457617947195
  - 0.18928365138566244
  - 0.19628604056077464
  train_level4__ndcg:
  - 0.6664450219669908
  - 0.658278726285199
  - 0.6732853144084648
  - 0.6621167435900162
  - 0.6908602745607688
  train_level4__ndcg_oob:
  - 0.6678576049310764
  - 0.6593785969245578
  - 0.6739311392019978
  - 0.6621038341213852
  - 0.6902771157781861
  train_level4__neg_coverage_error:
  - -83.33251231527093
  - -84.27586206896552
  - -83.34085213032581
  - -83.80798004987531
  - -83.48737373737374
  train_level4__neg_coverage_error_oob:
  - -84.1847290640394
  - -85.1576354679803
  - -84.07518796992481
  - -84.69825436408978
  - -84.22727272727273
  train_level4__neg_hamming_loss_macro:
  - -0.5610741785833852
  - -0.5840068869864653
  - -0.5596515560746527
  - -0.567682734910297
  - -0.5718348533882512
  train_level4__neg_hamming_loss_macro_masked:
  - -0.620788048126622
  - -0.6477357831308593
  - -0.6193919052331007
  - -0.6279698404332668
  - -0.6339685267225226
  train_level4__neg_hamming_loss_macro_oob:
  - -0.563011143526711
  - -0.5876655985460807
  - -0.562133489062462
  - -0.5709028399874101
  - -0.5748994802392859
  train_level4__neg_hamming_loss_micro:
  - -0.5610741785833852
  - -0.5840068869864652
  - -0.5596515560746527
  - -0.5676827349102971
  - -0.5718348533882515
  train_level4__neg_hamming_loss_micro_masked:
  - -0.6284312928488199
  - -0.6560670136629798
  - -0.6278883582254369
  - -0.6357256428532266
  - -0.6418254541414365
  train_level4__neg_hamming_loss_micro_oob:
  - -0.563011143526711
  - -0.5876655985460806
  - -0.562133489062462
  - -0.5709028399874101
  - -0.574899480239286
  train_level4__neg_hamming_loss_samples:
  - -0.5610741785833852
  - -0.5840068869864651
  - -0.5596515560746527
  - -0.5676827349102971
  - -0.5718348533882515
  train_level4__neg_hamming_loss_samples_masked:
  - -0.6272211010273078
  - -0.6547919421307642
  - -0.6267324242283235
  - -0.6345756972557647
  - -0.640716966548903
  train_level4__neg_hamming_loss_samples_oob:
  - -0.563011143526711
  - -0.5876655985460806
  - -0.562133489062462
  - -0.5709028399874102
  - -0.574899480239286
  train_level4__neg_hamming_loss_weighted:
  - -0.4822063788092225
  - -0.49860409348705875
  - -0.4760509377371669
  - -0.4872350877941241
  - -0.491268735231356
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.5630457094086739
  - -0.5846003193081238
  - -0.5556179754558566
  - -0.5684304801336678
  - -0.5747068288218181
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.48444430566348845
  - -0.5033596692018015
  - -0.4790344765925536
  - -0.4910234581447102
  - -0.49483760324793513
  train_level4__neg_label_ranking_loss:
  - -0.3954177523898502
  - -0.40953499759570317
  - -0.3871277381043925
  - -0.4263637899799625
  - -0.3665410689057739
  train_level4__neg_label_ranking_loss_oob:
  - -0.40035187283184964
  - -0.4137634890837138
  - -0.3924060217440273
  - -0.4317111540053376
  - -0.37201486576118536
  train_level4__precision_macro:
  - 0.43892582141661474
  - 0.4159931130135348
  - 0.4403484439253473
  - 0.432317265089703
  - 0.42816514661174865
  train_level4__precision_macro_masked:
  - 0.3792119518733779
  - 0.3522642168691406
  - 0.38060809476689933
  - 0.3720301595667333
  - 0.3660314732774773
  train_level4__precision_macro_oob:
  - 0.43698885647328894
  - 0.4123344014539193
  - 0.4378665109375381
  - 0.42909716001258996
  - 0.425100519760714
  train_level4__precision_micro:
  - 0.43892582141661485
  - 0.41599311301353487
  - 0.44034844392534733
  - 0.4323172650897029
  - 0.42816514661174854
  train_level4__precision_micro_masked:
  - 0.3715687071511801
  - 0.3439329863370202
  - 0.37211164177456313
  - 0.3642743571467734
  - 0.3581745458585634
  train_level4__precision_micro_oob:
  - 0.436988856473289
  - 0.41233440145391936
  - 0.43786651093753803
  - 0.4290971600125899
  - 0.42510051976071395
  train_level4__precision_samples:
  - 0.43892582141661485
  - 0.41599311301353475
  - 0.44034844392534733
  - 0.432317265089703
  - 0.42816514661174854
  train_level4__precision_samples_masked:
  - 0.3727788989726921
  - 0.3452080578692358
  - 0.37326757577167663
  - 0.3654243027442353
  - 0.359283033451097
  train_level4__precision_samples_oob:
  - 0.43698885647328906
  - 0.4123344014539193
  - 0.43786651093753803
  - 0.42909716001258985
  - 0.4251005197607139
  train_level4__precision_weighted:
  - 0.5177936211907775
  - 0.5013959065129413
  - 0.5239490622628331
  - 0.5127649122058758
  - 0.5087312647686439
  train_level4__precision_weighted_masked:
  - 0.4369542905913261
  - 0.4153996806918763
  - 0.4443820245441435
  - 0.43156951986633224
  - 0.425293171178182
  train_level4__precision_weighted_oob:
  - 0.5155556943365115
  - 0.4966403307981984
  - 0.5209655234074464
  - 0.5089765418552898
  - 0.5051623967520649
  train_level4__recall_macro:
  - 0.43892582141661474
  - 0.4159931130135348
  - 0.4403484439253473
  - 0.432317265089703
  - 0.42816514661174865
  train_level4__recall_macro_masked:
  - 0.3792119518733779
  - 0.3522642168691406
  - 0.38060809476689933
  - 0.3720301595667333
  - 0.3660314732774773
  train_level4__recall_macro_oob:
  - 0.43698885647328894
  - 0.4123344014539193
  - 0.4378665109375381
  - 0.42909716001258996
  - 0.425100519760714
  train_level4__recall_micro:
  - 0.43892582141661485
  - 0.41599311301353487
  - 0.44034844392534733
  - 0.4323172650897029
  - 0.42816514661174854
  train_level4__recall_micro_masked:
  - 0.3715687071511801
  - 0.3439329863370202
  - 0.37211164177456313
  - 0.3642743571467734
  - 0.3581745458585634
  train_level4__recall_micro_oob:
  - 0.436988856473289
  - 0.41233440145391936
  - 0.43786651093753803
  - 0.4290971600125899
  - 0.42510051976071395
  train_level4__recall_samples:
  - 0.43892582141661485
  - 0.41599311301353475
  - 0.44034844392534733
  - 0.432317265089703
  - 0.42816514661174854
  train_level4__recall_samples_masked:
  - 0.3727788989726921
  - 0.3452080578692358
  - 0.37326757577167663
  - 0.3654243027442353
  - 0.359283033451097
  train_level4__recall_samples_oob:
  - 0.43698885647328906
  - 0.4123344014539193
  - 0.43786651093753803
  - 0.42909716001258985
  - 0.4251005197607139
  train_level4__recall_weighted:
  - 0.5177936211907775
  - 0.5013959065129413
  - 0.5239490622628331
  - 0.5127649122058758
  - 0.5087312647686439
  train_level4__recall_weighted_masked:
  - 0.4369542905913261
  - 0.4153996806918763
  - 0.4443820245441435
  - 0.43156951986633224
  - 0.425293171178182
  train_level4__recall_weighted_oob:
  - 0.5155556943365115
  - 0.4966403307981984
  - 0.5209655234074464
  - 0.5089765418552898
  - 0.5051623967520649
  train_level4__roc_auc_macro:
  - 0.6809801402033088
  - 0.676469498162403
  - 0.6952697880652234
  - 0.6705066401946987
  - 0.6910255734765015
  train_level4__roc_auc_macro_masked:
  - 0.659994052850976
  - 0.655905041080566
  - 0.6799183815053006
  - 0.6495605650104728
  - 0.6698491094749504
  train_level4__roc_auc_macro_oob:
  - 0.674340926235758
  - 0.6697322648336961
  - 0.6881166900153773
  - 0.662410184235145
  - 0.6841798752765558
  train_level4__roc_auc_micro:
  - 0.6529815632067917
  - 0.6368261258158247
  - 0.6598542296774547
  - 0.6389365914424988
  - 0.6777799077302743
  train_level4__roc_auc_micro_masked:
  - 0.635323860854937
  - 0.620988301854178
  - 0.6437229591535318
  - 0.6243887930844136
  - 0.6599234104539486
  train_level4__roc_auc_micro_oob:
  - 0.6510448057392437
  - 0.6344033708943804
  - 0.6573243310833619
  - 0.6361979879840798
  - 0.6745198058871473
  train_level4__roc_auc_samples:
  - 0.6419281382543323
  - 0.6251736855162624
  - 0.6462005690676983
  - 0.6253632500556628
  - 0.667372852067
  train_level4__roc_auc_samples_masked:
  - 0.6265970792932553
  - 0.6113752413842958
  - 0.6306817721643507
  - 0.6105361632011119
  - 0.6513345093171846
  train_level4__roc_auc_samples_oob:
  - 0.6404103622319077
  - 0.6231187094007012
  - 0.6440448578446243
  - 0.6229388933231679
  - 0.6644840063537212
  train_level4__roc_auc_weighted:
  - 0.6782004256375513
  - 0.6787322115737433
  - 0.6945530987047043
  - 0.6747782341312697
  - 0.692448268376603
  train_level4__roc_auc_weighted_masked:
  - 0.657162585714297
  - 0.6579761370790985
  - 0.6763123919727253
  - 0.6553387382161379
  - 0.67167922042892
  train_level4__roc_auc_weighted_oob:
  - 0.6707390408067825
  - 0.6703955163546825
  - 0.6858746198409935
  - 0.6657053234359424
  - 0.6851744385648543
  train_level4__tn_macro:
  - 0.22200966091156918
  - 0.19570519871825529
  - 0.22118402803124312
  - 0.2164491683412827
  - 0.20993919780327547
  train_level4__tn_macro_masked:
  - 0.24857395369514568
  - 0.2191900786164183
  - 0.24870700530612103
  - 0.24195980293321168
  - 0.23500450095189354
  train_level4__tn_macro_oob:
  - 0.2209335692763882
  - 0.19328997082596014
  - 0.21957807139207244
  - 0.2142943611844176
  - 0.20753653035206435
  train_level4__tn_micro:
  - 0.22200966091156918
  - 0.19570519871825529
  - 0.22118402803124315
  - 0.21644916834128272
  - 0.20993919780327547
  train_level4__tn_micro_masked:
  - 0.25157846245562693
  - 0.22186076772934288
  - 0.25094553184440826
  - 0.24507922583474973
  - 0.23784789733903672
  train_level4__tn_micro_oob:
  - 0.22093356927638816
  - 0.1932899708259601
  - 0.21957807139207242
  - 0.2142943611844176
  - 0.20753653035206432
  train_level4__tn_samples:
  - 0.22200966091156912
  - 0.19570519871825526
  - 0.2211840280312431
  - 0.21644916834128267
  - 0.20993919780327544
  train_level4__tn_samples_masked:
  - 0.2523877031602221
  - 0.2228202181095772
  - 0.2518744046541342
  - 0.24589661974992727
  - 0.23855088895204793
  train_level4__tn_samples_oob:
  - 0.2209335692763881
  - 0.19328997082596008
  - 0.2195780713920724
  - 0.21429436118441755
  - 0.20753653035206432
  train_level4__tn_weighted:
  - 0.19416602914165046
  - 0.17105455487962
  - 0.19826088574358877
  - 0.1871257823737663
  - 0.1825412355389256
  train_level4__tn_weighted_masked:
  - 0.2253780529728999
  - 0.1989560864163412
  - 0.23196209649672936
  - 0.2180459436603199
  - 0.21322262196220904
  train_level4__tn_weighted_oob:
  - 0.1930096704025045
  - 0.1680279141118162
  - 0.19625954255677344
  - 0.1849635999686881
  - 0.17961402135593652
  train_level4__tp_macro:
  - 0.21691616050504567
  - 0.22028791429527955
  - 0.21916441589410415
  - 0.21586809674842014
  - 0.21822594880847304
  train_level4__tp_macro_masked:
  - 0.1306379981782322
  - 0.13307413825272232
  - 0.13190108946077828
  - 0.1300703566335216
  - 0.1310269723255838
  train_level4__tp_macro_oob:
  - 0.2160552871969009
  - 0.21904443062795925
  - 0.21828843954546556
  - 0.2148027988281722
  - 0.2175639894086496
  train_level4__tp_micro:
  - 0.21691616050504567
  - 0.22028791429527955
  - 0.21916441589410418
  - 0.21586809674842022
  - 0.21822594880847307
  train_level4__tp_micro_masked:
  - 0.11999024469555321
  - 0.1220722186076773
  - 0.12116610993015488
  - 0.11919513131202368
  - 0.1203266485195267
  train_level4__tp_micro_oob:
  - 0.21605528719690087
  - 0.21904443062795925
  - 0.21828843954546562
  - 0.2148027988281723
  - 0.2175639894086496
  train_level4__tp_samples:
  - 0.21691616050504564
  - 0.2202879142952795
  - 0.21916441589410415
  - 0.21586809674842014
  - 0.218225948808473
  train_level4__tp_samples_masked:
  - 0.12039119581247011
  - 0.12238783975965853
  - 0.12139317111754237
  - 0.11952768299430809
  - 0.12073214449904908
  train_level4__tp_samples_oob:
  - 0.21605528719690079
  - 0.21904443062795922
  - 0.2182884395454656
  - 0.21480279882817224
  - 0.21756398940864954
  train_level4__tp_weighted:
  - 0.3236275920491271
  - 0.3303413516333211
  - 0.32568817651924425
  - 0.3256391298321097
  - 0.3261900292297184
  train_level4__tp_weighted_masked:
  - 0.21157623761842623
  - 0.21644359427553508
  - 0.2124199280474142
  - 0.21352357620601226
  - 0.2120705492159729
  train_level4__tp_weighted_oob:
  - 0.322546023934007
  - 0.3286124166863821
  - 0.3247059808506729
  - 0.3240129418866016
  - 0.32554837539612846
  train_level5__average_precision_macro:
  - 0.34934440468354844
  - 0.3435513348288202
  - 0.36715497420199944
  - 0.3386656956343537
  - 0.3620854875684356
  train_level5__average_precision_macro_masked:
  - 0.22372287487148526
  - 0.22084314820497555
  - 0.24037979304650559
  - 0.21854892412199717
  - 0.2356978305918896
  train_level5__average_precision_macro_oob:
  - 0.34567817920360655
  - 0.339123359949357
  - 0.36157577941325375
  - 0.3331342578305273
  - 0.35883341165552846
  train_level5__average_precision_micro:
  - 0.3107437638447291
  - 0.29744846098793865
  - 0.31841130780821947
  - 0.29766050632412716
  - 0.3402008717558084
  train_level5__average_precision_micro_masked:
  - 0.17607822950291432
  - 0.16751104985897636
  - 0.1814174065261131
  - 0.1684185272026907
  - 0.1957532729080041
  train_level5__average_precision_micro_oob:
  - 0.3107318304854385
  - 0.29660658188042555
  - 0.31781795283404124
  - 0.2964064774393308
  - 0.33978713506343894
  train_level5__average_precision_samples:
  - 0.32097761864600277
  - 0.3108103229079031
  - 0.32746397139019345
  - 0.30735310377794006
  - 0.3502518198401159
  train_level5__average_precision_samples_masked:
  - 0.19469332906126624
  - 0.18889547393520073
  - 0.2001308502163738
  - 0.18419947158231692
  - 0.21656354883842405
  train_level5__average_precision_samples_oob:
  - 0.32070507229292405
  - 0.3099445949208375
  - 0.32732470556973825
  - 0.306443911000745
  - 0.3498351848447133
  train_level5__average_precision_weighted:
  - 0.47567101444247334
  - 0.47620022373871645
  - 0.4956258476529738
  - 0.468284235642942
  - 0.4919212982647764
  train_level5__average_precision_weighted_masked:
  - 0.32624894046552405
  - 0.32927182878413913
  - 0.34648788612817366
  - 0.32511884740190067
  - 0.34222948133883674
  train_level5__average_precision_weighted_oob:
  - 0.4718254866721225
  - 0.47073740240816936
  - 0.48858924851875213
  - 0.4628129941479348
  - 0.48826132429389196
  train_level5__f1_macro:
  - 0.4397388684298627
  - 0.4172844229757521
  - 0.44039710927804954
  - 0.4321719971914873
  - 0.42948906541139564
  train_level5__f1_macro_masked:
  - 0.38018536357030147
  - 0.3536499457746988
  - 0.38083784890800415
  - 0.37192429712699415
  - 0.36768043554016894
  train_level5__f1_macro_oob:
  - 0.4378975560763308
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108056
  - 0.426424438560361
  train_level5__f1_micro:
  - 0.43973886842986276
  - 0.4172844229757521
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.42948906541139553
  train_level5__f1_micro_masked:
  - 0.3725171395279517
  - 0.34536976794621554
  - 0.37233249592800155
  - 0.3641921157958221
  - 0.3598133437031276
  train_level5__f1_micro_oob:
  - 0.43789755607633074
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108055
  - 0.4264244385603609
  train_level5__f1_samples:
  - 0.4397388684298627
  - 0.417284422975752
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.4294890654113955
  train_level5__f1_samples_masked:
  - 0.37369615032638215
  - 0.3466546447297433
  - 0.3735067738238662
  - 0.3653314108821121
  - 0.36092951247698724
  train_level5__f1_samples_oob:
  - 0.4378975560763308
  - 0.4139365823329666
  - 0.4382558337591551
  - 0.42924242791080547
  - 0.42642443856036094
  train_level5__f1_weighted:
  - 0.5186545947380642
  - 0.5022520859484605
  - 0.5238356226683833
  - 0.5125084878792695
  - 0.5100644199237226
  train_level5__f1_weighted_masked:
  - 0.43811300578683804
  - 0.4163941733915714
  - 0.4446753952592226
  - 0.43127821418479123
  - 0.4270170114340945
  train_level5__f1_weighted_oob:
  - 0.5163363372135481
  - 0.4982115418714189
  - 0.5217593421640501
  - 0.5087661490761575
  - 0.5067007750754076
  train_level5__fn_macro:
  - -0.017121813573102496
  - -0.014323975321631835
  - -0.016838212034941725
  - -0.016439483814735006
  - -0.015323134255173088
  train_level5__fn_macro_masked:
  - -0.01262888824951982
  - -0.010727408134742442
  - -0.012567609520302713
  - -0.01210940811060598
  - -0.011741446396970525
  train_level5__fn_macro_oob:
  - -0.01783920799655651
  - -0.01501745659763738
  - -0.01771418838358031
  - -0.017286879887659493
  - -0.01620574678827106
  train_level5__fn_micro:
  - -0.017121813573102492
  - -0.014323975321631833
  - -0.016838212034941725
  - -0.016439483814735006
  - -0.01532313425517309
  train_level5__fn_micro_masked:
  - -0.012004444083136872
  - -0.010274343960095423
  - -0.011870910747315241
  - -0.011486375349525742
  - -0.011193822565413033
  train_level5__fn_micro_oob:
  - -0.017839207996556507
  - -0.01501745659763738
  - -0.01771418838358031
  - -0.017286879887659493
  - -0.01620574678827106
  train_level5__fn_samples:
  - -0.017121813573102492
  - -0.014323975321631831
  - -0.01683821203494172
  - -0.016439483814735006
  - -0.01532313425517309
  train_level5__fn_samples_masked:
  - -0.011907824579476313
  - -0.010228334457334485
  - -0.011837963860787637
  - -0.01144455808499725
  - -0.011126950538090798
  train_level5__fn_samples_oob:
  - -0.017839207996556507
  - -0.015017456597637379
  - -0.01771418838358031
  - -0.017286879887659493
  - -0.01620574678827106
  train_level5__fn_weighted:
  - -0.022212563515370858
  - -0.01807872229597739
  - -0.022520214341400464
  - -0.021508955736636092
  - -0.01947737560400307
  train_level5__fn_weighted_masked:
  - -0.017357846303970997
  - -0.014160964163084969
  - -0.01778219331698008
  - -0.016863781279727517
  - -0.01587860707064056
  train_level5__fn_weighted_oob:
  - -0.023027957591449794
  - -0.019047166972821765
  - -0.0232396125895727
  - -0.022797318935428138
  - -0.02055254349458465
  train_level5__fp_macro:
  - -0.5431393179970347
  - -0.5683916017026162
  - -0.5427646786870086
  - -0.5513885189937776
  - -0.5551878003334314
  train_level5__fp_macro_masked:
  - -0.6071857481801788
  - -0.6356226460905585
  - -0.6065945415716931
  - -0.6159662947624
  - -0.6205781180628605
  train_level5__fp_macro_oob:
  - -0.5442632359271128
  - -0.5710459610693961
  - -0.5440299778572645
  - -0.553470692201535
  - -0.557369814651368
  train_level5__fp_micro:
  - -0.5431393179970347
  - -0.568391601702616
  - -0.5427646786870088
  - -0.5513885189937777
  - -0.5551878003334314
  train_level5__fp_micro_masked:
  - -0.6154784163889114
  - -0.644355888093689
  - -0.6157965933246832
  - -0.6243215088546521
  - -0.6289928337314593
  train_level5__fp_micro_oob:
  - -0.5442632359271127
  - -0.571045961069396
  - -0.5440299778572645
  - -0.553470692201535
  - -0.557369814651368
  train_level5__fp_samples:
  - -0.5431393179970347
  - -0.5683916017026162
  - -0.5427646786870087
  - -0.5513885189937777
  - -0.5551878003334314
  train_level5__fp_samples_masked:
  - -0.6143960250941415
  - -0.6431170208129222
  - -0.6146552623153462
  - -0.6232240310328907
  - -0.627943536984922
  train_level5__fp_samples_oob:
  - -0.5442632359271127
  - -0.571045961069396
  - -0.5440299778572646
  - -0.553470692201535
  - -0.557369814651368
  train_level5__fp_weighted:
  - -0.459132841746565
  - -0.4796691917555622
  - -0.4536441629902161
  - -0.46598255638409464
  - -0.4704582044722743
  train_level5__fp_weighted_masked:
  - -0.5445291479091909
  - -0.5694448624453439
  - -0.5375424114237973
  - -0.5518580045354812
  - -0.5571043814952649
  train_level5__fp_weighted_oob:
  - -0.4606357051950021
  - -0.4827412911557594
  - -0.4550010452463772
  - -0.4684365319884148
  - -0.47274668143000775
  train_level5__jaccard_macro:
  - 0.2975226400049791
  - 0.27792960903429176
  - 0.2999897186996153
  - 0.2921062070171532
  - 0.2884837497989702
  train_level5__jaccard_macro_masked:
  - 0.2477063459536109
  - 0.2257081621107783
  - 0.2499683673175663
  - 0.24245497983529676
  - 0.2373736148095641
  train_level5__jaccard_macro_oob:
  - 0.2959845603102028
  - 0.2751471998378136
  - 0.29818621125596284
  - 0.2895955139645307
  - 0.2859726842887712
  train_level5__jaccard_micro:
  - 0.2818367127990559
  - 0.26365092315595445
  - 0.2823777205710274
  - 0.27565013280622647
  - 0.2734709169814855
  train_level5__jaccard_micro_masked:
  - 0.2288915899365624
  - 0.20872927452650894
  - 0.2287521837208908
  - 0.22263746208375929
  - 0.21937341236240473
  train_level5__jaccard_micro_oob:
  - 0.2803257608229747
  - 0.2609836263305491
  - 0.2806194786781547
  - 0.2732709588914407
  - 0.2709907607933565
  train_level5__jaccard_samples:
  - 0.28867839095891845
  - 0.2701423382918807
  - 0.2888295626534095
  - 0.2832824047780297
  - 0.2809891165474496
  train_level5__jaccard_samples_masked:
  - 0.23647109742225486
  - 0.21587352199534315
  - 0.23584458228604938
  - 0.23124733458900912
  - 0.22762446282390691
  train_level5__jaccard_samples_oob:
  - 0.2870307565791403
  - 0.2673446245530244
  - 0.2870984483507978
  - 0.2809573032647781
  - 0.2782719953382215
  train_level5__jaccard_weighted:
  - 0.36533988584033444
  - 0.3501291490054262
  - 0.371700108091342
  - 0.3612744386699605
  - 0.35833410317548303
  train_level5__jaccard_weighted_masked:
  - 0.292673423312263
  - 0.27372630078659294
  - 0.29927568888407824
  - 0.2884415357450545
  - 0.2835398020743101
  train_level5__jaccard_weighted_oob:
  - 0.3632075844705392
  - 0.3464716567938817
  - 0.36981343033798303
  - 0.3578738029511447
  - 0.3552493231077569
  train_level5__label_ranking_average_precision_score:
  - 0.32097761864600277
  - 0.31081032290790306
  - 0.3274639713901931
  - 0.3073531037779402
  - 0.3502518198401156
  train_level5__label_ranking_average_precision_score_oob:
  - 0.3207050722929241
  - 0.3099445949208375
  - 0.3273247055697383
  - 0.3064439110007448
  - 0.3498351848447131
  train_level5__matthews_corrcoef_macro:
  - 0.18835927991755086
  - 0.17348288465365
  - 0.1959902312888602
  - 0.17922649149654357
  - 0.18180978353121718
  train_level5__matthews_corrcoef_macro_masked:
  - 0.13529164184315806
  - 0.12240189144473634
  - 0.14258880498373033
  - 0.1284779558679843
  - 0.12768149519618782
  train_level5__matthews_corrcoef_macro_oob:
  - 0.18398650900939487
  - 0.16564422074879578
  - 0.19031098749903436
  - 0.1735965468568184
  - 0.17452456395584118
  train_level5__matthews_corrcoef_micro:
  - 0.21588165895781591
  - 0.20379440110934843
  - 0.21756972280601286
  - 0.2108544564343798
  - 0.21227001036412924
  train_level5__matthews_corrcoef_micro_masked:
  - 0.15338590710459554
  - 0.14388181151475485
  - 0.15473382277350672
  - 0.14963535853567067
  - 0.14870753818851876
  train_level5__matthews_corrcoef_micro_oob:
  - 0.21151072401706478
  - 0.1978025344897655
  - 0.21233745598552112
  - 0.20487909608557944
  - 0.20599255736664557
  train_level5__matthews_corrcoef_samples:
  - 0.21417233851860884
  - 0.20187844655136633
  - 0.2161922024367983
  - 0.20859142955356574
  - 0.2089596307350979
  train_level5__matthews_corrcoef_samples_masked:
  - 0.1535308631648654
  - 0.14307475634868386
  - 0.15213139795496858
  - 0.1479614317394204
  - 0.14652920370318845
  train_level5__matthews_corrcoef_samples_oob:
  - 0.21039200717086234
  - 0.19569852405438054
  - 0.21042738119856305
  - 0.20266375408406706
  - 0.20272077713585548
  train_level5__matthews_corrcoef_weighted:
  - 0.20659951861664153
  - 0.19004566316013177
  - 0.21970788758804388
  - 0.19812754111227
  - 0.2062370547357194
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.1535790436640856
  - 0.1388925299575066
  - 0.16462303000732453
  - 0.1475232501186966
  - 0.15089697724046733
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.2014571363719036
  - 0.1791489236260187
  - 0.2139818447739887
  - 0.1897117231824936
  - 0.19737593873225467
  train_level5__ndcg:
  - 0.6662382016461474
  - 0.6574206654605224
  - 0.6725039677607066
  - 0.6613682648467248
  - 0.6904003999941757
  train_level5__ndcg_oob:
  - 0.6679365920228256
  - 0.6580097175227283
  - 0.6736914428613303
  - 0.6612131981396802
  - 0.691091550427028
  train_level5__neg_coverage_error:
  - -83.2192118226601
  - -84.43596059113301
  - -83.44360902255639
  - -83.90274314214464
  - -83.44949494949495
  train_level5__neg_coverage_error_oob:
  - -84.0615763546798
  - -85.29064039408867
  - -84.17543859649123
  - -84.7206982543641
  - -84.18686868686869
  train_level5__neg_hamming_loss_macro:
  - -0.5602611315701373
  - -0.582715577024248
  - -0.5596028907219505
  - -0.5678280028085128
  - -0.5705109345886044
  train_level5__neg_hamming_loss_macro_masked:
  - -0.6198146364296985
  - -0.6463500542253011
  - -0.6191621510919958
  - -0.6280757028730057
  - -0.632319564459831
  train_level5__neg_hamming_loss_macro_oob:
  - -0.5621024439236693
  - -0.5860634176670333
  - -0.5617441662408448
  - -0.5707575720891944
  - -0.573575561439639
  train_level5__neg_hamming_loss_micro:
  - -0.5602611315701372
  - -0.5827155770242479
  - -0.5596028907219505
  - -0.5678280028085126
  - -0.5705109345886045
  train_level5__neg_hamming_loss_micro_masked:
  - -0.6274828604720484
  - -0.6546302320537845
  - -0.6276675040719984
  - -0.6358078842041779
  - -0.6401866562968724
  train_level5__neg_hamming_loss_micro_oob:
  - -0.5621024439236693
  - -0.5860634176670333
  - -0.5617441662408448
  - -0.5707575720891945
  - -0.5735755614396391
  train_level5__neg_hamming_loss_samples:
  - -0.5602611315701372
  - -0.5827155770242479
  - -0.5596028907219505
  - -0.5678280028085126
  - -0.5705109345886045
  train_level5__neg_hamming_loss_samples_masked:
  - -0.6263038496736177
  - -0.6533453552702567
  - -0.6264932261761339
  - -0.6346685891178879
  - -0.6390704875230128
  train_level5__neg_hamming_loss_samples_oob:
  - -0.5621024439236693
  - -0.5860634176670333
  - -0.5617441662408448
  - -0.5707575720891945
  - -0.5735755614396391
  train_level5__neg_hamming_loss_weighted:
  - -0.48134540526193575
  - -0.4977479140515396
  - -0.4761643773316166
  - -0.48749151212073055
  - -0.48993558007627735
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.5618869942131619
  - -0.5836058266084287
  - -0.5553246047407774
  - -0.5687217858152088
  - -0.5729829885659056
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.4836636627864519
  - -0.5017884581285811
  - -0.4782406578359499
  - -0.49123385092384253
  - -0.4932992249245924
  train_level5__neg_label_ranking_loss:
  - -0.3942323408733195
  - -0.4101027952869648
  - -0.3913038485219954
  - -0.4283407016513222
  - -0.36889703223970477
  train_level5__neg_label_ranking_loss_oob:
  - -0.3999305972834748
  - -0.4149687040363266
  - -0.39646036998807593
  - -0.433169056273728
  - -0.3734380381296411
  train_level5__precision_macro:
  - 0.4397388684298627
  - 0.4172844229757521
  - 0.44039710927804954
  - 0.4321719971914873
  - 0.42948906541139564
  train_level5__precision_macro_masked:
  - 0.38018536357030147
  - 0.3536499457746988
  - 0.38083784890800415
  - 0.37192429712699415
  - 0.36768043554016894
  train_level5__precision_macro_oob:
  - 0.4378975560763308
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108056
  - 0.426424438560361
  train_level5__precision_micro:
  - 0.43973886842986276
  - 0.4172844229757521
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.42948906541139553
  train_level5__precision_micro_masked:
  - 0.3725171395279517
  - 0.34536976794621554
  - 0.37233249592800155
  - 0.3641921157958221
  - 0.3598133437031276
  train_level5__precision_micro_oob:
  - 0.43789755607633074
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108055
  - 0.4264244385603609
  train_level5__precision_samples:
  - 0.4397388684298627
  - 0.417284422975752
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.4294890654113955
  train_level5__precision_samples_masked:
  - 0.37369615032638215
  - 0.3466546447297433
  - 0.3735067738238662
  - 0.3653314108821121
  - 0.36092951247698724
  train_level5__precision_samples_oob:
  - 0.4378975560763308
  - 0.4139365823329666
  - 0.4382558337591551
  - 0.42924242791080547
  - 0.42642443856036094
  train_level5__precision_weighted:
  - 0.5186545947380642
  - 0.5022520859484605
  - 0.5238356226683833
  - 0.5125084878792695
  - 0.5100644199237226
  train_level5__precision_weighted_masked:
  - 0.43811300578683804
  - 0.4163941733915714
  - 0.4446753952592226
  - 0.43127821418479123
  - 0.4270170114340945
  train_level5__precision_weighted_oob:
  - 0.5163363372135481
  - 0.4982115418714189
  - 0.5217593421640501
  - 0.5087661490761575
  - 0.5067007750754076
  train_level5__recall_macro:
  - 0.4397388684298627
  - 0.4172844229757521
  - 0.44039710927804954
  - 0.4321719971914873
  - 0.42948906541139564
  train_level5__recall_macro_masked:
  - 0.38018536357030147
  - 0.3536499457746988
  - 0.38083784890800415
  - 0.37192429712699415
  - 0.36768043554016894
  train_level5__recall_macro_oob:
  - 0.4378975560763308
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108056
  - 0.426424438560361
  train_level5__recall_micro:
  - 0.43973886842986276
  - 0.4172844229757521
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.42948906541139553
  train_level5__recall_micro_masked:
  - 0.3725171395279517
  - 0.34536976794621554
  - 0.37233249592800155
  - 0.3641921157958221
  - 0.3598133437031276
  train_level5__recall_micro_oob:
  - 0.43789755607633074
  - 0.41393658233296665
  - 0.43825583375915517
  - 0.4292424279108055
  - 0.4264244385603609
  train_level5__recall_samples:
  - 0.4397388684298627
  - 0.417284422975752
  - 0.4403971092780495
  - 0.4321719971914873
  - 0.4294890654113955
  train_level5__recall_samples_masked:
  - 0.37369615032638215
  - 0.3466546447297433
  - 0.3735067738238662
  - 0.3653314108821121
  - 0.36092951247698724
  train_level5__recall_samples_oob:
  - 0.4378975560763308
  - 0.4139365823329666
  - 0.4382558337591551
  - 0.42924242791080547
  - 0.42642443856036094
  train_level5__recall_weighted:
  - 0.5186545947380642
  - 0.5022520859484605
  - 0.5238356226683833
  - 0.5125084878792695
  - 0.5100644199237226
  train_level5__recall_weighted_masked:
  - 0.43811300578683804
  - 0.4163941733915714
  - 0.4446753952592226
  - 0.43127821418479123
  - 0.4270170114340945
  train_level5__recall_weighted_oob:
  - 0.5163363372135481
  - 0.4982115418714189
  - 0.5217593421640501
  - 0.5087661490761575
  - 0.5067007750754076
  train_level5__roc_auc_macro:
  - 0.6796344370495546
  - 0.6744942106735389
  - 0.6930088820360321
  - 0.6685035931352502
  - 0.6913632295566928
  train_level5__roc_auc_macro_masked:
  - 0.6598372502345679
  - 0.65510427747658
  - 0.6776236414488254
  - 0.6475740439301597
  - 0.6705768287733811
  train_level5__roc_auc_macro_oob:
  - 0.6733638851945666
  - 0.667097616248945
  - 0.6864345773186598
  - 0.6604111564357231
  - 0.6849649427791222
  train_level5__roc_auc_micro:
  - 0.6526399749864926
  - 0.6359032472513136
  - 0.6574773985057761
  - 0.6373613143510379
  - 0.67779044815726
  train_level5__roc_auc_micro_masked:
  - 0.6353656429748993
  - 0.6204271673400252
  - 0.6413076176925563
  - 0.6229230567572152
  - 0.6598518274956762
  train_level5__roc_auc_micro_oob:
  - 0.6508559027111764
  - 0.6331651325105797
  - 0.654899189273809
  - 0.6346614622411392
  - 0.6753050853293323
  train_level5__roc_auc_samples:
  - 0.6411776926456153
  - 0.624642415603282
  - 0.644273340371089
  - 0.6244227346466648
  - 0.6672644469066676
  train_level5__roc_auc_samples_masked:
  - 0.6262216128728173
  - 0.6106142252468769
  - 0.6283924901863042
  - 0.6095076699747228
  - 0.6508206275240215
  train_level5__roc_auc_samples_oob:
  - 0.6398066299043959
  - 0.6221389832414239
  - 0.6425536830443502
  - 0.6222104954910479
  - 0.6653800205334518
  train_level5__roc_auc_weighted:
  - 0.6784820565586569
  - 0.6779274463745432
  - 0.6927148001097169
  - 0.6725752565553516
  - 0.69360648366558
  train_level5__roc_auc_weighted_masked:
  - 0.6576848647961896
  - 0.6577520760193732
  - 0.6742386151396343
  - 0.6531726715763103
  - 0.6727365218120404
  train_level5__roc_auc_weighted_oob:
  - 0.6716004532602526
  - 0.6694126276289599
  - 0.6841069182085586
  - 0.6638389070767448
  - 0.686727019901889
  train_level5__tn_macro:
  - 0.2229661868095079
  - 0.19709216127026638
  - 0.22123269338394527
  - 0.21644916834128272
  - 0.21131215063253894
  train_level5__tn_macro_masked:
  - 0.24970628563538
  - 0.22070846082575538
  - 0.24877451857408228
  - 0.2419494202276125
  - 0.2365524151985474
  train_level5__tn_macro_oob:
  - 0.22184226887942993
  - 0.19443780190348653
  - 0.2199673942136896
  - 0.2143669951335254
  - 0.2091301363146023
  train_level5__tn_micro:
  - 0.22296618680950786
  - 0.19709216127026638
  - 0.2212326933839453
  - 0.21644916834128272
  - 0.21131215063253897
  train_level5__tn_micro_masked:
  - 0.25266238517193723
  - 0.22343309477336804
  - 0.25100074538276784
  - 0.24507922583474973
  - 0.23940336647964003
  train_level5__tn_micro_oob:
  - 0.2218422688794299
  - 0.19443780190348653
  - 0.21996739421368958
  - 0.21436699513352542
  - 0.20913013631460234
  train_level5__tn_samples:
  - 0.22296618680950783
  - 0.19709216127026633
  - 0.22123269338394524
  - 0.21644916834128267
  - 0.21131215063253897
  train_level5__tn_samples_masked:
  - 0.2534459276281628
  - 0.22439333353709356
  - 0.2519417513003012
  - 0.2458849242636739
  - 0.24010676957154453
  train_level5__tn_samples_oob:
  - 0.22184226887942987
  - 0.1944378019034865
  - 0.21996739421368952
  - 0.2143669951335254
  - 0.20913013631460234
  train_level5__tn_weighted:
  - 0.19539768214538797
  - 0.17204510099099818
  - 0.19831670112491248
  - 0.18707767030437253
  - 0.183801740631854
  train_level5__tn_weighted_masked:
  - 0.22687422475026675
  - 0.20006345413138277
  - 0.23212095433712537
  - 0.21795335612876426
  - 0.2147144312273078
  train_level5__tn_weighted_oob:
  - 0.19389481869695094
  - 0.16897300159080098
  - 0.1969598188687514
  - 0.1846236947000524
  - 0.18151326367412046
  train_level5__tp_macro:
  - 0.2167726816203549
  - 0.22019226170548573
  - 0.21916441589410415
  - 0.21572282885020447
  - 0.21817691477885648
  train_level5__tp_macro_masked:
  - 0.13047907793492142
  - 0.13294148494894356
  - 0.1320633303339219
  - 0.12997487689938167
  - 0.13112802034162155
  train_level5__tp_macro_oob:
  - 0.21605528719690087
  - 0.21949878042948015
  - 0.21828843954546562
  - 0.21487543277728
  - 0.21729430224575855
  train_level5__tp_micro:
  - 0.21677268162035487
  - 0.22019226170548567
  - 0.21916441589410418
  - 0.21572282885020458
  - 0.21817691477885653
  train_level5__tp_micro_masked:
  - 0.11985475435601442
  - 0.12193667317284754
  - 0.1213317505452337
  - 0.11911288996107243
  - 0.12040997722348759
  train_level5__tp_micro_oob:
  - 0.21605528719690087
  - 0.21949878042948012
  - 0.21828843954546562
  - 0.2148754327772801
  - 0.21729430224575855
  train_level5__tp_samples:
  - 0.21677268162035482
  - 0.22019226170548567
  - 0.21916441589410415
  - 0.21572282885020452
  - 0.21817691477885642
  train_level5__tp_samples_masked:
  - 0.12025022269821943
  - 0.12226131119264966
  - 0.12156502252356495
  - 0.11944648661843818
  - 0.1208227429054427
  train_level5__tp_samples_oob:
  - 0.2160552871969008
  - 0.21949878042948007
  - 0.2182884395454656
  - 0.21487543277728005
  - 0.21729430224575852
  train_level5__tp_weighted:
  - 0.32325691259267614
  - 0.33020698495746226
  - 0.325518921543471
  - 0.32543081757489684
  - 0.3262626792918687
  train_level5__tp_weighted_masked:
  - 0.21123878103657132
  - 0.2163307192601886
  - 0.21255444092209722
  - 0.21332485805602694
  - 0.2123025802067867
  train_level5__tp_weighted_oob:
  - 0.32244151851659725
  - 0.3292385402806179
  - 0.3247995232952988
  - 0.32414245437610484
  - 0.3251875114012871
  train_level6__average_precision_macro:
  - 0.34788204151203084
  - 0.34597387921093203
  - 0.3693732564285416
  - 0.33659078260719816
  - 0.36171847754060055
  train_level6__average_precision_macro_masked:
  - 0.22149751416882044
  - 0.22216256005138887
  - 0.24199250093804647
  - 0.2161334120758229
  - 0.23505319259875734
  train_level6__average_precision_macro_oob:
  - 0.34373315041175806
  - 0.34106804056413487
  - 0.36288009209085853
  - 0.333928648026077
  - 0.35746761738437527
  train_level6__average_precision_micro:
  - 0.3107447066476701
  - 0.2996110710770803
  - 0.31981173473120994
  - 0.2976443439330897
  - 0.3398008400580449
  train_level6__average_precision_micro_masked:
  - 0.1753981186971736
  - 0.16848533063451823
  - 0.18245848814847349
  - 0.16808531899979567
  - 0.19605983877977043
  train_level6__average_precision_micro_oob:
  - 0.31060597825093594
  - 0.29915524118098874
  - 0.3183112779741497
  - 0.2972878374939759
  - 0.33848955350528614
  train_level6__average_precision_samples:
  - 0.3229786686753781
  - 0.3120483945822225
  - 0.32891057470913165
  - 0.30736137395347257
  - 0.3497699688281018
  train_level6__average_precision_samples_masked:
  - 0.19536673295942283
  - 0.18914714256866072
  - 0.2010451716725484
  - 0.18400086560206338
  - 0.21681852289947284
  train_level6__average_precision_samples_oob:
  - 0.3232943801338587
  - 0.3118228370211885
  - 0.3278065566216302
  - 0.3069233126726374
  - 0.3489325294994271
  train_level6__average_precision_weighted:
  - 0.47377976412127804
  - 0.4776979587927698
  - 0.49817364004160763
  - 0.4668638302647872
  - 0.4909932772402002
  train_level6__average_precision_weighted_masked:
  - 0.32385527297539807
  - 0.32997245625653954
  - 0.34866593001930124
  - 0.32346311155505875
  - 0.3410711464795812
  train_level6__average_precision_weighted_oob:
  - 0.4690798702835181
  - 0.4712616461821093
  - 0.4909655552793541
  - 0.46364332861948165
  - 0.4862799398115906
  train_level6__f1_macro:
  - 0.4404084365584199
  - 0.41781051221961835
  - 0.440908095481422
  - 0.43292254799893476
  - 0.4301755418260274
  train_level6__f1_macro_masked:
  - 0.3810601079402627
  - 0.3544699972434947
  - 0.3813408479321633
  - 0.3726466709454451
  - 0.368434242551536
  train_level6__f1_macro_oob:
  - 0.4384475584676456
  - 0.4150126739681477
  - 0.4389128160206342
  - 0.4302835145146843
  - 0.42698832990095137
  train_level6__f1_micro:
  - 0.4404084365584198
  - 0.41781051221961835
  - 0.440908095481422
  - 0.4329225479989347
  - 0.43017554182602724
  train_level6__f1_micro_masked:
  - 0.3733571796330922
  - 0.34615593146822815
  - 0.3728846313115976
  - 0.3649597017380339
  - 0.360535525804122
  train_level6__f1_micro_oob:
  - 0.4384475584676455
  - 0.41501267396814767
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__f1_samples:
  - 0.4404084365584197
  - 0.41781051221961835
  - 0.44090809548142196
  - 0.43292254799893465
  - 0.43017554182602724
  train_level6__f1_samples_masked:
  - 0.3745372054811855
  - 0.34746055599556414
  - 0.37405329171599605
  - 0.366116037441614
  - 0.36164631307464895
  train_level6__f1_samples_oob:
  - 0.4384475584676455
  - 0.4150126739681476
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__f1_weighted:
  - 0.5194745215792355
  - 0.5028659030621035
  - 0.524202298715135
  - 0.5128972854130186
  - 0.5109250845286125
  train_level6__f1_weighted_masked:
  - 0.43925577356375695
  - 0.4174767403852103
  - 0.44481088813353675
  - 0.43165334309580533
  - 0.42801801580825294
  train_level6__f1_weighted_oob:
  - 0.5172461638957203
  - 0.4995830865758399
  - 0.5220174883026721
  - 0.5098355373428977
  - 0.5071483418816473
  train_level6__fn_macro:
  - -0.01714572672055096
  - -0.014395714763977233
  - -0.016886877387643866
  - -0.01634263854925792
  - -0.015274100225556534
  train_level6__fn_macro_masked:
  - -0.01257248836474887
  - -0.010595145444232863
  - -0.012662774880777805
  - -0.01206795077262145
  - -0.011735166916535521
  train_level6__fn_macro_oob:
  - -0.017576163374623366
  - -0.015352240661915923
  - -0.017665523030878167
  - -0.017238457254920948
  - -0.016181229773462782
  train_level6__fn_micro:
  - -0.01714572672055096
  - -0.014395714763977234
  - -0.016886877387643866
  - -0.016342638549257923
  - -0.015274100225556536
  train_level6__fn_micro_masked:
  - -0.011950247947321356
  - -0.01016590761223162
  - -0.01195373105485465
  - -0.011458961565875322
  - -0.011193822565413033
  train_level6__fn_micro_oob:
  - -0.01757616337462337
  - -0.015352240661915921
  - -0.017665523030878167
  - -0.01723845725492095
  - -0.016181229773462782
  train_level6__fn_samples:
  - -0.017145726720550956
  - -0.014395714763977234
  - -0.016886877387643866
  - -0.01634263854925792
  - -0.015274100225556536
  train_level6__fn_samples_masked:
  - -0.011850453665071457
  - -0.010123011569441499
  - -0.01191625804121776
  - -0.011414189359705762
  - -0.011128710234560258
  train_level6__fn_samples_oob:
  - -0.01757616337462337
  - -0.015352240661915921
  - -0.017665523030878164
  - -0.017238457254920948
  - -0.016181229773462782
  train_level6__fn_weighted:
  - -0.02224253012903775
  - -0.018078219990647078
  - -0.02245302916017748
  - -0.021367220180854567
  - -0.019389877353968073
  train_level6__fn_weighted_masked:
  - -0.01728354781589251
  - -0.013845639678051575
  - -0.017968118652706748
  - -0.016714350397619333
  - -0.015824517892018792
  train_level6__fn_weighted_oob:
  - -0.022655011752452603
  - -0.019176761748042642
  - -0.023353052184022276
  - -0.02261553333269184
  - -0.020583035308990798
  train_level6__fp_macro:
  - -0.5424458367210293
  - -0.5677937730164044
  - -0.5422050271309341
  - -0.5507348134518073
  - -0.5545503579484161
  train_level6__fp_macro_masked:
  - -0.6063674036949885
  - -0.6349348573122723
  - -0.6059963771870589
  - -0.6152853782819334
  - -0.6198305905319283
  train_level6__fp_macro_oob:
  - -0.5439762781577311
  - -0.5696350853699363
  - -0.5434216609484877
  - -0.5524780282303948
  - -0.556830440325586
  train_level6__fp_micro:
  - -0.5424458367210292
  - -0.5677937730164044
  - -0.5422050271309341
  - -0.5507348134518074
  - -0.5545503579484162
  train_level6__fp_micro_masked:
  - -0.6146925724195865
  - -0.6436781609195402
  - -0.6151616376335477
  - -0.6235813366960908
  - -0.628270651630465
  train_level6__fp_micro_oob:
  - -0.5439762781577311
  - -0.5696350853699363
  - -0.5434216609484878
  - -0.5524780282303949
  - -0.5568304403255859
  train_level6__fp_samples:
  - -0.5424458367210292
  - -0.5677937730164043
  - -0.5422050271309341
  - -0.5507348134518074
  - -0.5545503579484161
  train_level6__fp_samples_masked:
  - -0.6136123408537429
  - -0.6424164324349945
  - -0.6140304502427862
  - -0.6224697731986804
  - -0.627224976690791
  train_level6__fp_samples_oob:
  - -0.5439762781577311
  - -0.5696350853699363
  - -0.5434216609484878
  - -0.5524780282303949
  - -0.5568304403255859
  train_level6__fp_weighted:
  - -0.45828294829172667
  - -0.4790558769472494
  - -0.45334467212468743
  - -0.4657354944061268
  - -0.4696850381174196
  train_level6__fp_weighted_masked:
  - -0.5434606786203506
  - -0.5686776199367383
  - -0.5372209932137564
  - -0.5516323065065755
  - -0.5561574662997282
  train_level6__fp_weighted_oob:
  - -0.46009882435182714
  - -0.48124015167611756
  - -0.45462945951330547
  - -0.4675489293244105
  - -0.47226862280936194
  train_level6__jaccard_macro:
  - 0.2981443186648569
  - 0.2783433171227238
  - 0.3004277964014972
  - 0.2927194042178556
  - 0.28903467732032834
  train_level6__jaccard_macro_masked:
  - 0.24844998300277485
  - 0.22632102710730076
  - 0.2503441274694743
  - 0.24301285362030103
  - 0.23790681982607917
  train_level6__jaccard_macro_oob:
  - 0.2965377153986823
  - 0.2761054801075515
  - 0.29873238438864097
  - 0.2904927847912163
  - 0.28648395145628164
  train_level6__jaccard_micro:
  - 0.28238703445315017
  - 0.264071096064325
  - 0.28279801479539285
  - 0.27626110467361914
  - 0.2740277994689989
  train_level6__jaccard_micro_masked:
  - 0.22952622109682147
  - 0.2093038503778255
  - 0.2291691409762636
  - 0.22321144140972118
  - 0.21991054486310654
  train_level6__jaccard_micro_oob:
  - 0.28077671092326306
  - 0.26183974291275025
  - 0.28115842633580646
  - 0.2741154332603264
  - 0.27144638403990023
  train_level6__jaccard_samples:
  - 0.2892188931238565
  - 0.2707054418657263
  - 0.2893021165778442
  - 0.28391427629026134
  - 0.28150639833367125
  train_level6__jaccard_samples_masked:
  - 0.23710095429940778
  - 0.21660387335338716
  - 0.23630622890726868
  - 0.23186869552230915
  - 0.22813068311787865
  train_level6__jaccard_samples_oob:
  - 0.28745170998836533
  - 0.26832326838004544
  - 0.2876024017813112
  - 0.28181674941986484
  - 0.27870857110083036
  train_level6__jaccard_weighted:
  - 0.36614929628575243
  - 0.3507008784977343
  - 0.3720426951306219
  - 0.3616228311823287
  - 0.359083846411169
  train_level6__jaccard_weighted_masked:
  - 0.29365790843310313
  - 0.2746295935039892
  - 0.299352494834974
  - 0.28874831890213365
  - 0.28430349903497376
  train_level6__jaccard_weighted_oob:
  - 0.3641443346323026
  - 0.3478090482611539
  - 0.36998417229605707
  - 0.3588534837891155
  - 0.3556635091426977
  train_level6__label_ranking_average_precision_score:
  - 0.3229786686753784
  - 0.31204839458222255
  - 0.3289105747091316
  - 0.3073613739534725
  - 0.34976996882810196
  train_level6__label_ranking_average_precision_score_oob:
  - 0.3232943801338585
  - 0.3118228370211885
  - 0.3278065566216303
  - 0.3069233126726373
  - 0.3489325294994272
  train_level6__matthews_corrcoef_macro:
  - 0.18963482380826052
  - 0.17436114744112613
  - 0.19639508368049366
  - 0.18014428542649413
  - 0.18397666065942245
  train_level6__matthews_corrcoef_macro_masked:
  - 0.13690748529887706
  - 0.1242517422972886
  - 0.14300967048807017
  - 0.1289404544458314
  - 0.12976229309749096
  train_level6__matthews_corrcoef_macro_oob:
  - 0.18487102755176968
  - 0.16518115990312085
  - 0.19030023323558948
  - 0.17357807978736556
  - 0.17637227094236693
  train_level6__matthews_corrcoef_micro:
  - 0.2164566212250691
  - 0.20405129426111293
  - 0.2179033657971969
  - 0.21194537322144827
  - 0.2131272974685511
  train_level6__matthews_corrcoef_micro_masked:
  - 0.15425915843336327
  - 0.14504078525138753
  - 0.15468372056922394
  - 0.15031769367415004
  - 0.14921345382364612
  train_level6__matthews_corrcoef_micro_oob:
  - 0.2129900612993888
  - 0.1976326094539842
  - 0.21316498330124106
  - 0.2060889620430223
  - 0.20664422963541554
  train_level6__matthews_corrcoef_samples:
  - 0.21489179962750904
  - 0.20187101138173744
  - 0.21619938342723036
  - 0.2097757615456008
  - 0.20942326527875565
  train_level6__matthews_corrcoef_samples_masked:
  - 0.15457413613741428
  - 0.1439620271158334
  - 0.1519157500224784
  - 0.14838508941193754
  - 0.14647084665839255
  train_level6__matthews_corrcoef_samples_oob:
  - 0.21159419355722683
  - 0.19572675999377967
  - 0.2115003971578507
  - 0.20363095984748072
  - 0.2028390457716179
  train_level6__matthews_corrcoef_weighted:
  - 0.20844028593264438
  - 0.19174763633902542
  - 0.22064122263547806
  - 0.19848631236069503
  - 0.21044862665218975
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.1556131321044014
  - 0.1422149061114714
  - 0.1646388032406474
  - 0.1479793970203711
  - 0.15532624160396172
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.2022071844964515
  - 0.18036036848300196
  - 0.21240172354262007
  - 0.19019470852062312
  - 0.20035202849057632
  train_level6__ndcg:
  - 0.6690601851972348
  - 0.659800870497447
  - 0.6738088857324647
  - 0.662093182777104
  - 0.6906390895338597
  train_level6__ndcg_oob:
  - 0.670476684667176
  - 0.6609355058926414
  - 0.673634623387532
  - 0.6627165369605712
  - 0.6912163824012127
  train_level6__neg_coverage_error:
  - -83.25369458128078
  - -84.47783251231527
  - -83.34335839598998
  - -83.92019950124688
  - -83.44949494949495
  train_level6__neg_coverage_error_oob:
  - -84.14285714285714
  - -85.34482758620689
  - -84.00751879699249
  - -84.82543640897755
  - -84.28787878787878
  train_level6__neg_hamming_loss_macro:
  - -0.5595915634415801
  - -0.5821894877803817
  - -0.5590919045185779
  - -0.5670774520010653
  - -0.5698244581739725
  train_level6__neg_hamming_loss_macro_masked:
  - -0.6189398920597373
  - -0.6455300027565052
  - -0.6186591520678366
  - -0.6273533290545549
  - -0.6315657574484639
  train_level6__neg_hamming_loss_macro_oob:
  - -0.5615524415323545
  - -0.5849873260318523
  - -0.5610871839793659
  - -0.5697164854853157
  - -0.5730116700990486
  train_level6__neg_hamming_loss_micro:
  - -0.5595915634415802
  - -0.5821894877803817
  - -0.559091904518578
  - -0.5670774520010653
  - -0.5698244581739728
  train_level6__neg_hamming_loss_micro_masked:
  - -0.6266428203669079
  - -0.6538440685317719
  - -0.6271153686884023
  - -0.6350402982619661
  - -0.639464474195878
  train_level6__neg_hamming_loss_micro_oob:
  - -0.5615524415323545
  - -0.5849873260318523
  - -0.5610871839793659
  - -0.5697164854853158
  - -0.5730116700990487
  train_level6__neg_hamming_loss_samples:
  - -0.5595915634415801
  - -0.5821894877803816
  - -0.559091904518578
  - -0.5670774520010653
  - -0.5698244581739726
  train_level6__neg_hamming_loss_samples_masked:
  - -0.6254627945188144
  - -0.6525394440044359
  - -0.625946708284004
  - -0.6338839625583861
  - -0.6383536869253511
  train_level6__neg_hamming_loss_samples_oob:
  - -0.5615524415323545
  - -0.5849873260318523
  - -0.561087183979366
  - -0.5697164854853158
  - -0.5730116700990487
  train_level6__neg_hamming_loss_weighted:
  - -0.48052547842076454
  - -0.4971340969378965
  - -0.4757977012848648
  - -0.48710271458698146
  - -0.48907491547138754
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.560744226436243
  - -0.5825232596147897
  - -0.5551891118664632
  - -0.5683466569041946
  - -0.5719819841917471
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.48275383610427963
  - -0.5004169134241601
  - -0.4779825116973278
  - -0.49016446265710223
  - -0.49285165811835274
  train_level6__neg_label_ranking_loss:
  - -0.39880080609050544
  - -0.41214536442667843
  - -0.3913161741717619
  - -0.43232968314749826
  - -0.369289441264474
  train_level6__neg_label_ranking_loss_oob:
  - -0.40388984521312454
  - -0.4168472970176756
  - -0.39767238694766693
  - -0.43736584822149904
  - -0.3745499381031213
  train_level6__precision_macro:
  - 0.4404084365584199
  - 0.41781051221961835
  - 0.440908095481422
  - 0.43292254799893476
  - 0.4301755418260274
  train_level6__precision_macro_masked:
  - 0.3810601079402627
  - 0.3544699972434947
  - 0.3813408479321633
  - 0.3726466709454451
  - 0.368434242551536
  train_level6__precision_macro_oob:
  - 0.4384475584676456
  - 0.4150126739681477
  - 0.4389128160206342
  - 0.4302835145146843
  - 0.42698832990095137
  train_level6__precision_micro:
  - 0.4404084365584198
  - 0.41781051221961835
  - 0.440908095481422
  - 0.4329225479989347
  - 0.43017554182602724
  train_level6__precision_micro_masked:
  - 0.3733571796330922
  - 0.34615593146822815
  - 0.3728846313115976
  - 0.3649597017380339
  - 0.360535525804122
  train_level6__precision_micro_oob:
  - 0.4384475584676455
  - 0.41501267396814767
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__precision_samples:
  - 0.4404084365584197
  - 0.41781051221961835
  - 0.44090809548142196
  - 0.43292254799893465
  - 0.43017554182602724
  train_level6__precision_samples_masked:
  - 0.3745372054811855
  - 0.34746055599556414
  - 0.37405329171599605
  - 0.366116037441614
  - 0.36164631307464895
  train_level6__precision_samples_oob:
  - 0.4384475584676455
  - 0.4150126739681476
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__precision_weighted:
  - 0.5194745215792355
  - 0.5028659030621035
  - 0.524202298715135
  - 0.5128972854130186
  - 0.5109250845286125
  train_level6__precision_weighted_masked:
  - 0.43925577356375695
  - 0.4174767403852103
  - 0.44481088813353675
  - 0.43165334309580533
  - 0.42801801580825294
  train_level6__precision_weighted_oob:
  - 0.5172461638957203
  - 0.4995830865758399
  - 0.5220174883026721
  - 0.5098355373428977
  - 0.5071483418816473
  train_level6__recall_macro:
  - 0.4404084365584199
  - 0.41781051221961835
  - 0.440908095481422
  - 0.43292254799893476
  - 0.4301755418260274
  train_level6__recall_macro_masked:
  - 0.3810601079402627
  - 0.3544699972434947
  - 0.3813408479321633
  - 0.3726466709454451
  - 0.368434242551536
  train_level6__recall_macro_oob:
  - 0.4384475584676456
  - 0.4150126739681477
  - 0.4389128160206342
  - 0.4302835145146843
  - 0.42698832990095137
  train_level6__recall_micro:
  - 0.4404084365584198
  - 0.41781051221961835
  - 0.440908095481422
  - 0.4329225479989347
  - 0.43017554182602724
  train_level6__recall_micro_masked:
  - 0.3733571796330922
  - 0.34615593146822815
  - 0.3728846313115976
  - 0.3649597017380339
  - 0.360535525804122
  train_level6__recall_micro_oob:
  - 0.4384475584676455
  - 0.41501267396814767
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__recall_samples:
  - 0.4404084365584197
  - 0.41781051221961835
  - 0.44090809548142196
  - 0.43292254799893465
  - 0.43017554182602724
  train_level6__recall_samples_masked:
  - 0.3745372054811855
  - 0.34746055599556414
  - 0.37405329171599605
  - 0.366116037441614
  - 0.36164631307464895
  train_level6__recall_samples_oob:
  - 0.4384475584676455
  - 0.4150126739681476
  - 0.4389128160206341
  - 0.43028351451468416
  - 0.42698832990095126
  train_level6__recall_weighted:
  - 0.5194745215792355
  - 0.5028659030621035
  - 0.524202298715135
  - 0.5128972854130186
  - 0.5109250845286125
  train_level6__recall_weighted_masked:
  - 0.43925577356375695
  - 0.4174767403852103
  - 0.44481088813353675
  - 0.43165334309580533
  - 0.42801801580825294
  train_level6__recall_weighted_oob:
  - 0.5172461638957203
  - 0.4995830865758399
  - 0.5220174883026721
  - 0.5098355373428977
  - 0.5071483418816473
  train_level6__roc_auc_macro:
  - 0.679727221566
  - 0.67622859529344
  - 0.6943970913331945
  - 0.6683890314970858
  - 0.6917463308270367
  train_level6__roc_auc_macro_masked:
  - 0.6585012224693768
  - 0.6557193867809501
  - 0.6786214682756433
  - 0.6468836119474183
  - 0.6707755036050724
  train_level6__roc_auc_macro_oob:
  - 0.6732763006116629
  - 0.6689514699640291
  - 0.6866224048930172
  - 0.6611075173078416
  - 0.6847910979861865
  train_level6__roc_auc_micro:
  - 0.6523536086739652
  - 0.6372039816778466
  - 0.6582537953125428
  - 0.6374542853618329
  - 0.6775162308134339
  train_level6__roc_auc_micro_masked:
  - 0.6346566715701883
  - 0.6211349957125603
  - 0.6421780866541449
  - 0.622670415034412
  - 0.6601502299025757
  train_level6__roc_auc_micro_oob:
  - 0.6505720607010673
  - 0.634738502519131
  - 0.655373283380554
  - 0.6355164565134238
  - 0.6746152238706762
  train_level6__roc_auc_samples:
  - 0.6414212861945567
  - 0.6256016093009522
  - 0.6448367051527397
  - 0.6246306557885984
  - 0.6669609213375562
  train_level6__roc_auc_samples_masked:
  - 0.6267185307106671
  - 0.6111754257891792
  - 0.6290490000662795
  - 0.6095142868389661
  - 0.6506750583621532
  train_level6__roc_auc_samples_oob:
  - 0.6403058119212283
  - 0.6238311796908588
  - 0.6425031767747181
  - 0.622935302634796
  - 0.6646750151618025
  train_level6__roc_auc_weighted:
  - 0.6780881499818548
  - 0.6788182984956487
  - 0.6947101530704581
  - 0.6729658831063297
  - 0.6935459917649681
  train_level6__roc_auc_weighted_masked:
  - 0.6568467076488002
  - 0.65824096430756
  - 0.6760832479891101
  - 0.6532544848154567
  - 0.6726604784721251
  train_level6__roc_auc_weighted_oob:
  - 0.6708386513543959
  - 0.6704084219081947
  - 0.6853389425443931
  - 0.6651553541134827
  - 0.6861354056380672
  train_level6__tn_macro:
  - 0.22365966808551346
  - 0.19768998995647807
  - 0.22179234494001998
  - 0.21710287388325303
  - 0.21194959301755417
  train_level6__tn_macro_masked:
  - 0.2505246301205703
  - 0.2213962496040416
  - 0.24937268295871656
  - 0.24263033670807888
  - 0.23729994272947957
  train_level6__tn_macro_oob:
  - 0.22212922664881152
  - 0.1958486776029461
  - 0.22057571112246632
  - 0.21535965910466554
  - 0.20966951064038442
  train_level6__tn_micro:
  - 0.2236596680855134
  - 0.19768998995647807
  - 0.22179234494001995
  - 0.21710287388325303
  - 0.21194959301755417
  train_level6__tn_micro_masked:
  - 0.25344822914126225
  - 0.2241108219475168
  - 0.2516357010739033
  - 0.24581939799331104
  - 0.2401255485806344
  train_level6__tn_micro_oob:
  - 0.22212922664881152
  - 0.1958486776029461
  - 0.22057571112246635
  - 0.2153596591046655
  - 0.20966951064038442
  train_level6__tn_samples:
  - 0.22365966808551338
  - 0.19768998995647805
  - 0.2217923449400199
  - 0.217102873883253
  - 0.21194959301755414
  train_level6__tn_samples_masked:
  - 0.2542296118685613
  - 0.2250939219150214
  - 0.25256656337286115
  - 0.24663918209788427
  - 0.24082532986567562
  train_level6__tn_samples_oob:
  - 0.22212922664881152
  - 0.19584867760294603
  - 0.22057571112246632
  - 0.21535965910466548
  - 0.20966951064038436
  train_level6__tn_weighted:
  - 0.19624757560022624
  - 0.1726584157993109
  - 0.19861619199044106
  - 0.18732473228234037
  - 0.18457490698670875
  train_level6__tn_weighted_masked:
  - 0.2279426940391072
  - 0.20083069663998826
  - 0.23244237254716632
  - 0.21817905415767017
  - 0.21566134642284449
  train_level6__tn_weighted_oob:
  - 0.1944316995401258
  - 0.1704741410704428
  - 0.19733140460182313
  - 0.18551129736405675
  - 0.18199132229476625
  train_level6__tp_macro:
  - 0.2167487684729064
  - 0.2201205222631403
  - 0.21911575054140203
  - 0.2158196741156816
  - 0.21822594880847304
  train_level6__tp_macro_masked:
  - 0.13053547781969238
  - 0.13307374763945315
  - 0.13196816497344682
  - 0.1300163342373662
  - 0.13113429982205657
  train_level6__tp_macro_oob:
  - 0.21631833181883403
  - 0.2191639963652016
  - 0.21833710489816777
  - 0.21492385541001857
  - 0.21731881926056684
  train_level6__tp_micro:
  - 0.21674876847290642
  - 0.22012052226314027
  - 0.21911575054140206
  - 0.21581967411568168
  - 0.21822594880847307
  train_level6__tp_micro_masked:
  - 0.11990895049182994
  - 0.12204510952071135
  - 0.12124893023769429
  - 0.11914030374472284
  - 0.12040997722348759
  train_level6__tp_micro_oob:
  - 0.216318331818834
  - 0.2191639963652016
  - 0.21833710489816774
  - 0.21492385541001865
  - 0.21731881926056684
  train_level6__tp_samples:
  - 0.21674876847290633
  - 0.22012052226314022
  - 0.219115750541402
  - 0.21581967411568162
  - 0.21822594880847304
  train_level6__tp_samples_masked:
  - 0.12030759361262429
  - 0.12236663408054266
  - 0.12148672834313486
  - 0.11947685534372966
  - 0.12082098320897325
  train_level6__tp_samples_oob:
  - 0.21631833181883398
  - 0.21916399636520154
  - 0.2183371048981677
  - 0.2149238554100186
  - 0.21731881926056676
  train_level6__tp_weighted:
  - 0.32322694597900925
  - 0.33020748726279253
  - 0.32558610672469396
  - 0.32557255313067834
  - 0.3263501775419037
  train_level6__tp_weighted_masked:
  - 0.21131307952464976
  - 0.21664604374522203
  - 0.21236851558637054
  - 0.2134742889381351
  - 0.21235666938540845
  train_level6__tp_weighted_oob:
  - 0.32281446435559435
  - 0.32910894550539693
  - 0.32468608370084917
  - 0.32432423997884113
  - 0.325157019586881
  train_level7__average_precision_macro:
  - 0.34746125755375834
  - 0.34534022874501363
  - 0.36789959264186944
  - 0.33807996896752746
  - 0.36049261042209346
  train_level7__average_precision_macro_masked:
  - 0.22224172054015767
  - 0.22184195237808577
  - 0.2404268172017881
  - 0.21673783924326534
  - 0.2355712933593664
  train_level7__average_precision_macro_oob:
  - 0.3433440240100659
  - 0.3401709683676186
  - 0.36146666163915847
  - 0.33442533140673186
  - 0.3560285561009322
  train_level7__average_precision_micro:
  - 0.3104171256220568
  - 0.2990163276970757
  - 0.32011179943441853
  - 0.29894009615104333
  - 0.33889338628854226
  train_level7__average_precision_micro_masked:
  - 0.17602680570193924
  - 0.16819773449812409
  - 0.18275068224035904
  - 0.1684172085116544
  - 0.19651388314878404
  train_level7__average_precision_micro_oob:
  - 0.3097094191930586
  - 0.2980024476369231
  - 0.3181972116634927
  - 0.2981671154481441
  - 0.3370905093430965
  train_level7__average_precision_samples:
  - 0.3213003246164159
  - 0.3114862144989102
  - 0.32897038699777637
  - 0.30797867262123035
  - 0.34916071591401904
  train_level7__average_precision_samples_masked:
  - 0.19485982412304112
  - 0.18903193767361923
  - 0.20089401687457076
  - 0.18389427930633098
  - 0.217341561345491
  train_level7__average_precision_samples_oob:
  - 0.3206569524971097
  - 0.3109910587578781
  - 0.32779317245574624
  - 0.30752687135225926
  - 0.3476484630879869
  train_level7__average_precision_weighted:
  - 0.47267524160106283
  - 0.47705975671495293
  - 0.496391748748477
  - 0.46977276525137207
  - 0.4889505398836717
  train_level7__average_precision_weighted_masked:
  - 0.32370953973164346
  - 0.32955952246268355
  - 0.34708228109632494
  - 0.3259232076949895
  - 0.3402578327289312
  train_level7__average_precision_weighted_oob:
  - 0.4681968497019053
  - 0.47098151908812286
  - 0.4891161141724972
  - 0.46551695090145623
  - 0.4836507949561421
  train_level7__f1_macro:
  - 0.44045626285331674
  - 0.41821703572624236
  - 0.44081076477601766
  - 0.4328257027334578
  - 0.43005295675198596
  train_level7__f1_macro_masked:
  - 0.381110015963952
  - 0.35481475557480285
  - 0.3811886887508181
  - 0.3726109820058059
  - 0.36838336066227195
  train_level7__f1_macro_oob:
  - 0.43847147161509387
  - 0.4154191974747716
  - 0.4391318101077938
  - 0.4300656126673608
  - 0.4277728743748162
  train_level7__f1_micro:
  - 0.44045626285331674
  - 0.4182170357262423
  - 0.4408107647760177
  - 0.4328257027334576
  - 0.4300529567519859
  train_level7__f1_micro_masked:
  - 0.3733842777009999
  - 0.34656256777271743
  - 0.37269138392733897
  - 0.36490487417073303
  - 0.360535525804122
  train_level7__f1_micro_oob:
  - 0.438471471615094
  - 0.41541919747477163
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.42777287437481615
  train_level7__f1_samples:
  - 0.44045626285331674
  - 0.41821703572624225
  - 0.4408107647760177
  - 0.43282570273345755
  - 0.4300529567519859
  train_level7__f1_samples_masked:
  - 0.37453892226904134
  - 0.34788217710085645
  - 0.3738599258754947
  - 0.3660299564134128
  - 0.36166438647215665
  train_level7__f1_samples_oob:
  - 0.438471471615094
  - 0.4154191974747716
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.4277728743748161
  train_level7__f1_weighted:
  - 0.5196976343498984
  - 0.5029846982727227
  - 0.524203849142394
  - 0.5130231569891622
  - 0.5103430885927737
  train_level7__f1_weighted_masked:
  - 0.43948372796214524
  - 0.41734675049236086
  - 0.44496922867972916
  - 0.4317622857606777
  - 0.4275825818224396
  train_level7__f1_weighted_oob:
  - 0.5169580814920655
  - 0.4999660943902038
  - 0.5222727919913196
  - 0.5097382729431503
  - 0.5076473470530589
  train_level7__fn_macro:
  - -0.017073987278205558
  - -0.014204409584389496
  - -0.016740881329537435
  - -0.016415272498365732
  - -0.015592821418064135
  train_level7__fn_macro_masked:
  - -0.012547529946900008
  - -0.010419474689561972
  - -0.012580157326700186
  - -0.012106158563507618
  - -0.011988457427650109
  train_level7__fn_macro_oob:
  - -0.017767468554211106
  - -0.015089196039982784
  - -0.017373530914665303
  - -0.017093189356705323
  - -0.01625478081788761
  train_level7__fn_micro:
  - -0.017073987278205558
  - -0.014204409584389498
  - -0.016740881329537435
  - -0.016415272498365736
  - -0.015592821418064137
  train_level7__fn_micro_masked:
  - -0.01189605181150584
  - -0.010003253090435914
  - -0.011870910747315241
  - -0.011486375349525742
  - -0.011416032442642075
  train_level7__fn_micro_oob:
  - -0.017767468554211106
  - -0.015089196039982782
  - -0.017373530914665303
  - -0.017093189356705323
  - -0.016254780817887615
  train_level7__fn_samples:
  - -0.017073987278205555
  - -0.014204409584389498
  - -0.01674088132953743
  - -0.016415272498365736
  - -0.015592821418064133
  train_level7__fn_samples_masked:
  - -0.011798351584584183
  - -0.009949557317897907
  - -0.011837339362866146
  - -0.011441293404448404
  - -0.01135474273473995
  train_level7__fn_samples_oob:
  - -0.017767468554211102
  - -0.015089196039982782
  - -0.017373530914665303
  - -0.017093189356705323
  - -0.01625478081788761
  train_level7__fn_weighted:
  - -0.022256380244598077
  - -0.017709276725531832
  - -0.022416594119591172
  - -0.02142963583844643
  - -0.02002649340952575
  train_level7__fn_weighted_masked:
  - -0.017480560452063993
  - -0.013575138481847134
  - -0.017886755904901918
  - -0.016834337526325276
  - -0.01631263174307484
  train_level7__fn_weighted_oob:
  - -0.02319289987675915
  - -0.01895775662402597
  - -0.02299386986902249
  - -0.02227380760737638
  - -0.020712956952982156
  train_level7__fp_macro:
  - -0.5424697498684777
  - -0.5675785546893682
  - -0.5424483538944448
  - -0.5507590247681766
  - -0.55435422182995
  train_level7__fp_macro_masked:
  - -0.606342454089148
  - -0.634765769735635
  - -0.6062311539224817
  - -0.6152828594306865
  - -0.619628181910078
  train_level7__fp_macro_oob:
  - -0.543761059830695
  - -0.5694916064852455
  - -0.5434946589775409
  - -0.5528411979759339
  - -0.5559723448072962
  train_level7__fp_micro:
  - -0.5424697498684777
  - -0.5675785546893682
  - -0.5424483538944449
  - -0.5507590247681766
  - -0.55435422182995
  train_level7__fp_micro_masked:
  - -0.6147196704874942
  - -0.6434341791368466
  - -0.6154377053253458
  - -0.6236087504797412
  - -0.6280484417532359
  train_level7__fp_micro_oob:
  - -0.5437610598306949
  - -0.5694916064852455
  - -0.5434946589775409
  - -0.552841197975934
  - -0.5559723448072963
  train_level7__fp_samples:
  - -0.5424697498684777
  - -0.5675785546893682
  - -0.5424483538944448
  - -0.5507590247681766
  - -0.55435422182995
  train_level7__fp_samples_masked:
  - -0.6136627261463744
  - -0.6421682655812456
  - -0.6143027347616391
  - -0.6225287501821388
  - -0.6269808707931034
  train_level7__fp_samples_oob:
  - -0.5437610598306949
  - -0.5694916064852455
  - -0.5434946589775409
  - -0.552841197975934
  - -0.5559723448072962
  train_level7__fp_weighted:
  - -0.45804598540550373
  - -0.4793060250017456
  - -0.45337955673801483
  - -0.46554720717239134
  - -0.4696304179977006
  train_level7__fp_weighted_masked:
  - -0.5430357115857907
  - -0.5690781110257921
  - -0.5371440154153689
  - -0.5514033767129968
  - -0.5561047864344856
  train_level7__fp_weighted_oob:
  - -0.45984901863117544
  - -0.4810761489857703
  - -0.45473333813965783
  - -0.4679879194494733
  - -0.4716396959939589
  train_level7__jaccard_macro:
  - 0.29824083049173883
  - 0.27854800746602815
  - 0.3002968753013855
  - 0.2927090892967685
  - 0.28882973258428035
  train_level7__jaccard_macro_masked:
  - 0.24853032070264675
  - 0.22646277036894347
  - 0.2501740567625846
  - 0.24305870915434644
  - 0.23781371325813427
  train_level7__jaccard_macro_oob:
  - 0.2964454577238363
  - 0.27638889491640073
  - 0.29880261630733435
  - 0.2903933031864701
  - 0.2869635174674404
  train_level7__jaccard_micro:
  - 0.282426361224834
  - 0.26439596655932995
  - 0.28271793751365526
  - 0.27618223670997544
  - 0.273928320449754
  train_level7__jaccard_micro_masked:
  - 0.22954670398320756
  - 0.209601259181532
  - 0.22902317375224782
  - 0.22317042501467013
  - 0.21991054486310654
  train_level7__jaccard_micro_oob:
  - 0.28079632465543647
  - 0.2621634673427502
  - 0.28133817637613606
  - 0.2739385901330907
  - 0.2720808383233533
  train_level7__jaccard_samples:
  - 0.28919792167612507
  - 0.27099361600987715
  - 0.28932568980019924
  - 0.28378223990936674
  - 0.28139979717987473
  train_level7__jaccard_samples_masked:
  - 0.23704748721985497
  - 0.21687019567880686
  - 0.23626975008806902
  - 0.23172755789473323
  - 0.22812585714902806
  train_level7__jaccard_samples_oob:
  - 0.2875307614320722
  - 0.2686086926704281
  - 0.2878930153527118
  - 0.281508388591478
  - 0.27940093277735556
  train_level7__jaccard_weighted:
  - 0.36644954867430496
  - 0.35071684550115334
  - 0.37205068466817237
  - 0.361739186674004
  - 0.358463515891592
  train_level7__jaccard_weighted_masked:
  - 0.2939018460423354
  - 0.2744520046092495
  - 0.29947408741694764
  - 0.2888586396418493
  - 0.2839102132343672
  train_level7__jaccard_weighted_oob:
  - 0.3637575598140088
  - 0.3481435940891186
  - 0.3701645677984718
  - 0.35880707719113636
  - 0.35598827715976256
  train_level7__label_ranking_average_precision_score:
  - 0.32130032461641606
  - 0.31148621449891034
  - 0.3289703869977761
  - 0.30797867262123024
  - 0.34916071591401887
  train_level7__label_ranking_average_precision_score_oob:
  - 0.32065695249710946
  - 0.31099105875787825
  - 0.32779317245574613
  - 0.30752687135225926
  - 0.347648463087987
  train_level7__matthews_corrcoef_macro:
  - 0.19014100346281604
  - 0.17449085052053478
  - 0.1975954214214973
  - 0.1795564935912698
  - 0.18278916035821155
  train_level7__matthews_corrcoef_macro_masked:
  - 0.13757281206312452
  - 0.12481812335537297
  - 0.14388406344378898
  - 0.12848341359339618
  - 0.12835749826489737
  train_level7__matthews_corrcoef_macro_oob:
  - 0.1851039672571593
  - 0.16746220534954942
  - 0.19208608851819017
  - 0.17361924951344476
  - 0.17634037203404804
  train_level7__matthews_corrcoef_micro:
  - 0.21675877817851275
  - 0.20517974880228687
  - 0.21832469403302535
  - 0.2115863839731361
  - 0.21183836920619326
  train_level7__matthews_corrcoef_micro_masked:
  - 0.15456530769220628
  - 0.1462318908890384
  - 0.15498542537569995
  - 0.15013158185905684
  - 0.14801013210605143
  train_level7__matthews_corrcoef_micro_oob:
  - 0.21233444631151674
  - 0.19903278605166635
  - 0.21441595401953106
  - 0.2063990216417715
  - 0.20715631270019302
  train_level7__matthews_corrcoef_samples:
  - 0.21537540464835062
  - 0.20303143254114642
  - 0.21620587293984647
  - 0.20913535587645474
  - 0.20810303814341383
  train_level7__matthews_corrcoef_samples_masked:
  - 0.15515534190803984
  - 0.1455330263974048
  - 0.15184781239310932
  - 0.14812723796967983
  - 0.14512048357159382
  train_level7__matthews_corrcoef_samples_oob:
  - 0.210801251191504
  - 0.19727375273875064
  - 0.2124782901735115
  - 0.20352653894209208
  - 0.2033107845350523
  train_level7__matthews_corrcoef_weighted:
  - 0.2097087984534672
  - 0.19131844413641538
  - 0.22263173139419534
  - 0.1982665493557245
  - 0.2073893841072689
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.15653378970762033
  - 0.1423683226480033
  - 0.1669244383329561
  - 0.1473544842540942
  - 0.152111681958816
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.20252989437380337
  - 0.18312023082158785
  - 0.21397284938269287
  - 0.1908268703842479
  - 0.19977473246072366
  train_level7__ndcg:
  - 0.6672218598172069
  - 0.6587300204060086
  - 0.6724239915848197
  - 0.6630306925054251
  - 0.6901353595681031
  train_level7__ndcg_oob:
  - 0.6681082168989846
  - 0.6594843776022499
  - 0.6722002426545473
  - 0.6635242629925555
  - 0.6896501594919114
  train_level7__neg_coverage_error:
  - -83.32019704433498
  - -84.48275862068965
  - -83.32832080200501
  - -83.93765586034912
  - -83.5909090909091
  train_level7__neg_coverage_error_oob:
  - -84.04926108374384
  - -85.3743842364532
  - -84.08521303258145
  - -84.81546134663341
  - -84.41414141414141
  train_level7__neg_hamming_loss_macro:
  - -0.5595437371466833
  - -0.5817829642737576
  - -0.5591892352239823
  - -0.5671742972665422
  - -0.569947043248014
  train_level7__neg_hamming_loss_macro_masked:
  - -0.618889984036048
  - -0.6451852444251971
  - -0.6188113112491819
  - -0.6273890179941941
  - -0.631616639337728
  train_level7__neg_hamming_loss_macro_oob:
  - -0.5615285283849061
  - -0.5845808025252284
  - -0.5608681898922062
  - -0.5699343873326391
  - -0.5722271256251837
  train_level7__neg_hamming_loss_micro:
  - -0.5595437371466833
  - -0.5817829642737578
  - -0.5591892352239823
  - -0.5671742972665423
  - -0.5699470432480142
  train_level7__neg_hamming_loss_micro_masked:
  - -0.6266157222990001
  - -0.6534374322272826
  - -0.627308616072661
  - -0.635095125829267
  - -0.639464474195878
  train_level7__neg_hamming_loss_micro_oob:
  - -0.561528528384906
  - -0.5845808025252284
  - -0.5608681898922062
  - -0.5699343873326392
  - -0.5722271256251839
  train_level7__neg_hamming_loss_samples:
  - -0.5595437371466833
  - -0.5817829642737578
  - -0.5591892352239823
  - -0.5671742972665423
  - -0.5699470432480142
  train_level7__neg_hamming_loss_samples_masked:
  - -0.6254610777309586
  - -0.6521178228991434
  - -0.6261400741245053
  - -0.6339700435865873
  - -0.6383356135278434
  train_level7__neg_hamming_loss_samples_oob:
  - -0.561528528384906
  - -0.5845808025252284
  - -0.5608681898922062
  - -0.5699343873326392
  - -0.5722271256251839
  train_level7__neg_hamming_loss_weighted:
  - -0.4803023656501017
  - -0.4970153017272773
  - -0.4757961508576059
  - -0.48697684301083777
  - -0.4896569114072264
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.5605162720378548
  - -0.5826532495076391
  - -0.5550307713202708
  - -0.5682377142393221
  - -0.5724174181775605
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.48304191850793454
  - -0.5000339056097962
  - -0.4777272080086803
  - -0.49026172705684967
  - -0.4923526529469411
  train_level7__neg_label_ranking_loss:
  - -0.3998061206632638
  - -0.41137705031453053
  - -0.3945561896347478
  - -0.43195676500801394
  - -0.37005436342410636
  train_level7__neg_label_ranking_loss_oob:
  - -0.4052481022609743
  - -0.4165767562182579
  - -0.40057693901310804
  - -0.43657317395999223
  - -0.37577463800960703
  train_level7__precision_macro:
  - 0.44045626285331674
  - 0.41821703572624236
  - 0.44081076477601766
  - 0.4328257027334578
  - 0.43005295675198596
  train_level7__precision_macro_masked:
  - 0.381110015963952
  - 0.35481475557480285
  - 0.3811886887508181
  - 0.3726109820058059
  - 0.36838336066227195
  train_level7__precision_macro_oob:
  - 0.43847147161509387
  - 0.4154191974747716
  - 0.4391318101077938
  - 0.4300656126673608
  - 0.4277728743748162
  train_level7__precision_micro:
  - 0.44045626285331674
  - 0.4182170357262423
  - 0.4408107647760177
  - 0.4328257027334576
  - 0.4300529567519859
  train_level7__precision_micro_masked:
  - 0.3733842777009999
  - 0.34656256777271743
  - 0.37269138392733897
  - 0.36490487417073303
  - 0.360535525804122
  train_level7__precision_micro_oob:
  - 0.438471471615094
  - 0.41541919747477163
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.42777287437481615
  train_level7__precision_samples:
  - 0.44045626285331674
  - 0.41821703572624225
  - 0.4408107647760177
  - 0.43282570273345755
  - 0.4300529567519859
  train_level7__precision_samples_masked:
  - 0.37453892226904134
  - 0.34788217710085645
  - 0.3738599258754947
  - 0.3660299564134128
  - 0.36166438647215665
  train_level7__precision_samples_oob:
  - 0.438471471615094
  - 0.4154191974747716
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.4277728743748161
  train_level7__precision_weighted:
  - 0.5196976343498984
  - 0.5029846982727227
  - 0.524203849142394
  - 0.5130231569891622
  - 0.5103430885927737
  train_level7__precision_weighted_masked:
  - 0.43948372796214524
  - 0.41734675049236086
  - 0.44496922867972916
  - 0.4317622857606777
  - 0.4275825818224396
  train_level7__precision_weighted_oob:
  - 0.5169580814920655
  - 0.4999660943902038
  - 0.5222727919913196
  - 0.5097382729431503
  - 0.5076473470530589
  train_level7__recall_macro:
  - 0.44045626285331674
  - 0.41821703572624236
  - 0.44081076477601766
  - 0.4328257027334578
  - 0.43005295675198596
  train_level7__recall_macro_masked:
  - 0.381110015963952
  - 0.35481475557480285
  - 0.3811886887508181
  - 0.3726109820058059
  - 0.36838336066227195
  train_level7__recall_macro_oob:
  - 0.43847147161509387
  - 0.4154191974747716
  - 0.4391318101077938
  - 0.4300656126673608
  - 0.4277728743748162
  train_level7__recall_micro:
  - 0.44045626285331674
  - 0.4182170357262423
  - 0.4408107647760177
  - 0.4328257027334576
  - 0.4300529567519859
  train_level7__recall_micro_masked:
  - 0.3733842777009999
  - 0.34656256777271743
  - 0.37269138392733897
  - 0.36490487417073303
  - 0.360535525804122
  train_level7__recall_micro_oob:
  - 0.438471471615094
  - 0.41541919747477163
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.42777287437481615
  train_level7__recall_samples:
  - 0.44045626285331674
  - 0.41821703572624225
  - 0.4408107647760177
  - 0.43282570273345755
  - 0.4300529567519859
  train_level7__recall_samples_masked:
  - 0.37453892226904134
  - 0.34788217710085645
  - 0.3738599258754947
  - 0.3660299564134128
  - 0.36166438647215665
  train_level7__recall_samples_oob:
  - 0.438471471615094
  - 0.4154191974747716
  - 0.43913181010779373
  - 0.4300656126673607
  - 0.4277728743748161
  train_level7__recall_weighted:
  - 0.5196976343498984
  - 0.5029846982727227
  - 0.524203849142394
  - 0.5130231569891622
  - 0.5103430885927737
  train_level7__recall_weighted_masked:
  - 0.43948372796214524
  - 0.41734675049236086
  - 0.44496922867972916
  - 0.4317622857606777
  - 0.4275825818224396
  train_level7__recall_weighted_oob:
  - 0.5169580814920655
  - 0.4999660943902038
  - 0.5222727919913196
  - 0.5097382729431503
  - 0.5076473470530589
  train_level7__roc_auc_macro:
  - 0.6787963115158023
  - 0.6759148438038617
  - 0.6937712289862801
  - 0.6697243299604577
  - 0.691104826144638
  train_level7__roc_auc_macro_masked:
  - 0.6578510929247875
  - 0.6564252436577797
  - 0.6783737836731312
  - 0.6482356968301353
  - 0.6708422096709223
  train_level7__roc_auc_macro_oob:
  - 0.6722561519187978
  - 0.6683547989842498
  - 0.6860292174432773
  - 0.6619096405886983
  - 0.6837458999681207
  train_level7__roc_auc_micro:
  - 0.6519181106593993
  - 0.6370642698383892
  - 0.658370276752638
  - 0.638457976363246
  - 0.6765522494053702
  train_level7__roc_auc_micro_masked:
  - 0.6348647707110027
  - 0.6213332916809846
  - 0.642311592402011
  - 0.6231097854687521
  - 0.6597153584522965
  train_level7__roc_auc_micro_oob:
  - 0.6496591121060799
  - 0.6343937430094109
  - 0.655239821631293
  - 0.6361802540095733
  - 0.6732009057842129
  train_level7__roc_auc_samples:
  - 0.6405010085709129
  - 0.6251771186238836
  - 0.645206019674931
  - 0.6251023387732936
  - 0.6655541509156923
  train_level7__roc_auc_samples_masked:
  - 0.6264518982163265
  - 0.6115793121342284
  - 0.629624511254614
  - 0.6096494185742861
  - 0.6501961177401894
  train_level7__roc_auc_samples_oob:
  - 0.6387479086421245
  - 0.6229713883814473
  - 0.6425435418895095
  - 0.6233183559231041
  - 0.6626013163195956
  train_level7__roc_auc_weighted:
  - 0.6773492811480831
  - 0.678486822081564
  - 0.6940210801296897
  - 0.674377719401095
  - 0.6923244869615435
  train_level7__roc_auc_weighted_masked:
  - 0.6565186549232075
  - 0.6582499557290409
  - 0.6756205002290055
  - 0.6545220523963721
  - 0.6719946298371061
  train_level7__roc_auc_weighted_oob:
  - 0.6701840598827898
  - 0.6698238208720807
  - 0.6848043514170398
  - 0.6660322167545757
  - 0.6843665914261265
  train_level7__tn_macro:
  - 0.22363575493806495
  - 0.1979052082835143
  - 0.22154901817650918
  - 0.21707866256688377
  - 0.2121457291360204
  train_level7__tn_macro_masked:
  - 0.2505495797264108
  - 0.22156533718067892
  - 0.2491379062232937
  - 0.24263285555932582
  - 0.23750235135132997
  train_level7__tn_macro_oob:
  - 0.2223444449758477
  - 0.1959921564876369
  - 0.2205027130934131
  - 0.21499648935912646
  - 0.2105276061586741
  train_level7__tn_micro:
  - 0.22363575493806495
  - 0.19790520828351427
  - 0.22154901817650924
  - 0.21707866256688377
  - 0.2121457291360204
  train_level7__tn_micro_masked:
  - 0.25342113107335446
  - 0.22435480373021036
  - 0.2513596333821053
  - 0.2457919842096606
  - 0.24034775845786346
  train_level7__tn_micro_oob:
  - 0.2223444449758477
  - 0.1959921564876369
  - 0.22050271309341316
  - 0.21499648935912646
  - 0.2105276061586741
  train_level7__tn_samples:
  - 0.22363575493806492
  - 0.19790520828351427
  - 0.2215490181765092
  - 0.21707866256688368
  - 0.21214572913602034
  train_level7__tn_samples_masked:
  - 0.2541792265759298
  - 0.22534208876877024
  - 0.25229427885400824
  - 0.24658020511442572
  - 0.24106943576336312
  train_level7__tn_samples_oob:
  - 0.22234444497584765
  - 0.19599215648763685
  - 0.2205027130934131
  - 0.21499648935912638
  - 0.2105276061586741
  train_level7__tn_weighted:
  - 0.1964845384864493
  - 0.17240826774481485
  - 0.19858130737711374
  - 0.18751301951607577
  - 0.18462952710642758
  train_level7__tn_weighted_masked:
  - 0.22836766107366702
  - 0.20043020555093435
  - 0.2325193503455538
  - 0.21840798395124864
  - 0.21571402628808728
  train_level7__tn_weighted_oob:
  - 0.19468150526077752
  - 0.17063814376079015
  - 0.19722752597547066
  - 0.18507230723899395
  - 0.18262024911016933
  train_level7__tp_macro:
  - 0.21682050791525181
  - 0.22031182744272806
  - 0.21926174659950842
  - 0.21574704016657378
  - 0.21790722761596543
  train_level7__tp_macro_masked:
  - 0.1305604362375412
  - 0.13324941839412405
  - 0.13205078252752445
  - 0.12997812644648005
  - 0.130881009310942
  train_level7__tp_macro_oob:
  - 0.21612702663924627
  - 0.21942704098713475
  - 0.21862909701438057
  - 0.21506912330823422
  - 0.21724526821614196
  train_level7__tp_micro:
  - 0.21682050791525181
  - 0.220311827442728
  - 0.21926174659950848
  - 0.21574704016657387
  - 0.21790722761596548
  train_level7__tp_micro_masked:
  - 0.11996314662764544
  - 0.12220776404250705
  - 0.1213317505452337
  - 0.11911288996107243
  - 0.12018776734625854
  train_level7__tp_micro_oob:
  - 0.21612702663924627
  - 0.21942704098713472
  - 0.2186290970143806
  - 0.21506912330823427
  - 0.217245268216142
  train_level7__tp_samples:
  - 0.21682050791525173
  - 0.22031182744272798
  - 0.2192617465995084
  - 0.2157470401665738
  - 0.21790722761596543
  train_level7__tp_samples_masked:
  - 0.12035969569311154
  - 0.12254008833208624
  - 0.12156564702148645
  - 0.11944975129898702
  - 0.12059495070879353
  train_level7__tp_samples_oob:
  - 0.21612702663924624
  - 0.21942704098713467
  - 0.21862909701438055
  - 0.2150691233082342
  - 0.21724526821614193
  train_level7__tp_weighted:
  - 0.3232130958634489
  - 0.3305764305279078
  - 0.32562254176528027
  - 0.32551013747308655
  - 0.32571356148634606
  train_level7__tp_weighted_masked:
  - 0.2111160668884783
  - 0.21691654494142645
  - 0.2124498783341754
  - 0.2133543018094292
  - 0.2118685555343524
  train_level7__tp_weighted_oob:
  - 0.32227657623128786
  - 0.32932795062941367
  - 0.32504526601584893
  - 0.32466596570415657
  - 0.3250270979428897
  train_level8__average_precision_macro:
  - 0.3487447342298964
  - 0.3424267183022278
  - 0.36856019243094656
  - 0.33483736776071227
  - 0.3602270380236819
  train_level8__average_precision_macro_masked:
  - 0.22250229517754874
  - 0.21835122480343158
  - 0.2420515132545459
  - 0.21476077256629442
  - 0.23378771852968622
  train_level8__average_precision_macro_oob:
  - 0.3443712915093685
  - 0.33721931399776855
  - 0.3637175302051247
  - 0.33012166465350684
  - 0.3569027298021643
  train_level8__average_precision_micro:
  - 0.3109853663093303
  - 0.29877745623952523
  - 0.3183784936119284
  - 0.29688373558494086
  - 0.33817705252292796
  train_level8__average_precision_micro_masked:
  - 0.17559239822490402
  - 0.16766183987105712
  - 0.18202531524187743
  - 0.1676275368441658
  - 0.19468934208926558
  train_level8__average_precision_micro_oob:
  - 0.31093569228400086
  - 0.29741677111649006
  - 0.3184997570317417
  - 0.2956073754619223
  - 0.3378615403189139
  train_level8__average_precision_samples:
  - 0.32159232716214703
  - 0.31230948649386114
  - 0.3283962396966068
  - 0.3073921612413783
  - 0.34953338183308674
  train_level8__average_precision_samples_masked:
  - 0.1937935620008785
  - 0.18874870095790078
  - 0.20139467757565005
  - 0.18403258281769017
  - 0.2161311703774339
  train_level8__average_precision_samples_oob:
  - 0.3215720119446031
  - 0.3113173690641674
  - 0.32829275040491807
  - 0.3062881766620252
  - 0.34909131188288156
  train_level8__average_precision_weighted:
  - 0.4744845251284637
  - 0.4738100683779266
  - 0.4961775674680008
  - 0.4649783969499781
  - 0.4890202505415201
  train_level8__average_precision_weighted_masked:
  - 0.32411848054994846
  - 0.32545039039304613
  - 0.3472360024086627
  - 0.3216599634133684
  - 0.3390969475914108
  train_level8__average_precision_weighted_oob:
  - 0.46922870845053927
  - 0.4673557051952456
  - 0.49086006483356204
  - 0.4595991079738466
  - 0.48489472365199654
  train_level8__f1_macro:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.4413460836557413
  - 0.4328741253661963
  - 0.43105815435912526
  train_level8__f1_macro_masked:
  - 0.38115969966389623
  - 0.3557795090343145
  - 0.3817588345653133
  - 0.3724027678100262
  - 0.3694692014863199
  train_level8__f1_macro_oob:
  - 0.43933234492323886
  - 0.4163278970778134
  - 0.43971579434021946
  - 0.4305982616274848
  - 0.4288516230263804
  train_level8__f1_micro:
  - 0.4405519154431106
  - 0.41914964847673253
  - 0.4413460836557413
  - 0.4328741253661962
  - 0.43105815435912526
  train_level8__f1_micro_masked:
  - 0.3734655719047232
  - 0.3475656039904576
  - 0.37327112608011487
  - 0.3647403914688305
  - 0.3616465751902672
  train_level8__f1_micro_oob:
  - 0.4393323449232388
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.4305982616274847
  - 0.4288516230263803
  train_level8__f1_samples:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.44134608365574124
  - 0.4328741253661961
  - 0.4310581543591252
  train_level8__f1_samples_masked:
  - 0.37464316119570595
  - 0.34887934376065693
  - 0.3744526492385632
  - 0.3659031892299384
  - 0.3627571209141404
  train_level8__f1_samples_oob:
  - 0.43933234492323875
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.43059826162748466
  - 0.4288516230263803
  train_level8__f1_weighted:
  - 0.5195719760287237
  - 0.5035922365697367
  - 0.5246831895699657
  - 0.5128283681244277
  - 0.5112896605704249
  train_level8__f1_weighted_masked:
  - 0.4392933686064284
  - 0.41802731507178886
  - 0.4454654968444983
  - 0.4312152141392353
  - 0.4284796924668445
  train_level8__f1_weighted_oob:
  - 0.5179681326468377
  - 0.5006454623494528
  - 0.5228242272864345
  - 0.5098399584519772
  - 0.5087333859383419
  train_level8__fn_macro:
  - -0.017097900425654025
  - -0.014228322731837963
  - -0.017008540769399227
  - -0.016148948018303754
  - -0.015494753358831029
  train_level8__fn_macro_masked:
  - -0.012606219753943517
  - -0.01050419649967586
  - -0.012920482064457317
  - -0.012003206462132973
  - -0.01192116640174259
  train_level8__fn_macro_oob:
  - -0.017528337079726435
  - -0.015041369745085848
  - -0.017568192325473877
  - -0.017141611989443865
  - -0.016107678729037952
  train_level8__fn_micro:
  - -0.017097900425654025
  - -0.014228322731837965
  - -0.017008540769399227
  - -0.016148948018303754
  - -0.015494753358831029
  train_level8__fn_micro_masked:
  - -0.011950247947321356
  - -0.010084580351333767
  - -0.012202191977472876
  - -0.011404133998574484
  - -0.011332703738681185
  train_level8__fn_micro_oob:
  - -0.017528337079726435
  - -0.015041369745085848
  - -0.01756819232547388
  - -0.017141611989443865
  - -0.016107678729037952
  train_level8__fn_samples:
  - -0.01709790042565402
  - -0.014228322731837963
  - -0.017008540769399224
  - -0.016148948018303754
  - -0.015494753358831026
  train_level8__fn_samples_masked:
  - -0.011846033251814119
  - -0.010038902379536375
  - -0.01216242068426287
  - -0.011354919752568084
  - -0.011270881290399323
  train_level8__fn_samples_oob:
  - -0.017528337079726432
  - -0.015041369745085848
  - -0.017568192325473877
  - -0.01714161198944386
  - -0.016107678729037952
  train_level8__fn_weighted:
  - -0.022326638103531377
  - -0.017783617914418223
  - -0.022714276153317614
  - -0.020989605452423794
  - -0.01988755679431866
  train_level8__fn_weighted_masked:
  - -0.017574595287025287
  - -0.013685810803566841
  - -0.018294182664590944
  - -0.016573455155356426
  - -0.01636899314829734
  train_level8__fn_weighted_oob:
  - -0.0228390923792635
  - -0.018881155061153163
  - -0.023279148484677
  - -0.02251462801958499
  - -0.020649852154472063
  train_level8__fp_macro:
  - -0.5423501841312353
  - -0.5666220287914295
  - -0.5416453755748594
  - -0.5509769266155
  - -0.5534470922820437
  train_level8__fp_macro_masked:
  - -0.6062340805821601
  - -0.6337162944660097
  - -0.6053206833702293
  - -0.6155940257278407
  - -0.6186096321119375
  train_level8__fp_macro_oob:
  - -0.5431393179970347
  - -0.5686307331771007
  - -0.5427160133343066
  - -0.5522601263830714
  - -0.5550406982445817
  train_level8__fp_micro:
  - -0.5423501841312354
  - -0.5666220287914295
  - -0.5416453755748595
  - -0.5509769266155001
  - -0.5534470922820437
  train_level8__fp_micro_masked:
  - -0.6145841801479555
  - -0.6423498156582086
  - -0.6145266819424123
  - -0.6238554745325949
  - -0.6270207210710516
  train_level8__fp_micro_oob:
  - -0.5431393179970347
  - -0.5686307331771008
  - -0.5427160133343066
  - -0.5522601263830714
  - -0.5550406982445817
  train_level8__fp_samples:
  - -0.5423501841312353
  - -0.5666220287914295
  - -0.5416453755748595
  - -0.5509769266155001
  - -0.5534470922820437
  train_level8__fp_samples_masked:
  - -0.6135108055524799
  - -0.6410817538598065
  - -0.6133849300771739
  - -0.6227418910174934
  - -0.6259719977954603
  train_level8__fp_samples_oob:
  - -0.5431393179970347
  - -0.5686307331771008
  - -0.5427160133343066
  - -0.5522601263830714
  - -0.5550406982445817
  train_level8__fp_weighted:
  - -0.458101385867745
  - -0.4786241455158449
  - -0.4526025342767166
  - -0.46618202642314854
  - -0.4688227826352564
  train_level8__fp_weighted_masked:
  - -0.5431320361065463
  - -0.5682868741246444
  - -0.5362403204909106
  - -0.5522113307054082
  - -0.5551513143848583
  train_level8__fp_weighted_oob:
  - -0.4591927749738989
  - -0.48047338258939404
  - -0.4538966242288886
  - -0.4676454135284378
  - -0.4706167619071862
  train_level8__jaccard_macro:
  - 0.29829909935396165
  - 0.2792703277386919
  - 0.30068561067778155
  - 0.2926566122220324
  - 0.28974379526649713
  train_level8__jaccard_macro_masked:
  - 0.24857930786600277
  - 0.2271497010432957
  - 0.2505452683390054
  - 0.2428064828430951
  - 0.2387328123701402
  train_level8__jaccard_macro_oob:
  - 0.29723967355963093
  - 0.27712651754906525
  - 0.29928957744328233
  - 0.2906963339172744
  - 0.28798158006891694
  train_level8__jaccard_micro:
  - 0.282505022004815
  - 0.265141889030072
  - 0.2831584863244661
  - 0.27622166947332644
  - 0.27474450729755917
  train_level8__jaccard_micro_masked:
  - 0.22960815673730509
  - 0.2103354933967681
  - 0.22946117946542216
  - 0.22304739233206483
  - 0.22073782720737828
  train_level8__jaccard_micro_oob:
  - 0.2815028193184604
  - 0.26288768761513603
  - 0.281817756499228
  - 0.27437096002838585
  - 0.2729542475500905
  train_level8__jaccard_samples:
  - 0.2892599951750534
  - 0.2718322637488044
  - 0.28983600679561117
  - 0.28388395335304883
  - 0.2821655651444719
  train_level8__jaccard_samples_masked:
  - 0.23708934235882032
  - 0.21770976102414621
  - 0.23679110498913242
  - 0.23166287486582507
  - 0.228880567940637
  train_level8__jaccard_samples_oob:
  - 0.28816576533783445
  - 0.26941634291598504
  - 0.28838366090013196
  - 0.28207396273517715
  - 0.2801943074443859
  train_level8__jaccard_weighted:
  - 0.3663155558480254
  - 0.35121674668193725
  - 0.37243849352110164
  - 0.3615287882026081
  - 0.35938210148056826
  train_level8__jaccard_weighted_masked:
  - 0.293769114657969
  - 0.27494977887536043
  - 0.2998385354867819
  - 0.288372879707294
  - 0.2847170703227489
  train_level8__jaccard_weighted_oob:
  - 0.3647720530157872
  - 0.34873273437186497
  - 0.3706722763777826
  - 0.3587938495617249
  - 0.3570329867873795
  train_level8__label_ranking_average_precision_score:
  - 0.3215923271621471
  - 0.31230948649386114
  - 0.3283962396966067
  - 0.3073921612413782
  - 0.3495333818330867
  train_level8__label_ranking_average_precision_score_oob:
  - 0.3215720119446029
  - 0.3113173690641673
  - 0.32829275040491834
  - 0.30628817666202535
  - 0.3490913118828819
  train_level8__matthews_corrcoef_macro:
  - 0.19022002291910445
  - 0.1755109694423749
  - 0.19680417589119317
  - 0.1800537290397512
  - 0.18405081940263945
  train_level8__matthews_corrcoef_macro_masked:
  - 0.13727189517443444
  - 0.12543946746464937
  - 0.14223619933137646
  - 0.12825434175208858
  - 0.12975705055314093
  train_level8__matthews_corrcoef_macro_oob:
  - 0.18742735480080996
  - 0.16775251386198173
  - 0.19181013563335936
  - 0.17355078844507074
  - 0.17847154361407708
  train_level8__matthews_corrcoef_micro:
  - 0.21676797218385838
  - 0.20602208228737703
  - 0.2179064150234505
  - 0.2126015180894016
  - 0.21318946899217328
  train_level8__matthews_corrcoef_micro_masked:
  - 0.1543347061183265
  - 0.14648717880394402
  - 0.15364517755210788
  - 0.15046117177412463
  - 0.14923984809363108
  train_level8__matthews_corrcoef_micro_oob:
  - 0.21403536120375571
  - 0.20013047688386468
  - 0.2143089497650862
  - 0.2067519517678523
  - 0.2087660614784258
  train_level8__matthews_corrcoef_samples:
  - 0.21526318498221828
  - 0.20360677380392225
  - 0.21599404152029875
  - 0.20981140228493403
  - 0.2094681436377835
  train_level8__matthews_corrcoef_samples_masked:
  - 0.15508590886620477
  - 0.14537452153718247
  - 0.1507565870478138
  - 0.14843048068694273
  - 0.1467218355533544
  train_level8__matthews_corrcoef_samples_oob:
  - 0.21252313230098166
  - 0.19843653716680015
  - 0.21253925928361367
  - 0.20374421629667747
  - 0.20485298697231516
  train_level8__matthews_corrcoef_weighted:
  - 0.20937806753928886
  - 0.19282788871150383
  - 0.22136005397633612
  - 0.1987241260788927
  - 0.20901786960696786
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.15589174012861354
  - 0.14361878080563228
  - 0.16471373050490679
  - 0.14756271456503672
  - 0.15293774018030817
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.20610908697497057
  - 0.18310069567549345
  - 0.21422485075682182
  - 0.19002023779653265
  - 0.2017636830742992
  train_level8__ndcg:
  - 0.6680867456619547
  - 0.6609412257845731
  - 0.6728953338660262
  - 0.6624799704682368
  - 0.6899412104248801
  train_level8__ndcg_oob:
  - 0.6696277256350076
  - 0.6606891938380515
  - 0.6742812821748085
  - 0.662126825380556
  - 0.6906590544084258
  train_level8__neg_coverage_error:
  - -83.2192118226601
  - -84.53940886699507
  - -83.27568922305764
  - -83.91521197007481
  - -83.59343434343434
  train_level8__neg_coverage_error_oob:
  - -84.16009852216749
  - -85.35714285714286
  - -83.98997493734336
  - -84.88029925187033
  - -84.38888888888889
  train_level8__neg_hamming_loss_macro:
  - -0.5594480845568894
  - -0.5808503515232675
  - -0.5586539163442588
  - -0.5671258746338037
  - -0.5689418456408746
  train_level8__neg_hamming_loss_macro_masked:
  - -0.6188403003361038
  - -0.6442204909656857
  - -0.6182411654346867
  - -0.6275972321899739
  - -0.6305307985136801
  train_level8__neg_hamming_loss_macro_oob:
  - -0.5606676550767612
  - -0.5836721029221865
  - -0.5602842056597805
  - -0.5694017383725152
  - -0.5711483769736195
  train_level8__neg_hamming_loss_micro:
  - -0.5594480845568893
  - -0.5808503515232675
  - -0.5586539163442586
  - -0.5671258746338038
  - -0.5689418456408748
  train_level8__neg_hamming_loss_micro_masked:
  - -0.6265344280952768
  - -0.6524343960095424
  - -0.6267288739198852
  - -0.6352596085311695
  - -0.6383534248097328
  train_level8__neg_hamming_loss_micro_oob:
  - -0.5606676550767612
  - -0.5836721029221866
  - -0.5602842056597805
  - -0.5694017383725153
  - -0.5711483769736196
  train_level8__neg_hamming_loss_samples:
  - -0.5594480845568893
  - -0.5808503515232675
  - -0.5586539163442586
  - -0.5671258746338038
  - -0.5689418456408747
  train_level8__neg_hamming_loss_samples_masked:
  - -0.625356838804294
  - -0.651120656239343
  - -0.6255473507614369
  - -0.6340968107700616
  - -0.6372428790858596
  train_level8__neg_hamming_loss_samples_oob:
  - -0.5606676550767612
  - -0.5836721029221866
  - -0.5602842056597804
  - -0.5694017383725153
  - -0.5711483769736198
  train_level8__neg_hamming_loss_weighted:
  - -0.4804280239712763
  - -0.4964077634302632
  - -0.4753168104300343
  - -0.4871716318755724
  - -0.4887103394295751
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.5607066313935715
  - -0.581972684928211
  - -0.5545345031555016
  - -0.5687847858607646
  - -0.5715203075331555
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.48203186735316234
  - -0.49935453765054716
  - -0.4771757727135654
  - -0.49016004154802273
  - -0.49126661406165806
  train_level8__neg_label_ranking_loss:
  - -0.40365323368516676
  - -0.41333212500901406
  - -0.3922343793930374
  - -0.43493052154530126
  - -0.37049191729291425
  train_level8__neg_label_ranking_loss_oob:
  - -0.4096371916127342
  - -0.41843853228843325
  - -0.3983192762170214
  - -0.4398547993996012
  - -0.3762560556809877
  train_level8__precision_macro:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.4413460836557413
  - 0.4328741253661963
  - 0.43105815435912526
  train_level8__precision_macro_masked:
  - 0.38115969966389623
  - 0.3557795090343145
  - 0.3817588345653133
  - 0.3724027678100262
  - 0.3694692014863199
  train_level8__precision_macro_oob:
  - 0.43933234492323886
  - 0.4163278970778134
  - 0.43971579434021946
  - 0.4305982616274848
  - 0.4288516230263804
  train_level8__precision_micro:
  - 0.4405519154431106
  - 0.41914964847673253
  - 0.4413460836557413
  - 0.4328741253661962
  - 0.43105815435912526
  train_level8__precision_micro_masked:
  - 0.3734655719047232
  - 0.3475656039904576
  - 0.37327112608011487
  - 0.3647403914688305
  - 0.3616465751902672
  train_level8__precision_micro_oob:
  - 0.4393323449232388
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.4305982616274847
  - 0.4288516230263803
  train_level8__precision_samples:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.44134608365574124
  - 0.4328741253661961
  - 0.4310581543591252
  train_level8__precision_samples_masked:
  - 0.37464316119570595
  - 0.34887934376065693
  - 0.3744526492385632
  - 0.3659031892299384
  - 0.3627571209141404
  train_level8__precision_samples_oob:
  - 0.43933234492323875
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.43059826162748466
  - 0.4288516230263803
  train_level8__precision_weighted:
  - 0.5195719760287237
  - 0.5035922365697367
  - 0.5246831895699657
  - 0.5128283681244277
  - 0.5112896605704249
  train_level8__precision_weighted_masked:
  - 0.4392933686064284
  - 0.41802731507178886
  - 0.4454654968444983
  - 0.4312152141392353
  - 0.4284796924668445
  train_level8__precision_weighted_oob:
  - 0.5179681326468377
  - 0.5006454623494528
  - 0.5228242272864345
  - 0.5098399584519772
  - 0.5087333859383419
  train_level8__recall_macro:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.4413460836557413
  - 0.4328741253661963
  - 0.43105815435912526
  train_level8__recall_macro_masked:
  - 0.38115969966389623
  - 0.3557795090343145
  - 0.3817588345653133
  - 0.3724027678100262
  - 0.3694692014863199
  train_level8__recall_macro_oob:
  - 0.43933234492323886
  - 0.4163278970778134
  - 0.43971579434021946
  - 0.4305982616274848
  - 0.4288516230263804
  train_level8__recall_micro:
  - 0.4405519154431106
  - 0.41914964847673253
  - 0.4413460836557413
  - 0.4328741253661962
  - 0.43105815435912526
  train_level8__recall_micro_masked:
  - 0.3734655719047232
  - 0.3475656039904576
  - 0.37327112608011487
  - 0.3647403914688305
  - 0.3616465751902672
  train_level8__recall_micro_oob:
  - 0.4393323449232388
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.4305982616274847
  - 0.4288516230263803
  train_level8__recall_samples:
  - 0.4405519154431106
  - 0.4191496484767325
  - 0.44134608365574124
  - 0.4328741253661961
  - 0.4310581543591252
  train_level8__recall_samples_masked:
  - 0.37464316119570595
  - 0.34887934376065693
  - 0.3744526492385632
  - 0.3659031892299384
  - 0.3627571209141404
  train_level8__recall_samples_oob:
  - 0.43933234492323875
  - 0.41632789707781337
  - 0.43971579434021946
  - 0.43059826162748466
  - 0.4288516230263803
  train_level8__recall_weighted:
  - 0.5195719760287237
  - 0.5035922365697367
  - 0.5246831895699657
  - 0.5128283681244277
  - 0.5112896605704249
  train_level8__recall_weighted_masked:
  - 0.4392933686064284
  - 0.41802731507178886
  - 0.4454654968444983
  - 0.4312152141392353
  - 0.4284796924668445
  train_level8__recall_weighted_oob:
  - 0.5179681326468377
  - 0.5006454623494528
  - 0.5228242272864345
  - 0.5098399584519772
  - 0.5087333859383419
  train_level8__roc_auc_macro:
  - 0.6804516968153503
  - 0.6748131012782523
  - 0.6941940800521138
  - 0.6673431001089328
  - 0.6914988104268087
  train_level8__roc_auc_macro_masked:
  - 0.65981403401853
  - 0.6542003100802896
  - 0.6796100545859003
  - 0.6461546720289568
  - 0.6703310965901367
  train_level8__roc_auc_macro_oob:
  - 0.6737725352091554
  - 0.6672812735313601
  - 0.6872937202877967
  - 0.6589373614602801
  - 0.6848456099984337
  train_level8__roc_auc_micro:
  - 0.6518330407105165
  - 0.6364864135794659
  - 0.6571590234554912
  - 0.6365446636741048
  - 0.6767702836034118
  train_level8__roc_auc_micro_masked:
  - 0.6341484801385819
  - 0.6201795175660059
  - 0.6414812038785349
  - 0.621813161999349
  - 0.6592183620269145
  train_level8__roc_auc_micro_oob:
  - 0.6499086845567457
  - 0.6335581684175385
  - 0.6551502078936916
  - 0.6338753897635263
  - 0.6743191901770972
  train_level8__roc_auc_samples:
  - 0.6403013093444794
  - 0.6256276979688126
  - 0.6442635450535462
  - 0.6237266112523439
  - 0.6666286937802851
  train_level8__roc_auc_samples_masked:
  - 0.6252364599641751
  - 0.6107646576760075
  - 0.6289739194025323
  - 0.6088607675154373
  - 0.6504976960086547
  train_level8__roc_auc_samples_oob:
  - 0.6386072813063862
  - 0.6233514901533026
  - 0.642518443456932
  - 0.6213590199746549
  - 0.6645189536470095
  train_level8__roc_auc_weighted:
  - 0.6790802601640498
  - 0.6772556786911524
  - 0.693485743688186
  - 0.6710193739334075
  - 0.6930204450756289
  train_level8__roc_auc_weighted_masked:
  - 0.6577490418408543
  - 0.6566140072984943
  - 0.6752594273441218
  - 0.6513680314247051
  - 0.6720024917290603
  train_level8__roc_auc_weighted_oob:
  - 0.6715735564517699
  - 0.6686285172746544
  - 0.6854486424828629
  - 0.6621021709143404
  - 0.6858385235446686
  train_level8__tn_macro:
  - 0.2237553206753073
  - 0.19886173418145295
  - 0.22235199649609458
  - 0.21686076071956034
  - 0.21305285868392668
  train_level8__tn_macro_masked:
  - 0.2506579532333985
  - 0.22261481245030423
  - 0.2500483767755461
  - 0.2423216892621715
  - 0.23852090114947044
  train_level8__tn_macro_oob:
  - 0.2229661868095079
  - 0.19685302979578173
  - 0.22128135873664737
  - 0.21557756095198893
  - 0.21145925272138866
  train_level8__tn_micro:
  - 0.2237553206753073
  - 0.19886173418145298
  - 0.2223519964960946
  - 0.2168607607195603
  - 0.21305285868392665
  train_level8__tn_micro_masked:
  - 0.25355662141289326
  - 0.2254391672088484
  - 0.2522706567650388
  - 0.24554526015680683
  - 0.24137547914004778
  train_level8__tn_micro_oob:
  - 0.22296618680950786
  - 0.19685302979578173
  - 0.22128135873664745
  - 0.21557756095198896
  - 0.21145925272138866
  train_level8__tn_samples:
  - 0.22375532067530723
  - 0.19886173418145292
  - 0.22235199649609458
  - 0.21686076071956029
  - 0.21305285868392662
  train_level8__tn_samples_masked:
  - 0.25433114716982436
  - 0.22642860049020921
  - 0.2532120835384735
  - 0.2463670642790711
  - 0.24207830876100628
  train_level8__tn_samples_oob:
  - 0.22296618680950783
  - 0.1968530297957817
  - 0.2212813587366474
  - 0.21557756095198893
  - 0.2114592527213886
  train_level8__tn_weighted:
  - 0.196429138024208
  - 0.17309014723071536
  - 0.19935832983841187
  - 0.18687820026531854
  - 0.18543716246887182
  train_level8__tn_weighted_masked:
  - 0.22827133655291143
  - 0.20122144245208207
  - 0.23342304527001206
  - 0.21760002995883726
  - 0.21666749833771445
  train_level8__tn_weighted_oob:
  - 0.19533774891805417
  - 0.17124091015716628
  - 0.19806423988623997
  - 0.18541481316002933
  - 0.18364318319694212
  train_level8__tp_macro:
  - 0.21679659476780333
  - 0.22028791429527955
  - 0.21899408715964666
  - 0.21601336464663576
  - 0.21800529567519855
  train_level8__tp_macro_masked:
  - 0.13050174643049772
  - 0.13316469658401017
  - 0.1317104577897673
  - 0.13008107854785467
  - 0.13094830033684948
  train_level8__tp_macro_oob:
  - 0.21636615811373092
  - 0.2194748672820317
  - 0.218434435603572
  - 0.21502070067549564
  - 0.21739237030499164
  train_level8__tp_micro:
  - 0.21679659476780333
  - 0.22028791429527955
  - 0.2189940871596467
  - 0.21601336464663584
  - 0.21800529567519858
  train_level8__tp_micro_masked:
  - 0.11990895049182994
  - 0.1221264367816092
  - 0.12100046931507606
  - 0.11919513131202368
  - 0.12027109605021943
  train_level8__tp_micro_oob:
  - 0.21636615811373092
  - 0.21947486728203167
  - 0.21843443560357204
  - 0.21502070067549572
  - 0.21739237030499167
  train_level8__tp_samples:
  - 0.21679659476780327
  - 0.2202879142952795
  - 0.2189940871596466
  - 0.21601336464663576
  - 0.21800529567519852
  train_level8__tp_samples_masked:
  - 0.12031201402588163
  - 0.12245074327044778
  - 0.1212405657000897
  - 0.11953612495086735
  - 0.12067881215313417
  train_level8__tp_samples_oob:
  - 0.2163661581137309
  - 0.21947486728203158
  - 0.218434435603572
  - 0.21502070067549567
  - 0.21739237030499162
  train_level8__tp_weighted:
  - 0.3231428380045156
  - 0.3305020893390214
  - 0.32532485973155384
  - 0.3259501678591092
  - 0.3258524981015531
  train_level8__tp_weighted_masked:
  - 0.211022032053517
  - 0.21680587261970677
  - 0.2120424515744864
  - 0.21361518418039802
  - 0.21181219412912988
  train_level8__tp_weighted_oob:
  - 0.3226303837287835
  - 0.3294045521922865
  - 0.32475998740019446
  - 0.32442514529194794
  - 0.3250902027413997
  train_level9__average_precision_macro:
  - 0.34608979313140775
  - 0.34326623595749234
  - 0.36970115927664404
  - 0.3364125421276861
  - 0.3565024091486094
  train_level9__average_precision_macro_masked:
  - 0.220949998737177
  - 0.21973992787502794
  - 0.2421478138291616
  - 0.2158394383505142
  - 0.23096066838526905
  train_level9__average_precision_macro_oob:
  - 0.3417455601415259
  - 0.33804020008354646
  - 0.364172916814933
  - 0.33399306239391285
  - 0.3521327086408829
  train_level9__average_precision_micro:
  - 0.3104554027046475
  - 0.29779345541584745
  - 0.3215928170872735
  - 0.2975545271436645
  - 0.33684943311520665
  train_level9__average_precision_micro_masked:
  - 0.17552805205904437
  - 0.16738070774920671
  - 0.18374908993660388
  - 0.16799145224584044
  - 0.19440782379192104
  train_level9__average_precision_micro_oob:
  - 0.3101972277711267
  - 0.2974339966127897
  - 0.3209838435830795
  - 0.2974197394559467
  - 0.3355164337513124
  train_level9__average_precision_samples:
  - 0.3215835268031359
  - 0.31061418717952394
  - 0.3300453483005838
  - 0.3066927906998897
  - 0.3496587695873881
  train_level9__average_precision_samples_masked:
  - 0.19444417597169478
  - 0.1878415053467382
  - 0.20215256892651975
  - 0.18364558491442867
  - 0.2172321191568925
  train_level9__average_precision_samples_oob:
  - 0.321401215460836
  - 0.3103663997236293
  - 0.32927339777860554
  - 0.30668001608293993
  - 0.3488598622175383
  train_level9__average_precision_weighted:
  - 0.47209100572476187
  - 0.4752642318937209
  - 0.49806111252147917
  - 0.46797715718496513
  - 0.4847466369216526
  train_level9__average_precision_weighted_masked:
  - 0.3223846576564501
  - 0.3273431039274539
  - 0.3486452815314278
  - 0.3251608640463097
  - 0.3360292628116847
  train_level9__average_precision_weighted_oob:
  - 0.4673199404070349
  - 0.4685438987751857
  - 0.4914035951290002
  - 0.4646495821606765
  - 0.4803525630505674
  train_level9__f1_macro:
  - 0.4405997417380076
  - 0.4195083456884595
  - 0.44081076477601766
  - 0.4332372951117353
  - 0.4313278415220163
  train_level9__f1_macro_masked:
  - 0.38106929828159547
  - 0.35619983509976544
  - 0.3812027209775095
  - 0.372906272658007
  - 0.36979256989046017
  train_level9__f1_macro_oob:
  - 0.43947582380792966
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206965
  - 0.4287535549671473
  train_level9__f1_micro:
  - 0.44059974173800753
  - 0.4195083456884595
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__f1_micro_masked:
  - 0.3733842777009999
  - 0.3479722402949469
  - 0.37271899069651876
  - 0.36517901200723724
  - 0.36195211377145714
  train_level9__f1_micro_oob:
  - 0.4394758238079296
  - 0.4166865942895404
  - 0.4393021388422513
  - 0.4307677408420696
  - 0.4287535549671472
  train_level9__f1_samples:
  - 0.44059974173800753
  - 0.41950834568845957
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__f1_samples_masked:
  - 0.3745450280480926
  - 0.3492935664102341
  - 0.37389464137535205
  - 0.36635186832283245
  - 0.36308247718778514
  train_level9__f1_samples_oob:
  - 0.4394758238079296
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206954
  - 0.4287535549671471
  train_level9__f1_weighted:
  - 0.519680762390943
  - 0.5040455671303447
  - 0.5242302064057968
  - 0.5135950404518477
  - 0.51162241906677
  train_level9__f1_weighted_masked:
  - 0.4391361949933262
  - 0.4185473722004494
  - 0.4448856621415024
  - 0.43221475106341056
  - 0.4289386578421046
  train_level9__f1_weighted_oob:
  - 0.5175992159323671
  - 0.5012663117377203
  - 0.5222417834461398
  - 0.5102950726219179
  - 0.5083054399518071
  train_level9__fn_macro:
  - -0.01697833468841169
  - -0.014371801616528766
  - -0.016935542740346008
  - -0.016173159334673025
  - -0.01547023634402275
  train_level9__fn_macro_masked:
  - -0.01261820806395786
  - -0.010658189030439276
  - -0.012779450418815064
  - -0.012007420063889052
  - -0.011878728118590509
  train_level9__fn_macro_oob:
  - -0.017408771342484104
  - -0.01501745659763738
  - -0.01747086162006959
  - -0.01711740067307459
  - -0.01632833186231244
  train_level9__fn_micro:
  - -0.01697833468841169
  - -0.014371801616528767
  - -0.01693554274034601
  - -0.016173159334673025
  - -0.015470236344022751
  train_level9__fn_micro_masked:
  - -0.011950247947321356
  - -0.010247234873129472
  - -0.012064158131573861
  - -0.011404133998574484
  - -0.011304927504027553
  train_level9__fn_micro_oob:
  - -0.017408771342484097
  - -0.01501745659763738
  - -0.01747086162006959
  - -0.017117400673074594
  - -0.016328331862312445
  train_level9__fn_samples:
  - -0.016978334688411686
  - -0.014371801616528767
  - -0.01693554274034601
  - -0.016173159334673025
  - -0.015470236344022751
  train_level9__fn_samples_masked:
  - -0.011845361285696309
  - -0.01019377216926866
  - -0.01202164855666956
  - -0.011358660218160769
  - -0.011247191784968726
  train_level9__fn_samples_oob:
  - -0.017408771342484097
  - -0.015017456597637379
  - -0.01747086162006959
  - -0.017117400673074594
  - -0.016328331862312445
  train_level9__fn_weighted:
  - -0.022174790472933602
  - -0.017868507515241203
  - -0.022563109495565906
  - -0.02104994058809593
  - -0.019779907432154388
  train_level9__fn_weighted_masked:
  - -0.0176775851697213
  - -0.01377623415339991
  - -0.0181290723181386
  - -0.016611499716316837
  - -0.016214583132071903
  train_level9__fn_weighted_oob:
  - -0.022843625144355974
  - -0.0188060604142713
  - -0.023300854466302888
  - -0.022533092651622587
  - -0.02101018585688892
  train_level9__fp_macro:
  - -0.5424219235735808
  - -0.5661198526950117
  - -0.5422536924836362
  - -0.5505895455535917
  - -0.5532019221339609
  train_level9__fp_macro_masked:
  - -0.6063124936544466
  - -0.6331419758697951
  - -0.6060178286036755
  - -0.615086307278104
  - -0.6183287019909492
  train_level9__fp_macro_oob:
  - -0.5431154048495863
  - -0.5682959491128223
  - -0.5432269995376792
  - -0.5521148584848559
  - -0.5549181131705404
  train_level9__fp_micro:
  - -0.5424219235735808
  - -0.5661198526950117
  - -0.5422536924836363
  - -0.5505895455535917
  - -0.553201922133961
  train_level9__fp_micro_masked:
  - -0.6146654743516787
  - -0.6417805248319237
  - -0.6152168511719074
  - -0.6234168539941882
  - -0.6267429587245154
  train_level9__fp_micro_oob:
  - -0.5431154048495863
  - -0.5682959491128222
  - -0.5432269995376792
  - -0.5521148584848559
  - -0.5549181131705404
  train_level9__fp_samples:
  - -0.5424219235735807
  - -0.5661198526950117
  - -0.5422536924836363
  - -0.5505895455535917
  - -0.5532019221339609
  train_level9__fp_samples_masked:
  - -0.6136096106662111
  - -0.6405126614204973
  - -0.6140837100679784
  - -0.6222894714590067
  - -0.6256703310272461
  train_level9__fp_samples_oob:
  - -0.5431154048495863
  - -0.5682959491128222
  - -0.5432269995376792
  - -0.5521148584848558
  - -0.5549181131705403
  train_level9__fp_weighted:
  - -0.4581444471361234
  - -0.478085925354414
  - -0.4532066840986372
  - -0.46535501896005643
  - -0.4685976735010755
  train_level9__fp_weighted_masked:
  - -0.5431862198369525
  - -0.5676763936461506
  - -0.5369852655403591
  - -0.5511737492202727
  - -0.5548467590258236
  train_level9__fp_weighted_oob:
  - -0.4595571589232769
  - -0.4799276278480084
  - -0.4544573620875572
  - -0.46717183472645957
  - -0.47068437419130416
  train_level9__jaccard_macro:
  - 0.29842482910050594
  - 0.27958384971380423
  - 0.3002084500444563
  - 0.2930363171112137
  - 0.2899103409096474
  train_level9__jaccard_macro_masked:
  - 0.24855773108303264
  - 0.22749198282190036
  - 0.2500960730837472
  - 0.24326117939454092
  - 0.23890937802334494
  train_level9__jaccard_macro_oob:
  - 0.2973314628441626
  - 0.2774505679460532
  - 0.2988726948493034
  - 0.29090804664821823
  - 0.287739023779333
  train_level9__jaccard_micro:
  - 0.282544356013556
  - 0.26542901668860547
  - 0.28271793751365526
  - 0.2765174928915812
  - 0.2749636622227779
  train_level9__jaccard_micro_masked:
  - 0.22954670398320756
  - 0.21063340991138826
  - 0.22904402409025362
  - 0.2233755345015511
  - 0.22096552659691723
  train_level9__jaccard_micro_oob:
  - 0.28162064421220384
  - 0.2631737928742958
  - 0.28147801683816653
  - 0.27450859382232234
  - 0.2728747971539134
  train_level9__jaccard_samples:
  - 0.2893061333571124
  - 0.2720887801749607
  - 0.28938981223217675
  - 0.284189131607939
  - 0.28241986327729346
  train_level9__jaccard_samples_masked:
  - 0.23703958621620855
  - 0.21797622873192862
  - 0.23636130061789246
  - 0.23200169711313712
  - 0.2291671163069493
  train_level9__jaccard_samples_oob:
  - 0.2883129362231518
  - 0.2696950333494487
  - 0.28811254047342744
  - 0.28210416219409074
  - 0.280179001311567
  train_level9__jaccard_weighted:
  - 0.36644686555505906
  - 0.3516315600845534
  - 0.372002155325126
  - 0.3622575770959356
  - 0.3597065494564854
  train_level9__jaccard_weighted_masked:
  - 0.29361002694362714
  - 0.2753896888378162
  - 0.2993457174651011
  - 0.2892217085331652
  - 0.2850881062933703
  train_level9__jaccard_weighted_oob:
  - 0.36435473927629053
  - 0.3492719630158527
  - 0.3701014270299866
  - 0.3592074867971348
  - 0.3565598768356255
  train_level9__label_ranking_average_precision_score:
  - 0.32158352680313573
  - 0.310614187179524
  - 0.33004534830058374
  - 0.30669279069988986
  - 0.3496587695873883
  train_level9__label_ranking_average_precision_score_oob:
  - 0.3214012154608357
  - 0.3103663997236294
  - 0.32927339777860565
  - 0.30668001608293993
  - 0.3488598622175384
  train_level9__matthews_corrcoef_macro:
  - 0.1908439988207273
  - 0.17490398427497414
  - 0.19572238421331112
  - 0.18073546347161143
  - 0.18406098821138403
  train_level9__matthews_corrcoef_macro_masked:
  - 0.13749927380508734
  - 0.12375123167064138
  - 0.14178947378700776
  - 0.12881375070968493
  - 0.12979489515815112
  train_level9__matthews_corrcoef_macro_oob:
  - 0.18748981414464683
  - 0.16875340046677811
  - 0.19263481689389922
  - 0.174406381020997
  - 0.17771358157658101
  train_level9__matthews_corrcoef_micro:
  - 0.21724026341217378
  - 0.20584081439078988
  - 0.2176345069234166
  - 0.21287048185879456
  - 0.21354501823823868
  train_level9__matthews_corrcoef_micro_masked:
  - 0.1542780460841223
  - 0.14587225628177242
  - 0.1539848679902651
  - 0.15076614812872763
  - 0.14960392123238198
  train_level9__matthews_corrcoef_micro_oob:
  - 0.21460176574988576
  - 0.20058216074022217
  - 0.21424109739518643
  - 0.20700768494464838
  - 0.20786342295366525
  train_level9__matthews_corrcoef_samples:
  - 0.21578371211706324
  - 0.20363875412048046
  - 0.21555667034319737
  - 0.2102110036153201
  - 0.20973546024183123
  train_level9__matthews_corrcoef_samples_masked:
  - 0.15497228216636266
  - 0.14505816210230812
  - 0.15104135299722748
  - 0.14889816706565856
  - 0.14700532133545965
  train_level9__matthews_corrcoef_samples_oob:
  - 0.21290996094946227
  - 0.19876953577879677
  - 0.2119330198313758
  - 0.20415458291538688
  - 0.2040333586158623
  train_level9__matthews_corrcoef_weighted:
  - 0.2105415922858999
  - 0.1926206021079654
  - 0.21958964953982707
  - 0.19999040611164712
  - 0.20950666418141128
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.156106712512922
  - 0.14246177007047758
  - 0.16348571949041366
  - 0.14857165346488363
  - 0.1536754109073641
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.20366699423796636
  - 0.1849260241968248
  - 0.21447116718684525
  - 0.1910236353525944
  - 0.20037771153955197
  train_level9__ndcg:
  - 0.6690471759650565
  - 0.6586553835169846
  - 0.6748358567643009
  - 0.6619712268027155
  - 0.6903094250979547
  train_level9__ndcg_oob:
  - 0.6703027792824373
  - 0.6597216285398262
  - 0.675955611088445
  - 0.6629293085540713
  - 0.6902377142051613
  train_level9__neg_coverage_error:
  - -83.22167487684729
  - -84.52463054187191
  - -83.25814536340852
  - -83.91271820448878
  - -83.57070707070707
  train_level9__neg_coverage_error_oob:
  - -84.15270935960591
  - -85.35221674876847
  - -83.93984962406014
  - -84.85536159600997
  - -84.35353535353535
  train_level9__neg_hamming_loss_macro:
  - -0.5594002582619924
  - -0.5804916543115406
  - -0.5591892352239823
  - -0.5667627048882646
  - -0.5686721584779836
  train_level9__neg_hamming_loss_macro_masked:
  - -0.6189307017184045
  - -0.6438001649002346
  - -0.6187972790224905
  - -0.627093727341993
  - -0.6302074301095398
  train_level9__neg_hamming_loss_macro_oob:
  - -0.5605241761920704
  - -0.5833134057104596
  - -0.5606978611577488
  - -0.5692322591579303
  - -0.5712464450328527
  train_level9__neg_hamming_loss_micro:
  - -0.5594002582619925
  - -0.5804916543115405
  - -0.5591892352239823
  - -0.5667627048882647
  - -0.5686721584779837
  train_level9__neg_hamming_loss_micro_masked:
  - -0.6266157222990001
  - -0.6520277597050531
  - -0.6272810093034812
  - -0.6348209879927628
  - -0.6380478862285428
  train_level9__neg_hamming_loss_micro_oob:
  - -0.5605241761920704
  - -0.5833134057104596
  - -0.5606978611577488
  - -0.5692322591579304
  - -0.5712464450328528
  train_level9__neg_hamming_loss_samples:
  - -0.5594002582619925
  - -0.5804916543115404
  - -0.5591892352239823
  - -0.5667627048882647
  - -0.5686721584779837
  train_level9__neg_hamming_loss_samples_masked:
  - -0.6254549719519074
  - -0.650706433589766
  - -0.626105358624648
  - -0.6336481316771676
  - -0.6369175228122148
  train_level9__neg_hamming_loss_samples_oob:
  - -0.5605241761920704
  - -0.5833134057104595
  - -0.5606978611577487
  - -0.5692322591579304
  - -0.5712464450328528
  train_level9__neg_hamming_loss_weighted:
  - -0.480319237609057
  - -0.49595443286965535
  - -0.47576979359420324
  - -0.4864049595481524
  - -0.48837758093322997
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.5608638050066738
  - -0.5814526277995508
  - -0.5551143378584976
  - -0.5677852489365893
  - -0.5710613421578953
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.48240078406763287
  - -0.49873368826227965
  - -0.47775821655386014
  - -0.48970492737808213
  - -0.4916945600481929
  train_level9__neg_label_ranking_loss:
  - -0.4034684545469559
  - -0.4151142013805239
  - -0.39540375350137263
  - -0.43314134546391275
  - -0.3712315656677034
  train_level9__neg_label_ranking_loss_oob:
  - -0.4098288386756168
  - -0.4193595101523844
  - -0.40100615330117406
  - -0.4375295359525655
  - -0.37675931524135725
  train_level9__precision_macro:
  - 0.4405997417380076
  - 0.4195083456884595
  - 0.44081076477601766
  - 0.4332372951117353
  - 0.4313278415220163
  train_level9__precision_macro_masked:
  - 0.38106929828159547
  - 0.35619983509976544
  - 0.3812027209775095
  - 0.372906272658007
  - 0.36979256989046017
  train_level9__precision_macro_oob:
  - 0.43947582380792966
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206965
  - 0.4287535549671473
  train_level9__precision_micro:
  - 0.44059974173800753
  - 0.4195083456884595
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__precision_micro_masked:
  - 0.3733842777009999
  - 0.3479722402949469
  - 0.37271899069651876
  - 0.36517901200723724
  - 0.36195211377145714
  train_level9__precision_micro_oob:
  - 0.4394758238079296
  - 0.4166865942895404
  - 0.4393021388422513
  - 0.4307677408420696
  - 0.4287535549671472
  train_level9__precision_samples:
  - 0.44059974173800753
  - 0.41950834568845957
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__precision_samples_masked:
  - 0.3745450280480926
  - 0.3492935664102341
  - 0.37389464137535205
  - 0.36635186832283245
  - 0.36308247718778514
  train_level9__precision_samples_oob:
  - 0.4394758238079296
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206954
  - 0.4287535549671471
  train_level9__precision_weighted:
  - 0.519680762390943
  - 0.5040455671303447
  - 0.5242302064057968
  - 0.5135950404518477
  - 0.51162241906677
  train_level9__precision_weighted_masked:
  - 0.4391361949933262
  - 0.4185473722004494
  - 0.4448856621415024
  - 0.43221475106341056
  - 0.4289386578421046
  train_level9__precision_weighted_oob:
  - 0.5175992159323671
  - 0.5012663117377203
  - 0.5222417834461398
  - 0.5102950726219179
  - 0.5083054399518071
  train_level9__recall_macro:
  - 0.4405997417380076
  - 0.4195083456884595
  - 0.44081076477601766
  - 0.4332372951117353
  - 0.4313278415220163
  train_level9__recall_macro_masked:
  - 0.38106929828159547
  - 0.35619983509976544
  - 0.3812027209775095
  - 0.372906272658007
  - 0.36979256989046017
  train_level9__recall_macro_oob:
  - 0.43947582380792966
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206965
  - 0.4287535549671473
  train_level9__recall_micro:
  - 0.44059974173800753
  - 0.4195083456884595
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__recall_micro_masked:
  - 0.3733842777009999
  - 0.3479722402949469
  - 0.37271899069651876
  - 0.36517901200723724
  - 0.36195211377145714
  train_level9__recall_micro_oob:
  - 0.4394758238079296
  - 0.4166865942895404
  - 0.4393021388422513
  - 0.4307677408420696
  - 0.4287535549671472
  train_level9__recall_samples:
  - 0.44059974173800753
  - 0.41950834568845957
  - 0.4408107647760177
  - 0.4332372951117352
  - 0.43132784152201625
  train_level9__recall_samples_masked:
  - 0.3745450280480926
  - 0.3492935664102341
  - 0.37389464137535205
  - 0.36635186832283245
  - 0.36308247718778514
  train_level9__recall_samples_oob:
  - 0.4394758238079296
  - 0.41668659428954036
  - 0.4393021388422512
  - 0.43076774084206954
  - 0.4287535549671471
  train_level9__recall_weighted:
  - 0.519680762390943
  - 0.5040455671303447
  - 0.5242302064057968
  - 0.5135950404518477
  - 0.51162241906677
  train_level9__recall_weighted_masked:
  - 0.4391361949933262
  - 0.4185473722004494
  - 0.4448856621415024
  - 0.43221475106341056
  - 0.4289386578421046
  train_level9__recall_weighted_oob:
  - 0.5175992159323671
  - 0.5012663117377203
  - 0.5222417834461398
  - 0.5102950726219179
  - 0.5083054399518071
  train_level9__roc_auc_macro:
  - 0.6794327944364608
  - 0.6749046014023962
  - 0.6962124179804849
  - 0.6687900112730272
  - 0.6900268810459682
  train_level9__roc_auc_macro_masked:
  - 0.6592835740229557
  - 0.6555779281564453
  - 0.680767688615233
  - 0.647391083949812
  - 0.669947240470088
  train_level9__roc_auc_macro_oob:
  - 0.672497562378385
  - 0.6679813127459773
  - 0.6896301988532265
  - 0.6620952517433488
  - 0.682644876641488
  train_level9__roc_auc_micro:
  - 0.6514744637115523
  - 0.6361019432250903
  - 0.6595800901221944
  - 0.6374540666877544
  - 0.6759845709239858
  train_level9__roc_auc_micro_masked:
  - 0.6339716622609897
  - 0.6200042715222321
  - 0.6435330490341782
  - 0.6227118154346198
  - 0.6589385481686644
  train_level9__roc_auc_micro_oob:
  - 0.6495096022373705
  - 0.6338667449180384
  - 0.6572127539348427
  - 0.6357133437480946
  - 0.6728239910636793
  train_level9__roc_auc_samples:
  - 0.6399073325110701
  - 0.624735876533864
  - 0.6457053031938019
  - 0.6237092566878955
  - 0.6664451018109104
  train_level9__roc_auc_samples_masked:
  - 0.6255965334962333
  - 0.6102985794162274
  - 0.6304739800924026
  - 0.6087803020899397
  - 0.6508383023664208
  train_level9__roc_auc_samples_oob:
  - 0.6383568748119642
  - 0.6230983185212254
  - 0.6436184453964038
  - 0.6221463724280587
  - 0.6641733004502232
  train_level9__roc_auc_weighted:
  - 0.6780445033090973
  - 0.677342342911436
  - 0.6956726775723973
  - 0.6735524640275776
  - 0.6911266461710965
  train_level9__roc_auc_weighted_masked:
  - 0.6570334395012101
  - 0.6571636558416394
  - 0.6771072247768395
  - 0.6542626035217994
  - 0.6706460348124132
  train_level9__roc_auc_weighted_oob:
  - 0.6702858447763811
  - 0.6691633720617007
  - 0.6874210690726833
  - 0.6660533927541962
  - 0.6835040052649096
  train_level9__tn_macro:
  - 0.22368358123296192
  - 0.19936391027787081
  - 0.2217436795873178
  - 0.2172481417814687
  - 0.21329802883200943
  train_level9__tn_macro_masked:
  - 0.25057954016111206
  - 0.22318913104651866
  - 0.24935123154210004
  - 0.2428294077119084
  - 0.23880183127045868
  train_level9__tn_macro_oob:
  - 0.22299009995695637
  - 0.1971878138600603
  - 0.2207703725332749
  - 0.21572282885020458
  - 0.21158183779543005
  train_level9__tn_micro:
  - 0.2236835812329619
  - 0.1993639102778708
  - 0.2217436795873178
  - 0.21724814178146865
  - 0.2132980288320094
  train_level9__tn_micro_masked:
  - 0.25347532720917
  - 0.22600845803513336
  - 0.25158048753554374
  - 0.24598388069521354
  - 0.24165324148658407
  train_level9__tn_micro_oob:
  - 0.22299009995695634
  - 0.19718781386006026
  - 0.22077037253327494
  - 0.21572282885020458
  - 0.21158183779543002
  train_level9__tn_samples:
  - 0.22368358123296184
  - 0.19936391027787073
  - 0.22174367958731778
  - 0.21724814178146862
  - 0.21329802883200935
  train_level9__tn_samples_masked:
  - 0.25423234205609313
  - 0.22699769292951852
  - 0.25251330354766904
  - 0.2468194838375578
  - 0.24237997552922041
  train_level9__tn_samples_oob:
  - 0.22299009995695632
  - 0.1971878138600602
  - 0.2207703725332749
  - 0.21572282885020455
  - 0.21158183779543
  train_level9__tn_weighted:
  - 0.19638607675582956
  - 0.17362836739214627
  - 0.19875418001649137
  - 0.18770520772841068
  - 0.1856622716030528
  train_level9__tn_weighted_masked:
  - 0.2282171528225052
  - 0.20183192293057567
  - 0.2326781002205637
  - 0.21863761144397287
  - 0.2169720536967493
  train_level9__tn_weighted_oob:
  - 0.19497336496867607
  - 0.17178666489855193
  - 0.19750350202757125
  - 0.18588839196200757
  - 0.18357557091282414
  train_level9__tp_macro:
  - 0.21691616050504567
  - 0.22014443541058878
  - 0.2190670851886999
  - 0.2159891533302665
  - 0.21802981269000685
  train_level9__tp_macro_masked:
  - 0.13048975812048338
  - 0.13301070405324675
  - 0.13185148943540956
  - 0.1300768649460986
  - 0.13099073862000157
  train_level9__tp_macro_oob:
  - 0.21648572385097326
  - 0.21949878042948015
  - 0.21853176630897633
  - 0.2150449119918649
  - 0.21717171717171718
  train_level9__tp_micro:
  - 0.21691616050504567
  - 0.22014443541058873
  - 0.2190670851886999
  - 0.21598915333026655
  - 0.21802981269000687
  train_level9__tp_micro_masked:
  - 0.11990895049182994
  - 0.12196378225981348
  - 0.12113850316097508
  - 0.11919513131202368
  - 0.12029887228487306
  train_level9__tp_micro_oob:
  - 0.21648572385097326
  - 0.21949878042948012
  - 0.21853176630897633
  - 0.21504491199186498
  - 0.21717171717171718
  train_level9__tp_samples:
  - 0.21691616050504564
  - 0.2201444354105887
  - 0.21906708518869983
  - 0.21598915333026647
  - 0.21802981269000685
  train_level9__tp_samples_masked:
  - 0.12031268599199944
  - 0.12229587348071547
  - 0.12138133782768303
  - 0.11953238448527465
  - 0.12070250165856476
  train_level9__tp_samples_oob:
  - 0.2164857238509732
  - 0.21949878042948007
  - 0.21853176630897628
  - 0.21504491199186498
  - 0.2171717171717171
  train_level9__tp_weighted:
  - 0.3232946856351134
  - 0.33041719973819844
  - 0.32547602638930556
  - 0.325889832723437
  - 0.3259601474637174
  train_level9__tp_weighted_masked:
  - 0.21091904217082103
  - 0.21671544926987366
  - 0.21220756192093873
  - 0.2135771396194376
  - 0.21196660414535531
  train_level9__tp_weighted_oob:
  - 0.322625850963691
  - 0.3294796468391683
  - 0.3247382814185686
  - 0.32440668065991035
  - 0.32472986903898293
start: 2023-12-31 06:20:20.531004
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
