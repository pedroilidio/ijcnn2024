active: true
cv:
  call: nakano_datasets_v2.cross_validation.cross_validate_cascade_levels
  params:
    cv: !!python/object:skmultilearn.model_selection.iterative_stratification.IterativeStratification
      desired_samples_per_combination_per_fold:
        ? !!python/tuple
        - 0
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - &id001 !!python/name:numpy.ndarray ''
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - &id002 !!python/object/apply:numpy.dtype
            args:
            - f8
            - false
            - true
            state: !!python/tuple
            - 3
            - <
            - null
            - null
            - null
            - -1
            - -1
            - 0
          - false
          - !!binary |
            MDMzMzMzC8BAMzMzMzPjP0AzMzMzM+M/YGZmZmZm9r/QzMzMzMwMQA==
        ? !!python/tuple
        - 1
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJmZmZmZyb8AmZmZmZnJv8CZmZmZmek/AJmZmZmZyb8AmZmZmZnJvw==
        ? !!python/tuple
        - 2
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+AmZmZmZnJv9DMzMzMzPw/zMzMzMzMFMBoZmZmZmYGQA==
        ? !!python/tuple
        - 3
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87+AmZmZmZnJv6CZmZmZmek/gJmZmZmZyb+gmZmZmZnpPw==
        ? !!python/tuple
        - 4
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AJqZmZmZyT8AmpmZmZnJPwCamZmZmck/AJqZmZmZyT+AmZmZmZnpvw==
        ? !!python/tuple
        - 5
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzMBEDQzMzMzMwMQJiZmZmZmRHAgJmZmZmZ2b9gZmZmZmb2vw==
        ? !!python/tuple
        - 6
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/QzMzMzMz8P8zMzMzMzBzAmJmZmZmZAcA0MzMzMzMXQA==
        ? !!python/tuple
        - 7
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T9mZmZmZmYkwNDMzMzMzPw/0MzMzMzM/D80MzMzMzMXQA==
        ? !!python/tuple
        - 8
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz4784MzMzMzMLQGRmZmZmZhbAZGZmZmZmHsDOzMzMzMwkQA==
        ? !!python/tuple
        - 9
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzMBMBwZmZmZmb2P8jMzMzMzATAIDMzMzMz47+cmZmZmZkRQA==
        ? !!python/tuple
        - 10
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAGMAAAAAAAADwPwAAAAAAAAjAAAAAAAAAAAAAAAAAAAAgQA==
        ? !!python/tuple
        - 11
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 12
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r+YmZmZmZkVwNDMzMzMzARA0MzMzMzMDEBAMzMzMzPjPw==
        ? !!python/tuple
        - 13
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZ+b84MzMzMzMDQJyZmZmZmRFAZGZmZmZmFsDAmZmZmZnZPw==
        ? !!python/tuple
        - 14
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZmEsDAmZmZmZnZP8CZmZmZmdk/ODMzMzMzA0BwZmZmZmb2Pw==
        ? !!python/tuple
        - 15
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8D8AAAAAAAAUwAAAAAAAABTAAAAAAAAAEEAAAAAAAAAUQA==
        ? !!python/tuple
        - 16
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAADwPwAAAAAAAAAAAAAAAAAAFMAAAAAAAAAYQA==
        ? !!python/tuple
        - 17
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz879oZmZmZmYGQMzMzMzMzBzA0MzMzMzM/D9oZmZmZmYOQA==
        ? !!python/tuple
        - 18
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZAUAwMzMzMzMTwICZmZmZmem/YGZmZmZmDsDQzMzMzMwcQA==
        ? !!python/tuple
        - 19
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz478gMzMzMzPjv5CZmZmZmfm/wJmZmZmZ2T84MzMzMzMDQA==
        ? !!python/tuple
        - 20
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmFsCgmZmZmZn5v4CZmZmZmdk/gJmZmZmZ2T+YmZmZmZkZQA==
        ? !!python/tuple
        - 21
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZCUDAmZmZmZnJP2RmZmZmZgbAkJmZmZmZ6b/AmZmZmZnJPw==
        ? !!python/tuple
        - 22
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAgwAAAAAAAACJAAAAAAAAAFMAAAAAAAAAcQA==
        ? !!python/tuple
        - 23
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            4MzMzMzM/D/IzMzMzMwQwMCZmZmZmek/cGZmZmZmBkAgMzMzMzPzvw==
        ? !!python/tuple
        - 24
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+gmZmZmZnZP6CZmZmZmdk/mJmZmZmZ+b80MzMzMzMDQA==
        ? !!python/tuple
        - 25
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAwAAAAAAAAPA/AAAAAAAA8D8AAAAAAAAAAA==
        ? !!python/tuple
        - 26
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzA8DQzMzMzMwEQICZmZmZmdm/mJmZmZmZEcBoZmZmZmYSQA==
        ? !!python/tuple
        - 27
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFMAAAAAAAAAIQAAAAAAAAABAAAAAAAAA8L8AAAAAAADwPw==
        ? !!python/tuple
        - 28
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAQAAAAAAAAPA/AAAAAAAA8L8AAAAAAADwvw==
        ? !!python/tuple
        - 29
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+gmZmZmZn5PzAzMzMzMwPAoJmZmZmZ+T+AmZmZmZnZvw==
        ? !!python/tuple
        - 30
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZAUAwMzMzMzMXwNDMzMzMzBRAYGZmZmZmDsCgmZmZmZkBQA==
        ? !!python/tuple
        - 31
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz8780MzMzMzMTQGhmZmZmZgZAmJmZmZmZAcDMzMzMzMwQwA==
        ? !!python/tuple
        - 32
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUBgZmZmZmYGwGBmZmZmZgbAwMzMzMzM/L/QzMzMzMwQQA==
        ? !!python/tuple
        - 33
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAAQAAAAAAAAPC/AAAAAAAAAMAAAAAAAAAIwA==
        ? !!python/tuple
        - 34
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZmBkBkZmZmZmYiwHBmZmZmZg5AkJmZmZmZAcA4MzMzMzMTQA==
        ? !!python/tuple
        - 35
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAAQAAAAAAAAABAAAAAAAAACMAAAAAAAAAAQA==
        ? !!python/tuple
        - 36
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAAAAAAAAAAAADAAAAAAAAA8D8AAAAAAAAIQA==
        ? !!python/tuple
        - 37
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz478wMzMzMzPjv8zMzMzMzATAoJmZmZmZ2T80MzMzMzMLQA==
        ? !!python/tuple
        - 38
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b8wMzMzMzMDwNDMzMzMzARAoJmZmZmZ+T9gZmZmZmb2vw==
        ? !!python/tuple
        - 39
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MjMzMzMzC8AyMzMzMzMLwM7MzMzMzARAkJmZmZmZ2b9nZmZmZmYSQA==
        ? !!python/tuple
        - 40
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            yMzMzMzM/L+QmZmZmZnpv87MzMzMzBBAwJmZmZmZyT/IzMzMzMz8vw==
        ? !!python/tuple
        - 41
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAACMAAAAAAAAAAAAAAAAAAAPC/AAAAAAAACEAAAAAAAADwPw==
        ? !!python/tuple
        - 42
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzC0A0MzMzMzMDQDQzMzMzMwNAMzMzMzMzIcCgmZmZmZnZPw==
        ? !!python/tuple
        - 43
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0DMzMzMzMwMwDAzMzMzM+O/NDMzMzMzC0CYmZmZmZn5vw==
        ? !!python/tuple
        - 44
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMz8z+YmZmZmZnpv6CZmZmZmck/zMzMzMzM/L80MzMzMzPzPw==
        ? !!python/tuple
        - 45
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzH8DQzMzMzMwYQNDMzMzMzBRAMDMzMzMzH8DQzMzMzMwQQA==
        ? !!python/tuple
        - 46
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z9AMzMzMzPjPzAzMzMzMwvAgJmZmZmZ2b/QzMzMzMwEQA==
        ? !!python/tuple
        - 47
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMBMCgmZmZmZnZPzQzMzMzMwtAMDMzMzMz478wMzMzMzPjvw==
        ? !!python/tuple
        - 48
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMz4z+AmZmZmZnZv0AzMzMzM+M/gJmZmZmZ2b+AmZmZmZnZvw==
        ? !!python/tuple
        - 49
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            kJmZmZmZAcDAmZmZmZnpP3BmZmZmZgZAwJmZmZmZ6T+QmZmZmZkBwA==
        ? !!python/tuple
        - 50
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D/MzMzMzMwcwNDMzMzMzPw/gJmZmZmZyb9oZmZmZmYOQA==
        ? !!python/tuple
        - 51
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8L8AAAAAAADwPw==
        ? !!python/tuple
        - 52
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T+YmZmZmZkBwJiZmZmZmQnA0MzMzMzM/D9oZmZmZmYGQA==
        ? !!python/tuple
        - 53
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAUwAAAAAAAAABAAAAAAAAA8L8AAAAAAAAAQA==
        ? !!python/tuple
        - 54
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAUwAAAAAAAAAhAAAAAAAAAAMAAAAAAAAAAQA==
        ? !!python/tuple
        - 55
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmIsBgZmZmZmYGQMDMzMzMzPw/wMzMzMzM/D9gZmZmZmYGQA==
        ? !!python/tuple
        - 56
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87+AmZmZmZnJv4CZmZmZmcm/gJmZmZmZyb/QzMzMzMz8Pw==
        ? !!python/tuple
        - 57
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b8wMzMzMzPjvzQzMzMzMwNAMDMzMzMz47+gmZmZmZnZPw==
        ? !!python/tuple
        - 58
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZyb+gmZmZmZnpP6CZmZmZmek/gJmZmZmZyb8wMzMzMzPzvw==
        ? !!python/tuple
        - 59
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZ6T/MzMzMzMwYwGhmZmZmZg5AgJmZmZmZyb/QzMzMzMz8Pw==
        ? !!python/tuple
        - 60
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAIwAAAAAAAAC5AAAAAAAAAIMAAAAAAAAAQwA==
        ? !!python/tuple
        - 61
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzG8CgmZmZmZnpv4CZmZmZmck/zMzMzMzMEECYmZmZmZkJQA==
        ? !!python/tuple
        - 62
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZyT80MzMzMzPzP6CZmZmZmck/mJmZmZmZ6b+YmZmZmZnpvw==
        ? !!python/tuple
        - 63
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAAAAAAAAAAAhAAAAAAAAAHMAAAAAAAAAUQA==
        ? !!python/tuple
        - 64
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAADwvwAAAAAAAADAAAAAAAAAAAAAAAAAAAAQQA==
        ? !!python/tuple
        - 65
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAUQAAAAAAAAAjAAAAAAAAAEEAAAAAAAAAQwA==
        ? !!python/tuple
        - 66
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAFMAAAAAAAAAAAAAAAAAAAPA/AAAAAAAAAAAAAAAAAAAQQA==
        ? !!python/tuple
        - 67
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            IDMzMzMz479wZmZmZmb2P8jMzMzMzATAkJmZmZmZ+b84MzMzMzMLQA==
        ? !!python/tuple
        - 68
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            wMzMzMzM/L9gZmZmZmYGwICZmZmZmem/YGZmZmZmBsBoZmZmZmYgQA==
        ? !!python/tuple
        - 69
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZ2b+gmZmZmZn5P4CZmZmZmdm/YGZmZmZm9r9AMzMzMzPjPw==
        ? !!python/tuple
        - 70
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            cGZmZmZmDkDAmZmZmZnpP8CZmZmZmek/IDMzMzMz87/IzMzMzMwQwA==
        ? !!python/tuple
        - 71
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAEAAAAAAAAAYwAAAAAAAAPA/AAAAAAAAAEAAAAAAAADwPw==
        ? !!python/tuple
        - 72
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzC0CgmZmZmZn5v2hmZmZmZhbAYGZmZmZm9j8wMzMzMzMDQA==
        ? !!python/tuple
        - 73
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZFcBgZmZmZmb2v4CZmZmZmdm/QDMzMzMz4z9oZmZmZmYaQA==
        ? !!python/tuple
        - 74
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            QDMzMzMzA0AAMzMzMzPjv0AzMzMzMwtAYGZmZmZmEsAAMzMzMzPjvw==
        ? !!python/tuple
        - 75
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZmDkCYmZmZmZkJwGhmZmZmZg5AmJmZmZmZAcCYmZmZmZkBwA==
        ? !!python/tuple
        - 76
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            0MzMzMzM/D8wMzMzMzPzv4CZmZmZmcm/mJmZmZmZAcDQzMzMzMz8Pw==
        ? !!python/tuple
        - 77
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            gJmZmZmZAcDAzMzMzMwQwEAzMzMzMxdAgJmZmZmZCcCAZmZmZmYOQA==
        ? !!python/tuple
        - 78
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZGcBAMzMzMzPjPzAzMzMzMwPAMDMzMzMzA8A0MzMzMzMlQA==
        ? !!python/tuple
        - 79
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUAwMzMzMzMTwGhmZmZmZiJAgJmZmZmZ6b8wMzMzMzMbwA==
        ? !!python/tuple
        - 80
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAcwAAAAAAAABhAAAAAAAAA8L8AAAAAAAAQQA==
        ? !!python/tuple
        - 81
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZEUCQmZmZmZn5vyAzMzMzM+O/IDMzMzMz47+QmZmZmZn5vw==
        ? !!python/tuple
        - 82
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMEMCgmZmZmZnpP6CZmZmZmek/MDMzMzMz879oZmZmZmYOQA==
        ? !!python/tuple
        - 83
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            YGZmZmZm9r9gZmZmZmb2v6CZmZmZmfk/MDMzMzMzA8DQzMzMzMwMQA==
        ? !!python/tuple
        - 84
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMzE8AwMzMzMzMbwICZmZmZmem/0MzMzMzMFEDQzMzMzMwcQA==
        ? !!python/tuple
        - 85
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            aGZmZmZm9j8wMzMzMzPjvzAzMzMzM+O/MDMzMzMz47+gmZmZmZnZPw==
        ? !!python/tuple
        - 86
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+T80MzMzMzMDwDQzMzMzMwPAzMzMzMzMBEAwMzMzMzPjPw==
        ? !!python/tuple
        - 87
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            oJmZmZmZCUDAzMzMzMz8v9DMzMzMzBRAYGZmZmZmDsBgZmZmZmYGwA==
        ? !!python/tuple
        - 88
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            nJmZmZmZCUCcmZmZmZkJQGRmZmZmZgbAZGZmZmZmBsCQmZmZmZnpvw==
        ? !!python/tuple
        - 89
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz87+AmZmZmZnJv6CZmZmZmek/gJmZmZmZyb+gmZmZmZnpPw==
        ? !!python/tuple
        - 90
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZGZmZmZm9r8yMzMzMzMLwDIzMzMzMwPAZ2ZmZmZmFkCcmZmZmZn5Pw==
        ? !!python/tuple
        - 91
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            zMzMzMzMDMBoZmZmZmb2PzQzMzMzMwNAMDMzMzMz47+gmZmZmZnZPw==
        ? !!python/tuple
        - 92
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAA8L8AAAAAAAAAwAAAAAAAABBAAAAAAAAACMAAAAAAAAAAQA==
        ? !!python/tuple
        - 93
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAMAAAAAAAAAIQAAAAAAAAPC/AAAAAAAAAAAAAAAAAAAAAA==
        ? !!python/tuple
        - 94
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAEEAAAAAAAAAQwAAAAAAAAPA/AAAAAAAACMAAAAAAAAAAQA==
        ? !!python/tuple
        - 95
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmHsCamZmZmZkRQJqZmZmZmRVAmJmZmZmZ+b8wMzMzMzPjvw==
        ? !!python/tuple
        - 96
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMzA0A0MzMzMzMLQDAzMzMzM+O/ZmZmZmZmEsAwMzMzMzPjvw==
        ? !!python/tuple
        - 97
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            ZmZmZmZmGsA0MzMzMzMDQKCZmZmZmdk/oJmZmZmZ2T80MzMzMzMLQA==
        ? !!python/tuple
        - 98
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            MDMzMzMz47+gmZmZmZnZP8zMzMzMzATAoJmZmZmZ2T80MzMzMzMDQA==
        ? !!python/tuple
        - 99
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAAPA/AAAAAAAA8D8AAAAAAAAAwA==
        ? !!python/tuple
        - 100
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            mJmZmZmZ+b+gmZmZmZnZP5qZmZmZmRVAZmZmZmZmEsCgmZmZmZnZPw==
        ? !!python/tuple
        - 101
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            NDMzMzMz8z/MzMzMzMz8v8zMzMzMzPy/zMzMzMzM/L/NzMzMzMwQQA==
        ? !!python/tuple
        - 102
        : !!python/object/apply:numpy.core.multiarray._reconstruct
          args:
          - *id001
          - !!python/tuple
            - 0
          - !!binary |
            Yg==
          state: !!python/tuple
          - 1
          - !!python/tuple
            - 5
          - *id002
          - false
          - !!binary |
            AAAAAAAAAAAAAAAAAAAAAAAAAAAAABzAAAAAAAAAGEAAAAAAAADwPw==
      desired_samples_per_fold: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple
          - 0
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple
          - 5
        - *id002
        - false
        - !!binary |
          wMzMzMzMDMBgZmZmZmYSwEAzMzMzMwNAgJmZmZmZ+b+gmZmZmZkdQA==
      n_labels: 103
      n_samples: 502
      n_splits: 5
      order: 1
      percentage_per_fold:
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      - 0.2
      random_state: null
      shuffle: false
    n_jobs: 5
    return_fitted_params:
    - n_components_
    - label_frequency_estimates_
    return_train_score: true
    scoring:
      average_precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: &id003 !!python/tuple
        - decision_function
        - predict_proba
        - predict
        _score_func: &id004 !!python/name:sklearn.metrics._ranking.average_precision_score ''
        _sign: 1
      average_precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      average_precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: *id003
        _score_func: *id004
        _sign: 1
      f1_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id005
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id006 !!python/name:sklearn.metrics._classification.f1_score ''
        _sign: 1
      f1_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id005
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id007
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id007
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id008
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id008
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id009
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      f1_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id009
          pos_label: null
        _response_method: predict
        _score_func: *id006
        _sign: 1
      fn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id010
          - 0
          - 1
        _response_method: predict
        _score_func: &id011 !!python/name:nakano_datasets_v2.scoring.fn ''
        _sign: -1
      fn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id010
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id012
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id012
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id013
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id013
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id014
          - 0
          - 1
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id014
        _response_method: predict
        _score_func: *id011
        _sign: -1
      fp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id015
          - 0
          - 1
        _response_method: predict
        _score_func: &id016 !!python/name:nakano_datasets_v2.scoring.fp ''
        _sign: -1
      fp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id015
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id017
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id017
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id018
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id018
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id019
          - 0
          - 1
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      fp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id019
        _response_method: predict
        _score_func: *id016
        _sign: -1
      jaccard_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id020
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id021 !!python/name:sklearn.metrics._classification.jaccard_score ''
        _sign: 1
      jaccard_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id020
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id022
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id022
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id023
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id023
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id024
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      jaccard_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id024
          pos_label: null
        _response_method: predict
        _score_func: *id021
        _sign: 1
      label_ranking_average_precision_score: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id025 !!python/name:sklearn.metrics._ranking.label_ranking_average_precision_score ''
        _sign: 1
      label_ranking_average_precision_score_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id025
        _sign: 1
      matthews_corrcoef_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id026 !!python/name:sklearn.metrics._classification.matthews_corrcoef ''
        _sign: 1
      matthews_corrcoef_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      matthews_corrcoef_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id026
        _sign: 1
      ndcg: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id027 !!python/name:sklearn.metrics._ranking.ndcg_score ''
        _sign: 1
      ndcg_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id027
        _sign: 1
      neg_coverage_error: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id028 !!python/name:sklearn.metrics._ranking.coverage_error ''
        _sign: -1
      neg_coverage_error_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id028
        _sign: -1
      neg_hamming_loss_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: &id029 !!python/name:sklearn.metrics._classification.hamming_loss ''
        _sign: -1
      neg_hamming_loss_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_hamming_loss_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs: {}
        _response_method: predict
        _score_func: *id029
        _sign: -1
      neg_label_ranking_loss: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: &id030 !!python/name:sklearn.metrics._ranking.label_ranking_loss ''
        _sign: -1
      neg_label_ranking_loss_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: null
        _kwargs: {}
        _response_method: *id003
        _score_func: *id030
        _sign: -1
      precision_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id031
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id032 !!python/name:sklearn.metrics._classification.precision_score ''
        _sign: 1
      precision_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id031
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id033
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id033
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id034
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id034
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id035
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      precision_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id035
          pos_label: null
        _response_method: predict
        _score_func: *id032
        _sign: 1
      recall_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          average: micro
          labels: &id036
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: &id037 !!python/name:sklearn.metrics._classification.recall_score ''
        _sign: 1
      recall_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          average: micro
          labels: *id036
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          average: micro
          labels: &id038
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          average: micro
          labels: *id038
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          average: micro
          labels: &id039
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          average: micro
          labels: *id039
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: &id040
          - 0
          - 1
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      recall_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          average: micro
          labels: *id040
          pos_label: null
        _response_method: predict
        _score_func: *id037
        _sign: 1
      roc_auc_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id041
          - 0
          - 1
        _response_method: *id003
        _score_func: &id042 !!python/name:sklearn.metrics._ranking.roc_auc_score ''
        _sign: 1
      roc_auc_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id041
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id043
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id043
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id044
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id044
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id045
          - 0
          - 1
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      roc_auc_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id045
        _response_method: *id003
        _score_func: *id042
        _sign: 1
      tn_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id046
          - 0
          - 1
        _response_method: predict
        _score_func: &id047 !!python/name:nakano_datasets_v2.scoring.tn ''
        _sign: 1
      tn_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id046
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id048
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id048
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id049
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id049
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id050
          - 0
          - 1
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tn_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id050
        _response_method: predict
        _score_func: *id047
        _sign: 1
      tp_macro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: macro
        _kwargs:
          labels: &id051
          - 0
          - 1
        _response_method: predict
        _score_func: &id052 !!python/name:nakano_datasets_v2.scoring.tp ''
        _sign: 1
      tp_macro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_macro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: macro
        _kwargs:
          labels: *id051
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: micro
        _kwargs:
          labels: &id053
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_micro_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: micro
        _kwargs:
          labels: *id053
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: samples
        _kwargs:
          labels: &id054
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_samples_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: samples
        _kwargs:
          labels: *id054
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted: !!python/object:nakano_datasets_v2.scoring.MultiLabelScorer
        _average: weighted
        _kwargs:
          labels: &id055
          - 0
          - 1
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_masked: !!python/object:nakano_datasets_v2.scoring.DroppedLabelsScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
      tp_weighted_oob: !!python/object:nakano_datasets_v2.scoring.OOBScorer
        _average: weighted
        _kwargs:
          labels: *id055
        _response_method: predict
        _score_func: *id052
        _sign: 1
    verbose: 10
dataset:
  call: data_loaders.load_nakano
  name: CAL500
  params:
    min_positives: 30
    path: nakano_datasets_v2/datasets/MLC/CAL500.csv
directory: nakano_datasets_per_level/runs
end: 2023-12-31 06:30:44.766138
estimator:
  call: nakano_datasets_v2.estimators.cascade_lc_proba
  final_params:
    memory: null
    steps:
    - - dropper
      - call: positive_dropper.PositiveDropper
        params:
          drop: 0.5
          random_state: 0
    - - estimator
      - call: deep_forest.cascade.Cascade
        params:
          final_estimator:
            call: deep_forest.estimator_adapters.RegressorAsBinaryClassifier
            params:
              estimator:
                call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                params:
                  estimators:
                  - - rf
                    - call: sklearn.ensemble._forest.RandomForestRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
                  - - xt
                    - call: sklearn.ensemble._forest.ExtraTreesRegressor
                      params:
                        bootstrap: true
                        ccp_alpha: 0.0
                        criterion: squared_error
                        max_depth: null
                        max_features: sqrt
                        max_leaf_nodes: null
                        max_samples: 0.5
                        min_impurity_decrease: 0.0
                        min_samples_leaf: 5
                        min_samples_split: 2
                        min_weight_fraction_leaf: 0.0
                        monotonic_cst: null
                        n_estimators: 150
                        n_jobs: 14
                        oob_score: true
                        random_state: 0
                        verbose: true
                        warm_start: false
          keep_original_features: true
          level:
            call: deep_forest.cascade.SequentialLevel
            params:
              last_level: null
              memory: null
              steps:
              - - alternating_forests
                - call: deep_forest.cascade.AlternatingLevel
                  params:
                    last_level: null
                    n_jobs: null
                    sparse_threshold: 0.3
                    transformer_weights: null
                    transformers:
                    - - rf
                      - call: deep_forest.estimator_adapters.EstimatorAsTransformer
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: null
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                    - - xt
                      - call: deep_forest.estimator_adapters.EstimatorAsTransformer
                        params:
                          estimator:
                            call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: false
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: null
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: false
                              random_state: 0
                              verbose: true
                              warm_start: false
                    verbose: false
                    verbose_feature_names_out: true
              - - label_imputer
                - call: deep_forest.weak_labels.LabelComplementImputer
                  params:
                    estimator:
                      call: deep_forest.estimator_adapters.MultiOutputVotingRegressor
                      params:
                        estimators:
                        - - rf
                          - call: sklearn.ensemble._forest.RandomForestRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                        - - xt
                          - call: sklearn.ensemble._forest.ExtraTreesRegressor
                            params:
                              bootstrap: true
                              ccp_alpha: 0.0
                              criterion: squared_error
                              max_depth: null
                              max_features: sqrt
                              max_leaf_nodes: null
                              max_samples: 0.5
                              min_impurity_decrease: 0.0
                              min_samples_leaf: 5
                              min_samples_split: 2
                              min_weight_fraction_leaf: 0.0
                              monotonic_cst: null
                              n_estimators: 150
                              n_jobs: 14
                              oob_score: true
                              random_state: 0
                              verbose: true
                              warm_start: false
                    label_freq_percentile: 0.5
                    last_level: null
                    threshold: 0.5
                    verbose: true
                    weight_proba: true
              verbose: false
          max_levels: 10
          memory: null
          verbose: 10
          warm_start: false
    verbose: false
  name: cascade_lc_proba
  params: {}
hash: 3c550b14fd893ee5597fdb56dfca0a61246b9f8848766ea672422141a9ae77d1
metaestimator: null
path: /home/pedro/mestrado/biomal_repo/scripts/cascade_forests/experiments/nakano_datasets_per_level/runs/3c550b1_20231231T062612446181_cascade_lc_proba_CAL500.yml
results:
  fit_time:
  - 248.72256350517273
  - 247.90768694877625
  - 258.94848132133484
  - 259.64205408096313
  - 265.8299729824066
  fitted_params:
    estimator.level1.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level10.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level2.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level3.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level4.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level5.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level6.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level7.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level8.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
    estimator.level9.label_imputer.label_frequency_estimates_:
    - - 0.08351674522368649
      - 0.43339497088716195
      - 0.2579699233810755
      - 0.2240346559118186
      - 0.37364171588309514
      - 0.3068317651414242
      - 0.2859503636189029
      - 0.20694415457353965
      - 0.25542835995422203
      - 0.20950315588245194
      - 0.3015506569453937
      - 0.1881546436646578
      - 0.09406493478463177
      - 0.20789662436679476
      - 0.26087677927565567
      - 0.25958549892373417
      - 0.2031035232497998
      - 0.1610341591959239
      - 0.31250896469725753
      - 0.17536904561261174
      - 0.2982804109527455
      - 0.14818220411432814
      - 0.3471826542320728
      - 0.32092375439731197
      - 0.18341548462083332
      - 0.2099983724048833
      - 0.1730126408712826
      - 0.2108797342592534
      - 0.11343115983943905
      - 0.10504751784163549
      - 0.3734949687608028
      - 0.23968159113803908
      - 0.3341116722539647
      - 0.16109039232672845
      - 0.36296418020319116
      - 0.11745364853264989
      - 0.10980958672790352
      - 0.08283595138433847
      - 0.05672693840716368
      - 0.044872895788389836
      - 0.08195221277378535
      - 0.04008248345369557
      - 0.03628343878343879
      - 0.07958162013140255
      - 0.06193761551381871
      - 0.1679252677299552
      - 0.0727868545857327
      - 0.04410650636982473
      - 0.17952248619921937
      - 0.19831449075954571
      - 0.08353406109461473
      - 0.34590220464699506
      - 0.14772230625832844
      - 0.12077460616786459
      - 0.10395892302142301
      - 0.393248447154697
      - 0.1101192876140355
      - 0.037167240812835775
      - 0.0756172812597356
      - 0.12493053069225843
      - 0.2387348970296993
      - 0.10062519749592251
      - 0.040171040299906285
      - 0.26427332349902183
      - 0.20529556977109098
      - 0.25158346230789413
      - 0.21994141100250844
      - 0.20628895320732724
      - 0.3759130925627736
      - 0.21097370905609542
      - 0.2228692951694881
      - 0.07872225156707915
      - 0.2880632559482041
      - 0.13115005149888867
      - 0.33711995326335037
      - 0.11163381324240994
      - 0.13772957869425254
      - 0.5045071154675935
      - 0.40831215466061166
      - 0.4276207928998563
      - 0.20579811914951227
      - 0.12339259115277218
      - 0.05390978868943358
      - 0.11341013495648075
      - 0.3278496461687217
      - 0.09305962737844758
      - 0.047872816709718824
      - 0.18757590858775328
      - 0.09345328234651153
      - 0.029578842395298094
      - 0.031141722673980743
      - 0.06520724173785399
      - 0.050945731389279776
      - 0.1121974421081564
      - 0.04132732252941247
      - 0.08709969749126374
      - 0.05555906821086818
      - 0.050282515479388855
      - 0.05544319912297441
      - 0.05926210464253943
      - 0.0526149045551518
      - 0.04493974254797123
      - 0.03735100405083129
    - - 0.10773566965353543
      - 0.44667113688114973
      - 0.3084293930115912
      - 0.20056826273134798
      - 0.3726401597140233
      - 0.2937021312021312
      - 0.28247576067343505
      - 0.2144620145935935
      - 0.22544176583650266
      - 0.2171236681027156
      - 0.29720372526056593
      - 0.19113423255367362
      - 0.08121085038698675
      - 0.23681395579894202
      - 0.27355105907737487
      - 0.2605758999603072
      - 0.24092441310183244
      - 0.2327306216510761
      - 0.28101090778129756
      - 0.18149549353253053
      - 0.26940044616280245
      - 0.15452080697474035
      - 0.35515349748648006
      - 0.287192710818026
      - 0.14201281174965386
      - 0.2129936413358873
      - 0.17417966996771345
      - 0.2596499363228566
      - 0.12929043559360193
      - 0.10683192521375666
      - 0.3306565793454903
      - 0.23634917955830512
      - 0.35909346429148414
      - 0.1409974970160155
      - 0.3401594173610246
      - 0.12002666717340629
      - 0.12286183051289928
      - 0.0860630889578258
      - 0.053513496534329866
      - 0.0321843788835719
      - 0.07070945368564416
      - 0.0485977417310926
      - 0.04500967174472867
      - 0.07786034246877621
      - 0.03734995273102572
      - 0.1935537345413068
      - 0.08077167794857386
      - 0.05138412034963759
      - 0.1777472098348386
      - 0.1871329318714838
      - 0.04278239128708908
      - 0.33431924532483315
      - 0.14838848039215685
      - 0.08621610027692406
      - 0.0994629277564584
      - 0.40370969785392175
      - 0.11259142645506925
      - 0.047307399390732724
      - 0.07187145040972248
      - 0.10867775387006152
      - 0.21763991630063056
      - 0.10063404090585187
      - 0.04311429868658784
      - 0.25637049090016617
      - 0.2228572107471224
      - 0.2691480014340977
      - 0.19204334752949764
      - 0.2461416329155139
      - 0.3932122465130776
      - 0.17020622817676176
      - 0.2222666015175374
      - 0.05093778976354734
      - 0.3002040920929196
      - 0.12799129532084075
      - 0.34922573211449925
      - 0.1069305537395081
      - 0.12186310602977268
      - 0.5196197101901852
      - 0.39361220668794983
      - 0.41933296527564834
      - 0.19340210253342943
      - 0.12146578090283655
      - 0.041884444000014606
      - 0.11297942601134088
      - 0.34892903392903396
      - 0.09453249236143976
      - 0.03383664054641631
      - 0.1798581084158007
      - 0.08803772713935595
      - 0.0321553811471513
      - 0.051465995667615276
      - 0.08526651427418735
      - 0.03650813472242044
      - 0.137392666632728
      - 0.037982074627987784
      - 0.11913816016677266
      - 0.06407675108170158
      - 0.047613034183111066
      - 0.06019974177868914
      - 0.06606201262584468
      - 0.06130795420406426
      - 0.06235349078275042
      - 0.03512023318554948
    - - 0.10442118561370797
      - 0.4100090204347451
      - 0.2476244762182262
      - 0.18532151992950555
      - 0.38700015262515264
      - 0.23628978397885958
      - 0.2384615357532962
      - 0.19251222523898892
      - 0.28375114865458323
      - 0.2139624533007668
      - 0.2728912544038593
      - 0.18861772418757708
      - 0.10391793755557799
      - 0.18717295027566916
      - 0.21293175625405786
      - 0.27791874602173855
      - 0.23279786878774672
      - 0.15356405024050218
      - 0.24606974918602342
      - 0.14686451495526018
      - 0.307816084077253
      - 0.1240036251714452
      - 0.330762833985779
      - 0.286614618648581
      - 0.10639764402264401
      - 0.21034458306668735
      - 0.21466093223905716
      - 0.2415730264567474
      - 0.10297478720774175
      - 0.0993071205728508
      - 0.37968802641331434
      - 0.23527871940793282
      - 0.3167627125960458
      - 0.1835246251502429
      - 0.35931911754990353
      - 0.12840417629317055
      - 0.1125196992929551
      - 0.06185143137812804
      - 0.07062173437473557
      - 0.03976731601731602
      - 0.09483590639052822
      - 0.051876170882892855
      - 0.0388809927257039
      - 0.08139750085772814
      - 0.041019127930892636
      - 0.2139788748073631
      - 0.07006045062000182
      - 0.039102762317048026
      - 0.1731288084640295
      - 0.22343756243756235
      - 0.09149545477670476
      - 0.3707223008519478
      - 0.14030190092749537
      - 0.0969442254368725
      - 0.12294424783164692
      - 0.41227735932817605
      - 0.09578979762067996
      - 0.06979112065347647
      - 0.06081299310229664
      - 0.11995868607226962
      - 0.2550732970230253
      - 0.10776144380311045
      - 0.028778445470518638
      - 0.24284624167565808
      - 0.22879974963308292
      - 0.2301444388944389
      - 0.205150480569319
      - 0.21816965260592705
      - 0.38284434316645266
      - 0.21350884409707932
      - 0.20767927404637643
      - 0.07801282563694106
      - 0.27922911103676473
      - 0.1550242649507355
      - 0.34108604258060776
      - 0.12281240678732422
      - 0.1353879983364163
      - 0.5215650442552617
      - 0.4006922183818806
      - 0.41395335536160327
      - 0.22632502395433424
      - 0.1261367905598675
      - 0.040227741163352475
      - 0.1057095163789128
      - 0.3569209971978261
      - 0.11587255723532633
      - 0.05006786185276812
      - 0.18180791111825592
      - 0.10631373941559125
      - 0.03663843277477746
      - 0.030771460135627676
      - 0.07084288958708543
      - 0.05234567280763419
      - 0.12309649651390353
      - 0.041611931887074204
      - 0.11317639054031886
      - 0.06561332458391284
      - 0.0451536837070545
      - 0.05267858627814408
      - 0.06653044050247997
      - 0.0825238733823071
      - 0.0489212067530566
      - 0.03558780576852867
    - - 0.09545334308605471
      - 0.42985805313022707
      - 0.280103954687288
      - 0.1957237977201381
      - 0.3714800362075448
      - 0.27852786712676814
      - 0.2345506163027683
      - 0.19122651488722914
      - 0.22703706350096714
      - 0.21226008517237507
      - 0.2835870630007433
      - 0.20046895219524796
      - 0.12874406085612977
      - 0.2007299875979757
      - 0.2879245942756448
      - 0.23780330415758125
      - 0.21522337462134833
      - 0.2127743677535877
      - 0.2565885790019193
      - 0.1531953667247785
      - 0.32437010590419674
      - 0.1286243157124857
      - 0.3581195372223892
      - 0.2538790435967855
      - 0.12215026668993553
      - 0.2261639621553414
      - 0.16639756384468876
      - 0.21150211426873927
      - 0.10935291745657143
      - 0.08821890421928712
      - 0.28977275556069
      - 0.21184606408499337
      - 0.3913634908407791
      - 0.15175652308404863
      - 0.40767731236771476
      - 0.13648663756422375
      - 0.10800073267477756
      - 0.04809692791632935
      - 0.06105568198881774
      - 0.037086776859504136
      - 0.11749770734903246
      - 0.05428626611434138
      - 0.02210024407826605
      - 0.08481539455376663
      - 0.03600530943935173
      - 0.1708638915949679
      - 0.06031376956376956
      - 0.05356004172471887
      - 0.18482340041479828
      - 0.19469944521527227
      - 0.06790086049113422
      - 0.3654184457979824
      - 0.14756351835299203
      - 0.07011760466855327
      - 0.10329571692790274
      - 0.43509340451156314
      - 0.10211766381202708
      - 0.04181192625341561
      - 0.0665887748615672
      - 0.11783139428743061
      - 0.19587893022221908
      - 0.14064120036342256
      - 0.030587875783344626
      - 0.24189673826770597
      - 0.2387363060356824
      - 0.26802592213136045
      - 0.18679721729101603
      - 0.18539693538821325
      - 0.44600983579833553
      - 0.22427156082251842
      - 0.19541906010656007
      - 0.09476844959986408
      - 0.29007221576394077
      - 0.10747076706080003
      - 0.3339602287878149
      - 0.09076893785227118
      - 0.1232594705298524
      - 0.5302581577553054
      - 0.3800840818045874
      - 0.39762955807966827
      - 0.23089486010317525
      - 0.10924164786524337
      - 0.05927009997476543
      - 0.11911663696980353
      - 0.343482775562824
      - 0.07093771012177083
      - 0.060451595844854274
      - 0.16155146508562068
      - 0.08504704014338904
      - 0.04319728384960028
      - 0.03514048373598935
      - 0.04356346601244561
      - 0.03857234719303686
      - 0.10203774124360084
      - 0.03888027821851351
      - 0.09030884943600462
      - 0.06138858055524722
      - 0.050498079962365675
      - 0.05163791385382293
      - 0.09716103493576021
      - 0.03820804663501293
      - 0.050625802148873716
      - 0.06697359142405582
    - - 0.15418776152787778
      - 0.40828686181438256
      - 0.2355069252086297
      - 0.19633832407903581
      - 0.3651959328668236
      - 0.2619814626798322
      - 0.2849680060277886
      - 0.18869814907314902
      - 0.26071740068469124
      - 0.18438412464728254
      - 0.332746625325972
      - 0.20072824216845955
      - 0.08119957074109901
      - 0.18806596654608013
      - 0.27553438213900866
      - 0.24850853403842527
      - 0.21252790501460714
      - 0.2126697806105133
      - 0.3237637638433534
      - 0.1440704337975036
      - 0.2816446109502191
      - 0.1432923213086414
      - 0.39091340815940223
      - 0.30458554517378045
      - 0.14732374632942813
      - 0.20119291411427395
      - 0.19825638536122692
      - 0.20958986911021787
      - 0.10648268372042147
      - 0.09080390283950654
      - 0.29002052251745447
      - 0.2291900868164118
      - 0.41467875330827136
      - 0.1533655078581549
      - 0.3534366802997969
      - 0.13884784418480067
      - 0.11278323508038418
      - 0.05560176084369633
      - 0.053024768791814246
      - 0.0479301253338603
      - 0.08700162812693601
      - 0.07138061386090494
      - 0.035351199538371056
      - 0.07761104192836522
      - 0.047070969154302485
      - 0.20315838188029195
      - 0.09079769645559119
      - 0.0392763034067382
      - 0.18827561327561332
      - 0.173242658540954
      - 0.0769802003356947
      - 0.33312741375760424
      - 0.1590459219701001
      - 0.1030761470441703
      - 0.11386066676701351
      - 0.4078246226953124
      - 0.13382200528939653
      - 0.056712416371507285
      - 0.06625151994470177
      - 0.13520938696719942
      - 0.22197867755368633
      - 0.11084813858320988
      - 0.03944407656953612
      - 0.28397729915587056
      - 0.2389555343331718
      - 0.21984412583233853
      - 0.1885948003784197
      - 0.21584400032202222
      - 0.42006508738845694
      - 0.20194364329321995
      - 0.2013986379426476
      - 0.07260398331826903
      - 0.27561175970073293
      - 0.15721444631019094
      - 0.320466746846456
      - 0.10122994203050381
      - 0.16359819918643448
      - 0.5094886559434627
      - 0.3631998888792366
      - 0.4291500868045811
      - 0.21820373826651657
      - 0.09842265451757932
      - 0.05317717832660713
      - 0.1744478576978577
      - 0.3465938704078612
      - 0.12053387658440845
      - 0.04766995622185355
      - 0.16159076776336834
      - 0.09713878826328767
      - 0.03606699699441876
      - 0.03670836966584389
      - 0.08227750931239303
      - 0.034868486600414306
      - 0.1732080827320387
      - 0.04257051282051282
      - 0.09428072650728898
      - 0.0706992318946778
      - 0.055000395517636885
      - 0.044942496278547
      - 0.06682189723856391
      - 0.04908079592068357
      - 0.05587407641863087
      - 0.042234323235272
  score_time:
  - 6.2399396896362305
  - 6.28241229057312
  - 6.241417407989502
  - 6.234109163284302
  - 6.080793619155884
  test_level0__average_precision_macro:
  - 0.32176269175739625
  - 0.31928144541409187
  - 0.3194697639455618
  - 0.30757625416328865
  - 0.32031112108852106
  test_level0__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro:
  - 0.49745493232393617
  - 0.4970038676596267
  - 0.497672037102908
  - 0.50663690750418
  - 0.5175057487686648
  test_level0__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples:
  - 0.527517509825195
  - 0.5287429052479408
  - 0.5295486007090238
  - 0.537498272208806
  - 0.5493318515170413
  test_level0__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted:
  - 0.4287437713120385
  - 0.4321258595231986
  - 0.4389002091429838
  - 0.4244519874969003
  - 0.4447525195782866
  test_level0__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.766792153754706
  - 0.7611840852845991
  - 0.7670946862929325
  test_level0__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro:
  - 0.7675504107542942
  - 0.7689320388349514
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929324
  test_level0__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929323
  test_level0__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted:
  - 0.6555831763579656
  - 0.6551512728242037
  - 0.6544355988901279
  - 0.6456794754569823
  - 0.6414665552000154
  test_level0__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro:
  - -0.23244958924570572
  - -0.23106796116504855
  - -0.23320784624529423
  - -0.23881591471540078
  - -0.2329053137070675
  test_level0__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro:
  - -0.23244958924570575
  - -0.23106796116504855
  - -0.23320784624529423
  - -0.23881591471540073
  - -0.23290531370706755
  test_level0__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples:
  - -0.23244958924570572
  - -0.23106796116504852
  - -0.23320784624529417
  - -0.2388159147154007
  - -0.23290531370706752
  test_level0__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted:
  - -0.3444168236420344
  - -0.34484872717579645
  - -0.3455644011098722
  - -0.3543205245430177
  - -0.35853344479998456
  test_level0__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  test_level0__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro:
  - 0.6473412477302279
  - 0.6494800136104317
  - 0.6468941923423415
  - 0.6403406956834046
  - 0.649300868377839
  test_level0__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro:
  - 0.62278442660203
  - 0.6246056782334385
  - 0.6217866323907455
  - 0.6144448713023435
  - 0.6221845893310753
  test_level0__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples:
  - 0.6258490334525433
  - 0.6273425484666882
  - 0.6241995373875175
  - 0.6173709220682427
  - 0.6245048021899566
  test_level0__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted:
  - 0.5169621514501219
  - 0.5165999639928177
  - 0.5129754680083307
  - 0.5060106222200679
  - 0.5044508565220734
  test_level0__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__label_ranking_average_precision_score:
  - 0.5275175098251949
  - 0.5287429052479409
  - 0.5295486007090239
  - 0.5374982722088062
  - 0.5493318515170413
  test_level0__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro:
  - 0.00036157229258439736
  - 0.00048596871248105346
  - 0.001144715813833233
  - 0.0
  - 0.0008497635537515175
  test_level0__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro:
  - 0.017553367714111097
  - 0.024796481478950177
  - 0.04767536439370126
  - 0.0
  - 0.04897734580119923
  test_level0__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples:
  - 0.001681681984990781
  - 0.0032456321697301132
  - 0.012828756553063586
  - 0.0
  - 0.013691983718262897
  test_level0__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted:
  - 0.0013605046561194528
  - 0.0018612932014618196
  - 0.004144928205192845
  - 0.0
  - 0.0033242537592022055
  test_level0__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__ndcg:
  - 0.8218291068504521
  - 0.8250603785551743
  - 0.8244390588030744
  - 0.830686498772908
  - 0.8373764717407861
  test_level0__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_coverage_error:
  - -88.16346153846153
  - -89.46666666666667
  - -90.03061224489795
  - -91.01960784313725
  - -88.52688172043011
  test_level0__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro:
  - -0.23244958924570572
  - -0.23106796116504855
  - -0.23320784624529423
  - -0.23881591471540078
  - -0.2329053137070675
  test_level0__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro:
  - -0.23244958924570575
  - -0.23106796116504855
  - -0.23320784624529423
  - -0.23881591471540073
  - -0.23290531370706755
  test_level0__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples:
  - -0.23244958924570572
  - -0.23106796116504852
  - -0.23320784624529417
  - -0.2388159147154007
  - -0.23290531370706752
  test_level0__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted:
  - -0.3444168236420344
  - -0.34484872717579645
  - -0.3455644011098722
  - -0.3543205245430177
  - -0.35853344479998456
  test_level0__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__neg_label_ranking_loss:
  - -0.2514917058727547
  - -0.25142636406918734
  - -0.24954677292129857
  - -0.250354917418075
  - -0.2414243700622858
  test_level0__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.766792153754706
  - 0.7611840852845991
  - 0.7670946862929325
  test_level0__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro:
  - 0.7675504107542942
  - 0.7689320388349514
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929324
  test_level0__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929323
  test_level0__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted:
  - 0.6555831763579656
  - 0.6551512728242037
  - 0.6544355988901279
  - 0.6456794754569823
  - 0.6414665552000154
  test_level0__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.766792153754706
  - 0.7611840852845991
  - 0.7670946862929325
  test_level0__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro:
  - 0.7675504107542942
  - 0.7689320388349514
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929324
  test_level0__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples:
  - 0.7675504107542941
  - 0.7689320388349513
  - 0.7667921537547058
  - 0.7611840852845992
  - 0.7670946862929323
  test_level0__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted:
  - 0.6555831763579656
  - 0.6551512728242037
  - 0.6544355988901279
  - 0.6456794754569823
  - 0.6414665552000154
  test_level0__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro:
  - 0.5830533964993134
  - 0.5910984590610706
  - 0.5766226092925273
  - 0.5608229069421868
  - 0.5724712121402461
  test_level0__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro:
  - 0.7457906973802929
  - 0.7458233930387432
  - 0.7471693041143987
  - 0.7460273190329992
  - 0.7552551384556653
  test_level0__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples:
  - 0.7485082941272452
  - 0.7485736359308126
  - 0.7504532270787013
  - 0.749645082581925
  - 0.7585756299377141
  test_level0__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted:
  - 0.5815891875011865
  - 0.581023915804851
  - 0.583887411155772
  - 0.5727925742716167
  - 0.5705289537258237
  test_level0__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro:
  - 0.767457057505601
  - 0.7687471104946831
  - 0.7660986724787004
  - 0.7611840852845991
  - 0.7663639210773567
  test_level0__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro:
  - 0.7674570575056012
  - 0.7687471104946834
  - 0.7660986724787002
  - 0.7611840852845992
  - 0.7663639210773567
  test_level0__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples:
  - 0.7674570575056011
  - 0.7687471104946833
  - 0.7660986724787003
  - 0.7611840852845992
  - 0.7663639210773566
  test_level0__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted:
  - 0.655231911805577
  - 0.6544429847108776
  - 0.6519245563536724
  - 0.6456794754569823
  - 0.6386078199621398
  test_level0__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro:
  - 9.335324869305452e-05
  - 0.0001849283402681461
  - 0.0006934812760055478
  - 0.0
  - 0.0007307652155757387
  test_level0__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro:
  - 9.335324869305452e-05
  - 0.0001849283402681461
  - 0.0006934812760055479
  - 0.0
  - 0.0007307652155757385
  test_level0__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples:
  - 9.335324869305451e-05
  - 0.00018492834026814607
  - 0.0006934812760055479
  - 0.0
  - 0.0007307652155757384
  test_level0__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted:
  - 0.00035126455238859895
  - 0.0007082881133260982
  - 0.002511042536455497
  - 0.0
  - 0.0028587352378755997
  test_level0__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level0__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro:
  - 0.2976976929390108
  - 0.3127406349610305
  - 0.30868450680728887
  - 0.3089856589506382
  - 0.2981146113050497
  test_level10__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro:
  - 0.24168453269358506
  - 0.24573235473678354
  - 0.255836451627058
  - 0.24557086545106982
  - 0.24129490559454386
  test_level10__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples:
  - 0.26415862592420264
  - 0.2630941160553259
  - 0.27696000248824537
  - 0.2650578567807022
  - 0.26034661338486553
  test_level10__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted:
  - 0.41420971393943606
  - 0.43453180439991385
  - 0.43599234932951175
  - 0.43205699010488685
  - 0.4302368764749549
  test_level10__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro:
  - 0.40795369678864823
  - 0.38455848358760986
  - 0.4067763027541113
  - 0.386065105653912
  - 0.410481261091972
  test_level10__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.410481261091972
  test_level10__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.4104812610919721
  test_level10__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted:
  - 0.48442083809406167
  - 0.46087850574056094
  - 0.49018921418630995
  - 0.4742534718151907
  - 0.49159195518271875
  test_level10__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro:
  - -0.03911501120238984
  - -0.034119278779472954
  - -0.041608876560332866
  - -0.035313154387968775
  - -0.0468733688276438
  test_level10__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro:
  - -0.039115011202389846
  - -0.034119278779472954
  - -0.04160887656033287
  - -0.03531315438796878
  - -0.046873368827643806
  test_level10__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples:
  - -0.039115011202389846
  - -0.034119278779472954
  - -0.04160887656033287
  - -0.035313154387968775
  - -0.046873368827643806
  test_level10__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted:
  - -0.05319148936170214
  - -0.04723063155690105
  - -0.05779719765924159
  - -0.04659695683773708
  - -0.06227238221530358
  test_level10__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro:
  - -0.5529312920089618
  - -0.5813222376329172
  - -0.5516148206855557
  - -0.5786217399581192
  - -0.542645370080384
  test_level10__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro:
  - -0.552931292008962
  - -0.5813222376329172
  - -0.5516148206855558
  - -0.5786217399581192
  - -0.5426453700803842
  test_level10__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples:
  - -0.5529312920089618
  - -0.5813222376329172
  - -0.5516148206855558
  - -0.578621739958119
  - -0.542645370080384
  test_level10__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted:
  - -0.4623876725442362
  - -0.491890862702538
  - -0.4520135881544485
  - -0.47914957134707215
  - -0.44613566260197757
  test_level10__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro:
  - 0.27243379807659257
  - 0.25417594487048584
  - 0.27298198036753396
  - 0.25623358199889473
  - 0.27429742243244176
  test_level10__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro:
  - 0.25624486923888823
  - 0.23805162841279834
  - 0.25531650292252206
  - 0.23920736022646852
  - 0.258242479968475
  test_level10__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples:
  - 0.26140327548104436
  - 0.2419006673449163
  - 0.2607344242807836
  - 0.244496323611715
  - 0.2637377519144278
  test_level10__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted:
  - 0.3356005722492677
  - 0.3161233137531156
  - 0.3409954285018802
  - 0.32876206991905066
  - 0.3427560993447212
  test_level10__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__label_ranking_average_precision_score:
  - 0.2641586259242027
  - 0.26309411605532584
  - 0.2769600024882453
  - 0.26505785678070226
  - 0.2603466133848654
  test_level10__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro:
  - 0.09672422409071835
  - 0.08316846769060651
  - 0.10546410806402591
  - 0.08823029898376743
  - 0.06547002307672868
  test_level10__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro:
  - 0.10808814851207849
  - 0.09773610106872196
  - 0.0989996925440424
  - 0.09499291487227901
  - 0.08695589319252969
  test_level10__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples:
  - 0.10291205388133136
  - 0.09522283660514799
  - 0.09525209274622468
  - 0.08487733775564578
  - 0.08708618998047361
  test_level10__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted:
  - 0.10339084852865947
  - 0.08561851180928587
  - 0.11977446532982838
  - 0.10327860173717053
  - 0.08200915731703849
  test_level10__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__ndcg:
  - 0.6113402920304304
  - 0.6156633583349825
  - 0.6282404820650908
  - 0.6163726530248604
  - 0.6116903492828749
  test_level10__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_coverage_error:
  - -89.17307692307692
  - -90.79047619047618
  - -89.1938775510204
  - -91.22549019607843
  - -91.47311827956989
  test_level10__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro:
  - -0.5920463032113518
  - -0.6154415164123902
  - -0.5932236972458887
  - -0.6139348943460881
  - -0.589518738908028
  test_level10__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro:
  - -0.5920463032113518
  - -0.6154415164123902
  - -0.5932236972458886
  - -0.613934894346088
  - -0.589518738908028
  test_level10__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples:
  - -0.5920463032113518
  - -0.6154415164123902
  - -0.5932236972458886
  - -0.6139348943460878
  - -0.5895187389080279
  test_level10__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted:
  - -0.5155791619059384
  - -0.5391214942594392
  - -0.50981078581369
  - -0.5257465281848093
  - -0.5084080448172813
  test_level10__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__neg_label_ranking_loss:
  - -0.4811900938838314
  - -0.473166730501379
  - -0.4754730294582948
  - -0.48621882853214343
  - -0.48306741065511194
  test_level10__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro:
  - 0.40795369678864823
  - 0.38455848358760986
  - 0.4067763027541113
  - 0.386065105653912
  - 0.410481261091972
  test_level10__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.410481261091972
  test_level10__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.4104812610919721
  test_level10__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted:
  - 0.48442083809406167
  - 0.46087850574056094
  - 0.49018921418630995
  - 0.4742534718151907
  - 0.49159195518271875
  test_level10__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro:
  - 0.40795369678864823
  - 0.38455848358760986
  - 0.4067763027541113
  - 0.386065105653912
  - 0.410481261091972
  test_level10__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.410481261091972
  test_level10__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples:
  - 0.40795369678864823
  - 0.3845584835876098
  - 0.40677630275411136
  - 0.38606510565391206
  - 0.4104812610919721
  test_level10__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted:
  - 0.48442083809406167
  - 0.46087850574056094
  - 0.49018921418630995
  - 0.4742534718151907
  - 0.49159195518271875
  test_level10__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro:
  - 0.5880356559030402
  - 0.5961770019032601
  - 0.6005304265446387
  - 0.5956987239661244
  - 0.5789306687473006
  test_level10__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro:
  - 0.5479349548411991
  - 0.5500263690530524
  - 0.5562153442511899
  - 0.5389687035388371
  - 0.5393794374611285
  test_level10__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples:
  - 0.5365369599979464
  - 0.5381419129375633
  - 0.5439329535363374
  - 0.5227638588879127
  - 0.5307550441918316
  test_level10__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted:
  - 0.5866631298287711
  - 0.5977328759309487
  - 0.6021065878229135
  - 0.5972444621167955
  - 0.5778394171864845
  test_level10__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro:
  - 0.2145257654966393
  - 0.187424872861766
  - 0.21448385179314444
  - 0.1825623453264801
  - 0.22371855099697255
  test_level10__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro:
  - 0.2145257654966393
  - 0.18742487286176607
  - 0.21448385179314444
  - 0.1825623453264801
  - 0.22371855099697255
  test_level10__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples:
  - 0.2145257654966392
  - 0.18742487286176604
  - 0.2144838517931444
  - 0.18256234532648014
  - 0.2237185509969725
  test_level10__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted:
  - 0.19284423926134084
  - 0.16255212200833952
  - 0.19991096819922377
  - 0.16652990410991023
  - 0.1924721573601622
  test_level10__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro:
  - 0.1934279312920089
  - 0.19713361072584376
  - 0.1922924509609669
  - 0.20350276032743198
  - 0.1867627100949995
  test_level10__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro:
  - 0.19342793129200897
  - 0.19713361072584373
  - 0.19229245096096692
  - 0.20350276032743195
  - 0.18676271009499948
  test_level10__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples:
  - 0.19342793129200891
  - 0.19713361072584373
  - 0.19229245096096687
  - 0.20350276032743195
  - 0.1867627100949994
  test_level10__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted:
  - 0.2915765988327209
  - 0.2983263837322214
  - 0.290278245987086
  - 0.3077235677052806
  - 0.2991197978225566
  test_level10__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level10__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro:
  - 0.3257230200498815
  - 0.34111971822297166
  - 0.32467536859370394
  - 0.32617896344130476
  - 0.318792174441779
  test_level1__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro:
  - 0.24666912601748564
  - 0.24712531813784722
  - 0.2595820109444268
  - 0.25346248763644164
  - 0.255397690473414
  test_level1__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples:
  - 0.2769852480404087
  - 0.27069544374098314
  - 0.28874372219039607
  - 0.2813589542090929
  - 0.27888533724541015
  test_level1__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted:
  - 0.4316807694242969
  - 0.45725633456420833
  - 0.4468122789690764
  - 0.445699621752497
  - 0.44839556665690505
  test_level1__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro:
  - 0.42615758028379386
  - 0.41812297734627835
  - 0.4231226471170994
  - 0.40748143917761276
  - 0.4360580436371229
  test_level1__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro:
  - 0.42615758028379386
  - 0.4181229773462783
  - 0.4231226471170993
  - 0.4074814391776128
  - 0.43605804363712286
  test_level1__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples:
  - 0.4261575802837939
  - 0.4181229773462783
  - 0.4231226471170992
  - 0.4074814391776128
  - 0.4360580436371228
  test_level1__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted:
  - 0.498104715437112
  - 0.485066925610708
  - 0.5023295213892418
  - 0.49081737118920915
  - 0.5078747345460137
  test_level1__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro:
  - -0.04443614637789395
  - -0.04225612575127138
  - -0.04646324549237171
  - -0.04245193222920236
  - -0.051884330305877434
  test_level1__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro:
  - -0.04443614637789395
  - -0.042256125751271384
  - -0.046463245492371706
  - -0.04245193222920236
  - -0.05188433030587744
  test_level1__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples:
  - -0.04443614637789395
  - -0.04225612575127137
  - -0.046463245492371706
  - -0.04245193222920237
  - -0.05188433030587745
  test_level1__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted:
  - -0.056549732884538184
  - -0.05466384874621579
  - -0.060433576225916025
  - -0.05290366445502075
  - -0.06496295655683357
  test_level1__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro:
  - -0.5294062733383122
  - -0.5396208969024504
  - -0.530414107390529
  - -0.5500666285931849
  - -0.5120576260569996
  test_level1__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro:
  - -0.5294062733383121
  - -0.5396208969024503
  - -0.5304141073905291
  - -0.5500666285931849
  - -0.5120576260569997
  test_level1__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples:
  - -0.5294062733383121
  - -0.5396208969024503
  - -0.5304141073905291
  - -0.5500666285931848
  - -0.5120576260569997
  test_level1__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted:
  - -0.44534555167834977
  - -0.46026922564307615
  - -0.43723690238484214
  - -0.4562789643557701
  - -0.42716230889715284
  test_level1__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro:
  - 0.29325511568909596
  - 0.28925616100906076
  - 0.2928465445123141
  - 0.2806209123876752
  - 0.30116711905273974
  test_level1__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro:
  - 0.2707752535737588
  - 0.26432078559738137
  - 0.26832945906892003
  - 0.2558723327954097
  - 0.27881983846205194
  test_level1__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples:
  - 0.2751117082526903
  - 0.26738238775775514
  - 0.2728335193833155
  - 0.25976183647824785
  - 0.28340737784398606
  test_level1__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted:
  - 0.351189312364333
  - 0.34121846114243126
  - 0.356061379647065
  - 0.34741933628999416
  - 0.35950830391141153
  test_level1__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__label_ranking_average_precision_score:
  - 0.27698524804040864
  - 0.27069544374098314
  - 0.2887437221903961
  - 0.28135895420909285
  - 0.27888533724541015
  test_level1__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro:
  - 0.09260721098787611
  - 0.09207835891295514
  - 0.09778360608951801
  - 0.08722478857604991
  - 0.07095385823614261
  test_level1__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro:
  - 0.1117511401187068
  - 0.10934943391930872
  - 0.10252294817426476
  - 0.09760369979596244
  - 0.10076784294906312
  test_level1__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples:
  - 0.10862872961070619
  - 0.10769492687504806
  - 0.10091429016642178
  - 0.09381430143154822
  - 0.1023358290005836
  test_level1__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted:
  - 0.09919974747458166
  - 0.09481363133073077
  - 0.11112641856544445
  - 0.10044729308115173
  - 0.07394051525194816
  test_level1__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__ndcg:
  - 0.6078696343121384
  - 0.605416078240689
  - 0.6224647577692206
  - 0.6154310031550667
  - 0.6106368479735815
  test_level1__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_coverage_error:
  - -89.5
  - -91.13333333333334
  - -90.39795918367346
  - -92.11764705882354
  - -91.46236559139786
  test_level1__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro:
  - -0.5738424197162062
  - -0.5818770226537217
  - -0.5768773528829005
  - -0.5925185608223872
  - -0.563941956362877
  test_level1__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro:
  - -0.5738424197162061
  - -0.5818770226537217
  - -0.5768773528829008
  - -0.5925185608223872
  - -0.5639419563628771
  test_level1__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples:
  - -0.573842419716206
  - -0.5818770226537217
  - -0.5768773528829008
  - -0.5925185608223872
  - -0.5639419563628771
  test_level1__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted:
  - -0.501895284562888
  - -0.5149330743892919
  - -0.49767047861075814
  - -0.5091826288107909
  - -0.49212526545398644
  test_level1__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__neg_label_ranking_loss:
  - -0.4414833708448504
  - -0.4425672651830513
  - -0.4364466137175838
  - -0.4552931758902048
  - -0.434895460737012
  test_level1__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro:
  - 0.42615758028379386
  - 0.41812297734627835
  - 0.4231226471170994
  - 0.40748143917761276
  - 0.4360580436371229
  test_level1__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro:
  - 0.42615758028379386
  - 0.4181229773462783
  - 0.4231226471170993
  - 0.4074814391776128
  - 0.43605804363712286
  test_level1__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples:
  - 0.4261575802837939
  - 0.4181229773462783
  - 0.4231226471170992
  - 0.4074814391776128
  - 0.4360580436371228
  test_level1__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted:
  - 0.498104715437112
  - 0.485066925610708
  - 0.5023295213892418
  - 0.49081737118920915
  - 0.5078747345460137
  test_level1__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro:
  - 0.42615758028379386
  - 0.41812297734627835
  - 0.4231226471170994
  - 0.40748143917761276
  - 0.4360580436371229
  test_level1__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro:
  - 0.42615758028379386
  - 0.4181229773462783
  - 0.4231226471170993
  - 0.4074814391776128
  - 0.43605804363712286
  test_level1__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples:
  - 0.4261575802837939
  - 0.4181229773462783
  - 0.4231226471170992
  - 0.4074814391776128
  - 0.4360580436371228
  test_level1__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted:
  - 0.498104715437112
  - 0.485066925610708
  - 0.5023295213892418
  - 0.49081737118920915
  - 0.5078747345460137
  test_level1__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro:
  - 0.5952082713252757
  - 0.6064603393164668
  - 0.6039490289801898
  - 0.5990793619619726
  - 0.5809313077483591
  test_level1__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro:
  - 0.5625635086457214
  - 0.5646240661781956
  - 0.5690235081661551
  - 0.5533926059259069
  - 0.5714048157550131
  test_level1__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples:
  - 0.5585243337685443
  - 0.557452031568123
  - 0.5635533862824162
  - 0.5447068241097952
  - 0.5651076614140251
  test_level1__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted:
  - 0.5883005056257028
  - 0.6014767589798394
  - 0.6064928249467868
  - 0.6034112216972097
  - 0.5804270348961804
  test_level1__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro:
  - 0.23805078416728903
  - 0.22912621359223298
  - 0.23568456508817118
  - 0.21111745669141443
  - 0.254306295020357
  test_level1__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro:
  - 0.23805078416728903
  - 0.229126213592233
  - 0.23568456508817118
  - 0.21111745669141443
  - 0.254306295020357
  test_level1__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples:
  - 0.23805078416728895
  - 0.22912621359223295
  - 0.23568456508817115
  - 0.2111174566914144
  - 0.25430629502035695
  test_level1__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted:
  - 0.20988636012722733
  - 0.1941737590678015
  - 0.21468765396883024
  - 0.18940051110121212
  - 0.211445511064987
  test_level1__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro:
  - 0.18810679611650483
  - 0.18899676375404528
  - 0.1874380820289281
  - 0.1963639824861984
  - 0.18175174861676582
  test_level1__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro:
  - 0.18810679611650485
  - 0.1889967637540453
  - 0.1874380820289281
  - 0.19636398248619835
  - 0.18175174861676585
  test_level1__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples:
  - 0.1881067961165048
  - 0.18899676375404528
  - 0.18743808202892806
  - 0.19636398248619832
  - 0.18175174861676582
  test_level1__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted:
  - 0.2882183553098849
  - 0.2908931665429067
  - 0.2876418674204116
  - 0.30141686008799695
  - 0.2964292234810266
  test_level1__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level1__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro:
  - 0.2942252756685753
  - 0.3183641772941792
  - 0.30607072249441936
  - 0.3104083615109749
  - 0.300880632213481
  test_level2__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro:
  - 0.23656239163588494
  - 0.24078881462130486
  - 0.2554697934185852
  - 0.2415044053959953
  - 0.24495795091188305
  test_level2__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples:
  - 0.2576923541856548
  - 0.2602708531990413
  - 0.2799627724662612
  - 0.26090905273959053
  - 0.2632159475724722
  test_level2__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted:
  - 0.4077432237866708
  - 0.43649437897987037
  - 0.43067561872312626
  - 0.4347722603938134
  - 0.4346056734565871
  test_level2__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro:
  - 0.4071135175504108
  - 0.39103097549699495
  - 0.4042995839112345
  - 0.385208452312964
  - 0.41183839649232706
  test_level2__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.385208452312964
  - 0.41183839649232695
  test_level2__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.3852084523129641
  - 0.41183839649232695
  test_level2__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted:
  - 0.4849882654479201
  - 0.4662592106014736
  - 0.4884604413557036
  - 0.47599621753843024
  - 0.4932255181757906
  test_level2__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro:
  - -0.03874159820761763
  - -0.0353213129912159
  - -0.04081632653061224
  - -0.032743194365124684
  - -0.045725023488881925
  test_level2__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro:
  - -0.03874159820761763
  - -0.0353213129912159
  - -0.04081632653061224
  - -0.03274319436512469
  - -0.04572502348888193
  test_level2__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples:
  - -0.03874159820761762
  - -0.035321312991215895
  - -0.040816326530612235
  - -0.032743194365124684
  - -0.04572502348888194
  test_level2__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted:
  - -0.05330729086248958
  - -0.048776679804268766
  - -0.0571878052364529
  - -0.043361545495041384
  - -0.06155169265953663
  test_level2__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro:
  - -0.5541448842419716
  - -0.5736477115117892
  - -0.5548840895581533
  - -0.5820483533219113
  - -0.542436580018791
  test_level2__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro:
  - -0.5541448842419716
  - -0.5736477115117892
  - -0.5548840895581534
  - -0.5820483533219113
  - -0.5424365800187911
  test_level2__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples:
  - -0.5541448842419716
  - -0.5736477115117892
  - -0.5548840895581534
  - -0.5820483533219113
  - -0.5424365800187909
  test_level2__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted:
  - -0.46170444368959024
  - -0.4849641095942576
  - -0.4543517534078435
  - -0.4806422369665283
  - -0.4452227891646728
  test_level2__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro:
  - 0.27182403773220565
  - 0.25957633710000205
  - 0.27068730785571254
  - 0.2556357299767144
  - 0.2756194114309878
  test_level2__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro:
  - 0.25558225399988277
  - 0.24303200965461755
  - 0.25336810082572797
  - 0.2385499557913351
  - 0.25931768881877343
  test_level2__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples:
  - 0.26105602916777093
  - 0.2470959297587752
  - 0.2588204813757642
  - 0.24405970146833147
  - 0.2649614831762368
  test_level2__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted:
  - 0.33607435638275995
  - 0.3209069818411187
  - 0.33940083995039516
  - 0.33055374478206784
  - 0.3440595905320733
  test_level2__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__label_ranking_average_precision_score:
  - 0.2576923541856547
  - 0.26027085319904103
  - 0.2799627724662612
  - 0.26090905273959064
  - 0.26321594757247213
  test_level2__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro:
  - 0.09828159129418547
  - 0.08600331617619948
  - 0.10394980564584515
  - 0.09656134949862376
  - 0.07061224200820605
  test_level2__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro:
  - 0.10833660214901536
  - 0.1011774467489535
  - 0.0986659015883149
  - 0.10249162688802767
  - 0.09199752767800316
  test_level2__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples:
  - 0.100992591708749
  - 0.10010519127327747
  - 0.09642247239244696
  - 0.09004449867592337
  - 0.09382160522172178
  test_level2__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted:
  - 0.10678391356522156
  - 0.09077094594554544
  - 0.11476864250555398
  - 0.11490781535842381
  - 0.09019973102331372
  test_level2__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__ndcg:
  - 0.6022885787269786
  - 0.6063598651013307
  - 0.6240330821079222
  - 0.6051575597081598
  - 0.6116151007899531
  test_level2__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_coverage_error:
  - -89.23076923076923
  - -90.19047619047619
  - -89.22448979591837
  - -91.32352941176471
  - -90.95698924731182
  test_level2__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro:
  - -0.5928864824495892
  - -0.6089690245030052
  - -0.5957004160887656
  - -0.6147915476870359
  - -0.588161603507673
  test_level2__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro:
  - -0.5928864824495892
  - -0.608969024503005
  - -0.5957004160887656
  - -0.614791547687036
  - -0.588161603507673
  test_level2__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples:
  - -0.5928864824495892
  - -0.608969024503005
  - -0.5957004160887656
  - -0.6147915476870358
  - -0.588161603507673
  test_level2__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted:
  - -0.5150117345520798
  - -0.5337407893985263
  - -0.5115395586442965
  - -0.5240037824615698
  - -0.5067744818242096
  test_level2__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__neg_label_ranking_loss:
  - -0.4785428515787459
  - -0.46648775874162485
  - -0.4616237902591356
  - -0.4828486464283098
  - -0.47925242314842886
  test_level2__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro:
  - 0.4071135175504108
  - 0.39103097549699495
  - 0.4042995839112345
  - 0.385208452312964
  - 0.41183839649232706
  test_level2__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.385208452312964
  - 0.41183839649232695
  test_level2__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.3852084523129641
  - 0.41183839649232695
  test_level2__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted:
  - 0.4849882654479201
  - 0.4662592106014736
  - 0.4884604413557036
  - 0.47599621753843024
  - 0.4932255181757906
  test_level2__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro:
  - 0.4071135175504108
  - 0.39103097549699495
  - 0.4042995839112345
  - 0.385208452312964
  - 0.41183839649232706
  test_level2__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.385208452312964
  - 0.41183839649232695
  test_level2__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples:
  - 0.40711351755041075
  - 0.3910309754969949
  - 0.4042995839112344
  - 0.3852084523129641
  - 0.41183839649232695
  test_level2__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted:
  - 0.4849882654479201
  - 0.4662592106014736
  - 0.4884604413557036
  - 0.47599621753843024
  - 0.4932255181757906
  test_level2__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro:
  - 0.5880793579910256
  - 0.5967316963893451
  - 0.5976924025647863
  - 0.5940303850878093
  - 0.580929879505684
  test_level2__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro:
  - 0.5434697132032695
  - 0.5485463019507135
  - 0.5575688344363526
  - 0.5384923142511642
  - 0.5455865723611643
  test_level2__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples:
  - 0.5322207052537671
  - 0.5393559335104723
  - 0.5488414113737834
  - 0.522222341922463
  - 0.5368217184994059
  test_level2__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted:
  - 0.5826335305923179
  - 0.595255612045709
  - 0.6002992405304125
  - 0.6009123489605492
  - 0.5786596827355774
  test_level2__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro:
  - 0.21331217326362958
  - 0.19509939898289408
  - 0.21121458292054685
  - 0.179135731962688
  - 0.22392734105856563
  test_level2__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro:
  - 0.21331217326362958
  - 0.19509939898289413
  - 0.21121458292054687
  - 0.17913573196268798
  - 0.2239273410585656
  test_level2__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples:
  - 0.21331217326362953
  - 0.19509939898289408
  - 0.2112145829205468
  - 0.17913573196268798
  - 0.22392734105856554
  test_level2__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted:
  - 0.19352746811598676
  - 0.16947887511662002
  - 0.19757280294582893
  - 0.16503723849045396
  - 0.19338503079746702
  test_level2__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro:
  - 0.19380134428678117
  - 0.19593157651410079
  - 0.19308500099068754
  - 0.20607272035027602
  - 0.18791105543376135
  test_level2__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro:
  - 0.19380134428678117
  - 0.19593157651410079
  - 0.19308500099068754
  - 0.20607272035027605
  - 0.18791105543376135
  test_level2__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples:
  - 0.19380134428678114
  - 0.19593157651410073
  - 0.19308500099068746
  - 0.20607272035027602
  - 0.18791105543376127
  test_level2__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted:
  - 0.29146079733193336
  - 0.29678033548485366
  - 0.29088763840987475
  - 0.31095897904797626
  - 0.2998404873783236
  test_level2__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level2__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro:
  - 0.29487926783593366
  - 0.31195350349782797
  - 0.3116801438146829
  - 0.30659732864362504
  - 0.295342096152854
  test_level3__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro:
  - 0.23974535155354426
  - 0.24276868472011204
  - 0.25671599829208175
  - 0.24297756729669953
  - 0.2449013222504356
  test_level3__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples:
  - 0.2611749402333635
  - 0.2626118792533463
  - 0.27853174385010065
  - 0.262221993948086
  - 0.26423949104895406
  test_level3__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted:
  - 0.409587901592113
  - 0.4334581834149259
  - 0.43925587480160333
  - 0.43027329228415373
  - 0.428565672047912
  test_level3__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.3887302493813059
  - 0.4132999269234785
  test_level3__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro:
  - 0.41019417475728154
  - 0.3914008321775312
  - 0.40766792153754705
  - 0.3887302493813059
  - 0.41329992692347844
  test_level3__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.38873024938130585
  - 0.41329992692347856
  test_level3__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted:
  - 0.48614628045579467
  - 0.46736733877877423
  - 0.4932837175530949
  - 0.47728960057518416
  - 0.4948158397955163
  test_level3__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro:
  - -0.039208364451082896
  - -0.03522884882108183
  - -0.04071725777689717
  - -0.03436131734247097
  - -0.04593381355047499
  test_level3__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro:
  - -0.039208364451082896
  - -0.03522884882108183
  - -0.040717257776897164
  - -0.03436131734247097
  - -0.045933813550474996
  test_level3__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples:
  - -0.039208364451082896
  - -0.03522884882108183
  - -0.040717257776897164
  - -0.034361317342470964
  - -0.045933813550475
  test_level3__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted:
  - -0.053724176265324414
  - -0.04846823175491708
  - -0.05692848931186197
  - -0.04633515422908901
  - -0.06174387654107449
  test_level3__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro:
  - -0.5505974607916355
  - -0.5733703190013869
  - -0.5516148206855557
  - -0.5769084332762231
  - -0.5407662595260465
  test_level3__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro:
  - -0.5505974607916355
  - -0.5733703190013869
  - -0.5516148206855558
  - -0.5769084332762231
  - -0.5407662595260465
  test_level3__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples:
  - -0.5505974607916355
  - -0.573370319001387
  - -0.5516148206855558
  - -0.576908433276223
  - -0.5407662595260465
  test_level3__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted:
  - -0.46012954327888084
  - -0.4841644294663088
  - -0.44978779313504313
  - -0.4763752451957269
  - -0.4434402836634092
  test_level3__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro:
  - 0.27438391860042155
  - 0.25977135025135634
  - 0.2737330948217758
  - 0.2581373561967745
  - 0.2765457499511323
  test_level3__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro:
  - 0.2580152671755725
  - 0.24331781341610623
  - 0.2560194114353263
  - 0.2412570888468809
  - 0.260477663004145
  test_level3__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples:
  - 0.26328277211518036
  - 0.2473691962172407
  - 0.2615624550628021
  - 0.24649102282304317
  - 0.2657877735222872
  test_level3__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted:
  - 0.3370524029625746
  - 0.32180436760173325
  - 0.3440215097865428
  - 0.3312422788791375
  - 0.3451353254820732
  test_level3__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__label_ranking_average_precision_score:
  - 0.2611749402333634
  - 0.2626118792533463
  - 0.27853174385010054
  - 0.26222199394808604
  - 0.26423949104895406
  test_level3__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro:
  - 0.09798386898627943
  - 0.08663394595474842
  - 0.10963801134232315
  - 0.09788661919165667
  - 0.07180484321748572
  test_level3__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro:
  - 0.11030484939319118
  - 0.10191044744665574
  - 0.102814320961382
  - 0.10130677211802555
  - 0.09302022794369844
  test_level3__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples:
  - 0.10415460710697687
  - 0.10060078690334488
  - 0.10012083728265289
  - 0.08991412722210569
  - 0.094369725372616
  test_level3__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted:
  - 0.10660806352256498
  - 0.09193814135086487
  - 0.12660939453386708
  - 0.11193426513146135
  - 0.09086463603513585
  test_level3__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__ndcg:
  - 0.6073157894711502
  - 0.611090823747443
  - 0.6301782256430396
  - 0.6108928405587667
  - 0.6144549205070859
  test_level3__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_coverage_error:
  - -89.0576923076923
  - -90.32380952380953
  - -89.40816326530613
  - -91.2156862745098
  - -90.88172043010752
  test_level3__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro:
  - -0.5898058252427184
  - -0.6085991678224688
  - -0.592332078462453
  - -0.611269750618694
  - -0.5867000730765215
  test_level3__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro:
  - -0.5898058252427184
  - -0.6085991678224688
  - -0.592332078462453
  - -0.611269750618694
  - -0.5867000730765216
  test_level3__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples:
  - -0.5898058252427185
  - -0.6085991678224688
  - -0.5923320784624528
  - -0.611269750618694
  - -0.5867000730765214
  test_level3__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted:
  - -0.5138537195442053
  - -0.5326326612212258
  - -0.506716282446905
  - -0.5227103994248159
  - -0.5051841602044838
  test_level3__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__neg_label_ranking_loss:
  - -0.48095508520397634
  - -0.4688720265774626
  - -0.46938542521322374
  - -0.4865115372821384
  - -0.48059454053100653
  test_level3__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.3887302493813059
  - 0.4132999269234785
  test_level3__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro:
  - 0.41019417475728154
  - 0.3914008321775312
  - 0.40766792153754705
  - 0.3887302493813059
  - 0.41329992692347844
  test_level3__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.38873024938130585
  - 0.41329992692347856
  test_level3__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted:
  - 0.48614628045579467
  - 0.46736733877877423
  - 0.4932837175530949
  - 0.47728960057518416
  - 0.4948158397955163
  test_level3__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.3887302493813059
  - 0.4132999269234785
  test_level3__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro:
  - 0.41019417475728154
  - 0.3914008321775312
  - 0.40766792153754705
  - 0.3887302493813059
  - 0.41329992692347844
  test_level3__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples:
  - 0.41019417475728154
  - 0.39140083217753124
  - 0.4076679215375471
  - 0.38873024938130585
  - 0.41329992692347856
  test_level3__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted:
  - 0.48614628045579467
  - 0.46736733877877423
  - 0.4932837175530949
  - 0.47728960057518416
  - 0.4948158397955163
  test_level3__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro:
  - 0.5872414164232136
  - 0.5981809277394552
  - 0.6027966921152488
  - 0.5946633975461189
  - 0.580639845908326
  test_level3__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro:
  - 0.5459221131848893
  - 0.549839674426116
  - 0.5581701452429735
  - 0.5384760915474829
  - 0.545573820642543
  test_level3__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples:
  - 0.5344672267373242
  - 0.5407409042580174
  - 0.5473956420185887
  - 0.5222933428998484
  - 0.5366526747998371
  test_level3__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted:
  - 0.582672353656654
  - 0.598137573909828
  - 0.605164200985763
  - 0.5991191819318581
  - 0.5782893351225123
  test_level3__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro:
  - 0.21685959671396565
  - 0.19537679149329631
  - 0.21448385179314447
  - 0.1842756520083762
  - 0.2255976615513102
  test_level3__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro:
  - 0.21685959671396565
  - 0.19537679149329634
  - 0.21448385179314444
  - 0.18427565200837617
  - 0.22559766155131017
  test_level3__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples:
  - 0.2168595967139656
  - 0.1953767914932963
  - 0.2144838517931444
  - 0.18427565200837612
  - 0.22559766155131009
  test_level3__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted:
  - 0.1951023685266961
  - 0.17027855524456884
  - 0.20213676321862925
  - 0.16930423026125554
  - 0.1951675362987306
  test_level3__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro:
  - 0.19333457804331589
  - 0.19602404068423485
  - 0.19318406974440264
  - 0.20445459737292976
  - 0.1877022653721683
  test_level3__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro:
  - 0.1933345780433159
  - 0.19602404068423485
  - 0.1931840697444026
  - 0.20445459737292976
  - 0.18770226537216828
  test_level3__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples:
  - 0.19333457804331586
  - 0.19602404068423485
  - 0.19318406974440258
  - 0.20445459737292976
  - 0.18770226537216822
  test_level3__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted:
  - 0.2910439119290986
  - 0.29708878353420537
  - 0.2911469543344657
  - 0.3079853703139286
  - 0.29964830349678573
  test_level3__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level3__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro:
  - 0.2985700281789323
  - 0.30785707114276184
  - 0.31006295597638933
  - 0.3069860065395428
  - 0.2958373661092268
  test_level4__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro:
  - 0.24076120270005422
  - 0.24134050021682754
  - 0.25830888386554607
  - 0.2452722287935486
  - 0.243694891477115
  test_level4__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples:
  - 0.263350071542177
  - 0.26149747222751846
  - 0.27968464305586566
  - 0.26444257788544456
  - 0.26405606836155954
  test_level4__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted:
  - 0.413842792339695
  - 0.42763212987230453
  - 0.4351801698063775
  - 0.43022407614259667
  - 0.42678938209986683
  test_level4__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro:
  - 0.4099141150112025
  - 0.3881645862228387
  - 0.40816326530612257
  - 0.38901580049495527
  - 0.4141350871698508
  test_level4__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro:
  - 0.4099141150112024
  - 0.38816458622283867
  - 0.40816326530612246
  - 0.38901580049495527
  - 0.4141350871698507
  test_level4__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples:
  - 0.40991411501120234
  - 0.38816458622283867
  - 0.4081632653061225
  - 0.38901580049495516
  - 0.4141350871698507
  test_level4__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted:
  - 0.4857332551029861
  - 0.46342605814816934
  - 0.4919136650848396
  - 0.4779304308411287
  - 0.49351859859513575
  test_level4__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro:
  - -0.03995519044062733
  - -0.0356911696717522
  - -0.04141073905290271
  - -0.03436131734247097
  - -0.04603820858127153
  test_level4__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro:
  - -0.039955190440627335
  - -0.0356911696717522
  - -0.04141073905290271
  - -0.03436131734247097
  - -0.04603820858127153
  test_level4__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples:
  - -0.039955190440627335
  - -0.03569116967175219
  - -0.04141073905290271
  - -0.034361317342470964
  - -0.046038208581271535
  test_level4__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted:
  - -0.05456952722107279
  - -0.04922221587555454
  - -0.05835472689711208
  - -0.04622574418368384
  - -0.062281991409380476
  test_level4__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro:
  - -0.5501306945481702
  - -0.5761442441054092
  - -0.5504259956409747
  - -0.5766228821625737
  - -0.5398267042488777
  test_level4__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro:
  - -0.5501306945481703
  - -0.5761442441054092
  - -0.5504259956409748
  - -0.5766228821625737
  - -0.5398267042488778
  test_level4__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples:
  - -0.5501306945481702
  - -0.5761442441054092
  - -0.5504259956409747
  - -0.5766228821625736
  - -0.5398267042488778
  test_level4__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted:
  - -0.4596972176759412
  - -0.48735172597627613
  - -0.4497316080180483
  - -0.4758438249751874
  - -0.44419940999548374
  test_level4__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro:
  - 0.27410877433817865
  - 0.25658082099550056
  - 0.2741167831381597
  - 0.25859490822709424
  - 0.27706871570107094
  test_level4__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro:
  - 0.2577936945928492
  - 0.2408214777420835
  - 0.2564102564102564
  - 0.2414771048744461
  - 0.26114146534132054
  test_level4__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples:
  - 0.26317520283991297
  - 0.24474164829880501
  - 0.2621026342590715
  - 0.24667587358087922
  - 0.26653992826612183
  test_level4__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted:
  - 0.3367297013602536
  - 0.31796580562023075
  - 0.3426803807239374
  - 0.3319345428540061
  - 0.34370987947092574
  test_level4__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__label_ranking_average_precision_score:
  - 0.26335007154217693
  - 0.26149747222751857
  - 0.27968464305586566
  - 0.2644425778854445
  - 0.26405606836155954
  test_level4__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro:
  - 0.09544927669253431
  - 0.08131430308015451
  - 0.1080757114918434
  - 0.09821798807702689
  - 0.06794255500813
  test_level4__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro:
  - 0.10761833713607484
  - 0.09663861465364602
  - 0.10119821987825872
  - 0.10164597811392848
  - 0.09364894297908004
  test_level4__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples:
  - 0.10164050856668426
  - 0.09470697487028075
  - 0.09688742151128314
  - 0.09096900549994061
  - 0.09428222787509591
  test_level4__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted:
  - 0.10329559087941756
  - 0.08322732949532934
  - 0.1213666386955676
  - 0.11407536321594192
  - 0.07713680689191876
  test_level4__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__ndcg:
  - 0.6088484137701001
  - 0.6112611585089265
  - 0.630761401717844
  - 0.6145929145901337
  - 0.6126739051738522
  test_level4__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_coverage_error:
  - -88.76923076923077
  - -90.4952380952381
  - -89.41836734693878
  - -91.26470588235294
  - -90.89247311827957
  test_level4__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro:
  - -0.5900858849887974
  - -0.6118354137771613
  - -0.5918367346938775
  - -0.6109841995050447
  - -0.5858649128301492
  test_level4__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro:
  - -0.5900858849887977
  - -0.6118354137771613
  - -0.5918367346938775
  - -0.6109841995050448
  - -0.5858649128301493
  test_level4__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples:
  - -0.5900858849887975
  - -0.6118354137771613
  - -0.5918367346938774
  - -0.6109841995050447
  - -0.5858649128301492
  test_level4__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted:
  - -0.514266744897014
  - -0.5365739418518307
  - -0.5080863349151604
  - -0.5220695691588714
  - -0.5064814014048643
  test_level4__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__neg_label_ranking_loss:
  - -0.4811781640427106
  - -0.471427169467116
  - -0.4709025975917024
  - -0.4856314129532716
  - -0.47715273557580534
  test_level4__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro:
  - 0.4099141150112025
  - 0.3881645862228387
  - 0.40816326530612257
  - 0.38901580049495527
  - 0.4141350871698508
  test_level4__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro:
  - 0.4099141150112024
  - 0.38816458622283867
  - 0.40816326530612246
  - 0.38901580049495527
  - 0.4141350871698507
  test_level4__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples:
  - 0.40991411501120234
  - 0.38816458622283867
  - 0.4081632653061225
  - 0.38901580049495516
  - 0.4141350871698507
  test_level4__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted:
  - 0.4857332551029861
  - 0.46342605814816934
  - 0.4919136650848396
  - 0.4779304308411287
  - 0.49351859859513575
  test_level4__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro:
  - 0.4099141150112025
  - 0.3881645862228387
  - 0.40816326530612257
  - 0.38901580049495527
  - 0.4141350871698508
  test_level4__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro:
  - 0.4099141150112024
  - 0.38816458622283867
  - 0.40816326530612246
  - 0.38901580049495527
  - 0.4141350871698507
  test_level4__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples:
  - 0.40991411501120234
  - 0.38816458622283867
  - 0.4081632653061225
  - 0.38901580049495516
  - 0.4141350871698507
  test_level4__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted:
  - 0.4857332551029861
  - 0.46342605814816934
  - 0.4919136650848396
  - 0.4779304308411287
  - 0.49351859859513575
  test_level4__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro:
  - 0.5892178170829588
  - 0.5950161713925983
  - 0.6017908233290437
  - 0.5928390470533493
  - 0.580554047175769
  test_level4__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro:
  - 0.5467367476082612
  - 0.5478129893099292
  - 0.5585641178833181
  - 0.5396287258578882
  - 0.5443407690156733
  test_level4__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples:
  - 0.5351229331455587
  - 0.538905259920703
  - 0.5464336561974968
  - 0.523988691030882
  - 0.5367531509063366
  test_level4__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted:
  - 0.5865173540092565
  - 0.5953230426172372
  - 0.6026427396132268
  - 0.596538694134052
  - 0.5778182796474296
  test_level4__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro:
  - 0.21732636295743096
  - 0.1926028663892741
  - 0.2156726768377254
  - 0.1845612031220256
  - 0.226537216828479
  test_level4__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro:
  - 0.2173263629574309
  - 0.19260286638927415
  - 0.21567267683772537
  - 0.1845612031220255
  - 0.22653721682847897
  test_level4__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples:
  - 0.21732636295743085
  - 0.19260286638927412
  - 0.2156726768377253
  - 0.18456120312202545
  - 0.22653721682847888
  test_level4__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted:
  - 0.19553469412963592
  - 0.1670912587346014
  - 0.20219294833562398
  - 0.16983565048179494
  - 0.1944084099666561
  test_level4__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro:
  - 0.19258775205377143
  - 0.19556171983356452
  - 0.19249058846839706
  - 0.20445459737292976
  - 0.18759787034137174
  test_level4__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro:
  - 0.19258775205377146
  - 0.1955617198335645
  - 0.19249058846839706
  - 0.20445459737292976
  - 0.18759787034137176
  test_level4__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples:
  - 0.19258775205377143
  - 0.19556171983356446
  - 0.19249058846839703
  - 0.20445459737292976
  - 0.18759787034137168
  test_level4__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted:
  - 0.29019856097335023
  - 0.29633479941356794
  - 0.28972071674921557
  - 0.3080947803593338
  - 0.2991101886284797
  test_level4__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level4__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro:
  - 0.30054135548192357
  - 0.31198701166702614
  - 0.3057392800330769
  - 0.3027189931640557
  - 0.2961890785357218
  test_level5__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro:
  - 0.24203660316352488
  - 0.24333386522670034
  - 0.25810705845579973
  - 0.2425270800585429
  - 0.24573723630683936
  test_level5__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples:
  - 0.2634439373057267
  - 0.26287678677847076
  - 0.27948927522230343
  - 0.26190957947810023
  - 0.26537373100806866
  test_level5__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted:
  - 0.4156338167017567
  - 0.4343932558738951
  - 0.4314919919355237
  - 0.42740398065647944
  - 0.4294045648257369
  test_level5__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro:
  - 0.4094473487677372
  - 0.38613037447988907
  - 0.4065781652466813
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro:
  - 0.40944734876773714
  - 0.386130374479889
  - 0.4065781652466812
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples:
  - 0.40944734876773714
  - 0.38613037447988907
  - 0.4065781652466812
  - 0.38682657529031034
  - 0.41423948220064727
  test_level5__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted:
  - 0.4853163697001513
  - 0.4620742179318748
  - 0.49075106535625684
  - 0.47629318766167267
  - 0.4956278166950137
  test_level5__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro:
  - -0.03976848394324122
  - -0.03504392048081369
  - -0.04160887656033288
  - -0.03483723586521987
  - -0.04582941851967846
  test_level5__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro:
  - -0.03976848394324122
  - -0.03504392048081369
  - -0.04160887656033287
  - -0.034837235865219876
  - -0.045829418519678464
  test_level5__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples:
  - -0.039768483943241215
  - -0.03504392048081368
  - -0.04160887656033287
  - -0.03483723586521987
  - -0.045829418519678464
  test_level5__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted:
  - -0.0542182626686842
  - -0.04836160773785723
  - -0.05829854178011738
  - -0.046151501652873184
  - -0.0614652099128446
  test_level5__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro:
  - -0.5507841672890216
  - -0.5788257050392973
  - -0.5518129581929859
  - -0.5783361888444698
  - -0.5399310992796741
  test_level5__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro:
  - -0.5507841672890217
  - -0.5788257050392973
  - -0.5518129581929859
  - -0.5783361888444698
  - -0.5399310992796743
  test_level5__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples:
  - -0.5507841672890217
  - -0.5788257050392973
  - -0.5518129581929858
  - -0.5783361888444697
  - -0.5399310992796742
  test_level5__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted:
  - -0.46046536763116447
  - -0.48956417433026794
  - -0.4509503928636257
  - -0.47755531068545404
  - -0.44290697339214163
  test_level5__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro:
  - 0.27360512699473294
  - 0.25508102423520373
  - 0.2727948826533398
  - 0.2564702905709944
  - 0.2774037787155995
  test_level5__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro:
  - 0.2574245803498063
  - 0.2392574767961499
  - 0.2551604078587416
  - 0.23979230587679962
  - 0.2612244897959184
  test_level5__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples:
  - 0.2626650062524608
  - 0.2432244604911095
  - 0.26067332258363224
  - 0.24523858454087033
  - 0.2664034798956553
  test_level5__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted:
  - 0.3362537096003268
  - 0.31700624629303625
  - 0.3415010721477794
  - 0.3303906407068641
  - 0.3461066070850845
  test_level5__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__label_ranking_average_precision_score:
  - 0.2634439373057268
  - 0.2628767867784707
  - 0.2794892752223035
  - 0.2619095794781003
  - 0.2653737310080687
  test_level5__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro:
  - 0.09620034537878838
  - 0.08133871317761192
  - 0.10512520841370714
  - 0.09379471084390872
  - 0.07201356747699456
  test_level5__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro:
  - 0.10768656415021167
  - 0.09644572939758647
  - 0.09877393041149755
  - 0.09746938759790584
  - 0.09440265583460049
  test_level5__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples:
  - 0.1025173446173255
  - 0.09413589989000021
  - 0.09521031946490345
  - 0.08556190580395903
  - 0.09557668344966652
  test_level5__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted:
  - 0.10361849860657435
  - 0.08343189068540455
  - 0.11908104364258959
  - 0.11190118415628822
  - 0.09071253397919964
  test_level5__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__ndcg:
  - 0.6098476907350113
  - 0.6152729851053281
  - 0.631187672861935
  - 0.6090619395724899
  - 0.6188156493582099
  test_level5__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_coverage_error:
  - -88.8173076923077
  - -90.44761904761904
  - -89.44897959183673
  - -91.2843137254902
  - -90.96774193548387
  test_level5__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro:
  - -0.5905526512322627
  - -0.6138696255201109
  - -0.5934218347533188
  - -0.6131734247096897
  - -0.5857605177993527
  test_level5__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro:
  - -0.5905526512322629
  - -0.6138696255201109
  - -0.5934218347533188
  - -0.6131734247096897
  - -0.5857605177993528
  test_level5__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples:
  - -0.5905526512322629
  - -0.6138696255201109
  - -0.5934218347533188
  - -0.6131734247096897
  - -0.5857605177993527
  test_level5__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted:
  - -0.5146836302998486
  - -0.5379257820681251
  - -0.5092489346437431
  - -0.5237068123383273
  - -0.5043721833049863
  test_level5__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__neg_label_ranking_loss:
  - -0.48003547132339097
  - -0.4689739574790867
  - -0.4708653248937508
  - -0.4883311535324643
  - -0.4812941349520531
  test_level5__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro:
  - 0.4094473487677372
  - 0.38613037447988907
  - 0.4065781652466813
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro:
  - 0.40944734876773714
  - 0.386130374479889
  - 0.4065781652466812
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples:
  - 0.40944734876773714
  - 0.38613037447988907
  - 0.4065781652466812
  - 0.38682657529031034
  - 0.41423948220064727
  test_level5__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted:
  - 0.4853163697001513
  - 0.4620742179318748
  - 0.49075106535625684
  - 0.47629318766167267
  - 0.4956278166950137
  test_level5__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro:
  - 0.4094473487677372
  - 0.38613037447988907
  - 0.4065781652466813
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro:
  - 0.40944734876773714
  - 0.386130374479889
  - 0.4065781652466812
  - 0.3868265752903103
  - 0.41423948220064727
  test_level5__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples:
  - 0.40944734876773714
  - 0.38613037447988907
  - 0.4065781652466812
  - 0.38682657529031034
  - 0.41423948220064727
  test_level5__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted:
  - 0.4853163697001513
  - 0.4620742179318748
  - 0.49075106535625684
  - 0.47629318766167267
  - 0.4956278166950137
  test_level5__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro:
  - 0.5879260223018109
  - 0.5980611320650255
  - 0.6013094754078587
  - 0.5911044037519319
  - 0.5833330180593925
  test_level5__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro:
  - 0.547712013827568
  - 0.5498636484785446
  - 0.5581512764017947
  - 0.5380763302380281
  - 0.5451779086913644
  test_level5__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples:
  - 0.5360597295276487
  - 0.5405184018966792
  - 0.5461285568257809
  - 0.5216349704527589
  - 0.5377777151749363
  test_level5__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted:
  - 0.5849534099469045
  - 0.5991423083889522
  - 0.6023470760877258
  - 0.5948301428961404
  - 0.5800512866254437
  test_level5__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro:
  - 0.2166728902165795
  - 0.189921405455386
  - 0.2142857142857143
  - 0.18284789644012944
  - 0.22643282179768237
  test_level5__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro:
  - 0.21667289021657954
  - 0.18992140545538605
  - 0.21428571428571427
  - 0.18284789644012944
  - 0.22643282179768243
  test_level5__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples:
  - 0.21667289021657948
  - 0.189921405455386
  - 0.21428571428571425
  - 0.18284789644012944
  - 0.2264328217976824
  test_level5__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted:
  - 0.19476654417441247
  - 0.16487881038060964
  - 0.2009741634900466
  - 0.16812416477152836
  - 0.19570084656999817
  test_level5__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro:
  - 0.19277445855115755
  - 0.196208969024503
  - 0.19229245096096692
  - 0.20397867885018087
  - 0.18780666040296481
  test_level5__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro:
  - 0.19277445855115757
  - 0.196208969024503
  - 0.19229245096096692
  - 0.20397867885018084
  - 0.18780666040296481
  test_level5__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples:
  - 0.19277445855115752
  - 0.19620896902450297
  - 0.19229245096096687
  - 0.20397867885018084
  - 0.18780666040296481
  test_level5__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted:
  - 0.2905498255257388
  - 0.29719540755126517
  - 0.28977690186621025
  - 0.3081690228901444
  - 0.2999269701250156
  test_level5__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level5__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro:
  - 0.30061965902468835
  - 0.31007485631310056
  - 0.3110038554788738
  - 0.3040828500252427
  - 0.2967952302746709
  test_level6__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro:
  - 0.24429217295293304
  - 0.24324890394250534
  - 0.2595462734036788
  - 0.2442141904068496
  - 0.24566799993898708
  test_level6__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples:
  - 0.265043726433765
  - 0.2628591650199976
  - 0.28234083813809147
  - 0.2635814182288973
  - 0.2629204297329509
  test_level6__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted:
  - 0.41830260646546824
  - 0.43027886871198967
  - 0.4351112883999166
  - 0.4288712574751911
  - 0.4294932996638214
  test_level6__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro:
  - 0.4079536967886483
  - 0.38742487286176613
  - 0.4054884089558154
  - 0.38844469826765654
  - 0.4125691617079027
  test_level6__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro:
  - 0.40795369678864823
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples:
  - 0.4079536967886482
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted:
  - 0.48446329864435045
  - 0.46370023419203743
  - 0.48915627242002274
  - 0.476937925429239
  - 0.49308618486167555
  test_level6__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro:
  - -0.039488424197162066
  - -0.03495145631067961
  - -0.041608876560332866
  - -0.035217970683418996
  - -0.04614260361206806
  test_level6__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro:
  - -0.03948842419716206
  - -0.03495145631067961
  - -0.04160887656033287
  - -0.035217970683418996
  - -0.04614260361206807
  test_level6__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples:
  - -0.03948842419716206
  - -0.034951456310679606
  - -0.04160887656033287
  - -0.035217970683418996
  - -0.046142603612068074
  test_level6__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted:
  - -0.053728036315350655
  - -0.048060775689724104
  - -0.05844980940279543
  - -0.04717135957611423
  - -0.06189762364630477
  test_level6__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro:
  - -0.5525578790141896
  - -0.5776236708275543
  - -0.5529027144838518
  - -0.5763373310489244
  - -0.5412882346800291
  test_level6__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro:
  - -0.5525578790141897
  - -0.5776236708275543
  - -0.5529027144838518
  - -0.5763373310489244
  - -0.5412882346800292
  test_level6__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples:
  - -0.5525578790141896
  - -0.5776236708275543
  - -0.5529027144838519
  - -0.5763373310489244
  - -0.5412882346800292
  test_level6__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted:
  - -0.461808665040299
  - -0.48823899011823846
  - -0.4523939181771817
  - -0.47589071499464664
  - -0.44501619149201954
  test_level6__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro:
  - 0.27257518385387
  - 0.25607001924015327
  - 0.2721158130904451
  - 0.25791890292566255
  - 0.2759686129113433
  test_level6__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro:
  - 0.25624486923888823
  - 0.24025229357798164
  - 0.25430257844050946
  - 0.24103715078849447
  - 0.25989740891753255
  test_level6__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples:
  - 0.2614653821160514
  - 0.24418158514012772
  - 0.25988928950846113
  - 0.2463676603706121
  - 0.2650183324166115
  test_level6__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted:
  - 0.33565794614212485
  - 0.3183009163473175
  - 0.34034354952561385
  - 0.3310060490730571
  - 0.3438150349134733
  test_level6__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__label_ranking_average_precision_score:
  - 0.26504372643376484
  - 0.26285916501999756
  - 0.2823408381380916
  - 0.2635814182288973
  - 0.2629204297329509
  test_level6__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro:
  - 0.09492318329851054
  - 0.08345342365673335
  - 0.10434224242680017
  - 0.09499734586993654
  - 0.068464499010823
  test_level6__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro:
  - 0.10689775814890153
  - 0.09825687540565704
  - 0.09753065992944907
  - 0.09815053371923875
  - 0.09155511749407544
  test_level6__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples:
  - 0.10193276964829887
  - 0.09587686965943447
  - 0.09377952427523505
  - 0.08746608371157842
  - 0.09204505957007651
  test_level6__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted:
  - 0.10250627593283922
  - 0.08732831787839578
  - 0.11709420741580968
  - 0.11086000550976313
  - 0.08556206287929403
  test_level6__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__ndcg:
  - 0.6155032082402442
  - 0.6144790079209373
  - 0.634502505714932
  - 0.6139876634311633
  - 0.6165981851118887
  test_level6__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_coverage_error:
  - -88.72115384615384
  - -90.44761904761904
  - -89.45918367346938
  - -91.2843137254902
  - -91.2258064516129
  test_level6__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro:
  - -0.5920463032113518
  - -0.6125751271382338
  - -0.5945115910441847
  - -0.6115553017323434
  - -0.5874308382920973
  test_level6__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro:
  - -0.5920463032113518
  - -0.6125751271382339
  - -0.5945115910441847
  - -0.6115553017323434
  - -0.5874308382920973
  test_level6__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples:
  - -0.5920463032113518
  - -0.6125751271382339
  - -0.5945115910441846
  - -0.6115553017323434
  - -0.5874308382920973
  test_level6__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted:
  - -0.5155367013556496
  - -0.5362997658079625
  - -0.5108437275799772
  - -0.5230620745707609
  - -0.5069138151383245
  test_level6__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__neg_label_ranking_loss:
  - -0.47981427137416344
  - -0.4718802893818672
  - -0.46949577888539223
  - -0.4855424043483406
  - -0.4827804736367298
  test_level6__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro:
  - 0.4079536967886483
  - 0.38742487286176613
  - 0.4054884089558154
  - 0.38844469826765654
  - 0.4125691617079027
  test_level6__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro:
  - 0.40795369678864823
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples:
  - 0.4079536967886482
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted:
  - 0.48446329864435045
  - 0.46370023419203743
  - 0.48915627242002274
  - 0.476937925429239
  - 0.49308618486167555
  test_level6__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro:
  - 0.4079536967886483
  - 0.38742487286176613
  - 0.4054884089558154
  - 0.38844469826765654
  - 0.4125691617079027
  test_level6__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro:
  - 0.40795369678864823
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples:
  - 0.4079536967886482
  - 0.3874248728617661
  - 0.40548840895581534
  - 0.3884446982676566
  - 0.4125691617079027
  test_level6__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted:
  - 0.48446329864435045
  - 0.46370023419203743
  - 0.48915627242002274
  - 0.476937925429239
  - 0.49308618486167555
  test_level6__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro:
  - 0.5907886480655806
  - 0.5966640309430694
  - 0.5999534634759855
  - 0.5910814825440986
  - 0.5815161504509918
  test_level6__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro:
  - 0.5496969725972752
  - 0.549551961750782
  - 0.5585974464460387
  - 0.5390482471181774
  - 0.5438623513146565
  test_level6__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples:
  - 0.5384423682924995
  - 0.5396148340114685
  - 0.5476326454603778
  - 0.5245310506908691
  - 0.5353534866912283
  test_level6__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted:
  - 0.5875474656907023
  - 0.5968937943676219
  - 0.6005673932264474
  - 0.5958611034513355
  - 0.5787177888097664
  test_level6__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro:
  - 0.2148991784914115
  - 0.19112343966712894
  - 0.21319595799484845
  - 0.18484675423567484
  - 0.22507568639732747
  test_level6__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro:
  - 0.2148991784914115
  - 0.191123439667129
  - 0.21319595799484842
  - 0.18484675423567484
  - 0.22507568639732747
  test_level6__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples:
  - 0.21489917849141144
  - 0.1911234396671289
  - 0.21319595799484836
  - 0.18484675423567482
  - 0.22507568639732742
  test_level6__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted:
  - 0.19342324676527808
  - 0.1662039945926391
  - 0.19953063817649044
  - 0.16978876046233557
  - 0.1935916284701202
  test_level6__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro:
  - 0.19305451829723674
  - 0.19630143319463708
  - 0.19229245096096692
  - 0.20359794403198175
  - 0.18749347531057522
  test_level6__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro:
  - 0.19305451829723674
  - 0.19630143319463708
  - 0.19229245096096692
  - 0.20359794403198173
  - 0.18749347531057522
  test_level6__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples:
  - 0.19305451829723672
  - 0.19630143319463705
  - 0.19229245096096687
  - 0.20359794403198173
  - 0.18749347531057514
  test_level6__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted:
  - 0.2910400518790724
  - 0.2974962395993983
  - 0.28962563424353227
  - 0.3071491649669034
  - 0.2994945563915554
  test_level6__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level6__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro:
  - 0.29637584919852794
  - 0.31233606892233756
  - 0.3092966744745346
  - 0.30592578978589974
  - 0.29367311983200545
  test_level7__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro:
  - 0.23964874978707665
  - 0.24200797243440617
  - 0.25921246455862634
  - 0.24589965022003174
  - 0.2433824053429779
  test_level7__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples:
  - 0.26120830843829046
  - 0.26036897550464677
  - 0.2808663091252563
  - 0.26527461756966925
  - 0.26252408866606064
  test_level7__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted:
  - 0.4133068063564948
  - 0.43270354452166215
  - 0.43606937135417817
  - 0.4309475158744707
  - 0.4258417133274909
  test_level7__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro:
  - 0.40823375653472743
  - 0.38603791030975504
  - 0.40628095898553596
  - 0.3856843708357129
  - 0.41204718655392003
  test_level7__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro:
  - 0.40823375653472743
  - 0.386037910309755
  - 0.40628095898553596
  - 0.38568437083571294
  - 0.41204718655392003
  test_level7__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples:
  - 0.4082337565347274
  - 0.38603791030975493
  - 0.406280958985536
  - 0.3856843708357129
  - 0.4120471865539201
  test_level7__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted:
  - 0.48456751999505915
  - 0.46198282591725215
  - 0.4904096327222123
  - 0.47464422197735207
  - 0.49379726522336564
  test_level7__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro:
  - -0.039581777445855115
  - -0.03458159963014332
  - -0.04121260154547256
  - -0.03540833809251857
  - -0.04603820858127153
  test_level7__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro:
  - -0.039581777445855115
  - -0.03458159963014332
  - -0.04121260154547256
  - -0.03540833809251856
  - -0.04603820858127153
  test_level7__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples:
  - -0.039581777445855115
  - -0.03458159963014331
  - -0.04121260154547256
  - -0.03540833809251856
  - -0.04603820858127154
  test_level7__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted:
  - -0.05415264181823798
  - -0.04764570362331257
  - -0.05748601854973249
  - -0.047120562055033254
  - -0.06100396859715375
  test_level7__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro:
  - -0.5521844660194174
  - -0.5793804900601017
  - -0.5525064394689915
  - -0.5789072910717685
  - -0.5419146048648084
  test_level7__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro:
  - -0.5521844660194175
  - -0.5793804900601017
  - -0.5525064394689915
  - -0.5789072910717685
  - -0.5419146048648085
  test_level7__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples:
  - -0.5521844660194174
  - -0.5793804900601017
  - -0.5525064394689915
  - -0.5789072910717684
  - -0.5419146048648085
  test_level7__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted:
  - -0.4612798381867028
  - -0.49037147045943535
  - -0.4521043487280553
  - -0.47823521596761465
  - -0.4451987661794805
  test_level7__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro:
  - 0.2727261277360524
  - 0.2550848166485555
  - 0.2724791904880885
  - 0.25564160681863746
  - 0.275722793921596
  test_level7__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro:
  - 0.256465896428362
  - 0.23918647951876254
  - 0.2549263380369242
  - 0.23891509433962263
  - 0.2594832686871343
  test_level7__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples:
  - 0.26172027119598307
  - 0.24303858666339503
  - 0.2605416622736557
  - 0.24435735922711754
  - 0.2647669600774807
  test_level7__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted:
  - 0.3357189297512054
  - 0.316872890818605
  - 0.3411773753726664
  - 0.32913107828628546
  - 0.34467672341431776
  test_level7__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__label_ranking_average_precision_score:
  - 0.26120830843829046
  - 0.26036897550464677
  - 0.2808663091252563
  - 0.26527461756966925
  - 0.2625240886660606
  test_level7__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro:
  - 0.09567867317196117
  - 0.0821985381763384
  - 0.10590028768546271
  - 0.09108138690366947
  - 0.06666395165715629
  test_level7__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro:
  - 0.1069157773771909
  - 0.09789319901583086
  - 0.09967898079440327
  - 0.09422350957316289
  - 0.09127985238345925
  test_level7__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples:
  - 0.10156223308234444
  - 0.09576895803247455
  - 0.0963856388711084
  - 0.08286462265718221
  - 0.09165561571915712
  test_level7__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted:
  - 0.10276575088197176
  - 0.08508386477324067
  - 0.12090867680289766
  - 0.10950862371885728
  - 0.08585139513760566
  test_level7__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__ndcg:
  - 0.607488003701623
  - 0.6104082961233024
  - 0.6325610414823709
  - 0.6158559942182096
  - 0.6161393871153734
  test_level7__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_coverage_error:
  - -88.97115384615384
  - -90.55238095238096
  - -89.22448979591837
  - -91.46078431372548
  - -91.12903225806451
  test_level7__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro:
  - -0.5917662434652725
  - -0.613962089690245
  - -0.593719041014464
  - -0.6143156291642872
  - -0.58795281344608
  test_level7__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro:
  - -0.5917662434652726
  - -0.613962089690245
  - -0.593719041014464
  - -0.6143156291642871
  - -0.58795281344608
  test_level7__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples:
  - -0.5917662434652726
  - -0.6139620896902449
  - -0.593719041014464
  - -0.6143156291642871
  - -0.58795281344608
  test_level7__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted:
  - -0.5154324800049408
  - -0.5380171740827479
  - -0.5095903672777877
  - -0.5253557780226479
  - -0.5062027347766344
  test_level7__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__neg_label_ranking_loss:
  - -0.48164246544789574
  - -0.4712795921324424
  - -0.4718696158642359
  - -0.48628527473226446
  - -0.48559421335548253
  test_level7__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro:
  - 0.40823375653472743
  - 0.38603791030975504
  - 0.40628095898553596
  - 0.3856843708357129
  - 0.41204718655392003
  test_level7__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro:
  - 0.40823375653472743
  - 0.386037910309755
  - 0.40628095898553596
  - 0.38568437083571294
  - 0.41204718655392003
  test_level7__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples:
  - 0.4082337565347274
  - 0.38603791030975493
  - 0.406280958985536
  - 0.3856843708357129
  - 0.4120471865539201
  test_level7__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted:
  - 0.48456751999505915
  - 0.46198282591725215
  - 0.4904096327222123
  - 0.47464422197735207
  - 0.49379726522336564
  test_level7__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro:
  - 0.40823375653472743
  - 0.38603791030975504
  - 0.40628095898553596
  - 0.3856843708357129
  - 0.41204718655392003
  test_level7__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro:
  - 0.40823375653472743
  - 0.386037910309755
  - 0.40628095898553596
  - 0.38568437083571294
  - 0.41204718655392003
  test_level7__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples:
  - 0.4082337565347274
  - 0.38603791030975493
  - 0.406280958985536
  - 0.3856843708357129
  - 0.4120471865539201
  test_level7__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted:
  - 0.48456751999505915
  - 0.46198282591725215
  - 0.4904096327222123
  - 0.47464422197735207
  - 0.49379726522336564
  test_level7__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro:
  - 0.5846441476934344
  - 0.59616094139677
  - 0.6013659011101028
  - 0.5933122216491156
  - 0.5791851027499856
  test_level7__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro:
  - 0.5452195718721933
  - 0.5490481700031078
  - 0.5584533695615084
  - 0.5402915391797233
  - 0.5411168362980014
  test_level7__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples:
  - 0.5341785087167659
  - 0.538090550745506
  - 0.5473860790698489
  - 0.5242455239936058
  - 0.5329189657139
  test_level7__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted:
  - 0.5840430538396626
  - 0.597758346973585
  - 0.6019767698506738
  - 0.597690099882581
  - 0.5761354031714743
  test_level7__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro:
  - 0.2152725914861837
  - 0.18936662043458158
  - 0.21359223300970878
  - 0.18227679421283075
  - 0.22444931621254824
  test_level7__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro:
  - 0.21527259148618372
  - 0.1893666204345816
  - 0.21359223300970873
  - 0.18227679421283077
  - 0.2244493162125483
  test_level7__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples:
  - 0.21527259148618366
  - 0.18936662043458155
  - 0.2135922330097087
  - 0.18227679421283072
  - 0.22444931621254818
  test_level7__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted:
  - 0.19395207361887412
  - 0.16407151425144226
  - 0.19982020762561692
  - 0.1674442594893677
  - 0.19340905378265927
  test_level7__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro:
  - 0.19296116504854366
  - 0.19667128987517335
  - 0.19268872597582723
  - 0.20340757662288217
  - 0.18759787034137176
  test_level7__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro:
  - 0.1929611650485437
  - 0.19667128987517338
  - 0.19268872597582723
  - 0.20340757662288217
  - 0.18759787034137176
  test_level7__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples:
  - 0.19296116504854363
  - 0.19667128987517332
  - 0.19268872597582717
  - 0.20340757662288214
  - 0.1875978703413717
  test_level7__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted:
  - 0.2906154463761851
  - 0.29791131166580986
  - 0.2905894250965952
  - 0.3071999624879843
  - 0.3003882114407065
  test_level7__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level7__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro:
  - 0.30088621052275144
  - 0.3101939219648387
  - 0.30888423748291793
  - 0.30868569314382366
  - 0.291350417387652
  test_level8__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro:
  - 0.24312681320047103
  - 0.2444546135232311
  - 0.2588892492364318
  - 0.2451937192020594
  - 0.24151492035381547
  test_level8__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples:
  - 0.2651238117219816
  - 0.26283047255416553
  - 0.2800909815178716
  - 0.2636189669469
  - 0.2605028574444638
  test_level8__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted:
  - 0.4168088990661301
  - 0.42952906365188764
  - 0.43615129840097894
  - 0.433479596661719
  - 0.4234558562293933
  test_level8__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro:
  - 0.40823375653472743
  - 0.38576051779935283
  - 0.4083614028135526
  - 0.3875880449267085
  - 0.41131642133834423
  test_level8__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro:
  - 0.40823375653472743
  - 0.3857605177993528
  - 0.4083614028135526
  - 0.38758804492670856
  - 0.4113164213383443
  test_level8__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples:
  - 0.4082337565347274
  - 0.3857605177993527
  - 0.4083614028135526
  - 0.3875880449267087
  - 0.41131642133834434
  test_level8__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted:
  - 0.48489176419726404
  - 0.46161725785876123
  - 0.49256627682839343
  - 0.4758321024703225
  - 0.49261052975486935
  test_level8__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro:
  - -0.03967513069454817
  - -0.03439667128987517
  - -0.040915395284327326
  - -0.03493241956976966
  - -0.046455788704457664
  test_level8__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro:
  - -0.03967513069454817
  - -0.034396671289875176
  - -0.040915395284327326
  - -0.034932419569769654
  - -0.04645578870445767
  test_level8__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples:
  - -0.039675130694548165
  - -0.03439667128987517
  - -0.04091539528432732
  - -0.034932419569769654
  - -0.04645578870445767
  test_level8__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted:
  - -0.05390945866658434
  - -0.047664743626358974
  - -0.05710136659492259
  - -0.0465422518150345
  - -0.061820750093689626
  test_level8__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro:
  - -0.5520911127707244
  - -0.5798428109107722
  - -0.5507232019021201
  - -0.5774795355035218
  - -0.5422277899571979
  test_level8__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro:
  - -0.5520911127707244
  - -0.579842810910772
  - -0.5507232019021201
  - -0.5774795355035218
  - -0.542227789957198
  test_level8__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples:
  - -0.5520911127707244
  - -0.579842810910772
  - -0.5507232019021201
  - -0.5774795355035217
  - -0.542227789957198
  test_level8__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted:
  - -0.46119877713615165
  - -0.49071799851487985
  - -0.45033235657668397
  - -0.477625645714643
  - -0.4455687201514409
  test_level8__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro:
  - 0.2725585762050481
  - 0.2549055583801239
  - 0.27441320693494625
  - 0.2572680836600311
  - 0.2748957364550312
  test_level8__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro:
  - 0.256465896428362
  - 0.23897353648757017
  - 0.2565666625171169
  - 0.24037780401416764
  - 0.25890392955710345
  test_level8__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples:
  - 0.2616732672635696
  - 0.24276907900332828
  - 0.26209272323524935
  - 0.24570582184906864
  - 0.26431473098821423
  test_level8__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted:
  - 0.33584453177007106
  - 0.3165439823006391
  - 0.34335355077842117
  - 0.33004691244110157
  - 0.34336565206666825
  test_level8__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__label_ranking_average_precision_score:
  - 0.2651238117219815
  - 0.2628304725541656
  - 0.28009098151787154
  - 0.26361896694690007
  - 0.2605028574444638
  test_level8__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro:
  - 0.09490802528102178
  - 0.083289305216666
  - 0.11055487571813535
  - 0.09357556509046304
  - 0.06518141358990978
  test_level8__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro:
  - 0.10661884408013213
  - 0.09819486308417395
  - 0.1029777564950245
  - 0.09806599515695318
  - 0.08917720559385975
  test_level8__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples:
  - 0.10109280601158023
  - 0.09585008415310363
  - 0.09871871704094375
  - 0.08673494243933814
  - 0.08905091978615856
  test_level8__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted:
  - 0.10264078791989378
  - 0.08495601627334695
  - 0.12606529564170876
  - 0.11000210512985843
  - 0.08302987368383234
  test_level8__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__ndcg:
  - 0.6127181316352478
  - 0.6160244276419253
  - 0.6315441099035631
  - 0.6127370971571278
  - 0.6113719050663525
  test_level8__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_coverage_error:
  - -88.98076923076923
  - -90.65714285714286
  - -89.3061224489796
  - -91.34313725490196
  - -91.44086021505376
  test_level8__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro:
  - -0.5917662434652725
  - -0.6142394822006472
  - -0.5916385971864474
  - -0.6124119550732915
  - -0.5886835786616557
  test_level8__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro:
  - -0.5917662434652726
  - -0.6142394822006473
  - -0.5916385971864474
  - -0.6124119550732915
  - -0.5886835786616557
  test_level8__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples:
  - -0.5917662434652726
  - -0.6142394822006472
  - -0.5916385971864473
  - -0.6124119550732913
  - -0.5886835786616555
  test_level8__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted:
  - -0.5151082358027359
  - -0.5383827421412388
  - -0.5074337231716066
  - -0.5241678975296775
  - -0.5073894702451305
  test_level8__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__neg_label_ranking_loss:
  - -0.47936733601914716
  - -0.4705109126693064
  - -0.472699847503893
  - -0.4852539021063873
  - -0.4846628051763647
  test_level8__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro:
  - 0.40823375653472743
  - 0.38576051779935283
  - 0.4083614028135526
  - 0.3875880449267085
  - 0.41131642133834423
  test_level8__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro:
  - 0.40823375653472743
  - 0.3857605177993528
  - 0.4083614028135526
  - 0.38758804492670856
  - 0.4113164213383443
  test_level8__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples:
  - 0.4082337565347274
  - 0.3857605177993527
  - 0.4083614028135526
  - 0.3875880449267087
  - 0.41131642133834434
  test_level8__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted:
  - 0.48489176419726404
  - 0.46161725785876123
  - 0.49256627682839343
  - 0.4758321024703225
  - 0.49261052975486935
  test_level8__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro:
  - 0.40823375653472743
  - 0.38576051779935283
  - 0.4083614028135526
  - 0.3875880449267085
  - 0.41131642133834423
  test_level8__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro:
  - 0.40823375653472743
  - 0.3857605177993528
  - 0.4083614028135526
  - 0.38758804492670856
  - 0.4113164213383443
  test_level8__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples:
  - 0.4082337565347274
  - 0.3857605177993527
  - 0.4083614028135526
  - 0.3875880449267087
  - 0.41131642133834434
  test_level8__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted:
  - 0.48489176419726404
  - 0.46161725785876123
  - 0.49256627682839343
  - 0.4758321024703225
  - 0.49261052975486935
  test_level8__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro:
  - 0.5883579129161783
  - 0.5949807895906746
  - 0.6011915582501811
  - 0.5932314216259492
  - 0.5760259441478784
  test_level8__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro:
  - 0.5487799381507766
  - 0.5502084949036984
  - 0.558279359957953
  - 0.5400908112562937
  - 0.5393257524213961
  test_level8__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples:
  - 0.5378888516250405
  - 0.5400766270697682
  - 0.5460663861355088
  - 0.5238226759203328
  - 0.5311192806197061
  test_level8__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted:
  - 0.5853307307806696
  - 0.5956027972449077
  - 0.6025445708899129
  - 0.5971525806253608
  - 0.5746398138697165
  test_level8__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro:
  - 0.21536594473487672
  - 0.1889042995839112
  - 0.21537547057658019
  - 0.18370454978107748
  - 0.22413613112015865
  test_level8__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro:
  - 0.21536594473487677
  - 0.18890429958391122
  - 0.21537547057658016
  - 0.18370454978107748
  - 0.22413613112015868
  test_level8__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples:
  - 0.2153659447348767
  - 0.18890429958391117
  - 0.2153754705765801
  - 0.18370454978107745
  - 0.2241361311201586
  test_level8__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted:
  - 0.19403313466942532
  - 0.16372498619599776
  - 0.2015921997769883
  - 0.16805382974233932
  - 0.1930390998106989
  test_level8__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro:
  - 0.19286781179985057
  - 0.19685621821544155
  - 0.1929859322369725
  - 0.20388349514563112
  - 0.18718029021818564
  test_level8__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro:
  - 0.19286781179985063
  - 0.19685621821544153
  - 0.19298593223697247
  - 0.20388349514563106
  - 0.1871802902181856
  test_level8__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples:
  - 0.1928678117998506
  - 0.19685621821544147
  - 0.19298593223697244
  - 0.20388349514563106
  - 0.18718029021818552
  test_level8__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted:
  - 0.29085862952783864
  - 0.2978922716627635
  - 0.29097407705140504
  - 0.3077782727279831
  - 0.2995714299441706
  test_level8__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level8__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro:
  - 0.29660216367347086
  - 0.3081397397992062
  - 0.3080567350674629
  - 0.3052438336410538
  - 0.29321126568687056
  test_level9__average_precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro:
  - 0.2423263432007816
  - 0.24321116011988492
  - 0.2585166461371945
  - 0.24649802458040854
  - 0.24258030402281303
  test_level9__average_precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples:
  - 0.2644743023879508
  - 0.26139578563496263
  - 0.28071781294943216
  - 0.2653364515184677
  - 0.2609900471618236
  test_level9__average_precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted:
  - 0.41279019634283787
  - 0.43047074292986715
  - 0.43316755937201973
  - 0.4289627090788795
  - 0.425778182096303
  test_level9__average_precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__average_precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro:
  - 0.40823375653472743
  - 0.38622283865002316
  - 0.40628095898553596
  - 0.38463735008566524
  - 0.4103768660611754
  test_level9__f1_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro:
  - 0.40823375653472743
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.38463735008566535
  - 0.41037686606117546
  test_level9__f1_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples:
  - 0.4082337565347274
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.3846373500856653
  - 0.4103768660611755
  test_level9__f1_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted:
  - 0.48415449464225047
  - 0.46254260200681635
  - 0.4906127635298085
  - 0.47336646894708445
  - 0.491572736794565
  test_level9__f1_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__f1_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro:
  - -0.039581777445855115
  - -0.034396671289875176
  - -0.04032098276203685
  - -0.035503521797068345
  - -0.04666457876605073
  test_level9__fn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro:
  - -0.039581777445855115
  - -0.034396671289875176
  - -0.040320982762036855
  - -0.035503521797068345
  - -0.046664578766050735
  test_level9__fn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples:
  - -0.039581777445855115
  - -0.03439667128987517
  - -0.04032098276203685
  - -0.03550352179706834
  - -0.04666457876605075
  test_level9__fn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted:
  - -0.05379365716579688
  - -0.04703642352582776
  - -0.05597334232295205
  - -0.04717135957611422
  - -0.06207539373672728
  test_level9__fn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro:
  - -0.5521844660194174
  - -0.5793804900601016
  - -0.5533980582524272
  - -0.5798591281172664
  - -0.5429585551727736
  test_level9__fp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro:
  - -0.5521844660194175
  - -0.5793804900601017
  - -0.5533980582524272
  - -0.5798591281172664
  - -0.5429585551727738
  test_level9__fp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples:
  - -0.5521844660194174
  - -0.5793804900601017
  - -0.5533980582524272
  - -0.5798591281172663
  - -0.5429585551727737
  test_level9__fp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted:
  - -0.46205184819195255
  - -0.49042097446735594
  - -0.45341389414723954
  - -0.47946217147680137
  - -0.44635186946870764
  test_level9__fp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__fp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro:
  - 0.2726838456623491
  - 0.25548002819564736
  - 0.27278099444127757
  - 0.2549903854547576
  - 0.27426002279492023
  test_level9__jaccard_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro:
  - 0.256465896428362
  - 0.2393284822093623
  - 0.2549263380369242
  - 0.23811207353721053
  - 0.2581598476390622
  test_level9__jaccard_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples:
  - 0.2617982269486189
  - 0.24311796119024612
  - 0.2606524758956155
  - 0.2435761971656477
  - 0.26358520046601797
  test_level9__jaccard_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted:
  - 0.33523222550841697
  - 0.31757906841339745
  - 0.341663274621928
  - 0.3280991706325222
  - 0.34259632958591624
  test_level9__jaccard_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__jaccard_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__label_ranking_average_precision_score:
  - 0.2644743023879507
  - 0.2613957856349626
  - 0.2807178129494321
  - 0.2653364515184678
  - 0.2609900471618237
  test_level9__label_ranking_average_precision_score_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro:
  - 0.0942768982983363
  - 0.08313102968681245
  - 0.10789256976520001
  - 0.08988802895230748
  - 0.06517237519071059
  test_level9__matthews_corrcoef_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro:
  - 0.1069157773771909
  - 0.09873099760897021
  - 0.10248861113178705
  - 0.09265164989423615
  - 0.08747097104693025
  test_level9__matthews_corrcoef_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples:
  - 0.10158567851484984
  - 0.09735941398214787
  - 0.09723539374820395
  - 0.08119276369098734
  - 0.08730072878423131
  test_level9__matthews_corrcoef_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted:
  - 0.1003598468136864
  - 0.0864183922812196
  - 0.12336277981687198
  - 0.10688932991899253
  - 0.08207887621976304
  test_level9__matthews_corrcoef_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__matthews_corrcoef_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__ndcg:
  - 0.6120397352422159
  - 0.6131489996013615
  - 0.6327733039471942
  - 0.6165972695458938
  - 0.6125263244642075
  test_level9__ndcg_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_coverage_error:
  - -88.97115384615384
  - -90.72380952380952
  - -89.36734693877551
  - -91.40196078431373
  - -91.26881720430107
  test_level9__neg_coverage_error_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro:
  - -0.5917662434652725
  - -0.6137771613499768
  - -0.593719041014464
  - -0.6153626499143348
  - -0.5896231339388246
  test_level9__neg_hamming_loss_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro:
  - -0.5917662434652726
  - -0.6137771613499768
  - -0.593719041014464
  - -0.6153626499143346
  - -0.5896231339388245
  test_level9__neg_hamming_loss_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples:
  - -0.5917662434652726
  - -0.6137771613499768
  - -0.5937190410144639
  - -0.6153626499143346
  - -0.5896231339388244
  test_level9__neg_hamming_loss_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted:
  - -0.5158455053577495
  - -0.5374573979931837
  - -0.5093872364701916
  - -0.5266335310529155
  - -0.508427263205435
  test_level9__neg_hamming_loss_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_hamming_loss_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__neg_label_ranking_loss:
  - -0.48114382069863176
  - -0.4714505364687567
  - -0.4727779265895779
  - -0.4869467188692904
  - -0.4858300565061255
  test_level9__neg_label_ranking_loss_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro:
  - 0.40823375653472743
  - 0.38622283865002316
  - 0.40628095898553596
  - 0.38463735008566524
  - 0.4103768660611754
  test_level9__precision_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro:
  - 0.40823375653472743
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.38463735008566535
  - 0.41037686606117546
  test_level9__precision_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples:
  - 0.4082337565347274
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.3846373500856653
  - 0.4103768660611755
  test_level9__precision_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted:
  - 0.48415449464225047
  - 0.46254260200681635
  - 0.4906127635298085
  - 0.47336646894708445
  - 0.491572736794565
  test_level9__precision_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__precision_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro:
  - 0.40823375653472743
  - 0.38622283865002316
  - 0.40628095898553596
  - 0.38463735008566524
  - 0.4103768660611754
  test_level9__recall_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro:
  - 0.40823375653472743
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.38463735008566535
  - 0.41037686606117546
  test_level9__recall_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples:
  - 0.4082337565347274
  - 0.3862228386500231
  - 0.40628095898553596
  - 0.3846373500856653
  - 0.4103768660611755
  test_level9__recall_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted:
  - 0.48415449464225047
  - 0.46254260200681635
  - 0.4906127635298085
  - 0.47336646894708445
  - 0.491572736794565
  test_level9__recall_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__recall_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro:
  - 0.5885595006904802
  - 0.5925024593919532
  - 0.5991665774831427
  - 0.5948295759767602
  - 0.5780464892256882
  test_level9__roc_auc_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro:
  - 0.5477869948650075
  - 0.5495572759589934
  - 0.5577972596965441
  - 0.5404253827150107
  - 0.5406395446437364
  test_level9__roc_auc_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples:
  - 0.5369689425901689
  - 0.5388178500611165
  - 0.5457373560905593
  - 0.5236220071396398
  - 0.5317954972534399
  test_level9__roc_auc_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted:
  - 0.5857766573392382
  - 0.5954919251857745
  - 0.6015262497121574
  - 0.5964956234307864
  - 0.5785417975424886
  test_level9__roc_auc_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__roc_auc_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro:
  - 0.2152725914861837
  - 0.18936662043458155
  - 0.21270061422627307
  - 0.18132495716733293
  - 0.22340536590458288
  test_level9__tn_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro:
  - 0.21527259148618372
  - 0.1893666204345816
  - 0.21270061422627304
  - 0.18132495716733296
  - 0.22340536590458293
  test_level9__tn_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples:
  - 0.21527259148618366
  - 0.18936662043458158
  - 0.212700614226273
  - 0.1813249571673329
  - 0.22340536590458288
  test_level9__tn_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted:
  - 0.19318006361362444
  - 0.16402201024352162
  - 0.19851066220643274
  - 0.16621730398018117
  - 0.19225595049343214
  test_level9__tn_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tn_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro:
  - 0.19296116504854366
  - 0.19685621821544155
  - 0.19358034475926297
  - 0.2033123929183324
  - 0.18697150015659256
  test_level9__tp_macro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_macro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro:
  - 0.1929611650485437
  - 0.19685621821544153
  - 0.19358034475926292
  - 0.2033123929183324
  - 0.18697150015659256
  test_level9__tp_micro_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_micro_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples:
  - 0.19296116504854366
  - 0.19685621821544147
  - 0.19358034475926286
  - 0.20331239291833236
  - 0.1869715001565925
  test_level9__tp_samples_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_samples_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted:
  - 0.29097443102862613
  - 0.29852059176329476
  - 0.29210210132337566
  - 0.3071491649669034
  - 0.29931678630113295
  test_level9__tp_weighted_masked:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  test_level9__tp_weighted_oob:
  - .nan
  - .nan
  - .nan
  - .nan
  - .nan
  train_level0__average_precision_macro:
  - 0.7039914992998756
  - 0.6885046829822722
  - 0.6979452001623269
  - 0.7056094685150905
  - 0.693733414248095
  train_level0__average_precision_macro_masked:
  - 0.23047302740006434
  - 0.22264212209105083
  - 0.22695044604860934
  - 0.23483166214230242
  - 0.226068036107585
  train_level0__average_precision_macro_oob:
  - 0.27271661895536686
  - 0.2732008957565149
  - 0.27625051409332135
  - 0.274865631132707
  - 0.278408402030163
  train_level0__average_precision_micro:
  - 0.6425803348106077
  - 0.6426568825998942
  - 0.6424135368156941
  - 0.6433654319684451
  - 0.6428702093779778
  train_level0__average_precision_micro_masked:
  - 0.37251342450808433
  - 0.3744151272372956
  - 0.3723142215675962
  - 0.37419643199678104
  - 0.3716397657984226
  train_level0__average_precision_micro_oob:
  - 0.4976547229701596
  - 0.5008652985669951
  - 0.5002772918102809
  - 0.49900406709590794
  - 0.49664648829218205
  train_level0__average_precision_samples:
  - 0.6564886817382776
  - 0.6576635569038612
  - 0.6570834121688164
  - 0.6583732213157256
  - 0.6567366404245699
  train_level0__average_precision_samples_masked:
  - 0.4328269881225753
  - 0.4362577250009694
  - 0.4325905975423751
  - 0.43498279599488343
  - 0.43103509193297157
  train_level0__average_precision_samples_oob:
  - 0.5322712107700889
  - 0.5342333423477388
  - 0.5338758362155226
  - 0.532181749041895
  - 0.5300076514742943
  train_level0__average_precision_weighted:
  - 0.7528222091342214
  - 0.7454646922940257
  - 0.7503225724266458
  - 0.7579731346804858
  - 0.7453642884292375
  train_level0__average_precision_weighted_masked:
  - 0.32409699831512206
  - 0.32051558605525504
  - 0.32136688804855085
  - 0.3303642885575393
  - 0.32061386603088354
  train_level0__average_precision_weighted_oob:
  - 0.3888650400917237
  - 0.3921812298120839
  - 0.39273880899264685
  - 0.39296182838559085
  - 0.3920873215865054
  train_level0__f1_macro:
  - 0.766356052105186
  - 0.7670147465212397
  - 0.7677593002018644
  - 0.768470873786408
  - 0.7672988819521921
  train_level0__f1_macro_masked:
  - 0.8563327720184238
  - 0.8561004847571785
  - 0.8565509301735902
  - 0.8576535102506148
  - 0.8568834941660562
  train_level0__f1_macro_oob:
  - 0.765624237693321
  - 0.7655229757159281
  - 0.7665817552629048
  - 0.7672330097087381
  - 0.7663968476274123
  train_level0__f1_micro:
  - 0.7663560521051861
  - 0.7670147465212394
  - 0.7677593002018649
  - 0.7684708737864078
  - 0.7672988819521922
  train_level0__f1_micro_masked:
  - 0.8678280105073967
  - 0.8675834534767661
  - 0.8680720102404881
  - 0.8689520563008577
  - 0.8679884856474133
  train_level0__f1_micro_oob:
  - 0.765624237693321
  - 0.7655229757159278
  - 0.766581755262905
  - 0.7672330097087379
  - 0.7663968476274123
  train_level0__f1_samples:
  - 0.7663560521051861
  - 0.7670147465212392
  - 0.7677593002018649
  - 0.7684708737864077
  - 0.7672988819521922
  train_level0__f1_samples_masked:
  - 0.8676379371315293
  - 0.8672734688687684
  - 0.8676818655496775
  - 0.8686807498864502
  - 0.8677261060804053
  train_level0__f1_samples_oob:
  - 0.765624237693321
  - 0.7655229757159276
  - 0.766581755262905
  - 0.7672330097087378
  - 0.7663968476274122
  train_level0__f1_weighted:
  - 0.6546707415734097
  - 0.6585257752762345
  - 0.6591330762607014
  - 0.659121832968408
  - 0.6606517124583308
  train_level0__f1_weighted_masked:
  - 0.769382417795486
  - 0.7695009609963097
  - 0.7691057151528913
  - 0.7713458492966074
  - 0.7728219214045198
  train_level0__f1_weighted_oob:
  - 0.6519249384606453
  - 0.6529072743985979
  - 0.6546372703806986
  - 0.6544664268585132
  - 0.6572695868015285
  train_level0__fn_macro:
  - -0.23364394789481382
  - -0.23298525347876056
  - -0.23224069979813516
  - -0.2315291262135922
  - -0.2326773803024189
  train_level0__fn_macro_masked:
  - -0.143667227981576
  - -0.14389951524282163
  - -0.14344906982640987
  - -0.1423464897493851
  - -0.1430741095987291
  train_level0__fn_macro_oob:
  - -0.23435136849295016
  - -0.23442811376586534
  - -0.23332211861962893
  - -0.2326941747572815
  - -0.2335556768818098
  train_level0__fn_micro:
  - -0.23364394789481388
  - -0.23298525347876062
  - -0.23224069979813516
  - -0.23152912621359223
  - -0.23267738030241888
  train_level0__fn_micro_masked:
  - -0.13217198949260334
  - -0.1324165465232339
  - -0.13192798975951195
  - -0.1310479436991423
  - -0.13198461165962713
  train_level0__fn_micro_oob:
  - -0.23435136849295019
  - -0.23442811376586534
  - -0.23332211861962895
  - -0.23269417475728155
  - -0.23355567688180975
  train_level0__fn_samples:
  - -0.23364394789481382
  - -0.23298525347876056
  - -0.23224069979813508
  - -0.23152912621359217
  - -0.2326773803024188
  train_level0__fn_samples_masked:
  - -0.13236206286847066
  - -0.13272653113123148
  - -0.13231813445032256
  - -0.13131925011354995
  - -0.1322470259220665
  train_level0__fn_samples_oob:
  - -0.23435136849295013
  - -0.23442811376586528
  - -0.2333221186196289
  - -0.23269417475728146
  - -0.2335556768818097
  train_level0__fn_weighted:
  - -0.3453292584265902
  - -0.3414742247237656
  - -0.3408669237392986
  - -0.3408781670315921
  - -0.33925928423491125
  train_level0__fn_weighted_masked:
  - -0.2306175822045141
  - -0.23049903900369037
  - -0.2308942848471088
  - -0.22865415070339257
  - -0.22701875136583372
  train_level0__fn_weighted_oob:
  - -0.3479827590444678
  - -0.346908512457873
  - -0.34499572505766846
  - -0.34525831508706073
  - -0.34255240658495556
  train_level0__fp_macro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.3737745388942958e-05
  train_level0__fp_macro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -4.2396235214312964e-05
  train_level0__fp_macro_oob:
  - -2.439381372883837e-05
  - -4.89105182069404e-05
  - -9.612611746611555e-05
  - -7.281553398058252e-05
  - -4.7475490777885916e-05
  train_level0__fp_micro:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.3737745388942958e-05
  train_level0__fp_micro_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.6902692959565253e-05
  train_level0__fp_micro_oob:
  - -2.4393813728838365e-05
  - -4.89105182069404e-05
  - -9.612611746611554e-05
  - -7.281553398058253e-05
  - -4.7475490777885916e-05
  train_level0__fp_samples:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.3737745388942955e-05
  train_level0__fp_samples_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -2.686799752814423e-05
  train_level0__fp_samples_oob:
  - -2.4393813728838365e-05
  - -4.8910518206940396e-05
  - -9.612611746611554e-05
  - -7.281553398058252e-05
  - -4.747549077788591e-05
  train_level0__fp_weighted:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -8.900330675795414e-05
  train_level0__fp_weighted_masked:
  - -0.0
  - -0.0
  - -0.0
  - -0.0
  - -0.00015932722964661397
  train_level0__fp_weighted_oob:
  - -9.230249488675556e-05
  - -0.0001842131435290672
  - -0.0003670045616328755
  - -0.00027525805442602436
  - -0.00017800661351590827
  train_level0__jaccard_macro:
  - 0.6457318665390939
  - 0.6458620395370902
  - 0.6467164594565945
  - 0.6478376188774071
  - 0.6458594711694327
  train_level0__jaccard_macro_masked:
  - 0.7665153185162318
  - 0.7661166950619399
  - 0.766922311253506
  - 0.7682861279412122
  - 0.7667725789012402
  train_level0__jaccard_macro_oob:
  - 0.6452997505615217
  - 0.6449181983415576
  - 0.645964731937694
  - 0.6470820866951201
  - 0.6452896575326251
  train_level0__jaccard_micro:
  - 0.6212133196235071
  - 0.6220794160815581
  - 0.6230595210234807
  - 0.6239973196160744
  - 0.6224533025226267
  train_level0__jaccard_micro_masked:
  - 0.7665160581267554
  - 0.7661345607677994
  - 0.7668968504126464
  - 0.7682716379457015
  - 0.7667664812966396
  train_level0__jaccard_micro_oob:
  - 0.6202521639460891
  - 0.6201192575130252
  - 0.6215099853872382
  - 0.6223666075999212
  - 0.6212669334975369
  train_level0__jaccard_samples:
  - 0.6238232248078044
  - 0.6248175645556047
  - 0.6258543694410529
  - 0.6266443218190598
  - 0.6252501260118649
  train_level0__jaccard_samples_masked:
  - 0.7685400029105208
  - 0.7677905020581084
  - 0.768390438860256
  - 0.7700514170975497
  - 0.7687911546272367
  train_level0__jaccard_samples_oob:
  - 0.622867791722216
  - 0.6228251533308421
  - 0.6242997003153222
  - 0.6250033077691495
  - 0.6240652887893395
  train_level0__jaccard_weighted:
  - 0.5149539769845419
  - 0.517410499908961
  - 0.5184885124256529
  - 0.5189768147802567
  - 0.5196662522720633
  train_level0__jaccard_weighted_masked:
  - 0.6520225067455465
  - 0.6521920186852215
  - 0.6522906572642293
  - 0.6545180945861613
  - 0.6555570215032788
  train_level0__jaccard_weighted_oob:
  - 0.51333576426416
  - 0.5138556826631966
  - 0.5156184555065363
  - 0.5161383874986195
  - 0.5175297689169388
  train_level0__label_ranking_average_precision_score:
  - 0.6564886817382775
  - 0.6576635569038612
  - 0.6570834121688162
  - 0.658373221315726
  - 0.6567366404245698
  train_level0__label_ranking_average_precision_score_oob:
  - 0.532271210770089
  - 0.5342333423477389
  - 0.5338758362155221
  - 0.5321817490418944
  - 0.5300076514742946
  train_level0__matthews_corrcoef_macro:
  - 0.0013368844198585529
  - 0.001654294022985925
  - 0.0019217425429990651
  - 0.001727176428450052
  - 0.001313543351435323
  train_level0__matthews_corrcoef_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0012165693342524096
  train_level0__matthews_corrcoef_macro_oob:
  - -0.0005885261153114487
  - -0.00010497510785912607
  - 0.00019627666896308843
  - -0.0012303800259371588
  - 0.0003195057505645075
  train_level0__matthews_corrcoef_micro:
  - 0.049717231727627764
  - 0.07582959433816877
  - 0.07687185423963601
  - 0.06453580608407916
  - 0.06740404987349355
  train_level0__matthews_corrcoef_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.002022561130197995
  train_level0__matthews_corrcoef_micro_oob:
  - 0.008729474377033654
  - 0.0285609103512583
  - 0.04378650025475622
  - 0.010445566687704756
  - 0.03947213350473004
  train_level0__matthews_corrcoef_samples:
  - 0.013771773345123443
  - 0.033647277120489386
  - 0.03371138995893967
  - 0.023078413844122802
  - 0.026096876829094246
  train_level0__matthews_corrcoef_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.0001279765091907613
  train_level0__matthews_corrcoef_samples_oob:
  - 0.0006713073972241657
  - 0.005754845878721532
  - 0.012962898658272019
  - 0.0013402322022809882
  - 0.009829918701639856
  train_level0__matthews_corrcoef_weighted:
  - 0.004727385867104336
  - 0.006230616919784367
  - 0.007025318282325907
  - 0.006176707761586917
  - 0.004925055009736761
  train_level0__matthews_corrcoef_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - -0.004571930048025209
  train_level0__matthews_corrcoef_weighted_oob:
  - -0.0022268936441470462
  - -0.0003953708797198651
  - 0.00043757851496994455
  - -0.004651095633445692
  - 0.001197968377471486
  train_level0__ndcg:
  - 0.8841203034403338
  - 0.8850512282686861
  - 0.8841223412922617
  - 0.8848509577590434
  - 0.8847895731417307
  train_level0__ndcg_oob:
  - 0.827334720886488
  - 0.8288574290721479
  - 0.8274944894987769
  - 0.8278539308099652
  - 0.8249648991449594
  train_level0__neg_coverage_error:
  - -78.76884422110552
  - -78.90680100755668
  - -79.60643564356435
  - -78.6975
  - -78.84596577017115
  train_level0__neg_coverage_error_oob:
  - -89.78391959798995
  - -89.49622166246851
  - -89.65346534653466
  - -89.225
  - -89.91198044009779
  train_level0__neg_hamming_loss_macro:
  - -0.23364394789481382
  - -0.23298525347876056
  - -0.23224069979813516
  - -0.2315291262135922
  - -0.23270111804780785
  train_level0__neg_hamming_loss_macro_masked:
  - -0.143667227981576
  - -0.14389951524282163
  - -0.14344906982640987
  - -0.1423464897493851
  - -0.14311650583394342
  train_level0__neg_hamming_loss_macro_oob:
  - -0.234375762306679
  - -0.23447702428407227
  - -0.23341824473709508
  - -0.23276699029126208
  - -0.2336031523725877
  train_level0__neg_hamming_loss_micro:
  - -0.23364394789481388
  - -0.23298525347876062
  - -0.23224069979813516
  - -0.23152912621359223
  - -0.23270111804780783
  train_level0__neg_hamming_loss_micro_masked:
  - -0.13217198949260334
  - -0.1324165465232339
  - -0.13192798975951195
  - -0.1310479436991423
  - -0.1320115143525867
  train_level0__neg_hamming_loss_micro_oob:
  - -0.23437576230667903
  - -0.2344770242840723
  - -0.23341824473709508
  - -0.23276699029126213
  - -0.23360315237258766
  train_level0__neg_hamming_loss_samples:
  - -0.23364394789481382
  - -0.23298525347876056
  - -0.23224069979813508
  - -0.23152912621359217
  - -0.23270111804780777
  train_level0__neg_hamming_loss_samples_masked:
  - -0.13236206286847066
  - -0.13272653113123148
  - -0.13231813445032256
  - -0.13131925011354995
  - -0.13227389391959463
  train_level0__neg_hamming_loss_samples_oob:
  - -0.23437576230667895
  - -0.23447702428407224
  - -0.23341824473709497
  - -0.23276699029126205
  - -0.23360315237258758
  train_level0__neg_hamming_loss_weighted:
  - -0.3453292584265902
  - -0.3414742247237656
  - -0.3408669237392986
  - -0.3408781670315921
  - -0.3393482875416692
  train_level0__neg_hamming_loss_weighted_masked:
  - -0.2306175822045141
  - -0.23049903900369037
  - -0.2308942848471088
  - -0.22865415070339257
  - -0.2271780785954803
  train_level0__neg_hamming_loss_weighted_oob:
  - -0.3480750615393546
  - -0.34709272560140214
  - -0.3453627296193013
  - -0.3455335731414868
  - -0.3427304131984715
  train_level0__neg_label_ranking_loss:
  - -0.16232231093244404
  - -0.16304745586820285
  - -0.1630374935307724
  - -0.16054346644950107
  - -0.1633338186430628
  train_level0__neg_label_ranking_loss_oob:
  - -0.2517405151750782
  - -0.2518251117224507
  - -0.25137667506497624
  - -0.2518382408281178
  - -0.25274270692157147
  train_level0__precision_macro:
  - 0.766356052105186
  - 0.7670147465212397
  - 0.7677593002018644
  - 0.768470873786408
  - 0.7672988819521921
  train_level0__precision_macro_masked:
  - 0.8563327720184238
  - 0.8561004847571785
  - 0.8565509301735902
  - 0.8576535102506148
  - 0.8568834941660562
  train_level0__precision_macro_oob:
  - 0.765624237693321
  - 0.7655229757159281
  - 0.7665817552629048
  - 0.7672330097087381
  - 0.7663968476274123
  train_level0__precision_micro:
  - 0.7663560521051861
  - 0.7670147465212394
  - 0.7677593002018649
  - 0.7684708737864078
  - 0.7672988819521922
  train_level0__precision_micro_masked:
  - 0.8678280105073967
  - 0.8675834534767661
  - 0.8680720102404881
  - 0.8689520563008577
  - 0.8679884856474133
  train_level0__precision_micro_oob:
  - 0.765624237693321
  - 0.7655229757159278
  - 0.766581755262905
  - 0.7672330097087379
  - 0.7663968476274123
  train_level0__precision_samples:
  - 0.7663560521051861
  - 0.7670147465212392
  - 0.7677593002018649
  - 0.7684708737864077
  - 0.7672988819521922
  train_level0__precision_samples_masked:
  - 0.8676379371315293
  - 0.8672734688687684
  - 0.8676818655496775
  - 0.8686807498864502
  - 0.8677261060804053
  train_level0__precision_samples_oob:
  - 0.765624237693321
  - 0.7655229757159276
  - 0.766581755262905
  - 0.7672330097087378
  - 0.7663968476274122
  train_level0__precision_weighted:
  - 0.6546707415734097
  - 0.6585257752762345
  - 0.6591330762607014
  - 0.659121832968408
  - 0.6606517124583308
  train_level0__precision_weighted_masked:
  - 0.769382417795486
  - 0.7695009609963097
  - 0.7691057151528913
  - 0.7713458492966074
  - 0.7728219214045198
  train_level0__precision_weighted_oob:
  - 0.6519249384606453
  - 0.6529072743985979
  - 0.6546372703806986
  - 0.6544664268585132
  - 0.6572695868015285
  train_level0__recall_macro:
  - 0.766356052105186
  - 0.7670147465212397
  - 0.7677593002018644
  - 0.768470873786408
  - 0.7672988819521921
  train_level0__recall_macro_masked:
  - 0.8563327720184238
  - 0.8561004847571785
  - 0.8565509301735902
  - 0.8576535102506148
  - 0.8568834941660562
  train_level0__recall_macro_oob:
  - 0.765624237693321
  - 0.7655229757159281
  - 0.7665817552629048
  - 0.7672330097087381
  - 0.7663968476274123
  train_level0__recall_micro:
  - 0.7663560521051861
  - 0.7670147465212394
  - 0.7677593002018649
  - 0.7684708737864078
  - 0.7672988819521922
  train_level0__recall_micro_masked:
  - 0.8678280105073967
  - 0.8675834534767661
  - 0.8680720102404881
  - 0.8689520563008577
  - 0.8679884856474133
  train_level0__recall_micro_oob:
  - 0.765624237693321
  - 0.7655229757159278
  - 0.766581755262905
  - 0.7672330097087379
  - 0.7663968476274123
  train_level0__recall_samples:
  - 0.7663560521051861
  - 0.7670147465212392
  - 0.7677593002018649
  - 0.7684708737864077
  - 0.7672988819521922
  train_level0__recall_samples_masked:
  - 0.8676379371315293
  - 0.8672734688687684
  - 0.8676818655496775
  - 0.8686807498864502
  - 0.8677261060804053
  train_level0__recall_samples_oob:
  - 0.765624237693321
  - 0.7655229757159276
  - 0.766581755262905
  - 0.7672330097087378
  - 0.7663968476274122
  train_level0__recall_weighted:
  - 0.6546707415734097
  - 0.6585257752762345
  - 0.6591330762607014
  - 0.659121832968408
  - 0.6606517124583308
  train_level0__recall_weighted_masked:
  - 0.769382417795486
  - 0.7695009609963097
  - 0.7691057151528913
  - 0.7713458492966074
  - 0.7728219214045198
  train_level0__recall_weighted_oob:
  - 0.6519249384606453
  - 0.6529072743985979
  - 0.6546372703806986
  - 0.6544664268585132
  - 0.6572695868015285
  train_level0__roc_auc_macro:
  - 0.8082740242799827
  - 0.8022220545939833
  - 0.8050621402669311
  - 0.8114646677345475
  - 0.8041204327457188
  train_level0__roc_auc_macro_masked:
  - 0.6308143130948526
  - 0.6207689426051577
  - 0.6249931093313791
  - 0.6348267713264057
  - 0.6250676926100156
  train_level0__roc_auc_macro_oob:
  - 0.5443029218481622
  - 0.5439210134724088
  - 0.5523327235086195
  - 0.553250733747139
  - 0.5534297524836087
  train_level0__roc_auc_micro:
  - 0.8368478465463375
  - 0.8359909542539511
  - 0.8368299479915262
  - 0.8385596840083336
  - 0.8357749181066609
  train_level0__roc_auc_micro_masked:
  - 0.7663151453503292
  - 0.7653311637601276
  - 0.7655003686311511
  - 0.7676974477512801
  - 0.7636053260778854
  train_level0__roc_auc_micro_oob:
  - 0.7449597503588328
  - 0.7445848331462476
  - 0.74531730331192
  - 0.7449379122052595
  - 0.7442584592842247
  train_level0__roc_auc_samples:
  - 0.8376776890675559
  - 0.8369525441317972
  - 0.8369625064692275
  - 0.839456533550499
  - 0.8366661813569373
  train_level0__roc_auc_samples_masked:
  - 0.768808362667162
  - 0.7703706448818489
  - 0.7665779799557598
  - 0.7709289423225314
  - 0.7679462926062294
  train_level0__roc_auc_samples_oob:
  - 0.7482594848249218
  - 0.7481748882775492
  - 0.7486233249350237
  - 0.7481617591718822
  - 0.7472572930784286
  train_level0__roc_auc_weighted:
  - 0.7952062453089848
  - 0.7962843904901924
  - 0.7944885487467883
  - 0.8030328973162001
  - 0.7978739596672335
  train_level0__roc_auc_weighted_masked:
  - 0.6161643611441173
  - 0.6187390095467643
  - 0.6170154249811052
  - 0.6284749578697301
  - 0.6233983748291765
  train_level0__roc_auc_weighted_oob:
  - 0.5455549987892736
  - 0.5486565031609428
  - 0.5539336865893489
  - 0.5566899399646884
  - 0.5579798605414843
  train_level0__tn_macro:
  - 0.7655998438795921
  - 0.7652539678657899
  - 0.7659569354993749
  - 0.7672087378640777
  - 0.7658746172288555
  train_level0__tn_macro_masked:
  - 0.8563327720184238
  - 0.8561004847571785
  - 0.8565509301735902
  - 0.8576535102506148
  - 0.8568834941660562
  train_level0__tn_macro_oob:
  - 0.7655754500658632
  - 0.7652050573475829
  - 0.7658608093819088
  - 0.7671359223300971
  - 0.7658508794834665
  train_level0__tn_micro:
  - 0.7655998438795921
  - 0.7652539678657896
  - 0.7659569354993752
  - 0.7672087378640776
  - 0.7658746172288556
  train_level0__tn_micro_masked:
  - 0.8678280105073967
  - 0.8675834534767661
  - 0.8680720102404881
  - 0.8689520563008577
  - 0.8679884856474133
  train_level0__tn_micro_oob:
  - 0.7655754500658632
  - 0.7652050573475826
  - 0.765860809381909
  - 0.7671359223300971
  - 0.7658508794834666
  train_level0__tn_samples:
  - 0.7655998438795921
  - 0.7652539678657896
  - 0.765956935499375
  - 0.7672087378640776
  - 0.7658746172288554
  train_level0__tn_samples_masked:
  - 0.8676379371315293
  - 0.8672734688687684
  - 0.8676818655496775
  - 0.8686807498864502
  - 0.8677261060804053
  train_level0__tn_samples_oob:
  - 0.7655754500658632
  - 0.7652050573475825
  - 0.765860809381909
  - 0.7671359223300971
  - 0.7658508794834665
  train_level0__tn_weighted:
  - 0.6518326359657585
  - 0.651894102109188
  - 0.6522741066590487
  - 0.6543746741737045
  - 0.6553115140528535
  train_level0__tn_weighted_masked:
  - 0.769382417795486
  - 0.7695009609963097
  - 0.7691057151528913
  - 0.7713458492966074
  - 0.7728219214045198
  train_level0__tn_weighted_oob:
  - 0.6517403334708718
  - 0.651709888965659
  - 0.6519071020974159
  - 0.6540994161192786
  - 0.6552225107460955
  train_level0__tp_macro:
  - 0.0007562082255939893
  - 0.0017607786554498543
  - 0.0018023647024896664
  - 0.0012621359223300972
  - 0.0014242647233365777
  train_level0__tp_macro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_macro_oob:
  - 4.878762745767674e-05
  - 0.0003179183683451126
  - 0.0007209458809958665
  - 9.70873786407767e-05
  - 0.000545968143945688
  train_level0__tp_micro:
  - 0.0007562082255939893
  - 0.0017607786554498545
  - 0.0018023647024896664
  - 0.001262135922330097
  - 0.0014242647233365774
  train_level0__tp_micro_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_micro_oob:
  - 4.878762745767673e-05
  - 0.0003179183683451126
  - 0.0007209458809958666
  - 9.70873786407767e-05
  - 0.000545968143945688
  train_level0__tp_samples:
  - 0.0007562082255939893
  - 0.0017607786554498543
  - 0.0018023647024896661
  - 0.001262135922330097
  - 0.0014242647233365774
  train_level0__tp_samples_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_samples_oob:
  - 4.878762745767673e-05
  - 0.0003179183683451126
  - 0.0007209458809958665
  - 9.708737864077669e-05
  - 0.0005459681439456879
  train_level0__tp_weighted:
  - 0.002838105607651118
  - 0.00663167316704642
  - 0.006858969601652639
  - 0.004747158794703368
  - 0.005340198405477249
  train_level0__tp_weighted_masked:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  train_level0__tp_weighted_oob:
  - 0.0001846049897735111
  - 0.001197385432938937
  - 0.00273016828328279
  - 0.0003670107392346992
  - 0.0020470760554329452
  train_level10__average_precision_macro:
  - 0.39192599009027257
  - 0.3987354620381131
  - 0.3998057048443885
  - 0.3915101565426266
  - 0.39180707824658073
  train_level10__average_precision_macro_masked:
  - 0.2617128184390972
  - 0.26469756132659134
  - 0.2649628960540696
  - 0.26066782303866237
  - 0.25563133821718
  train_level10__average_precision_macro_oob:
  - 0.38585295907487815
  - 0.3917289255142094
  - 0.39520193104116164
  - 0.3866918073335168
  - 0.3845878166533151
  train_level10__average_precision_micro:
  - 0.3176655388381148
  - 0.32887531884413446
  - 0.33915293002256774
  - 0.31421869773744404
  - 0.32033048875137365
  train_level10__average_precision_micro_masked:
  - 0.1796400308296846
  - 0.18485483236377465
  - 0.1928709115399627
  - 0.17663248038670637
  - 0.17873769161931458
  train_level10__average_precision_micro_oob:
  - 0.317545765147781
  - 0.3279027629803052
  - 0.3389908230786139
  - 0.31514166140153016
  - 0.319070339674582
  train_level10__average_precision_samples:
  - 0.3255026302128289
  - 0.33304142068820275
  - 0.3478832924816202
  - 0.3219576517078867
  - 0.324020669014811
  train_level10__average_precision_samples_masked:
  - 0.1971204695290759
  - 0.20227288791217127
  - 0.2128841028616827
  - 0.19461560887951582
  - 0.19531585171915697
  train_level10__average_precision_samples_oob:
  - 0.3257076469485773
  - 0.33236115222501866
  - 0.3479310141099054
  - 0.32323754987571063
  - 0.3238578072289294
  train_level10__average_precision_weighted:
  - 0.5282730409255871
  - 0.5345950868547906
  - 0.5349304320397744
  - 0.528623768772723
  - 0.5241783696394865
  train_level10__average_precision_weighted_masked:
  - 0.3761508707030602
  - 0.37889203991533116
  - 0.37906331444009256
  - 0.3757997390265419
  - 0.3656569903442447
  train_level10__average_precision_weighted_oob:
  - 0.5208379632844912
  - 0.5267716810310911
  - 0.5294977038042887
  - 0.5233765559362451
  - 0.516743297371687
  train_level10__f1_macro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.4823127943862346
  - 0.4656067961165049
  - 0.4916799202411755
  train_level10__f1_macro_masked:
  - 0.4371433743761935
  - 0.4274837635736059
  - 0.42994319678436854
  - 0.41195181451788293
  - 0.44086535273928573
  train_level10__f1_macro_oob:
  - 0.4884861199199882
  - 0.47807586021373905
  - 0.4801739882726137
  - 0.46310679611650496
  - 0.4909915256248962
  train_level10__f1_micro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.48231279438623476
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__f1_micro_masked:
  - 0.4283146688787502
  - 0.4177109903515582
  - 0.42092218863196884
  - 0.40185836815482734
  - 0.4323531785531732
  train_level10__f1_micro_oob:
  - 0.4884861199199883
  - 0.478075860213739
  - 0.48017398827261365
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__f1_samples:
  - 0.4889983900082938
  - 0.47939644420532634
  - 0.4823127943862347
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__f1_samples_masked:
  - 0.42923538184551124
  - 0.4190012769247197
  - 0.42204768808484544
  - 0.40294835278599095
  - 0.4338859711603019
  train_level10__f1_samples_oob:
  - 0.4884861199199882
  - 0.478075860213739
  - 0.4801739882726137
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__f1_weighted:
  - 0.571615230905281
  - 0.5683804699429491
  - 0.5668855647244568
  - 0.559393181107288
  - 0.5722724205279806
  train_level10__f1_weighted_masked:
  - 0.5037567330860075
  - 0.500844292995763
  - 0.4986737314318996
  - 0.48924091757786936
  - 0.5053597865803577
  train_level10__f1_weighted_oob:
  - 0.5705755858070666
  - 0.5670707722230721
  - 0.5640176426514197
  - 0.5569275883640912
  - 0.5710300930344872
  train_level10__fn_macro:
  - -0.01988095818900327
  - -0.02005331246484557
  - -0.019633759492454102
  - -0.01723300970873786
  - -0.021648823794715978
  train_level10__fn_macro_masked:
  - -0.01625733639754494
  - -0.0159544902624397
  - -0.01588848309242724
  - -0.013395115500412395
  - -0.017436333380817817
  train_level10__fn_macro_oob:
  - -0.02056398497341074
  - -0.02037123083319068
  - -0.02011439007978468
  - -0.017815533980582523
  - -0.02207610321171695
  train_level10__fn_micro:
  - -0.01988095818900327
  - -0.020053312464845565
  - -0.0196337594924541
  - -0.017233009708737864
  - -0.021648823794715978
  train_level10__fn_micro_masked:
  - -0.01498686575418222
  - -0.014805367638904292
  - -0.01462537789035052
  - -0.012398284583241697
  - -0.01608781038982002
  train_level10__fn_micro_oob:
  - -0.02056398497341074
  - -0.020371230833190677
  - -0.020114390079784678
  - -0.017815533980582523
  - -0.022076103211716953
  train_level10__fn_samples:
  - -0.01988095818900327
  - -0.02005331246484556
  - -0.0196337594924541
  - -0.017233009708737864
  - -0.021648823794715978
  train_level10__fn_samples_masked:
  - -0.014865226548342585
  - -0.014743862926973206
  - -0.014550170225549091
  - -0.012339162751795838
  - -0.016001550827166724
  train_level10__fn_samples_oob:
  - -0.020563984973410738
  - -0.020371230833190677
  - -0.020114390079784675
  - -0.017815533980582523
  - -0.02207610321171695
  train_level10__fn_weighted:
  - -0.029998049358040065
  - -0.02947935120235813
  - -0.029578432738026857
  - -0.02494135126681263
  - -0.03179649331929776
  train_level10__fn_weighted_masked:
  - -0.02585835949094852
  - -0.02462987896228443
  - -0.02551603118463555
  - -0.021006562444667348
  - -0.02764516897323336
  train_level10__fn_weighted_oob:
  - -0.030949575643855656
  - -0.029756195741422475
  - -0.030125889681072018
  - -0.02574783651339797
  - -0.03235580100744802
  train_level10__fp_macro:
  - -0.49112065180270287
  - -0.500550243329828
  - -0.4980534461213112
  - -0.5171601941747571
  - -0.4866712559641086
  train_level10__fp_macro_masked:
  - -0.5465992892262616
  - -0.5565617461639544
  - -0.5541683201232043
  - -0.5746530699817047
  - -0.5416983138798964
  train_level10__fp_macro_oob:
  - -0.4909498951066009
  - -0.5015529089530704
  - -0.4997116216476017
  - -0.5190776699029126
  - -0.4869323711633869
  train_level10__fp_micro:
  - -0.4911206518027028
  - -0.5005502433298281
  - -0.49805344612131114
  - -0.5171601941747572
  - -0.48667125596410854
  train_level10__fp_micro_masked:
  - -0.5566984653670676
  - -0.5674836420095375
  - -0.5644524334776806
  - -0.5857433472619309
  - -0.5515590110570068
  train_level10__fp_micro_oob:
  - -0.490949895106601
  - -0.5015529089530704
  - -0.49971162164760163
  - -0.5190776699029126
  - -0.4869323711633869
  train_level10__fp_samples:
  - -0.49112065180270276
  - -0.500550243329828
  - -0.49805344612131114
  - -0.5171601941747572
  - -0.48667125596410854
  train_level10__fp_samples_masked:
  - -0.5558993916061462
  - -0.5662548601483071
  - -0.5634021416896055
  - -0.5847124844622132
  - -0.5501124780125314
  train_level10__fp_samples_oob:
  - -0.4909498951066009
  - -0.5015529089530704
  - -0.49971162164760163
  - -0.5190776699029126
  - -0.4869323711633869
  train_level10__fp_weighted:
  - -0.39838671973667905
  - -0.40214017885469283
  - -0.4035360025375163
  - -0.41566546762589923
  - -0.39593108615272166
  train_level10__fp_weighted_masked:
  - -0.470384907423044
  - -0.47452582804195265
  - -0.4758102373834649
  - -0.4897525199774632
  - -0.4669950444464088
  train_level10__fp_weighted_oob:
  - -0.398474838549078
  - -0.4031730320355055
  - -0.4058564676675081
  - -0.4173245751225107
  - -0.3966141059580648
  train_level10__jaccard_macro:
  - 0.34494523387518417
  - 0.3384400768206248
  - 0.33941891797008994
  - 0.32641042775646933
  - 0.34701393985190515
  train_level10__jaccard_macro_masked:
  - 0.29912870912051803
  - 0.2932948549440693
  - 0.2932044420200474
  - 0.2798429260036017
  - 0.3019646573911329
  train_level10__jaccard_macro_oob:
  - 0.34460899198128286
  - 0.3375443223858748
  - 0.33761866489577774
  - 0.324322013332812
  - 0.3462915572440435
  train_level10__jaccard_micro:
  - 0.3236253269187304
  - 0.3152672124029013
  - 0.31779459733350224
  - 0.3034468576490501
  - 0.3259785020695299
  train_level10__jaccard_micro_masked:
  - 0.27251935256861365
  - 0.2639915892763273
  - 0.2665620310802187
  - 0.25145353837685347
  - 0.275797566542534
  train_level10__jaccard_micro_oob:
  - 0.32317673450284845
  - 0.31412594604148925
  - 0.3159401040431352
  - 0.30132659507264686
  - 0.3253736039012113
  train_level10__jaccard_samples:
  - 0.3297619805090253
  - 0.321306247221622
  - 0.32357557151639066
  - 0.30915465314601936
  - 0.33176131796339237
  train_level10__jaccard_samples_masked:
  - 0.27915466478102996
  - 0.2704478132173526
  - 0.2730204427603176
  - 0.25766707609588513
  - 0.28210797838446444
  train_level10__jaccard_samples_oob:
  - 0.3292448313290914
  - 0.31996631052135227
  - 0.32159258388624445
  - 0.30698945236616887
  - 0.3311605475817669
  train_level10__jaccard_weighted:
  - 0.4196553452568856
  - 0.41787226950248063
  - 0.4147187633132551
  - 0.4089126083442135
  - 0.4188281591786098
  train_level10__jaccard_weighted_masked:
  - 0.35428056748164116
  - 0.35351384744409453
  - 0.34893369324639945
  - 0.3418521832738646
  - 0.3542446750750642
  train_level10__jaccard_weighted_oob:
  - 0.41878541724751656
  - 0.4167632974063667
  - 0.41193312222242445
  - 0.4066251418440497
  - 0.41748476961055336
  train_level10__label_ranking_average_precision_score:
  - 0.32550263021282877
  - 0.3330414206882025
  - 0.3478832924816201
  - 0.32195765170788654
  - 0.3240206690148111
  train_level10__label_ranking_average_precision_score_oob:
  - 0.32570764694857723
  - 0.3323611522250185
  - 0.3479310141099056
  - 0.3232375498757109
  - 0.3238578072289292
  train_level10__matthews_corrcoef_macro:
  - 0.24552391560326794
  - 0.2379819078176861
  - 0.2395289045170172
  - 0.23462114739904844
  - 0.2430751605120065
  train_level10__matthews_corrcoef_macro_masked:
  - 0.17958788655470584
  - 0.17368958049848687
  - 0.1761691857193509
  - 0.17517173163049435
  - 0.1767560500435987
  train_level10__matthews_corrcoef_macro_oob:
  - 0.2416319951995733
  - 0.23482671290776067
  - 0.23392737908185476
  - 0.22994798343538034
  - 0.2412392100852789
  train_level10__matthews_corrcoef_micro:
  - 0.254402781320892
  - 0.24462913469423386
  - 0.24871223603233514
  - 0.24054791473298914
  - 0.25121352310226563
  train_level10__matthews_corrcoef_micro_masked:
  - 0.1770913388395421
  - 0.170825189313982
  - 0.17357030343609572
  - 0.17105845688734772
  - 0.17435277937093094
  train_level10__matthews_corrcoef_micro_oob:
  - 0.25168938152249487
  - 0.24230239447928226
  - 0.24506638379397858
  - 0.23614751234558337
  - 0.24917449407227882
  train_level10__matthews_corrcoef_samples:
  - 0.2518240899576507
  - 0.241600512752049
  - 0.248299232364466
  - 0.23827271439222378
  - 0.2495747552370475
  train_level10__matthews_corrcoef_samples_masked:
  - 0.17521715492968978
  - 0.1680568809998208
  - 0.17346857478439137
  - 0.16822481426844627
  - 0.17249654947277956
  train_level10__matthews_corrcoef_samples_oob:
  - 0.24918521620126366
  - 0.23916400422359876
  - 0.24456092122080222
  - 0.2337226828252602
  - 0.2474064570617322
  train_level10__matthews_corrcoef_weighted:
  - 0.27821999088857957
  - 0.2732377741448686
  - 0.27133996259018395
  - 0.2760570461369391
  - 0.27797910227137707
  train_level10__matthews_corrcoef_weighted_masked:
  - 0.20695553631123745
  - 0.20548904030411966
  - 0.20327161949010064
  - 0.21245064112478
  - 0.2063175870934896
  train_level10__matthews_corrcoef_weighted_oob:
  - 0.27353629619601216
  - 0.26927153957529176
  - 0.2636364560965423
  - 0.27089988670248316
  - 0.27572027253658277
  train_level10__ndcg:
  - 0.6706414460278467
  - 0.6749741597891498
  - 0.6889269260205402
  - 0.6653006461606307
  - 0.6661582553648424
  train_level10__ndcg_oob:
  - 0.671731846286814
  - 0.6757887460072355
  - 0.6902761716037363
  - 0.6680005924904904
  - 0.6671137864243472
  train_level10__neg_coverage_error:
  - -81.76884422110552
  - -81.53148614609572
  - -81.43316831683168
  - -82.9025
  - -81.87530562347189
  train_level10__neg_coverage_error_oob:
  - -82.7537688442211
  - -82.51889168765743
  - -82.40841584158416
  - -83.8
  - -82.83374083129584
  train_level10__neg_hamming_loss_macro:
  - -0.5110016099917061
  - -0.5206035557946735
  - -0.5176872056137655
  - -0.5343932038834951
  - -0.5083200797588245
  train_level10__neg_hamming_loss_macro_masked:
  - -0.5628566256238065
  - -0.5725162364263942
  - -0.5700568032156315
  - -0.5880481854821171
  - -0.5591346472607143
  train_level10__neg_hamming_loss_macro_oob:
  - -0.5115138800800118
  - -0.521924139786261
  - -0.5198260117273863
  - -0.5368932038834952
  - -0.5090084743751039
  train_level10__neg_hamming_loss_micro:
  - -0.5110016099917061
  - -0.5206035557946737
  - -0.5176872056137652
  - -0.5343932038834951
  - -0.5083200797588245
  train_level10__neg_hamming_loss_micro_masked:
  - -0.5716853311212499
  - -0.5822890096484419
  - -0.5790778113680312
  - -0.5981416318451727
  - -0.5676468214468269
  train_level10__neg_hamming_loss_micro_oob:
  - -0.5115138800800118
  - -0.5219241397862611
  - -0.5198260117273863
  - -0.5368932038834952
  - -0.5090084743751039
  train_level10__neg_hamming_loss_samples:
  - -0.5110016099917061
  - -0.5206035557946737
  - -0.5176872056137652
  - -0.5343932038834951
  - -0.5083200797588244
  train_level10__neg_hamming_loss_samples_masked:
  - -0.5707646181544888
  - -0.5809987230752803
  - -0.5779523119151545
  - -0.597051647214009
  - -0.5661140288396981
  train_level10__neg_hamming_loss_samples_oob:
  - -0.5115138800800116
  - -0.521924139786261
  - -0.5198260117273863
  - -0.5368932038834952
  - -0.5090084743751039
  train_level10__neg_hamming_loss_weighted:
  - -0.4283847690947191
  - -0.431619530057051
  - -0.4331144352755432
  - -0.44060681889271186
  - -0.4277275794720195
  train_level10__neg_hamming_loss_weighted_masked:
  - -0.49624326691399234
  - -0.49915570700423695
  - -0.5013262685681004
  - -0.5107590824221306
  - -0.49464021341964226
  train_level10__neg_hamming_loss_weighted_oob:
  - -0.4294244141929337
  - -0.4329292277769279
  - -0.4359823573485803
  - -0.4430724116359087
  - -0.4289699069655128
  train_level10__neg_label_ranking_loss:
  - -0.3851017091745126
  - -0.37825400596212305
  - -0.36196801869933504
  - -0.3812071569534078
  - -0.38255898749533596
  train_level10__neg_label_ranking_loss_oob:
  - -0.3895183911889233
  - -0.3834239794546167
  - -0.3674798311681297
  - -0.3852680703601189
  - -0.388099101802157
  train_level10__precision_macro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.4823127943862346
  - 0.4656067961165049
  - 0.4916799202411755
  train_level10__precision_macro_masked:
  - 0.4371433743761935
  - 0.4274837635736059
  - 0.42994319678436854
  - 0.41195181451788293
  - 0.44086535273928573
  train_level10__precision_macro_oob:
  - 0.4884861199199882
  - 0.47807586021373905
  - 0.4801739882726137
  - 0.46310679611650496
  - 0.4909915256248962
  train_level10__precision_micro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.48231279438623476
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__precision_micro_masked:
  - 0.4283146688787502
  - 0.4177109903515582
  - 0.42092218863196884
  - 0.40185836815482734
  - 0.4323531785531732
  train_level10__precision_micro_oob:
  - 0.4884861199199883
  - 0.478075860213739
  - 0.48017398827261365
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__precision_samples:
  - 0.4889983900082938
  - 0.47939644420532634
  - 0.4823127943862347
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__precision_samples_masked:
  - 0.42923538184551124
  - 0.4190012769247197
  - 0.42204768808484544
  - 0.40294835278599095
  - 0.4338859711603019
  train_level10__precision_samples_oob:
  - 0.4884861199199882
  - 0.478075860213739
  - 0.4801739882726137
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__precision_weighted:
  - 0.571615230905281
  - 0.5683804699429491
  - 0.5668855647244568
  - 0.559393181107288
  - 0.5722724205279806
  train_level10__precision_weighted_masked:
  - 0.5037567330860075
  - 0.500844292995763
  - 0.4986737314318996
  - 0.48924091757786936
  - 0.5053597865803577
  train_level10__precision_weighted_oob:
  - 0.5705755858070666
  - 0.5670707722230721
  - 0.5640176426514197
  - 0.5569275883640912
  - 0.5710300930344872
  train_level10__recall_macro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.4823127943862346
  - 0.4656067961165049
  - 0.4916799202411755
  train_level10__recall_macro_masked:
  - 0.4371433743761935
  - 0.4274837635736059
  - 0.42994319678436854
  - 0.41195181451788293
  - 0.44086535273928573
  train_level10__recall_macro_oob:
  - 0.4884861199199882
  - 0.47807586021373905
  - 0.4801739882726137
  - 0.46310679611650496
  - 0.4909915256248962
  train_level10__recall_micro:
  - 0.48899839000829387
  - 0.47939644420532634
  - 0.48231279438623476
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__recall_micro_masked:
  - 0.4283146688787502
  - 0.4177109903515582
  - 0.42092218863196884
  - 0.40185836815482734
  - 0.4323531785531732
  train_level10__recall_micro_oob:
  - 0.4884861199199883
  - 0.478075860213739
  - 0.48017398827261365
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__recall_samples:
  - 0.4889983900082938
  - 0.47939644420532634
  - 0.4823127943862347
  - 0.46560679611650485
  - 0.4916799202411755
  train_level10__recall_samples_masked:
  - 0.42923538184551124
  - 0.4190012769247197
  - 0.42204768808484544
  - 0.40294835278599095
  - 0.4338859711603019
  train_level10__recall_samples_oob:
  - 0.4884861199199882
  - 0.478075860213739
  - 0.4801739882726137
  - 0.46310679611650485
  - 0.4909915256248962
  train_level10__recall_weighted:
  - 0.571615230905281
  - 0.5683804699429491
  - 0.5668855647244568
  - 0.559393181107288
  - 0.5722724205279806
  train_level10__recall_weighted_masked:
  - 0.5037567330860075
  - 0.500844292995763
  - 0.4986737314318996
  - 0.48924091757786936
  - 0.5053597865803577
  train_level10__recall_weighted_oob:
  - 0.5705755858070666
  - 0.5670707722230721
  - 0.5640176426514197
  - 0.5569275883640912
  - 0.5710300930344872
  train_level10__roc_auc_macro:
  - 0.7221116945495368
  - 0.7231431043987652
  - 0.7288163202027256
  - 0.722779108601744
  - 0.7174584586826187
  train_level10__roc_auc_macro_masked:
  - 0.7038254307129592
  - 0.7018526592575272
  - 0.7087246218273576
  - 0.7004931781197377
  - 0.6909977066218442
  train_level10__roc_auc_macro_oob:
  - 0.7156695838630737
  - 0.7162119792388664
  - 0.7225205988357908
  - 0.7158119521571678
  - 0.7105674299664019
  train_level10__roc_auc_micro:
  - 0.667648658202435
  - 0.6730601618044788
  - 0.6815271424514919
  - 0.6617057137707325
  - 0.6682156845201421
  train_level10__roc_auc_micro_masked:
  - 0.647784749797194
  - 0.6511801003772538
  - 0.6607062833987376
  - 0.6424820502014124
  - 0.6448112536766683
  train_level10__roc_auc_micro_oob:
  - 0.6662994371962202
  - 0.6707442261877565
  - 0.6798877602807222
  - 0.6606952586944141
  - 0.665884688320707
  train_level10__roc_auc_samples:
  - 0.6520702803394514
  - 0.6552344578977113
  - 0.668680050306698
  - 0.6449552763267925
  - 0.6493019763000814
  train_level10__roc_auc_samples_masked:
  - 0.6335403967073069
  - 0.6370413725799292
  - 0.6499027158081004
  - 0.6262065042821523
  - 0.6302263708192059
  train_level10__roc_auc_samples_oob:
  - 0.651282671154062
  - 0.6537014005891126
  - 0.6673902155909297
  - 0.644377630356199
  - 0.6480658982274625
  train_level10__roc_auc_weighted:
  - 0.7252163941970402
  - 0.7250446269819268
  - 0.7300637442399742
  - 0.7284839225067011
  - 0.7227469243227443
  train_level10__roc_auc_weighted_masked:
  - 0.70096630730892
  - 0.699192304965688
  - 0.7044443975033798
  - 0.7062438565695662
  - 0.6938639147942974
  train_level10__roc_auc_weighted_oob:
  - 0.7171757583896163
  - 0.7170473677161806
  - 0.7225713122303792
  - 0.7197639067884677
  - 0.715039329224596
  train_level10__tn_macro:
  - 0.2744791920768893
  - 0.26470372453596147
  - 0.267903489378064
  - 0.2500485436893204
  - 0.27922709901013604
  train_level10__tn_macro_masked:
  - 0.30973348279216245
  - 0.2995387385932239
  - 0.30238261005038586
  - 0.28300044026891025
  - 0.31522757652137445
  train_level10__tn_macro_oob:
  - 0.2746499487729912
  - 0.2637010589127192
  - 0.2662453138517735
  - 0.24813106796116502
  - 0.2789659838108577
  train_level10__tn_micro:
  - 0.2744791920768893
  - 0.26470372453596147
  - 0.267903489378064
  - 0.2500485436893204
  - 0.27922709901013604
  train_level10__tn_micro_masked:
  - 0.31112954514032903
  - 0.3000998114672286
  - 0.30361957676280743
  - 0.28320870903892675
  - 0.31645637728336606
  train_level10__tn_micro_oob:
  - 0.27464994877299115
  - 0.26370105891271917
  - 0.2662453138517735
  - 0.24813106796116505
  - 0.27896598381085763
  train_level10__tn_samples:
  - 0.27447919207688926
  - 0.2647037245359614
  - 0.267903489378064
  - 0.25004854368932034
  - 0.2792270990101359
  train_level10__tn_samples_masked:
  - 0.3117385455253832
  - 0.3010186087204614
  - 0.30427972386007196
  - 0.28396826542423687
  - 0.31764049606540207
  train_level10__tn_samples_oob:
  - 0.27464994877299115
  - 0.26370105891271917
  - 0.26624531385177347
  - 0.248131067961165
  - 0.2789659838108576
  train_level10__tn_weighted:
  - 0.25344591622907964
  - 0.2497539232544952
  - 0.24873810412153238
  - 0.23870920654780528
  - 0.2594694312068898
  train_level10__tn_weighted_masked:
  - 0.298997510372442
  - 0.2949751329543571
  - 0.29329547776942644
  - 0.2815933293191443
  - 0.30598620418775757
  train_level10__tn_weighted_oob:
  - 0.25335779741668063
  - 0.24872107007368255
  - 0.24641763899154065
  - 0.2370500990511939
  - 0.2587864114015467
  train_level10__tp_macro:
  - 0.2145191979314046
  - 0.21469271966936485
  - 0.21440930500817074
  - 0.21555825242718443
  - 0.2124528212310395
  train_level10__tp_macro_masked:
  - 0.1274098915840311
  - 0.12794502498038196
  - 0.12756058673398263
  - 0.12895137424897274
  - 0.12563777621791133
  train_level10__tp_macro_oob:
  - 0.21383617114699713
  - 0.21437480130101974
  - 0.21392867442084013
  - 0.2149757281553398
  - 0.21202554181403854
  train_level10__tp_micro:
  - 0.2145191979314046
  - 0.2146927196693649
  - 0.2144093050081707
  - 0.21555825242718446
  - 0.21245282123103948
  train_level10__tp_micro_masked:
  - 0.11718512373842113
  - 0.1176111788843296
  - 0.11730261186916142
  - 0.1186496591159006
  - 0.1158968012698071
  train_level10__tp_micro_oob:
  - 0.21383617114699713
  - 0.2143748013010198
  - 0.21392867442084015
  - 0.2149757281553398
  - 0.21202554181403852
  train_level10__tp_samples:
  - 0.21451919793140453
  - 0.21469271966936485
  - 0.21440930500817068
  - 0.2155582524271844
  - 0.2124528212310394
  train_level10__tp_samples_masked:
  - 0.11749683632012808
  - 0.11798266820425829
  - 0.11776796422477345
  - 0.1189800873617541
  - 0.11624547509489977
  train_level10__tp_samples_oob:
  - 0.21383617114699704
  - 0.21437480130101974
  - 0.21392867442084013
  - 0.21497572815533975
  - 0.2120255418140385
  train_level10__tp_weighted:
  - 0.31816931467620124
  - 0.31862654668845375
  - 0.31814746060292437
  - 0.32068397455948283
  - 0.31280298932109074
  train_level10__tp_weighted_masked:
  - 0.2047592227135655
  - 0.20586916004140587
  - 0.2053782536624732
  - 0.20764758825872529
  - 0.1993735823926003
  train_level10__tp_weighted_oob:
  - 0.3172177883903856
  - 0.3183497021493894
  - 0.3176000036598792
  - 0.3198774893128975
  - 0.31224368163294053
  train_level1__average_precision_macro:
  - 0.43505811709816333
  - 0.43675914841949176
  - 0.4446900136803904
  - 0.44044275126682214
  - 0.4254793416338025
  train_level1__average_precision_macro_masked:
  - 0.2978631376372289
  - 0.29605992477564014
  - 0.3030929623608431
  - 0.3010075445786297
  - 0.2840668278628539
  train_level1__average_precision_macro_oob:
  - 0.42571832448225316
  - 0.42595188221635794
  - 0.4328434052225376
  - 0.42869815519954035
  - 0.41627815729214507
  train_level1__average_precision_micro:
  - 0.30988209277357837
  - 0.3040765349666085
  - 0.32581600832132435
  - 0.3143592356992718
  - 0.31762923682232425
  train_level1__average_precision_micro_masked:
  - 0.1743056385199718
  - 0.17015539818384956
  - 0.18256472014366407
  - 0.17644850120134542
  - 0.17586121347728312
  train_level1__average_precision_micro_oob:
  - 0.30235491780498625
  - 0.2969734015190172
  - 0.31561163149791593
  - 0.30565761709326933
  - 0.3102409626821071
  train_level1__average_precision_samples:
  - 0.327533649548145
  - 0.32012143611672905
  - 0.3436563157966429
  - 0.33207889465888163
  - 0.3316479281086886
  train_level1__average_precision_samples_masked:
  - 0.20472882524873975
  - 0.1999317629713297
  - 0.21592037704944814
  - 0.20957063080356084
  - 0.2070160624044634
  train_level1__average_precision_samples_oob:
  - 0.32036403556856885
  - 0.313201620666931
  - 0.33416020316050465
  - 0.3239743701426008
  - 0.3252310241975806
  train_level1__average_precision_weighted:
  - 0.564968508524199
  - 0.5649501635277578
  - 0.5730942624714406
  - 0.5672562852524878
  - 0.5507552601005086
  train_level1__average_precision_weighted_masked:
  - 0.40911998742765743
  - 0.40706066148667475
  - 0.4127303555351626
  - 0.4087466413646788
  - 0.3886824782508304
  train_level1__average_precision_weighted_oob:
  - 0.5539626869352928
  - 0.553413091378465
  - 0.5603854697979493
  - 0.5542372934205922
  - 0.5408757432246678
  train_level1__f1_macro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650486
  - 0.5040710233342036
  train_level1__f1_macro_masked:
  - 0.44181578094562746
  - 0.4320502446666314
  - 0.4360792854596474
  - 0.4171874091035541
  - 0.4567945455866896
  train_level1__f1_macro_oob:
  - 0.4772405717909937
  - 0.467829106649385
  - 0.47089781793713353
  - 0.45410194174757273
  - 0.4908728368979515
  train_level1__f1_micro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.46856796116504856
  - 0.5040710233342037
  train_level1__f1_micro_masked:
  - 0.433568367205862
  - 0.4233115226793834
  - 0.4284119072909007
  - 0.40763140532219044
  - 0.4495170966613758
  train_level1__f1_micro_oob:
  - 0.47724057179099383
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__f1_samples:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650485
  - 0.5040710233342036
  train_level1__f1_samples_masked:
  - 0.4344621035938126
  - 0.42433553584262396
  - 0.42938081393605765
  - 0.4085128270311234
  - 0.45063675980755064
  train_level1__f1_samples_oob:
  - 0.4772405717909938
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__f1_weighted:
  - 0.572181596922065
  - 0.5670642119259379
  - 0.5652851300121283
  - 0.5589597018037744
  - 0.5772727205112708
  train_level1__f1_weighted_masked:
  - 0.5040302767410951
  - 0.4974978171067583
  - 0.49466079023888515
  - 0.4903665057087827
  - 0.5119287327030219
  train_level1__f1_weighted_oob:
  - 0.5564177427882467
  - 0.5509327036847615
  - 0.5472218466327585
  - 0.5427726514440622
  - 0.5621468688438346
  train_level1__fn_macro:
  - -0.022759428209006196
  - -0.02364823555305568
  - -0.023118331250600782
  - -0.02313106796116504
  - -0.027630735632729605
  train_level1__fn_macro_masked:
  - -0.01768794324039143
  - -0.018192852712587325
  - -0.018087700504896193
  - -0.01764467285427822
  - -0.02075927132391643
  train_level1__fn_macro_oob:
  - -0.0261989559447724
  - -0.026729598200092932
  - -0.027251754301643758
  - -0.025946601941747575
  - -0.030716642533292187
  train_level1__fn_micro:
  - -0.022759428209006196
  - -0.023648235553055685
  - -0.02311833125060079
  - -0.02313106796116505
  - -0.027630735632729605
  train_level1__fn_micro_masked:
  - -0.01664592838379649
  - -0.017356105134745482
  - -0.01718549990467631
  - -0.016659335825819223
  - -0.019746576632320895
  train_level1__fn_micro_oob:
  - -0.026198955944772406
  - -0.02672959820009293
  - -0.027251754301643758
  - -0.025946601941747572
  - -0.030716642533292187
  train_level1__fn_samples:
  - -0.022759428209006193
  - -0.023648235553055685
  - -0.023118331250600786
  - -0.023131067961165045
  - -0.0276307356327296
  train_level1__fn_samples_masked:
  - -0.016526709666514643
  - -0.0172743843639674
  - -0.017108345590993723
  - -0.016573421440533507
  - -0.019650242441934897
  train_level1__fn_samples_oob:
  - -0.026198955944772402
  - -0.026729598200092925
  - -0.027251754301643755
  - -0.025946601941747572
  - -0.030716642533292184
  train_level1__fn_weighted:
  - -0.03100736275821819
  - -0.030130132678073362
  - -0.02978684253064387
  - -0.031138828067980396
  - -0.03537249247438614
  train_level1__fn_weighted_masked:
  - -0.025552790146437406
  - -0.024508303541449943
  - -0.024996312297832727
  - -0.02517869254057897
  - -0.028432229555058124
  train_level1__fn_weighted_oob:
  - -0.034551987745993995
  - -0.03347982039480917
  - -0.03402391527786109
  - -0.034163278073193616
  - -0.03888105736920109
  train_level1__fp_macro:
  - -0.48502219837049326
  - -0.4933603971534078
  - -0.489185811785062
  - -0.5083009708737866
  - -0.46829824103306666
  train_level1__fp_macro_masked:
  - -0.5404962758139812
  - -0.5497569026207813
  - -0.5458330140354564
  - -0.5651679180421677
  - -0.522446183089394
  train_level1__fp_macro_oob:
  - -0.4965604722642339
  - -0.505441295150522
  - -0.5018504277612227
  - -0.5199514563106796
  - -0.47841052056875644
  train_level1__fp_micro:
  - -0.48502219837049326
  - -0.49336039715340785
  - -0.489185811785062
  - -0.5083009708737865
  - -0.46829824103306666
  train_level1__fp_micro_masked:
  - -0.5497857044103415
  - -0.5593323721858712
  - -0.5544025928044231
  - -0.5757092588519903
  - -0.5307363267063033
  train_level1__fp_micro_oob:
  - -0.4965604722642338
  - -0.5054412951505222
  - -0.5018504277612227
  - -0.5199514563106796
  - -0.4784105205687564
  train_level1__fp_samples:
  - -0.4850221983704932
  - -0.49336039715340785
  - -0.48918581178506193
  - -0.5083009708737865
  - -0.46829824103306666
  train_level1__fp_samples_masked:
  - -0.5490111867396728
  - -0.5583900797934087
  - -0.5535108404729486
  - -0.5749137515283431
  - -0.5297129977505145
  train_level1__fp_samples_oob:
  - -0.49656047226423383
  - -0.5054412951505222
  - -0.5018504277612227
  - -0.5199514563106795
  - -0.4784105205687564
  train_level1__fp_weighted:
  - -0.39681104031971703
  - -0.4028056553959888
  - -0.4049280274572277
  - -0.40990147012824524
  - -0.3873547870143431
  train_level1__fp_weighted_masked:
  - -0.4704169331124675
  - -0.4779938793517917
  - -0.480342897463282
  - -0.4844548017506384
  - -0.45963903774192
  train_level1__fp_weighted_oob:
  - -0.40903026946575943
  - -0.41558747592042944
  - -0.41875423808938034
  - -0.4230640704827442
  - -0.3989720737869642
  train_level1__jaccard_macro:
  - 0.357404809736552
  - 0.351458873572266
  - 0.3540007570878606
  - 0.33917916816465743
  - 0.3669641175771247
  train_level1__jaccard_macro_masked:
  - 0.31515616267818963
  - 0.3095336146779335
  - 0.3113181266149075
  - 0.29796431104539334
  - 0.3274813120041219
  train_level1__jaccard_macro_oob:
  - 0.34420114716375305
  - 0.3379061633087681
  - 0.3386769504115065
  - 0.3261190845735688
  - 0.3547701069417757
  train_level1__jaccard_micro:
  - 0.32645203041579035
  - 0.31838405984008256
  - 0.3224853011282377
  - 0.30596719232902764
  - 0.33696186864279026
  train_level1__jaccard_micro_masked:
  - 0.2767872903795234
  - 0.26848139551241473
  - 0.27259808678774433
  - 0.25599060838339893
  - 0.2899207051515625
  train_level1__jaccard_micro_oob:
  - 0.31340510060233245
  - 0.3053374193960289
  - 0.30795706360307407
  - 0.29374636918873936
  - 0.3252693668895006
  train_level1__jaccard_samples:
  - 0.33136767628880565
  - 0.32241746905682583
  - 0.32692554507802163
  - 0.3100474356798024
  - 0.3412849237773632
  train_level1__jaccard_samples_masked:
  - 0.2820120931059081
  - 0.27260189888405595
  - 0.27743518370276055
  - 0.26019778411393035
  - 0.2943831339602772
  train_level1__jaccard_samples_oob:
  - 0.31825157447427355
  - 0.30929272303985994
  - 0.3124040217794104
  - 0.29777741056479906
  - 0.32960667437020474
  train_level1__jaccard_weighted:
  - 0.42661033640835033
  - 0.4230085978826319
  - 0.41942806033956587
  - 0.41618286063859317
  - 0.42927692393221356
  train_level1__jaccard_weighted_masked:
  - 0.36332270539808303
  - 0.3592910399085038
  - 0.35462644697243345
  - 0.354568205430576
  - 0.3688347927496089
  train_level1__jaccard_weighted_oob:
  - 0.4112268947855445
  - 0.40708821667334
  - 0.40143606843790675
  - 0.4001349207483079
  - 0.41394968482100664
  train_level1__label_ranking_average_precision_score:
  - 0.3275336495481447
  - 0.3201214361167292
  - 0.3436563157966428
  - 0.33207889465888163
  - 0.3316479281086886
  train_level1__label_ranking_average_precision_score_oob:
  - 0.32036403556856874
  - 0.31320162066693114
  - 0.3341602031605046
  - 0.32397437014260094
  - 0.32523102419758065
  train_level1__matthews_corrcoef_macro:
  - 0.2386966267891144
  - 0.2249789846871585
  - 0.22968488329374756
  - 0.22317402102437717
  - 0.23522247160988738
  train_level1__matthews_corrcoef_macro_masked:
  - 0.17582207563282423
  - 0.16251842411147796
  - 0.1649622054660918
  - 0.1641401830054625
  - 0.16957094155088004
  train_level1__matthews_corrcoef_macro_oob:
  - 0.21037982763112428
  - 0.19847553816704872
  - 0.19527141609343673
  - 0.1968050056984148
  - 0.21032925407733247
  train_level1__matthews_corrcoef_micro:
  - 0.24824362298279556
  - 0.23645744773381547
  - 0.24261540767477266
  - 0.22361472006186142
  - 0.24453286743900807
  train_level1__matthews_corrcoef_micro_masked:
  - 0.17263939626333005
  - 0.16218479876501868
  - 0.16619669720179428
  - 0.15348780089095476
  - 0.1688057403195862
  train_level1__matthews_corrcoef_micro_oob:
  - 0.22255180211986256
  - 0.21151952069648833
  - 0.21279242674749965
  - 0.19994396522328495
  - 0.22195431095798468
  train_level1__matthews_corrcoef_samples:
  - 0.24609950728260221
  - 0.23403987908982657
  - 0.2419228716434549
  - 0.22106039036279157
  - 0.24255299744312525
  train_level1__matthews_corrcoef_samples_masked:
  - 0.1714921839844984
  - 0.16031011245010177
  - 0.1661707478035472
  - 0.15083143547619354
  - 0.16724685176988013
  train_level1__matthews_corrcoef_samples_oob:
  - 0.22023042938347367
  - 0.20939545140587618
  - 0.21218804504298652
  - 0.19781191151054764
  - 0.21963131757631002
  train_level1__matthews_corrcoef_weighted:
  - 0.2633227484824484
  - 0.2529724585093798
  - 0.2542723235155843
  - 0.257217655268052
  - 0.262108109749993
  train_level1__matthews_corrcoef_weighted_masked:
  - 0.19736087483209855
  - 0.1884520258348642
  - 0.18599568546959008
  - 0.1946050320206977
  - 0.19390935509921817
  train_level1__matthews_corrcoef_weighted_oob:
  - 0.23195135514186277
  - 0.22253965264512968
  - 0.21303823137005615
  - 0.22310129379931357
  - 0.23063561166709534
  train_level1__ndcg:
  - 0.6411792758268942
  - 0.6347583584232114
  - 0.6541273443435467
  - 0.6539518882799706
  - 0.6461774076506681
  train_level1__ndcg_oob:
  - 0.6371763878678031
  - 0.631165849675606
  - 0.6492433290919409
  - 0.6495486486239789
  - 0.6432987597925753
  train_level1__neg_coverage_error:
  - -82.66582914572864
  - -82.88413098236776
  - -83.01732673267327
  - -84.5675
  - -83.28361858190709
  train_level1__neg_coverage_error_oob:
  - -84.63316582914572
  - -84.63727959697734
  - -85.15841584158416
  - -86.7975
  - -84.9437652811736
  train_level1__neg_hamming_loss_macro:
  - -0.5077816265794994
  - -0.5170086327064636
  - -0.5123041430356629
  - -0.5314320388349515
  - -0.49592897666579633
  train_level1__neg_hamming_loss_macro_masked:
  - -0.5581842190543725
  - -0.5679497553333686
  - -0.5639207145403525
  - -0.5828125908964459
  - -0.5432054544133104
  train_level1__neg_hamming_loss_macro_oob:
  - -0.5227594282090062
  - -0.532170893350615
  - -0.5291021820628664
  - -0.5458980582524272
  - -0.5091271631020485
  train_level1__neg_hamming_loss_micro:
  - -0.5077816265794994
  - -0.5170086327064636
  - -0.5123041430356627
  - -0.5314320388349515
  - -0.4959289766657963
  train_level1__neg_hamming_loss_micro_masked:
  - -0.566431632794138
  - -0.5766884773206166
  - -0.5715880927090994
  - -0.5923685946778096
  - -0.5504829033386242
  train_level1__neg_hamming_loss_micro_oob:
  - -0.5227594282090062
  - -0.5321708933506151
  - -0.5291021820628665
  - -0.5458980582524272
  - -0.5091271631020485
  train_level1__neg_hamming_loss_samples:
  - -0.5077816265794994
  - -0.5170086327064636
  - -0.5123041430356627
  - -0.5314320388349515
  - -0.49592897666579633
  train_level1__neg_hamming_loss_samples_masked:
  - -0.5655378964061872
  - -0.5756644641573762
  - -0.5706191860639425
  - -0.5914871729688765
  - -0.5493632401924494
  train_level1__neg_hamming_loss_samples_oob:
  - -0.5227594282090061
  - -0.5321708933506151
  - -0.5291021820628664
  - -0.5458980582524271
  - -0.5091271631020486
  train_level1__neg_hamming_loss_weighted:
  - -0.42781840307793517
  - -0.4329357880740621
  - -0.4347148699878715
  - -0.44104029819622564
  - -0.4227272794887293
  train_level1__neg_hamming_loss_weighted_masked:
  - -0.4959697232589048
  - -0.5025021828932418
  - -0.5053392097611149
  - -0.5096334942912174
  - -0.48807126729697814
  train_level1__neg_hamming_loss_weighted_oob:
  - -0.4435822572117534
  - -0.44906729631523856
  - -0.45277815336724153
  - -0.45722734855593783
  - -0.43785313115616525
  train_level1__neg_label_ranking_loss:
  - -0.3423448545380403
  - -0.3509906744661487
  - -0.3311579689857421
  - -0.3528222083157321
  - -0.3430895987175694
  train_level1__neg_label_ranking_loss_oob:
  - -0.3562821609518424
  - -0.36460517922619196
  - -0.3486370248133959
  - -0.36894590186549253
  - -0.35629267291969696
  train_level1__precision_macro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650486
  - 0.5040710233342036
  train_level1__precision_macro_masked:
  - 0.44181578094562746
  - 0.4320502446666314
  - 0.4360792854596474
  - 0.4171874091035541
  - 0.4567945455866896
  train_level1__precision_macro_oob:
  - 0.4772405717909937
  - 0.467829106649385
  - 0.47089781793713353
  - 0.45410194174757273
  - 0.4908728368979515
  train_level1__precision_micro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.46856796116504856
  - 0.5040710233342037
  train_level1__precision_micro_masked:
  - 0.433568367205862
  - 0.4233115226793834
  - 0.4284119072909007
  - 0.40763140532219044
  - 0.4495170966613758
  train_level1__precision_micro_oob:
  - 0.47724057179099383
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__precision_samples:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650485
  - 0.5040710233342036
  train_level1__precision_samples_masked:
  - 0.4344621035938126
  - 0.42433553584262396
  - 0.42938081393605765
  - 0.4085128270311234
  - 0.45063675980755064
  train_level1__precision_samples_oob:
  - 0.4772405717909938
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__precision_weighted:
  - 0.572181596922065
  - 0.5670642119259379
  - 0.5652851300121283
  - 0.5589597018037744
  - 0.5772727205112708
  train_level1__precision_weighted_masked:
  - 0.5040302767410951
  - 0.4974978171067583
  - 0.49466079023888515
  - 0.4903665057087827
  - 0.5119287327030219
  train_level1__precision_weighted_oob:
  - 0.5564177427882467
  - 0.5509327036847615
  - 0.5472218466327585
  - 0.5427726514440622
  - 0.5621468688438346
  train_level1__recall_macro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650486
  - 0.5040710233342036
  train_level1__recall_macro_masked:
  - 0.44181578094562746
  - 0.4320502446666314
  - 0.4360792854596474
  - 0.4171874091035541
  - 0.4567945455866896
  train_level1__recall_macro_oob:
  - 0.4772405717909937
  - 0.467829106649385
  - 0.47089781793713353
  - 0.45410194174757273
  - 0.4908728368979515
  train_level1__recall_micro:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.46856796116504856
  - 0.5040710233342037
  train_level1__recall_micro_masked:
  - 0.433568367205862
  - 0.4233115226793834
  - 0.4284119072909007
  - 0.40763140532219044
  - 0.4495170966613758
  train_level1__recall_micro_oob:
  - 0.47724057179099383
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__recall_samples:
  - 0.49221837342050057
  - 0.4829913672935365
  - 0.4876958569643372
  - 0.4685679611650485
  - 0.5040710233342036
  train_level1__recall_samples_masked:
  - 0.4344621035938126
  - 0.42433553584262396
  - 0.42938081393605765
  - 0.4085128270311234
  - 0.45063675980755064
  train_level1__recall_samples_oob:
  - 0.4772405717909938
  - 0.46782910664938493
  - 0.47089781793713353
  - 0.4541019417475728
  - 0.4908728368979514
  train_level1__recall_weighted:
  - 0.572181596922065
  - 0.5670642119259379
  - 0.5652851300121283
  - 0.5589597018037744
  - 0.5772727205112708
  train_level1__recall_weighted_masked:
  - 0.5040302767410951
  - 0.4974978171067583
  - 0.49466079023888515
  - 0.4903665057087827
  - 0.5119287327030219
  train_level1__recall_weighted_oob:
  - 0.5564177427882467
  - 0.5509327036847615
  - 0.5472218466327585
  - 0.5427726514440622
  - 0.5621468688438346
  train_level1__roc_auc_macro:
  - 0.7389271181584665
  - 0.7318975547685068
  - 0.741955237014294
  - 0.7450946331377618
  - 0.7291612074710958
  train_level1__roc_auc_macro_masked:
  - 0.717065472851229
  - 0.7024850990022333
  - 0.7131420496424612
  - 0.7166717777566
  - 0.697222176285669
  train_level1__roc_auc_macro_oob:
  - 0.724405107239304
  - 0.716690506762262
  - 0.7241750777156405
  - 0.7304181238907189
  - 0.7147885943920516
  train_level1__roc_auc_micro:
  - 0.6720030307866977
  - 0.6634127233362981
  - 0.6794338638876265
  - 0.6630821300481344
  - 0.6723728928294613
  train_level1__roc_auc_micro_masked:
  - 0.6502892941821874
  - 0.6412107721861684
  - 0.6544299873235032
  - 0.6407707857752128
  - 0.6447207595780686
  train_level1__roc_auc_micro_oob:
  - 0.6584467312677648
  - 0.6502911883490783
  - 0.6623108174011547
  - 0.647344887996965
  - 0.6593198600001263
  train_level1__roc_auc_samples:
  - 0.6576657958119728
  - 0.6490499772464283
  - 0.668847001022642
  - 0.6471808954006317
  - 0.6569211671150009
  train_level1__roc_auc_samples_masked:
  - 0.636414294150288
  - 0.6316536225057074
  - 0.6445975016165729
  - 0.6265807782413431
  - 0.633746230215604
  train_level1__roc_auc_samples_oob:
  - 0.6437321781315548
  - 0.6354428385253373
  - 0.6513712013969426
  - 0.6310640264212642
  - 0.6437238475318731
  train_level1__roc_auc_weighted:
  - 0.7362336368405985
  - 0.7326873916379124
  - 0.7395446321702193
  - 0.7432158213506393
  - 0.7296434301238116
  train_level1__roc_auc_weighted_masked:
  - 0.7079067822462507
  - 0.7018266618987046
  - 0.7069742957338147
  - 0.714384964477788
  - 0.6954303787716988
  train_level1__roc_auc_weighted_oob:
  - 0.7197844689454096
  - 0.7168171285871456
  - 0.7204605183085232
  - 0.7266045441228614
  - 0.7138990483518072
  train_level1__tn_macro:
  - 0.28057764550909886
  - 0.2718935707123817
  - 0.27677112371431317
  - 0.2589077669902912
  - 0.29760011394117786
  train_level1__tn_macro_masked:
  - 0.3158364962044429
  - 0.3063435821363972
  - 0.3107179161381338
  - 0.2924855922084472
  - 0.33447970731187693
  train_level1__tn_macro_oob:
  - 0.26903937161535835
  - 0.2598126727152674
  - 0.2641065077381525
  - 0.247257281553398
  - 0.28748783440548814
  train_level1__tn_micro:
  - 0.2805776455090989
  - 0.2718935707123817
  - 0.27677112371431317
  - 0.2589077669902913
  - 0.29760011394117786
  train_level1__tn_micro_masked:
  - 0.31804230609705514
  - 0.30825108129089496
  - 0.313669417436065
  - 0.2932427974488674
  - 0.33727906163406957
  train_level1__tn_micro_oob:
  - 0.26903937161535835
  - 0.2598126727152674
  - 0.2641065077381525
  - 0.24725728155339805
  - 0.28748783440548814
  train_level1__tn_samples:
  - 0.2805776455090988
  - 0.2718935707123816
  - 0.2767711237143131
  - 0.25890776699029117
  - 0.29760011394117775
  train_level1__tn_samples_masked:
  - 0.3186267503918567
  - 0.3088833890753599
  - 0.3141710250767288
  - 0.293766998358107
  - 0.33803997632741906
  train_level1__tn_samples_oob:
  - 0.2690393716153583
  - 0.25981267271526737
  - 0.26410650773815236
  - 0.247257281553398
  - 0.2874878344054881
  train_level1__tn_weighted:
  - 0.2550215956460416
  - 0.2490884467131993
  - 0.247346079201821
  - 0.24447320404545927
  - 0.26804573034526835
  train_level1__tn_weighted_masked:
  - 0.2989654846830184
  - 0.29150708164451805
  - 0.28876281768960915
  - 0.286891047545969
  - 0.31334221089224623
  train_level1__tn_weighted_oob:
  - 0.2428023664999992
  - 0.2363066261887586
  - 0.23351986856966833
  - 0.23131060369096024
  - 0.2564284435726473
  train_level1__tp_macro:
  - 0.2116407279114016
  - 0.21109779658115477
  - 0.21092473325002403
  - 0.20966019417475731
  - 0.20647090939302584
  train_level1__tp_macro_masked:
  - 0.1259792847411846
  - 0.12570666253023435
  - 0.12536136932151368
  - 0.12470181689510688
  - 0.12231483827481272
  train_level1__tp_macro_oob:
  - 0.20820120017563543
  - 0.20801643393411753
  - 0.20679131019898112
  - 0.20684466019417475
  - 0.20338500249246327
  train_level1__tp_micro:
  - 0.21164072791140168
  - 0.21109779658115477
  - 0.21092473325002403
  - 0.2096601941747573
  - 0.20647090939302584
  train_level1__tp_micro_masked:
  - 0.11552606110880685
  - 0.11506044138848841
  - 0.11474248985483564
  - 0.11438860787332307
  - 0.11223803502730623
  train_level1__tp_micro_oob:
  - 0.20820120017563545
  - 0.20801643393411753
  - 0.20679131019898106
  - 0.20684466019417475
  - 0.20338500249246327
  train_level1__tp_samples:
  - 0.2116407279114016
  - 0.21109779658115474
  - 0.21092473325002395
  - 0.2096601941747572
  - 0.20647090939302581
  train_level1__tp_samples_masked:
  - 0.11583535320195604
  - 0.1154521467672641
  - 0.11520978885932881
  - 0.11474582867301644
  - 0.1125967834801316
  train_level1__tp_samples_oob:
  - 0.2082012001756354
  - 0.20801643393411745
  - 0.206791310198981
  - 0.20684466019417472
  - 0.20338500249246322
  train_level1__tp_weighted:
  - 0.3171600012760231
  - 0.3179757652127385
  - 0.3179390508103074
  - 0.31448649775831505
  - 0.3092269901660024
  train_level1__tp_weighted_masked:
  - 0.20506479205807662
  - 0.2059907354622404
  - 0.20589797254927603
  - 0.20347545816281365
  - 0.19858652181077555
  train_level1__tp_weighted_oob:
  - 0.3136153762882473
  - 0.31462607749600274
  - 0.31370197806309025
  - 0.3114620477531019
  - 0.3057184252711874
  train_level2__average_precision_macro:
  - 0.40558135329757466
  - 0.4114331727322687
  - 0.4164166049413071
  - 0.4082709985762384
  - 0.4004657007275992
  train_level2__average_precision_macro_masked:
  - 0.2726544481391745
  - 0.2757862560318825
  - 0.2809620059418155
  - 0.27508635066141635
  - 0.2632659722621829
  train_level2__average_precision_macro_oob:
  - 0.4022824757943522
  - 0.40790547180468195
  - 0.4117991318982112
  - 0.4058686666666637
  - 0.39683900211070827
  train_level2__average_precision_micro:
  - 0.31689861480266396
  - 0.32729108103196725
  - 0.33617394922259797
  - 0.31491006768620056
  - 0.3252139894019378
  train_level2__average_precision_micro_masked:
  - 0.17805589151722184
  - 0.18387115670088153
  - 0.19149970927463109
  - 0.17647266926778726
  - 0.18146698181655646
  train_level2__average_precision_micro_oob:
  - 0.3183938261545587
  - 0.3269699566576254
  - 0.33646351723816
  - 0.3163592161997849
  - 0.325171191312824
  train_level2__average_precision_samples:
  - 0.32236911031046017
  - 0.3304541915067845
  - 0.3424203095737278
  - 0.3217264196162822
  - 0.326943876548066
  train_level2__average_precision_samples_masked:
  - 0.19590370156303732
  - 0.20195114060439298
  - 0.2111837015003465
  - 0.19585138362250348
  - 0.19825826748453845
  train_level2__average_precision_samples_oob:
  - 0.32347403604984565
  - 0.3299875092493785
  - 0.3429032330025184
  - 0.3229986266570103
  - 0.32723292108479135
  train_level2__average_precision_weighted:
  - 0.5424649860594881
  - 0.5465674959296497
  - 0.5506481115080476
  - 0.5457805834540028
  - 0.532011541170681
  train_level2__average_precision_weighted_masked:
  - 0.3880214280537752
  - 0.3891964204401927
  - 0.39595718508831096
  - 0.39087901890210963
  - 0.3728726180566575
  train_level2__average_precision_weighted_oob:
  - 0.5381987604272129
  - 0.5421970727911742
  - 0.5452810941526314
  - 0.541473319233836
  - 0.5274237323820012
  train_level2__f1_macro:
  - 0.48397326438015315
  - 0.4782959575456703
  - 0.4770258579255982
  - 0.46182038834951467
  - 0.487691979015833
  train_level2__f1_macro_masked:
  - 0.4320711576616983
  - 0.4259900359107288
  - 0.4238981659176543
  - 0.40770092448720385
  - 0.43655127378464437
  train_level2__f1_macro_oob:
  - 0.4816314582621848
  - 0.474798855493874
  - 0.4731808132269537
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__f1_micro:
  - 0.4839732643801532
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.48769197901583305
  train_level2__f1_micro_masked:
  - 0.42325452785842665
  - 0.4162692691582566
  - 0.41476700166135577
  - 0.39751484495271605
  - 0.4281025530655619
  train_level2__f1_micro_oob:
  - 0.48163145826218473
  - 0.47479885549387396
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__f1_samples:
  - 0.48397326438015315
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.487691979015833
  train_level2__f1_samples_masked:
  - 0.4243314648794432
  - 0.41759729219060965
  - 0.41593145012457744
  - 0.3987724929971441
  - 0.4296915469713041
  train_level2__f1_samples_oob:
  - 0.4816314582621847
  - 0.4747988554938739
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__f1_weighted:
  - 0.5667137853906855
  - 0.5673019570940822
  - 0.5628068325879718
  - 0.5560283077885517
  - 0.5679486944280957
  train_level2__f1_weighted_masked:
  - 0.4985747122619953
  - 0.4989528851274594
  - 0.49347355655806174
  - 0.48568478287547956
  - 0.5005724780205996
  train_level2__f1_weighted_oob:
  - 0.5635849138501332
  - 0.5638205386108912
  - 0.5583394924357411
  - 0.5509574079866542
  - 0.563146234664284
  train_level2__fn_macro:
  - -0.02034444064985119
  - -0.019637573060086566
  - -0.01922522349322311
  - -0.016966019417475726
  - -0.021791250267049637
  train_level2__fn_macro_masked:
  - -0.016119689837793598
  - -0.015524738212135476
  - -0.015527805540504761
  - -0.013050176198397016
  - -0.017317619087042407
  train_level2__fn_macro_oob:
  - -0.02088110455188564
  - -0.020053312464845558
  - -0.020018263962318563
  - -0.017815533980582523
  - -0.02274076008260735
  train_level2__fn_micro:
  - -0.0203444406498512
  - -0.019637573060086573
  - -0.019225223493223108
  - -0.016966019417475726
  - -0.021791250267049634
  train_level2__fn_micro_masked:
  - -0.014876261578874603
  - -0.01452811356326938
  - -0.014325789143993246
  - -0.012150868704640423
  - -0.01598019961798176
  train_level2__fn_micro_oob:
  - -0.020881104551885642
  - -0.020053312464845565
  - -0.020018263962318563
  - -0.017815533980582523
  - -0.022740760082607354
  train_level2__fn_samples:
  - -0.020344440649851196
  - -0.019637573060086573
  - -0.019225223493223108
  - -0.016966019417475726
  - -0.021791250267049637
  train_level2__fn_samples_masked:
  - -0.014756572454598946
  - -0.01447668997148281
  - -0.014267659998862618
  - -0.012087395242770917
  - -0.015907907443633292
  train_level2__fn_samples_oob:
  - -0.020881104551885642
  - -0.02005331246484556
  - -0.02001826396231856
  - -0.017815533980582523
  - -0.022740760082607354
  train_level2__fn_weighted:
  - -0.030359937893233463
  - -0.028010107056176868
  - -0.028561799603309755
  - -0.024393441768324472
  - -0.03213168126006866
  train_level2__fn_weighted_masked:
  - -0.02551871700757638
  - -0.02305074744822017
  - -0.024693928268860705
  - -0.01991938716604143
  - -0.027450633400750026
  train_level2__fn_weighted_oob:
  - -0.031110124459324404
  - -0.028179625134125273
  - -0.029573095414069592
  - -0.025430351371077048
  - -0.03311865107679127
  train_level2__fp_macro:
  - -0.4956822949699956
  - -0.5020664693942432
  - -0.5037489185811784
  - -0.5212135922330097
  - -0.4905167707171174
  train_level2__fp_macro_masked:
  - -0.551809152500508
  - -0.5584852258771357
  - -0.560574028541841
  - -0.579248899314399
  - -0.546131107128313
  train_level2__fp_macro_oob:
  - -0.4974874371859297
  - -0.5051478320412804
  - -0.5068009228107277
  - -0.5249029126213592
  - -0.4936976285992357
  train_level2__fp_micro:
  - -0.4956822949699956
  - -0.5020664693942433
  - -0.5037489185811785
  - -0.5212135922330097
  - -0.4905167707171173
  train_level2__fp_micro_masked:
  - -0.5618692105626988
  - -0.569202617278474
  - -0.570907209194651
  - -0.5903342863426435
  - -0.5559172473164564
  train_level2__fp_micro_oob:
  - -0.49748743718592964
  - -0.5051478320412804
  - -0.5068009228107276
  - -0.5249029126213592
  - -0.49369762859923566
  train_level2__fp_samples:
  - -0.49568229496999555
  - -0.5020664693942433
  - -0.5037489185811785
  - -0.5212135922330097
  - -0.4905167707171173
  train_level2__fp_samples_masked:
  - -0.5609119626659579
  - -0.5679260178379074
  - -0.5698008898765599
  - -0.589140111760085
  - -0.5544005455850626
  train_level2__fp_samples_oob:
  - -0.49748743718592964
  - -0.5051478320412804
  - -0.5068009228107277
  - -0.5249029126213592
  - -0.49369762859923566
  train_level2__fp_weighted:
  - -0.4029262767160812
  - -0.40468793584974083
  - -0.40863136780871834
  - -0.4195782504431238
  - -0.3999196243118358
  train_level2__fp_weighted_masked:
  - -0.4759065707304283
  - -0.4779963674243205
  - -0.4818325151730775
  - -0.4943958299584791
  - -0.4719768885786504
  train_level2__fp_weighted_oob:
  - -0.4053049616905424
  - -0.4079998362549836
  - -0.41208741215018924
  - -0.4236122406422688
  - -0.40373511425892467
  train_level2__jaccard_macro:
  - 0.34103601580803516
  - 0.33777437774358415
  - 0.3353181623834283
  - 0.3234712120135205
  - 0.3435307725578167
  train_level2__jaccard_macro_masked:
  - 0.2955491933447598
  - 0.2922718032563582
  - 0.2888109052350146
  - 0.2768451367480332
  - 0.2984955971146135
  train_level2__jaccard_macro_oob:
  - 0.3391096912967497
  - 0.3350419559793346
  - 0.3319637911669613
  - 0.31962862509169304
  - 0.3398144253444377
  train_level2__jaccard_micro:
  - 0.31923794812383344
  - 0.3143160195422988
  - 0.3132199324644176
  - 0.300238271819229
  - 0.3224819099342322
  train_level2__jaccard_micro_masked:
  - 0.2684355435526016
  - 0.26284093694198385
  - 0.2616441886435873
  - 0.24806148356549784
  - 0.272347635591915
  train_level2__jaccard_micro_oob:
  - 0.31720326457168563
  - 0.31130245161704106
  - 0.30991280259388676
  - 0.29641283826305853
  - 0.3188798271840709
  train_level2__jaccard_samples:
  - 0.3257433490489353
  - 0.32035183814263335
  - 0.31912160006055573
  - 0.3064531315794842
  - 0.3284372579679928
  train_level2__jaccard_samples_masked:
  - 0.27552433265311455
  - 0.2693946016495226
  - 0.2682075186816843
  - 0.2548926838189454
  - 0.2788987235022482
  train_level2__jaccard_samples_oob:
  - 0.3235110186030395
  - 0.3171878063654491
  - 0.3157657190031995
  - 0.3024299805984095
  - 0.32490511744738093
  train_level2__jaccard_weighted:
  - 0.41539984760505305
  - 0.4170413201720313
  - 0.41131947827827325
  - 0.4062645813847831
  - 0.4142937740841177
  train_level2__jaccard_weighted_masked:
  - 0.3502253673272542
  - 0.3518843861967649
  - 0.34489942946295243
  - 0.33946109556744364
  - 0.34970842470235963
  train_level2__jaccard_weighted_oob:
  - 0.41247424043077036
  - 0.4138503860025414
  - 0.40688341149022705
  - 0.40146367830778606
  - 0.4095618330026642
  train_level2__label_ranking_average_precision_score:
  - 0.32236911031046
  - 0.33045419150678473
  - 0.3424203095737278
  - 0.32172641961628223
  - 0.32694387654806584
  train_level2__label_ranking_average_precision_score_oob:
  - 0.3234740360498456
  - 0.32998750924937875
  - 0.34290323300251835
  - 0.32299862665701057
  - 0.3272329210847914
  train_level2__matthews_corrcoef_macro:
  - 0.23772178084956266
  - 0.2347069268178754
  - 0.23519718131599862
  - 0.23157090131834185
  - 0.2398603377082807
  train_level2__matthews_corrcoef_macro_masked:
  - 0.17534211705389016
  - 0.1709717564801336
  - 0.17314115947788164
  - 0.17343168809367598
  - 0.17507634993505206
  train_level2__matthews_corrcoef_macro_oob:
  - 0.2322433656995406
  - 0.2277015564521193
  - 0.22669729013025872
  - 0.2227842943125712
  - 0.23135595032312292
  train_level2__matthews_corrcoef_micro:
  - 0.24804518186124253
  - 0.24493446484333645
  - 0.24496746010741258
  - 0.23783336047562778
  - 0.2468913533551273
  train_level2__matthews_corrcoef_micro_masked:
  - 0.17413163031502804
  - 0.1712023072508188
  - 0.17080512649416232
  - 0.16936340730359067
  - 0.1719192880298287
  train_level2__matthews_corrcoef_micro_oob:
  - 0.24402397856606037
  - 0.2401690653881232
  - 0.23861193712174775
  - 0.23052092954011477
  - 0.2398084698896177
  train_level2__matthews_corrcoef_samples:
  - 0.24591267780404372
  - 0.24224732882548047
  - 0.24442985959839092
  - 0.23596031449974372
  - 0.24579877155287008
  train_level2__matthews_corrcoef_samples_masked:
  - 0.17272326568275742
  - 0.16879231323615748
  - 0.17037524162612747
  - 0.1673097706999112
  - 0.170200146520175
  train_level2__matthews_corrcoef_samples_oob:
  - 0.24194176621584765
  - 0.23785166786455816
  - 0.23797691835726437
  - 0.22857955362610036
  - 0.23864927219407345
  train_level2__matthews_corrcoef_weighted:
  - 0.26999381579282067
  - 0.26936393632845584
  - 0.2676196822261429
  - 0.27133713985073354
  - 0.2725765902133056
  train_level2__matthews_corrcoef_weighted_masked:
  - 0.20248610800393024
  - 0.2035759974716705
  - 0.2002432845921334
  - 0.20980578743413159
  - 0.20387085584738254
  train_level2__matthews_corrcoef_weighted_oob:
  - 0.26120440079755514
  - 0.2621220891429061
  - 0.25692138561008804
  - 0.2610385977015905
  - 0.26306045787486715
  train_level2__ndcg:
  - 0.6594722289426079
  - 0.6650709248513533
  - 0.6697767107778568
  - 0.6540169217532881
  - 0.6623166819954391
  train_level2__ndcg_oob:
  - 0.6623939185460492
  - 0.6656527413867113
  - 0.6719472327095665
  - 0.6573757879640398
  - 0.6635758273359736
  train_level2__neg_coverage_error:
  - -81.89447236180905
  - -81.56423173803526
  - -81.36386138613861
  - -83.0225
  - -82.13691931540342
  train_level2__neg_coverage_error_oob:
  - -82.821608040201
  - -82.6574307304786
  - -82.3069306930693
  - -83.8675
  - -82.95843520782397
  train_level2__neg_hamming_loss_macro:
  - -0.5160267356198468
  - -0.5217040424543298
  - -0.5229741420744017
  - -0.5381796116504853
  - -0.5123080209841671
  train_level2__neg_hamming_loss_macro_masked:
  - -0.5679288423383017
  - -0.5740099640892712
  - -0.5761018340823457
  - -0.5922990755127961
  - -0.5634487262153555
  train_level2__neg_hamming_loss_macro_oob:
  - -0.5183685417378152
  - -0.525201144506126
  - -0.5268191867730463
  - -0.5427184466019417
  - -0.5164383886818429
  train_level2__neg_hamming_loss_micro:
  - -0.5160267356198468
  - -0.5217040424543298
  - -0.5229741420744016
  - -0.5381796116504854
  - -0.512308020984167
  train_level2__neg_hamming_loss_micro_masked:
  - -0.5767454721415733
  - -0.5837307308417434
  - -0.5852329983386442
  - -0.602485155047284
  - -0.5718974469344381
  train_level2__neg_hamming_loss_micro_oob:
  - -0.5183685417378153
  - -0.5252011445061261
  - -0.5268191867730463
  - -0.5427184466019418
  - -0.516438388681843
  train_level2__neg_hamming_loss_samples:
  - -0.5160267356198469
  - -0.5217040424543298
  - -0.5229741420744016
  - -0.5381796116504854
  - -0.512308020984167
  train_level2__neg_hamming_loss_samples_masked:
  - -0.5756685351205568
  - -0.5824027078093903
  - -0.5840685498754226
  - -0.6012275070028559
  - -0.5703084530286959
  train_level2__neg_hamming_loss_samples_oob:
  - -0.5183685417378152
  - -0.525201144506126
  - -0.5268191867730462
  - -0.5427184466019418
  - -0.516438388681843
  train_level2__neg_hamming_loss_weighted:
  - -0.4332862146093146
  - -0.43269804290591785
  - -0.4371931674120283
  - -0.4439716922114483
  - -0.43205130557190435
  train_level2__neg_hamming_loss_weighted_masked:
  - -0.5014252877380047
  - -0.5010471148725405
  - -0.5065264434419382
  - -0.5143152171245204
  - -0.4994275219794005
  train_level2__neg_hamming_loss_weighted_oob:
  - -0.43641508614986685
  - -0.4361794613891089
  - -0.44166050756425895
  - -0.44904259201334595
  - -0.43685376533571596
  train_level2__neg_label_ranking_loss:
  - -0.37093121260359924
  - -0.36737284133495246
  - -0.3468072771788058
  - -0.3669572721564569
  - -0.37017668915134566
  train_level2__neg_label_ranking_loss_oob:
  - -0.3747187388054055
  - -0.37118151544828737
  - -0.3508345929037073
  - -0.37011031957914625
  - -0.3742852192077654
  train_level2__precision_macro:
  - 0.48397326438015315
  - 0.4782959575456703
  - 0.4770258579255982
  - 0.46182038834951467
  - 0.487691979015833
  train_level2__precision_macro_masked:
  - 0.4320711576616983
  - 0.4259900359107288
  - 0.4238981659176543
  - 0.40770092448720385
  - 0.43655127378464437
  train_level2__precision_macro_oob:
  - 0.4816314582621848
  - 0.474798855493874
  - 0.4731808132269537
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__precision_micro:
  - 0.4839732643801532
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.48769197901583305
  train_level2__precision_micro_masked:
  - 0.42325452785842665
  - 0.4162692691582566
  - 0.41476700166135577
  - 0.39751484495271605
  - 0.4281025530655619
  train_level2__precision_micro_oob:
  - 0.48163145826218473
  - 0.47479885549387396
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__precision_samples:
  - 0.48397326438015315
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.487691979015833
  train_level2__precision_samples_masked:
  - 0.4243314648794432
  - 0.41759729219060965
  - 0.41593145012457744
  - 0.3987724929971441
  - 0.4296915469713041
  train_level2__precision_samples_oob:
  - 0.4816314582621847
  - 0.4747988554938739
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__precision_weighted:
  - 0.5667137853906855
  - 0.5673019570940822
  - 0.5628068325879718
  - 0.5560283077885517
  - 0.5679486944280957
  train_level2__precision_weighted_masked:
  - 0.4985747122619953
  - 0.4989528851274594
  - 0.49347355655806174
  - 0.48568478287547956
  - 0.5005724780205996
  train_level2__precision_weighted_oob:
  - 0.5635849138501332
  - 0.5638205386108912
  - 0.5583394924357411
  - 0.5509574079866542
  - 0.563146234664284
  train_level2__recall_macro:
  - 0.48397326438015315
  - 0.4782959575456703
  - 0.4770258579255982
  - 0.46182038834951467
  - 0.487691979015833
  train_level2__recall_macro_masked:
  - 0.4320711576616983
  - 0.4259900359107288
  - 0.4238981659176543
  - 0.40770092448720385
  - 0.43655127378464437
  train_level2__recall_macro_oob:
  - 0.4816314582621848
  - 0.474798855493874
  - 0.4731808132269537
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__recall_micro:
  - 0.4839732643801532
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.48769197901583305
  train_level2__recall_micro_masked:
  - 0.42325452785842665
  - 0.4162692691582566
  - 0.41476700166135577
  - 0.39751484495271605
  - 0.4281025530655619
  train_level2__recall_micro_oob:
  - 0.48163145826218473
  - 0.47479885549387396
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__recall_samples:
  - 0.48397326438015315
  - 0.47829595754567017
  - 0.4770258579255984
  - 0.46182038834951455
  - 0.487691979015833
  train_level2__recall_samples_masked:
  - 0.4243314648794432
  - 0.41759729219060965
  - 0.41593145012457744
  - 0.3987724929971441
  - 0.4296915469713041
  train_level2__recall_samples_oob:
  - 0.4816314582621847
  - 0.4747988554938739
  - 0.47318081322695377
  - 0.45728155339805826
  - 0.483561611318157
  train_level2__recall_weighted:
  - 0.5667137853906855
  - 0.5673019570940822
  - 0.5628068325879718
  - 0.5560283077885517
  - 0.5679486944280957
  train_level2__recall_weighted_masked:
  - 0.4985747122619953
  - 0.4989528851274594
  - 0.49347355655806174
  - 0.48568478287547956
  - 0.5005724780205996
  train_level2__recall_weighted_oob:
  - 0.5635849138501332
  - 0.5638205386108912
  - 0.5583394924357411
  - 0.5509574079866542
  - 0.563146234664284
  train_level2__roc_auc_macro:
  - 0.7258333474390753
  - 0.7272553939927714
  - 0.7333724731933247
  - 0.7289127705723529
  - 0.7217205750913523
  train_level2__roc_auc_macro_masked:
  - 0.7084008157454781
  - 0.7052686370832206
  - 0.7133065481524581
  - 0.7066886821779684
  - 0.6956828273528789
  train_level2__roc_auc_macro_oob:
  - 0.7202110691143884
  - 0.7215012760379063
  - 0.728207576663678
  - 0.7234264465988367
  - 0.7164490226256974
  train_level2__roc_auc_micro:
  - 0.6701327513554391
  - 0.6736706899368232
  - 0.6834116575716914
  - 0.6666687579583503
  - 0.6728824601128929
  train_level2__roc_auc_micro_masked:
  - 0.6492878363794766
  - 0.6519213286221041
  - 0.6622510023329325
  - 0.6461648556213158
  - 0.648325453280704
  train_level2__roc_auc_micro_oob:
  - 0.6692342588188451
  - 0.6715248967290244
  - 0.6812785785685718
  - 0.665175419014286
  - 0.6708341249016373
  train_level2__roc_auc_samples:
  - 0.6519038504032088
  - 0.6547884913815555
  - 0.6680892065522686
  - 0.6473716206471353
  - 0.6533015824851877
  train_level2__roc_auc_samples_masked:
  - 0.6323326785620799
  - 0.63580052151439
  - 0.647594639273017
  - 0.6279119181064812
  - 0.6328516264500585
  train_level2__roc_auc_samples_oob:
  - 0.6512343114425234
  - 0.6528934990095412
  - 0.6662573443107956
  - 0.6463134671561463
  - 0.6519463407598394
  train_level2__roc_auc_weighted:
  - 0.7294206599299168
  - 0.729205429139148
  - 0.7350520088758744
  - 0.7338748025482835
  - 0.725737354274776
  train_level2__roc_auc_weighted_masked:
  - 0.705292579802851
  - 0.7033166107627926
  - 0.7093326497887119
  - 0.7108597728320605
  - 0.696948940528733
  train_level2__roc_auc_weighted_oob:
  - 0.7218870277246979
  - 0.7221020967411604
  - 0.7278046595263516
  - 0.7259933924906882
  - 0.7193138316948843
  train_level2__tn_macro:
  - 0.2699175489095965
  - 0.26318749847154627
  - 0.2622080169181967
  - 0.24599514563106797
  - 0.2753815842571272
  train_level2__tn_macro_masked:
  - 0.30452361951791596
  - 0.29761525888004264
  - 0.29597690163174917
  - 0.2784046109362159
  - 0.31079478327295784
  train_level2__tn_macro_oob:
  - 0.2681124066936625
  - 0.2601061358245091
  - 0.2591560126886475
  - 0.2423058252427184
  - 0.27220072637500886
  train_level2__tn_micro:
  - 0.2699175489095965
  - 0.2631874984715463
  - 0.2622080169181967
  - 0.24599514563106797
  - 0.2753815842571273
  train_level2__tn_micro_masked:
  - 0.30595879994469793
  - 0.2983808361982921
  - 0.2971648010458371
  - 0.2786177699582142
  - 0.3120981410239165
  train_level2__tn_micro_oob:
  - 0.2681124066936625
  - 0.2601061358245091
  - 0.2591560126886475
  - 0.24230582524271846
  - 0.2722007263750089
  train_level2__tn_samples:
  - 0.26991754890959646
  - 0.2631874984715462
  - 0.2622080169181966
  - 0.24599514563106792
  - 0.2753815842571272
  train_level2__tn_samples_masked:
  - 0.30672597446557154
  - 0.2993474510308611
  - 0.29788097567311755
  - 0.27954063812636515
  - 0.3133524284928709
  train_level2__tn_samples_oob:
  - 0.26811240669366243
  - 0.260106135824509
  - 0.25915601268864746
  - 0.24230582524271838
  - 0.27220072637500886
  train_level2__tn_weighted:
  - 0.24890635924967747
  - 0.24720616625944716
  - 0.24364273885033028
  - 0.23479642373058074
  - 0.2554808930477757
  train_level2__tn_weighted_masked:
  - 0.2934758470650575
  - 0.2915045935719892
  - 0.28727319997981365
  - 0.2769500193381284
  - 0.301004360055516
  train_level2__tn_weighted_oob:
  - 0.24652767427521613
  - 0.24389426585420448
  - 0.24018669450885946
  - 0.23076243353143575
  - 0.2516654031006868
  train_level2__tp_macro:
  - 0.21405571547055663
  - 0.21510845907412385
  - 0.2148178410074017
  - 0.21582524271844658
  - 0.2123103947587059
  train_level2__tp_macro_masked:
  - 0.12754753814378242
  - 0.12837477703068617
  - 0.1279212642859051
  - 0.1292963135509881
  - 0.12575649051168675
  train_level2__tp_macro_oob:
  - 0.21351905156852222
  - 0.21469271966936487
  - 0.21402480053830628
  - 0.21497572815533975
  - 0.21136088494314817
  train_level2__tp_micro:
  - 0.21405571547055666
  - 0.2151084590741239
  - 0.2148178410074017
  - 0.2158252427184466
  - 0.2123103947587058
  train_level2__tp_micro_masked:
  - 0.11729572791372875
  - 0.11788843295996451
  - 0.1176022006155187
  - 0.11889707499450188
  - 0.11600441204164537
  train_level2__tp_micro_oob:
  - 0.21351905156852222
  - 0.2146927196693649
  - 0.21402480053830625
  - 0.2149757281553398
  - 0.2113608849431481
  train_level2__tp_samples:
  - 0.2140557154705566
  - 0.21510845907412385
  - 0.21481784100740164
  - 0.21582524271844655
  - 0.21231039475870575
  train_level2__tp_samples_masked:
  - 0.11760549041387172
  - 0.11824984115974868
  - 0.11805047445145993
  - 0.11923185487077902
  - 0.11633911847843321
  train_level2__tp_samples_oob:
  - 0.21351905156852216
  - 0.21469271966936485
  - 0.2140248005383062
  - 0.21497572815533975
  - 0.21136088494314803
  train_level2__tp_weighted:
  - 0.3178074261410078
  - 0.3200957908346351
  - 0.3191640937376415
  - 0.321231884057971
  - 0.3124678013803199
  train_level2__tp_weighted_masked:
  - 0.2050988651969377
  - 0.20744829155547015
  - 0.20620035657824806
  - 0.20873476353735118
  - 0.1995681179650836
  train_level2__tp_weighted_oob:
  - 0.31705723957491694
  - 0.31992627275668667
  - 0.31815279792688167
  - 0.3201949744552184
  - 0.31148083156359724
  train_level3__average_precision_macro:
  - 0.39405394565756663
  - 0.40332273647187783
  - 0.40460261846247214
  - 0.3955504155802452
  - 0.3956083645561202
  train_level3__average_precision_macro_masked:
  - 0.26240945598993903
  - 0.2690626389081712
  - 0.26895378744568044
  - 0.2636704749124094
  - 0.25997262771318413
  train_level3__average_precision_macro_oob:
  - 0.3901294411188784
  - 0.39807478338122426
  - 0.3975656184561134
  - 0.39335429720687376
  - 0.39057582520090667
  train_level3__average_precision_micro:
  - 0.31974710739280077
  - 0.32623150198713907
  - 0.3378080747822102
  - 0.31286728304839945
  - 0.3249345007676385
  train_level3__average_precision_micro_masked:
  - 0.18036516130474706
  - 0.18429952978519037
  - 0.1920121056716504
  - 0.17575599338228048
  - 0.18279059045820745
  train_level3__average_precision_micro_oob:
  - 0.32095776399090603
  - 0.3265904051024312
  - 0.3372202290592521
  - 0.315150773071574
  - 0.3250745662741662
  train_level3__average_precision_samples:
  - 0.32530343025875536
  - 0.3305329388978555
  - 0.3450427019923004
  - 0.32142007318263544
  - 0.329315766290532
  train_level3__average_precision_samples_masked:
  - 0.1961859146227395
  - 0.20242541366468275
  - 0.2107931658615457
  - 0.19484160602368977
  - 0.1998612591035434
  train_level3__average_precision_samples_oob:
  - 0.32654870187819185
  - 0.33109043998568743
  - 0.3450680328249221
  - 0.3228597958558039
  - 0.3294937434589292
  train_level3__average_precision_weighted:
  - 0.5300800199340808
  - 0.5392034487983288
  - 0.5394967185969651
  - 0.5330410741342375
  - 0.527381898050991
  train_level3__average_precision_weighted_masked:
  - 0.37658842552588195
  - 0.383339188448944
  - 0.3832755241353108
  - 0.37896787167811935
  - 0.3706200542749211
  train_level3__average_precision_weighted_oob:
  - 0.524838942752202
  - 0.5334429495369907
  - 0.5314219942036754
  - 0.5297561614846493
  - 0.5219767686203717
  train_level3__f1_macro:
  - 0.4870224910962579
  - 0.4791763468733952
  - 0.47986157839084875
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__f1_macro_masked:
  - 0.43543459609935686
  - 0.42732354667395006
  - 0.42730931919674503
  - 0.4105084724706239
  - 0.4378899559786981
  train_level3__f1_macro_oob:
  - 0.48558325608625647
  - 0.4772688366633246
  - 0.47738633086609633
  - 0.4617961165048544
  - 0.48724096185344307
  train_level3__f1_micro:
  - 0.487022491096258
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.46427184466019417
  - 0.48878391530372445
  train_level3__f1_micro_masked:
  - 0.4266832572929628
  - 0.41754463790617724
  - 0.41819865457417543
  - 0.40048383549593136
  - 0.42944768771354014
  train_level3__f1_micro_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.47738633086609633
  - 0.46179611650485436
  - 0.4872409618534432
  train_level3__f1_samples:
  - 0.4870224910962579
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__f1_samples_masked:
  - 0.42769756538207165
  - 0.41883801326962783
  - 0.4193184274095151
  - 0.401683492872465
  - 0.4310384499700989
  train_level3__f1_samples_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.4773863308660962
  - 0.46179611650485436
  - 0.4872409618534431
  train_level3__f1_weighted:
  - 0.5688874699232452
  - 0.5681875972072027
  - 0.5651654214605154
  - 0.5573063288499636
  - 0.5689245078414641
  train_level3__f1_weighted_masked:
  - 0.5014455695427046
  - 0.5007409323774648
  - 0.4967262286720816
  - 0.48726144035946445
  - 0.5018587664734977
  train_level3__f1_weighted_oob:
  - 0.5665027709052077
  - 0.5658880818557138
  - 0.5620733317812735
  - 0.5547922531539988
  - 0.5664832388675209
  train_level3__fn_macro:
  - -0.020539591159681903
  - -0.020004401946638616
  - -0.019705854080553687
  - -0.017694174757281553
  - -0.02217105419327272
  train_level3__fn_macro_masked:
  - -0.0163999467722329
  - -0.015720527818060288
  - -0.01588326895117985
  - -0.013846511562761335
  - -0.017662609323735395
  train_level3__fn_macro_oob:
  - -0.021320193199004727
  - -0.020591328165121905
  - -0.020474863020282612
  - -0.018082524271844657
  - -0.02304935077266361
  train_level3__fn_micro:
  - -0.020539591159681906
  - -0.020004401946638623
  - -0.019705854080553687
  - -0.017694174757281553
  - -0.022171054193272723
  train_level3__fn_micro_masked:
  - -0.015125120973316742
  - -0.014666740601086836
  - -0.014652613230928454
  - -0.01278315372773257
  - -0.016303031933496543
  train_level3__fn_micro_oob:
  - -0.021320193199004734
  - -0.020591328165121908
  - -0.020474863020282612
  - -0.01808252427184466
  - -0.023049350772663613
  train_level3__fn_samples:
  - -0.020539591159681903
  - -0.020004401946638623
  - -0.019705854080553687
  - -0.01769417475728155
  - -0.02217105419327272
  train_level3__fn_samples_masked:
  - -0.015001027401159009
  - -0.014615197998234039
  - -0.014596782359806796
  - -0.012728225882341723
  - -0.016227456598905794
  train_level3__fn_samples_oob:
  - -0.02132019319900473
  - -0.020591328165121908
  - -0.020474863020282612
  - -0.018082524271844657
  - -0.023049350772663606
  train_level3__fn_weighted:
  - -0.03097859994111466
  - -0.028935371363988112
  - -0.029402809364004478
  - -0.026154728391200078
  - -0.03261215036451688
  train_level3__fn_weighted_masked:
  - -0.026037224606262715
  - -0.023672998512514743
  - -0.02526646326323687
  - -0.021967873445223423
  - -0.02795810142614219
  train_level3__fn_weighted_oob:
  - -0.032118914899191546
  - -0.029710011249597525
  - -0.03047764474568414
  - -0.02611979981232405
  - -0.03398736301796081
  train_level3__fp_macro:
  - -0.4924379177440602
  - -0.5008192511799662
  - -0.5004325675285977
  - -0.5180339805825243
  - -0.48904503050300285
  train_level3__fp_macro_masked:
  - -0.5481654571284102
  - -0.5569559255079897
  - -0.5568074118520752
  - -0.5756450159666147
  - -0.5444474346975666
  train_level3__fp_macro_oob:
  - -0.4930965507147388
  - -0.5021398351715536
  - -0.5021388061136212
  - -0.5201213592233009
  - -0.48970968737389337
  train_level3__fp_micro:
  - -0.4924379177440601
  - -0.5008192511799663
  - -0.5004325675285975
  - -0.5180339805825243
  - -0.4890450305030028
  train_level3__fp_micro_masked:
  - -0.5581916217337205
  - -0.5677886214927359
  - -0.5671487321948961
  - -0.586733010776336
  - -0.5542492803529633
  train_level3__fp_micro_oob:
  - -0.49309655071473873
  - -0.5021398351715537
  - -0.502138806113621
  - -0.5201213592233009
  - -0.48970968737389325
  train_level3__fp_samples:
  - -0.4924379177440601
  - -0.5008192511799662
  - -0.5004325675285974
  - -0.5180339805825243
  - -0.48904503050300285
  train_level3__fp_samples_masked:
  - -0.5573014072167692
  - -0.566546788732138
  - -0.5660847902306781
  - -0.5855882812451934
  - -0.5527340934309953
  train_level3__fp_samples_oob:
  - -0.4930965507147387
  - -0.5021398351715536
  - -0.5021388061136212
  - -0.5201213592233009
  - -0.4897096873738932
  train_level3__fp_weighted:
  - -0.4001339301356402
  - -0.40287703142880915
  - -0.40543176917548
  - -0.41653894275883646
  - -0.39846334179401904
  train_level3__fp_weighted_masked:
  - -0.4725172058510326
  - -0.47558606911002044
  - -0.47800730806468156
  - -0.4907706861953122
  - -0.47018313210036006
  train_level3__fp_weighted_oob:
  - -0.40137831419560077
  - -0.4044019068946887
  - -0.40744902347304246
  - -0.41908794703367747
  - -0.3995293981145182
  train_level3__jaccard_macro:
  - 0.34328055976875016
  - 0.3382987547528513
  - 0.3375270461300861
  - 0.32522549372706605
  - 0.3442950493574509
  train_level3__jaccard_macro_masked:
  - 0.29790862402721263
  - 0.29315403906876464
  - 0.29136289085577133
  - 0.2787668215356403
  - 0.29935668749697025
  train_level3__jaccard_macro_oob:
  - 0.3421629492598649
  - 0.3369708266119972
  - 0.33539155314569935
  - 0.3232304294883988
  - 0.34287618509289264
  train_level3__jaccard_micro:
  - 0.3218967157344856
  - 0.31507686370360843
  - 0.31566965979511824
  - 0.302313819699077
  - 0.3234374754567017
  train_level3__jaccard_micro_masked:
  - 0.2711998453399884
  - 0.26385871469619454
  - 0.2643812737822621
  - 0.2503781108208442
  - 0.2734373661761935
  train_level3__jaccard_micro_oob:
  - 0.320640443284688
  - 0.313429479973019
  - 0.3135308322416705
  - 0.3002177549152649
  - 0.3220876223951795
  train_level3__jaccard_samples:
  - 0.3281828521517251
  - 0.3210547874383277
  - 0.32149362173289986
  - 0.30830876444923455
  - 0.3293576781663198
  train_level3__jaccard_samples_masked:
  - 0.2780148889673903
  - 0.2703072675928717
  - 0.270833407353311
  - 0.2569242612444062
  - 0.2799289446050887
  train_level3__jaccard_samples_oob:
  - 0.326700746792669
  - 0.3192918030044102
  - 0.31919766200516964
  - 0.3061403383957287
  - 0.3279623604191323
  train_level3__jaccard_weighted:
  - 0.4171190164671291
  - 0.4176930213485505
  - 0.41331914394793123
  - 0.40684651460665006
  - 0.41515709334464374
  train_level3__jaccard_weighted_masked:
  - 0.35246219316825994
  - 0.35327096814976683
  - 0.3475669052160744
  - 0.34026343599561676
  - 0.35068322487560744
  train_level3__jaccard_weighted_oob:
  - 0.414960803847263
  - 0.4156560330129914
  - 0.41029479749905706
  - 0.404692094251219
  - 0.41272625135448954
  train_level3__label_ranking_average_precision_score:
  - 0.32530343025875536
  - 0.33053293889785573
  - 0.34504270199230047
  - 0.3214200731826353
  - 0.32931576629053183
  train_level3__label_ranking_average_precision_score_oob:
  - 0.32654870187819196
  - 0.33109043998568743
  - 0.34506803282492227
  - 0.32285979585580354
  - 0.3294937434589291
  train_level3__matthews_corrcoef_macro:
  - 0.24042666896641635
  - 0.2374019788477061
  - 0.23621093213936936
  - 0.23304255915595082
  - 0.23912755359461643
  train_level3__matthews_corrcoef_macro_masked:
  - 0.17650779365347619
  - 0.17383788037904424
  - 0.17333714099137054
  - 0.17342089173774927
  - 0.17387032240801664
  train_level3__matthews_corrcoef_macro_oob:
  - 0.23514529501725348
  - 0.23202389677189672
  - 0.23071069441798014
  - 0.22682806943421555
  - 0.23481585061409926
  train_level3__matthews_corrcoef_micro:
  - 0.25035531155652535
  - 0.24457692137915804
  - 0.24611125930943212
  - 0.23768515686616343
  - 0.24672735929595413
  train_level3__matthews_corrcoef_micro_masked:
  - 0.17528135567158493
  - 0.17139794712132866
  - 0.17155049646629314
  - 0.16814435251733592
  - 0.17127706505899917
  train_level3__matthews_corrcoef_micro_oob:
  - 0.24642782508155708
  - 0.2407942582003811
  - 0.24118008838147503
  - 0.23396766650879483
  - 0.242405194944433
  train_level3__matthews_corrcoef_samples:
  - 0.24824190889774742
  - 0.2418074502067472
  - 0.2454935537486885
  - 0.23540050686291722
  - 0.24559403875817581
  train_level3__matthews_corrcoef_samples_masked:
  - 0.1738863336658781
  - 0.16886692647819557
  - 0.17099177411534133
  - 0.16563926892982117
  - 0.16968971936858238
  train_level3__matthews_corrcoef_samples_oob:
  - 0.24441313399820014
  - 0.23810940985346968
  - 0.24049780953407204
  - 0.23191176237181638
  - 0.24097390331394297
  train_level3__matthews_corrcoef_weighted:
  - 0.2723372465464141
  - 0.273783023720833
  - 0.2686403418913137
  - 0.2715760907282661
  - 0.2722101063844762
  train_level3__matthews_corrcoef_weighted_masked:
  - 0.20403524774586998
  - 0.20809147345666287
  - 0.20087437945103423
  - 0.207936733552616
  - 0.20318826496582712
  train_level3__matthews_corrcoef_weighted_oob:
  - 0.2645828739380065
  - 0.26599608686864096
  - 0.26154407060658497
  - 0.2644699150894872
  - 0.26613159008959186
  train_level3__ndcg:
  - 0.6686061104370548
  - 0.6699266693916182
  - 0.6819546312594413
  - 0.6615437360148064
  - 0.6702461362472072
  train_level3__ndcg_oob:
  - 0.6713032261753321
  - 0.6717051203517622
  - 0.6835049639887498
  - 0.6650275763910836
  - 0.6715390521717152
  train_level3__neg_coverage_error:
  - -81.85678391959799
  - -81.5969773299748
  - -81.4480198019802
  - -83.0275
  - -81.94132029339853
  train_level3__neg_coverage_error_oob:
  - -82.86180904522612
  - -82.544080604534
  - -82.43564356435644
  - -83.8575
  - -82.88264058679707
  train_level3__neg_hamming_loss_macro:
  - -0.5129775089037422
  - -0.5208236531266048
  - -0.5201384216091512
  - -0.5357281553398059
  - -0.5112160846962756
  train_level3__neg_hamming_loss_macro_masked:
  - -0.5645654039006431
  - -0.57267645332605
  - -0.5726906808032549
  - -0.5894915275293762
  - -0.5621100440213019
  train_level3__neg_hamming_loss_macro_oob:
  - -0.5144167439137435
  - -0.5227311633366755
  - -0.5226136691339037
  - -0.5382038834951456
  - -0.512759038146557
  train_level3__neg_hamming_loss_micro:
  - -0.512977508903742
  - -0.5208236531266048
  - -0.5201384216091512
  - -0.5357281553398058
  - -0.5112160846962756
  train_level3__neg_hamming_loss_micro_masked:
  - -0.5733167427070371
  - -0.5824553620938228
  - -0.5818013454258245
  - -0.5995161645040686
  - -0.5705523122864599
  train_level3__neg_hamming_loss_micro_oob:
  - -0.5144167439137435
  - -0.5227311633366756
  - -0.5226136691339037
  - -0.5382038834951456
  - -0.5127590381465569
  train_level3__neg_hamming_loss_samples:
  - -0.512977508903742
  - -0.520823653126605
  - -0.5201384216091511
  - -0.5357281553398058
  - -0.5112160846962754
  train_level3__neg_hamming_loss_samples_masked:
  - -0.5723024346179283
  - -0.5811619867303721
  - -0.580681572590485
  - -0.598316507127535
  - -0.5689615500299011
  train_level3__neg_hamming_loss_samples_oob:
  - -0.5144167439137435
  - -0.5227311633366756
  - -0.5226136691339036
  - -0.5382038834951456
  - -0.5127590381465568
  train_level3__neg_hamming_loss_weighted:
  - -0.431112530076755
  - -0.4318124027927973
  - -0.43483457853948465
  - -0.4426936711500365
  - -0.43107549215853597
  train_level3__neg_hamming_loss_weighted_masked:
  - -0.4985544304572954
  - -0.49925906762253525
  - -0.5032737713279184
  - -0.5127385596405357
  - -0.4981412335265022
  train_level3__neg_hamming_loss_weighted_oob:
  - -0.4334972290947923
  - -0.4341119181442861
  - -0.4379266682187266
  - -0.4452077468460013
  - -0.433516761132479
  train_level3__neg_label_ranking_loss:
  - -0.38209338082404026
  - -0.3741473088376994
  - -0.35802747103699184
  - -0.37508889061512724
  - -0.3754690599076502
  train_level3__neg_label_ranking_loss_oob:
  - -0.38667937784608974
  - -0.37849368871156075
  - -0.3629422032436577
  - -0.37928100839383233
  - -0.3806281740415447
  train_level3__precision_macro:
  - 0.4870224910962579
  - 0.4791763468733952
  - 0.47986157839084875
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__precision_macro_masked:
  - 0.43543459609935686
  - 0.42732354667395006
  - 0.42730931919674503
  - 0.4105084724706239
  - 0.4378899559786981
  train_level3__precision_macro_oob:
  - 0.48558325608625647
  - 0.4772688366633246
  - 0.47738633086609633
  - 0.4617961165048544
  - 0.48724096185344307
  train_level3__precision_micro:
  - 0.487022491096258
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.46427184466019417
  - 0.48878391530372445
  train_level3__precision_micro_masked:
  - 0.4266832572929628
  - 0.41754463790617724
  - 0.41819865457417543
  - 0.40048383549593136
  - 0.42944768771354014
  train_level3__precision_micro_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.47738633086609633
  - 0.46179611650485436
  - 0.4872409618534432
  train_level3__precision_samples:
  - 0.4870224910962579
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__precision_samples_masked:
  - 0.42769756538207165
  - 0.41883801326962783
  - 0.4193184274095151
  - 0.401683492872465
  - 0.4310384499700989
  train_level3__precision_samples_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.4773863308660962
  - 0.46179611650485436
  - 0.4872409618534431
  train_level3__precision_weighted:
  - 0.5688874699232452
  - 0.5681875972072027
  - 0.5651654214605154
  - 0.5573063288499636
  - 0.5689245078414641
  train_level3__precision_weighted_masked:
  - 0.5014455695427046
  - 0.5007409323774648
  - 0.4967262286720816
  - 0.48726144035946445
  - 0.5018587664734977
  train_level3__precision_weighted_oob:
  - 0.5665027709052077
  - 0.5658880818557138
  - 0.5620733317812735
  - 0.5547922531539988
  - 0.5664832388675209
  train_level3__recall_macro:
  - 0.4870224910962579
  - 0.4791763468733952
  - 0.47986157839084875
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__recall_macro_masked:
  - 0.43543459609935686
  - 0.42732354667395006
  - 0.42730931919674503
  - 0.4105084724706239
  - 0.4378899559786981
  train_level3__recall_macro_oob:
  - 0.48558325608625647
  - 0.4772688366633246
  - 0.47738633086609633
  - 0.4617961165048544
  - 0.48724096185344307
  train_level3__recall_micro:
  - 0.487022491096258
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.46427184466019417
  - 0.48878391530372445
  train_level3__recall_micro_masked:
  - 0.4266832572929628
  - 0.41754463790617724
  - 0.41819865457417543
  - 0.40048383549593136
  - 0.42944768771354014
  train_level3__recall_micro_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.47738633086609633
  - 0.46179611650485436
  - 0.4872409618534432
  train_level3__recall_samples:
  - 0.4870224910962579
  - 0.4791763468733951
  - 0.4798615783908488
  - 0.4642718446601941
  - 0.4887839153037245
  train_level3__recall_samples_masked:
  - 0.42769756538207165
  - 0.41883801326962783
  - 0.4193184274095151
  - 0.401683492872465
  - 0.4310384499700989
  train_level3__recall_samples_oob:
  - 0.4855832560862565
  - 0.4772688366633244
  - 0.4773863308660962
  - 0.46179611650485436
  - 0.4872409618534431
  train_level3__recall_weighted:
  - 0.5688874699232452
  - 0.5681875972072027
  - 0.5651654214605154
  - 0.5573063288499636
  - 0.5689245078414641
  train_level3__recall_weighted_masked:
  - 0.5014455695427046
  - 0.5007409323774648
  - 0.4967262286720816
  - 0.48726144035946445
  - 0.5018587664734977
  train_level3__recall_weighted_oob:
  - 0.5665027709052077
  - 0.5658880818557138
  - 0.5620733317812735
  - 0.5547922531539988
  - 0.5664832388675209
  train_level3__roc_auc_macro:
  - 0.7208838473766893
  - 0.7240358393274641
  - 0.7294893687914314
  - 0.7240265461337418
  - 0.7200990623782025
  train_level3__roc_auc_macro_masked:
  - 0.7039474880728217
  - 0.7032664948411078
  - 0.7105526778148197
  - 0.7015154767732928
  - 0.6950294322009324
  train_level3__roc_auc_macro_oob:
  - 0.7150171170679311
  - 0.7182411582163227
  - 0.723091544710313
  - 0.7181053532624669
  - 0.7145895078126688
  train_level3__roc_auc_micro:
  - 0.6690957840772881
  - 0.6720719385649074
  - 0.6817419688217576
  - 0.662910005857299
  - 0.6721067483166033
  train_level3__roc_auc_micro_masked:
  - 0.6489285916639282
  - 0.6514095608266309
  - 0.6609647248344697
  - 0.6433896849672316
  - 0.649251933561557
  train_level3__roc_auc_micro_oob:
  - 0.6681814565240923
  - 0.6703823431450853
  - 0.6796776196313594
  - 0.6623559850866362
  - 0.6706369108637993
  train_level3__roc_auc_samples:
  - 0.6524952530826075
  - 0.6542062784353102
  - 0.667566130661633
  - 0.6459248707582637
  - 0.6541442356541622
  train_level3__roc_auc_samples_masked:
  - 0.6330414897638644
  - 0.6369863780984553
  - 0.6480349706061318
  - 0.6274246266453364
  - 0.6350051704576634
  train_level3__roc_auc_samples_oob:
  - 0.6520010203828894
  - 0.6530936139426257
  - 0.66626010373031
  - 0.6451120092265872
  - 0.6531803831322689
  train_level3__roc_auc_weighted:
  - 0.7239618496621567
  - 0.7261934746592514
  - 0.7304526428025419
  - 0.729619268750655
  - 0.7239989177393902
  train_level3__roc_auc_weighted_masked:
  - 0.7005482324153558
  - 0.7012911357522553
  - 0.7054842386199315
  - 0.7070938680358199
  - 0.6959419567534538
  train_level3__roc_auc_weighted_oob:
  - 0.716618792115492
  - 0.718908887217482
  - 0.7222980550528997
  - 0.7214960835384521
  - 0.7175423694481913
  train_level3__tn_macro:
  - 0.27316192613553203
  - 0.26443471668582325
  - 0.26552436797077766
  - 0.24917475728155342
  - 0.2768533244712417
  train_level3__tn_macro_masked:
  - 0.30816731489001375
  - 0.2991445592491887
  - 0.299743518321515
  - 0.28200849428400016
  - 0.31247845570370436
  train_level3__tn_macro_oob:
  - 0.2725032931648534
  - 0.2631141326942359
  - 0.26381812938575416
  - 0.24708737864077673
  - 0.2761886676003513
  train_level3__tn_micro:
  - 0.27316192613553203
  - 0.2644347166858233
  - 0.26552436797077766
  - 0.2491747572815534
  - 0.2768533244712417
  train_level3__tn_micro_masked:
  - 0.3096363887736762
  - 0.2997948319840302
  - 0.30092327804559194
  - 0.28221904552452165
  - 0.31376610798740956
  train_level3__tn_micro_oob:
  - 0.2725032931648534
  - 0.2631141326942359
  - 0.2638181293857541
  - 0.2470873786407767
  - 0.2761886676003513
  train_level3__tn_samples:
  - 0.273161926135532
  - 0.26443471668582325
  - 0.2655243679707776
  - 0.24917475728155336
  - 0.27685332447124167
  train_level3__tn_samples_masked:
  - 0.31033652991476
  - 0.3007266801366304
  - 0.3015970753189994
  - 0.2830924686412568
  - 0.3150188806469382
  train_level3__tn_samples_oob:
  - 0.27250329316485333
  - 0.26311413269423584
  - 0.26381812938575405
  - 0.24708737864077662
  - 0.27618866760035127
  train_level3__tn_weighted:
  - 0.2516987058301184
  - 0.24901707068037895
  - 0.24684233748356874
  - 0.23783573141486816
  - 0.2569371755655924
  train_level3__tn_weighted_masked:
  - 0.2968652119444533
  - 0.29391489188628933
  - 0.29109840708820967
  - 0.2805751631012952
  - 0.30279811653380634
  train_level3__tn_weighted_oob:
  - 0.2504543217701579
  - 0.24749219521449942
  - 0.24482508318600624
  - 0.23528672714002713
  - 0.25587111924509326
  train_level3__tp_macro:
  - 0.21386056496072595
  - 0.21474163018757178
  - 0.2143372104200712
  - 0.21509708737864072
  - 0.2119305908324828
  train_level3__tp_macro_masked:
  - 0.12726728120934314
  - 0.12817898742476136
  - 0.12756580087523
  - 0.1284999781866238
  - 0.12541150027499376
  train_level3__tp_macro_oob:
  - 0.21307996292140313
  - 0.21415470396908848
  - 0.21356820148034222
  - 0.21470873786407765
  - 0.21105229425309188
  train_level3__tp_micro:
  - 0.21386056496072595
  - 0.21474163018757184
  - 0.21433721042007114
  - 0.21509708737864078
  - 0.21193059083248272
  train_level3__tp_micro_masked:
  - 0.1170468685192866
  - 0.11774980592214705
  - 0.11727537652858348
  - 0.11826478997140973
  - 0.11568157972613058
  train_level3__tp_micro_oob:
  - 0.21307996292140313
  - 0.21415470396908856
  - 0.2135682014803422
  - 0.21470873786407768
  - 0.21105229425309185
  train_level3__tp_samples:
  - 0.21386056496072592
  - 0.21474163018757178
  - 0.2143372104200711
  - 0.21509708737864075
  - 0.21193059083248267
  train_level3__tp_samples_masked:
  - 0.11736103546731165
  - 0.11811133313299746
  - 0.11772135209051574
  - 0.11859102423120821
  - 0.1160195693231607
  train_level3__tp_samples_oob:
  - 0.21307996292140305
  - 0.21415470396908845
  - 0.21356820148034217
  - 0.21470873786407763
  - 0.21105229425309177
  train_level3__tp_weighted:
  - 0.3171887640931267
  - 0.3191705265268239
  - 0.31832308397694686
  - 0.3194705974350954
  - 0.31198733227587166
  train_level3__tp_weighted_masked:
  - 0.20458035759825136
  - 0.20682604049117556
  - 0.20562782158387188
  - 0.2066862772581692
  - 0.19906064993969147
  train_level3__tp_weighted_oob:
  - 0.31604844913504976
  - 0.3183958866412145
  - 0.3172482485952672
  - 0.31950552601397136
  - 0.31061211962242763
  train_level4__average_precision_macro:
  - 0.39204983348565325
  - 0.40012586359167407
  - 0.4005342293966979
  - 0.39551154754897727
  - 0.39540549301516953
  train_level4__average_precision_macro_masked:
  - 0.26044585425692596
  - 0.26670280687170556
  - 0.26524089767387216
  - 0.26364840117435656
  - 0.25775941912895595
  train_level4__average_precision_macro_oob:
  - 0.3874591024731635
  - 0.3957909676496728
  - 0.39493474975265996
  - 0.38915648307061323
  - 0.3910198222912113
  train_level4__average_precision_micro:
  - 0.31964109664349116
  - 0.32267716590127965
  - 0.3378585204761875
  - 0.31658715677884086
  - 0.3223949598125557
  train_level4__average_precision_micro_masked:
  - 0.18016217050576783
  - 0.18172173411838308
  - 0.19154482852309465
  - 0.17757244385514476
  - 0.1806081634124295
  train_level4__average_precision_micro_oob:
  - 0.3213637175159244
  - 0.3232172335388668
  - 0.33710584414572786
  - 0.31712271986479623
  - 0.32364038855961946
  train_level4__average_precision_samples:
  - 0.3265282541847636
  - 0.3287748172340915
  - 0.3465132244794306
  - 0.3249374838164616
  - 0.32674055805857627
  train_level4__average_precision_samples_masked:
  - 0.19727511592025532
  - 0.2003382917716988
  - 0.2119753447897436
  - 0.1967321349402256
  - 0.19806179866257018
  train_level4__average_precision_samples_oob:
  - 0.32771354522673973
  - 0.3293708887159996
  - 0.3460243678183904
  - 0.32575552851707323
  - 0.32781602058154263
  train_level4__average_precision_weighted:
  - 0.5282913493751009
  - 0.5363907706448519
  - 0.5348648039406645
  - 0.5328904769499767
  - 0.5263168251495229
  train_level4__average_precision_weighted_masked:
  - 0.3744917855392432
  - 0.3807558493147649
  - 0.37787196663582573
  - 0.3784991851307399
  - 0.3668441629729362
  train_level4__average_precision_weighted_oob:
  - 0.5227813642947304
  - 0.5313144664290175
  - 0.5290264472632508
  - 0.5250930277759037
  - 0.5211848968605365
  train_level4__f1_macro:
  - 0.48765673025320777
  - 0.4792741679098091
  - 0.4806786503893107
  - 0.4640533980582524
  - 0.48937735893844797
  train_level4__f1_macro_masked:
  - 0.4359877896173293
  - 0.4274678406137065
  - 0.4282524705184361
  - 0.41046407563566856
  - 0.4385676651163956
  train_level4__f1_macro_oob:
  - 0.48660779626286765
  - 0.4779780391773251
  - 0.47863597039315586
  - 0.4626456310679612
  - 0.48783440548816676
  train_level4__f1_micro:
  - 0.48765673025320777
  - 0.479274167909809
  - 0.4806786503893108
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__f1_micro_masked:
  - 0.4272915802571547
  - 0.4177109903515582
  - 0.4192335975161369
  - 0.40031889157686384
  - 0.4300933523445697
  train_level4__f1_micro_oob:
  - 0.48660779626286776
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.46264563106796114
  - 0.48783440548816676
  train_level4__f1_samples:
  - 0.4876567302532077
  - 0.4792741679098089
  - 0.48067865038931074
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__f1_samples_masked:
  - 0.42826474534111686
  - 0.41898186656883163
  - 0.42035631471762425
  - 0.40148087320940645
  - 0.43167764763771366
  train_level4__f1_samples_oob:
  - 0.4866077962628677
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.4626456310679612
  - 0.4878344054881667
  train_level4__f1_weighted:
  - 0.5692930256444048
  - 0.5680915544571576
  - 0.5652841133789936
  - 0.557928266082786
  - 0.5694711716058131
  train_level4__f1_weighted_masked:
  - 0.5015927865278139
  - 0.5007152762179968
  - 0.49696253110509975
  - 0.48814654216374836
  - 0.5027755178096549
  train_level4__f1_weighted_oob:
  - 0.5673431681249416
  - 0.5668036369237663
  - 0.5626332424802187
  - 0.5563411010322178
  - 0.5670180024682923
  train_level4__fn_macro:
  - -0.02044201590476655
  - -0.020077767723949036
  - -0.019898106315485917
  - -0.017645631067961163
  - -0.022147316447883782
  train_level4__fn_macro_masked:
  - -0.016400727445810566
  - -0.015775954951887956
  - -0.016004643598665134
  - -0.013665249199277047
  - -0.01764780124620899
  train_level4__fn_macro_oob:
  - -0.02129579938527589
  - -0.020395686092294144
  - -0.020522926079015673
  - -0.017985436893203883
  - -0.022811973318774183
  train_level4__fn_micro:
  - -0.02044201590476655
  - -0.020077767723949036
  - -0.019898106315485917
  - -0.017645631067961166
  - -0.02214731644788378
  train_level4__fn_micro_masked:
  - -0.015125120973316742
  - -0.014694466008650327
  - -0.01476155459324019
  - -0.012645700461842973
  - -0.016303031933496543
  train_level4__fn_micro_oob:
  - -0.021295799385275895
  - -0.020395686092294148
  - -0.02052292607901567
  - -0.017985436893203883
  - -0.022811973318774183
  train_level4__fn_samples:
  - -0.020442015904766547
  - -0.020077767723949033
  - -0.019898106315485914
  - -0.017645631067961163
  - -0.02214731644788378
  train_level4__fn_samples_masked:
  - -0.015005094719063472
  - -0.014633819505227208
  - -0.014702764007233334
  - -0.012595635736096851
  - -0.01623228173255404
  train_level4__fn_samples_oob:
  - -0.02129579938527589
  - -0.020395686092294144
  - -0.02052292607901567
  - -0.01798543689320388
  - -0.02281197331877418
  train_level4__fn_weighted:
  - -0.03072339530935978
  - -0.02920093219198158
  - -0.029719744743752538
  - -0.025803878636221453
  - -0.03266446150024371
  train_level4__fn_weighted_masked:
  - -0.026042470275412927
  - -0.023940364716230546
  - -0.025482778040453943
  - -0.021452328207078424
  - -0.027830072390041517
  train_level4__fn_weighted_oob:
  - -0.03204909969767664
  - -0.02947515261219223
  - -0.030610823686332084
  - -0.025863570013554372
  - -0.03355375080759964
  train_level4__fp_macro:
  - -0.4919012538420256
  - -0.5006480643662419
  - -0.49942324329520343
  - -0.5183009708737863
  - -0.48847532461366827
  train_level4__fp_macro_masked:
  - -0.54761148293686
  - -0.5567562044344057
  - -0.5557428858828986
  - -0.5758706751650543
  - -0.5437845336373953
  train_level4__fp_macro_oob:
  - -0.4920964043518563
  - -0.5016262747303808
  - -0.5008411035278285
  - -0.5193689320388349
  - -0.48935362119305914
  train_level4__fp_micro:
  - -0.49190125384202565
  - -0.500648064366242
  - -0.4994232432952033
  - -0.5183009708737865
  - -0.4884753246136682
  train_level4__fp_micro_masked:
  - -0.5575832987695285
  - -0.5675945436397916
  - -0.5660048478906229
  - -0.5870354079612932
  - -0.5536036157219337
  train_level4__fp_micro_oob:
  - -0.49209640435185636
  - -0.5016262747303808
  - -0.5008411035278285
  - -0.5193689320388349
  - -0.4893536211930591
  train_level4__fp_samples:
  - -0.4919012538420256
  - -0.500648064366242
  - -0.4994232432952033
  - -0.5183009708737863
  - -0.4884753246136682
  train_level4__fp_samples_masked:
  - -0.5567301599398197
  - -0.5663843139259411
  - -0.5649409212751425
  - -0.5859234910544967
  - -0.5520900706297324
  train_level4__fp_samples_oob:
  - -0.49209640435185636
  - -0.5016262747303808
  - -0.5008411035278285
  - -0.519368932038835
  - -0.48935362119305903
  train_level4__fp_weighted:
  - -0.39998357904623544
  - -0.40270751335086064
  - -0.4049961418772537
  - -0.41626785528099264
  - -0.3978643668939433
  train_level4__fp_weighted_masked:
  - -0.47236474319677313
  - -0.47534435906577244
  - -0.4775546908544463
  - -0.4904011296291731
  - -0.46939440980030345
  train_level4__fp_weighted_oob:
  - -0.4006077321773818
  - -0.40372121046404125
  - -0.4067559338334491
  - -0.4177953289542279
  - -0.39942824672410815
  train_level4__jaccard_macro:
  - 0.34357706814028693
  - 0.338421009727788
  - 0.3380471864882935
  - 0.3252025866854529
  - 0.3447879380957999
  train_level4__jaccard_macro_masked:
  - 0.2980491895429755
  - 0.2933600832176272
  - 0.2919496547789249
  - 0.2788411789793066
  - 0.29989868558014215
  train_level4__jaccard_macro_oob:
  - 0.34267452077620586
  - 0.33762345767744745
  - 0.33633096962126624
  - 0.3242022486327193
  - 0.34335858876618114
  train_level4__jaccard_micro:
  - 0.32245108634288755
  - 0.31516145632316994
  - 0.3163772104647117
  - 0.3021286010018805
  - 0.32395738395298407
  train_level4__jaccard_micro_masked:
  - 0.27169154491270636
  - 0.2639915892763273
  - 0.2652090763425854
  - 0.250249183708541
  - 0.2739611001627967
  train_level4__jaccard_micro_oob:
  - 0.3215344938749194
  - 0.31404148657550973
  - 0.31460975879444614
  - 0.30093623202134545
  - 0.3226064706528735
  train_level4__jaccard_samples:
  - 0.3287408041465077
  - 0.32105766777649175
  - 0.32214110067681717
  - 0.3080654895616252
  - 0.329865852208906
  train_level4__jaccard_samples_masked:
  - 0.27847862331541834
  - 0.27033975104320035
  - 0.271611157040568
  - 0.2567092498628993
  - 0.2804488167852489
  train_level4__jaccard_samples_oob:
  - 0.327663163232586
  - 0.3197697151281705
  - 0.32026255736139725
  - 0.3067041180917348
  - 0.3284746924664428
  train_level4__jaccard_weighted:
  - 0.41727437488819635
  - 0.417652586733088
  - 0.41323656659275204
  - 0.40760229605530024
  - 0.41573183455149837
  train_level4__jaccard_weighted_masked:
  - 0.35227764306826914
  - 0.35340912202208635
  - 0.3475655040225587
  - 0.3410943812352127
  - 0.3516077233137768
  train_level4__jaccard_weighted_oob:
  - 0.41537359104552873
  - 0.4166999869739028
  - 0.41062358720955344
  - 0.4063613803504636
  - 0.41332388523404473
  train_level4__label_ranking_average_precision_score:
  - 0.3265282541847641
  - 0.32877481723409163
  - 0.3465132244794306
  - 0.3249374838164614
  - 0.32674055805857627
  train_level4__label_ranking_average_precision_score_oob:
  - 0.32771354522673984
  - 0.3293708887159996
  - 0.3460243678183902
  - 0.32575552851707323
  - 0.3278160205815427
  train_level4__matthews_corrcoef_macro:
  - 0.2413226157972089
  - 0.23738660670198902
  - 0.236276104747114
  - 0.2327187479525919
  - 0.23988090553293548
  train_level4__matthews_corrcoef_macro_masked:
  - 0.17697373690027074
  - 0.1742475906917363
  - 0.17323817713397932
  - 0.17363370695561914
  - 0.17443627934129696
  train_level4__matthews_corrcoef_macro_oob:
  - 0.23666077453172893
  - 0.2328030964400826
  - 0.23041856594242435
  - 0.22805431111936977
  - 0.2353598353148443
  train_level4__matthews_corrcoef_micro:
  - 0.25128488326466214
  - 0.24443020076695962
  - 0.24626598232189661
  - 0.237641325504594
  - 0.24737981105926576
  train_level4__matthews_corrcoef_micro_masked:
  - 0.17570307507091704
  - 0.17137570749107278
  - 0.17172574959251335
  - 0.16873622062668703
  - 0.17172745049736005
  train_level4__matthews_corrcoef_micro_oob:
  - 0.2475002267049354
  - 0.24212695641954426
  - 0.24223332541930945
  - 0.23512052159185734
  - 0.24374501865535206
  train_level4__matthews_corrcoef_samples:
  - 0.24897907335865868
  - 0.24154770479472298
  - 0.2457900979645039
  - 0.23525998310128102
  - 0.2461027364243624
  train_level4__matthews_corrcoef_samples_masked:
  - 0.1742735358453696
  - 0.1689522624369514
  - 0.17147418830162556
  - 0.16619213795370502
  - 0.170094808057165
  train_level4__matthews_corrcoef_samples_oob:
  - 0.2453551487429179
  - 0.23938770950523577
  - 0.2416392327758541
  - 0.23304332489171142
  - 0.24217008382758443
  train_level4__matthews_corrcoef_weighted:
  - 0.27364798553934233
  - 0.27358226563575644
  - 0.26797702448412264
  - 0.2728817965843377
  - 0.27354678026481594
  train_level4__matthews_corrcoef_weighted_masked:
  - 0.20413583171899904
  - 0.20804750796676102
  - 0.20010273039401577
  - 0.21002875050031145
  - 0.20473654801668895
  train_level4__matthews_corrcoef_weighted_oob:
  - 0.26742485883259653
  - 0.2660671718076785
  - 0.26000875759244674
  - 0.26678141805285677
  - 0.26663126703092527
  train_level4__ndcg:
  - 0.6699710614362697
  - 0.6690607810359888
  - 0.6850187298090079
  - 0.6665911638870401
  - 0.6669999596929774
  train_level4__ndcg_oob:
  - 0.6732177074617042
  - 0.671329484545866
  - 0.6858354593406012
  - 0.6692975681287295
  - 0.6700179053173513
  train_level4__neg_coverage_error:
  - -81.82412060301507
  - -81.45843828715365
  - -81.43564356435644
  - -83.0675
  - -81.91931540342298
  train_level4__neg_coverage_error_oob:
  - -82.86180904522612
  - -82.50377833753149
  - -82.45544554455445
  - -83.955
  - -82.88508557457213
  train_level4__neg_hamming_loss_macro:
  - -0.5123432697467922
  - -0.520725832090191
  - -0.5193213496106893
  - -0.5359466019417476
  - -0.5106226410615521
  train_level4__neg_hamming_loss_macro_masked:
  - -0.5640122103826707
  - -0.5725321593862934
  - -0.5717475294815638
  - -0.5895359243643314
  - -0.5614323348836044
  train_level4__neg_hamming_loss_macro_oob:
  - -0.5133922037371322
  - -0.5220219608226749
  - -0.5213640296068441
  - -0.5373543689320388
  - -0.5121655945118333
  train_level4__neg_hamming_loss_micro:
  - -0.5123432697467922
  - -0.520725832090191
  - -0.5193213496106892
  - -0.5359466019417476
  - -0.510622641061552
  train_level4__neg_hamming_loss_micro_masked:
  - -0.5727084197428453
  - -0.5822890096484419
  - -0.580766402483863
  - -0.5996811084231362
  - -0.5699066476554303
  train_level4__neg_hamming_loss_micro_oob:
  - -0.5133922037371322
  - -0.5220219608226749
  - -0.5213640296068441
  - -0.5373543689320388
  - -0.5121655945118333
  train_level4__neg_hamming_loss_samples:
  - -0.5123432697467922
  - -0.520725832090191
  - -0.5193213496106892
  - -0.5359466019417475
  - -0.510622641061552
  train_level4__neg_hamming_loss_samples_masked:
  - -0.5717352546588832
  - -0.5810181334311684
  - -0.5796436852823758
  - -0.5985191267905935
  - -0.5683223523622863
  train_level4__neg_hamming_loss_samples_oob:
  - -0.5133922037371322
  - -0.5220219608226749
  - -0.5213640296068442
  - -0.5373543689320388
  - -0.5121655945118332
  train_level4__neg_hamming_loss_weighted:
  - -0.4307069743555953
  - -0.4319084455428423
  - -0.43471588662100635
  - -0.44207173391721405
  - -0.430528828394187
  train_level4__neg_hamming_loss_weighted_masked:
  - -0.4984072134721861
  - -0.4992847237820031
  - -0.5030374688949003
  - -0.5118534578362516
  - -0.49722448219034504
  train_level4__neg_hamming_loss_weighted_oob:
  - -0.43265683187505855
  - -0.43319636307623366
  - -0.43736675751978116
  - -0.44365889896778227
  - -0.4329819975317078
  train_level4__neg_label_ranking_loss:
  - -0.38490288543470486
  - -0.3739384736607551
  - -0.35904205293786384
  - -0.37579917377249566
  - -0.3737211796940644
  train_level4__neg_label_ranking_loss_oob:
  - -0.3898517718192377
  - -0.37857536485543103
  - -0.3638066895870309
  - -0.3802455428970965
  - -0.37933323981928446
  train_level4__precision_macro:
  - 0.48765673025320777
  - 0.4792741679098091
  - 0.4806786503893107
  - 0.4640533980582524
  - 0.48937735893844797
  train_level4__precision_macro_masked:
  - 0.4359877896173293
  - 0.4274678406137065
  - 0.4282524705184361
  - 0.41046407563566856
  - 0.4385676651163956
  train_level4__precision_macro_oob:
  - 0.48660779626286765
  - 0.4779780391773251
  - 0.47863597039315586
  - 0.4626456310679612
  - 0.48783440548816676
  train_level4__precision_micro:
  - 0.48765673025320777
  - 0.479274167909809
  - 0.4806786503893108
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__precision_micro_masked:
  - 0.4272915802571547
  - 0.4177109903515582
  - 0.4192335975161369
  - 0.40031889157686384
  - 0.4300933523445697
  train_level4__precision_micro_oob:
  - 0.48660779626286776
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.46264563106796114
  - 0.48783440548816676
  train_level4__precision_samples:
  - 0.4876567302532077
  - 0.4792741679098089
  - 0.48067865038931074
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__precision_samples_masked:
  - 0.42826474534111686
  - 0.41898186656883163
  - 0.42035631471762425
  - 0.40148087320940645
  - 0.43167764763771366
  train_level4__precision_samples_oob:
  - 0.4866077962628677
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.4626456310679612
  - 0.4878344054881667
  train_level4__precision_weighted:
  - 0.5692930256444048
  - 0.5680915544571576
  - 0.5652841133789936
  - 0.557928266082786
  - 0.5694711716058131
  train_level4__precision_weighted_masked:
  - 0.5015927865278139
  - 0.5007152762179968
  - 0.49696253110509975
  - 0.48814654216374836
  - 0.5027755178096549
  train_level4__precision_weighted_oob:
  - 0.5673431681249416
  - 0.5668036369237663
  - 0.5626332424802187
  - 0.5563411010322178
  - 0.5670180024682923
  train_level4__recall_macro:
  - 0.48765673025320777
  - 0.4792741679098091
  - 0.4806786503893107
  - 0.4640533980582524
  - 0.48937735893844797
  train_level4__recall_macro_masked:
  - 0.4359877896173293
  - 0.4274678406137065
  - 0.4282524705184361
  - 0.41046407563566856
  - 0.4385676651163956
  train_level4__recall_macro_oob:
  - 0.48660779626286765
  - 0.4779780391773251
  - 0.47863597039315586
  - 0.4626456310679612
  - 0.48783440548816676
  train_level4__recall_micro:
  - 0.48765673025320777
  - 0.479274167909809
  - 0.4806786503893108
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__recall_micro_masked:
  - 0.4272915802571547
  - 0.4177109903515582
  - 0.4192335975161369
  - 0.40031889157686384
  - 0.4300933523445697
  train_level4__recall_micro_oob:
  - 0.48660779626286776
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.46264563106796114
  - 0.48783440548816676
  train_level4__recall_samples:
  - 0.4876567302532077
  - 0.4792741679098089
  - 0.48067865038931074
  - 0.4640533980582524
  - 0.489377358938448
  train_level4__recall_samples_masked:
  - 0.42826474534111686
  - 0.41898186656883163
  - 0.42035631471762425
  - 0.40148087320940645
  - 0.43167764763771366
  train_level4__recall_samples_oob:
  - 0.4866077962628677
  - 0.47797803917732506
  - 0.4786359703931558
  - 0.4626456310679612
  - 0.4878344054881667
  train_level4__recall_weighted:
  - 0.5692930256444048
  - 0.5680915544571576
  - 0.5652841133789936
  - 0.557928266082786
  - 0.5694711716058131
  train_level4__recall_weighted_masked:
  - 0.5015927865278139
  - 0.5007152762179968
  - 0.49696253110509975
  - 0.48814654216374836
  - 0.5027755178096549
  train_level4__recall_weighted_oob:
  - 0.5673431681249416
  - 0.5668036369237663
  - 0.5626332424802187
  - 0.5563411010322178
  - 0.5670180024682923
  train_level4__roc_auc_macro:
  - 0.7198491173945654
  - 0.7225624246165915
  - 0.727576870486565
  - 0.7238508026013841
  - 0.7208461535920924
  train_level4__roc_auc_macro_masked:
  - 0.7014465170305444
  - 0.7016972785563892
  - 0.7077532599615711
  - 0.7010082734726273
  - 0.6949185298294741
  train_level4__roc_auc_macro_oob:
  - 0.7138971969238916
  - 0.7167715691808703
  - 0.7210060135001453
  - 0.7170295877393814
  - 0.7150309364320698
  train_level4__roc_auc_micro:
  - 0.6687121442839097
  - 0.6703345573847739
  - 0.6810857681602522
  - 0.6640414490845072
  - 0.670450624004097
  train_level4__roc_auc_micro_masked:
  - 0.6483220570816083
  - 0.64953030764843
  - 0.6599217909186084
  - 0.64431169455731
  - 0.647224340142328
  train_level4__roc_auc_micro_oob:
  - 0.6681526149421843
  - 0.6687369096446929
  - 0.6790599485140267
  - 0.6628327468134281
  - 0.669386204659164
  train_level4__roc_auc_samples:
  - 0.6528259413237614
  - 0.6528094202845494
  - 0.668197457952809
  - 0.6475102345484136
  - 0.6516604992319274
  train_level4__roc_auc_samples_masked:
  - 0.6333974475959298
  - 0.6353424227598338
  - 0.6493095378845238
  - 0.6284728155896032
  - 0.632205265823274
  train_level4__roc_auc_samples_oob:
  - 0.6525898938058564
  - 0.6517911771329161
  - 0.6666301320357879
  - 0.6470138537743931
  - 0.6513563632143198
  train_level4__roc_auc_weighted:
  - 0.7235034370592477
  - 0.7250876523107925
  - 0.7294366556354721
  - 0.7294008930225455
  - 0.7241609856583505
  train_level4__roc_auc_weighted_masked:
  - 0.6990952887618777
  - 0.6998066128132293
  - 0.7038941735774723
  - 0.7067923897423021
  - 0.6956289512370557
  train_level4__roc_auc_weighted_oob:
  - 0.7160660406284224
  - 0.7179756188400255
  - 0.7217729967546341
  - 0.7204485451726538
  - 0.7173972506881174
  train_level4__tn_macro:
  - 0.2736985900375664
  - 0.26460590349954755
  - 0.26653369220417183
  - 0.24890776699029132
  - 0.2774230303605763
  train_level4__tn_macro_masked:
  - 0.30872128908156393
  - 0.29934428032277277
  - 0.3008080442906916
  - 0.28178283508556057
  - 0.31314135676387544
  train_level4__tn_macro_oob:
  - 0.2735034395277358
  - 0.26362769313540874
  - 0.2651158319715467
  - 0.2478398058252427
  - 0.27654473378118544
  train_level4__tn_micro:
  - 0.27369859003756647
  - 0.2646059034995476
  - 0.2665336922041719
  - 0.24890776699029127
  - 0.27742303036057636
  train_level4__tn_micro_masked:
  - 0.3102447117378681
  - 0.2999889098369746
  - 0.3020671623498652
  - 0.28191664833956454
  - 0.3144117726184391
  train_level4__tn_micro_oob:
  - 0.27350343952773576
  - 0.2636276931354088
  - 0.26511583197154664
  - 0.24783980582524273
  - 0.27654473378118544
  train_level4__tn_samples:
  - 0.2736985900375664
  - 0.26460590349954755
  - 0.26653369220417183
  - 0.24890776699029118
  - 0.2774230303605763
  train_level4__tn_samples_masked:
  - 0.31090777719170976
  - 0.30088915494282736
  - 0.302740944274535
  - 0.28275725883195335
  - 0.31566290344820125
  train_level4__tn_samples_oob:
  - 0.27350343952773576
  - 0.2636276931354087
  - 0.2651158319715466
  - 0.24783980582524268
  - 0.2765447337811854
  train_level4__tn_weighted:
  - 0.2518490569195232
  - 0.24918658875832733
  - 0.24727796478179498
  - 0.2381068188927119
  - 0.25753615046566825
  train_level4__tn_weighted_masked:
  - 0.29701767459871276
  - 0.2941566019305373
  - 0.29155102429844487
  - 0.28094471966743434
  - 0.3035868388338629
  train_level4__tn_weighted_oob:
  - 0.25122490378837675
  - 0.24817289164514672
  - 0.24551817282559957
  - 0.23657934521947663
  - 0.2559722706355034
  train_level4__tp_macro:
  - 0.21395814021564133
  - 0.21466826441026138
  - 0.2141449581851389
  - 0.21514563106796117
  - 0.21195432857787172
  train_level4__tp_macro_masked:
  - 0.12726650053576546
  - 0.1281235602909337
  - 0.12744442622774474
  - 0.12868124055010807
  - 0.12542630835252017
  train_level4__tp_macro_oob:
  - 0.21310435673513198
  - 0.21435034604191627
  - 0.21352013842160916
  - 0.2148058252427184
  - 0.21128967170698132
  train_level4__tp_micro:
  - 0.2139581402156413
  - 0.21466826441026143
  - 0.2141449581851389
  - 0.21514563106796117
  - 0.21195432857787166
  train_level4__tp_micro_masked:
  - 0.1170468685192866
  - 0.11772208051458356
  - 0.11716643516627176
  - 0.11840224323729932
  - 0.11568157972613058
  train_level4__tp_micro_oob:
  - 0.21310435673513198
  - 0.2143503460419163
  - 0.21352013842160916
  - 0.21480582524271843
  - 0.21128967170698126
  train_level4__tp_samples:
  - 0.21395814021564125
  - 0.21466826441026138
  - 0.21414495818513885
  - 0.2151456310679611
  - 0.2119543285778716
  train_level4__tp_samples_masked:
  - 0.1173569681494072
  - 0.11809271162600428
  - 0.1176153704430892
  - 0.11872361437745309
  - 0.11601474418951245
  train_level4__tp_samples_oob:
  - 0.21310435673513192
  - 0.21435034604191625
  - 0.2135201384216091
  - 0.21480582524271838
  - 0.2112896717069812
  train_level4__tp_weighted:
  - 0.31744396872488156
  - 0.31890496569883037
  - 0.3180061485971987
  - 0.31982144719007405
  - 0.3119350211401448
  train_level4__tp_weighted_masked:
  - 0.2045751119291011
  - 0.20655867428745975
  - 0.20541150680665482
  - 0.2072018224963142
  - 0.19918867897579218
  train_level4__tp_weighted_oob:
  - 0.3161182643365647
  - 0.31863074527861973
  - 0.3171150696546192
  - 0.3197617558127411
  - 0.31104573183278883
  train_level5__average_precision_macro:
  - 0.3930629102730572
  - 0.39692472547713525
  - 0.40147088338467135
  - 0.3932154888591185
  - 0.39117398942910153
  train_level5__average_precision_macro_masked:
  - 0.2616517032293738
  - 0.26417535511014917
  - 0.26696219616409944
  - 0.2627882285964899
  - 0.2550293398296808
  train_level5__average_precision_macro_oob:
  - 0.38782080942464003
  - 0.3931978306618999
  - 0.3942262341281461
  - 0.38990957113331415
  - 0.38735189483526294
  train_level5__average_precision_micro:
  - 0.3186530867141711
  - 0.3234813374876999
  - 0.33783621080555726
  - 0.31536533025758406
  - 0.32317556222748867
  train_level5__average_precision_micro_masked:
  - 0.18001883278030034
  - 0.18212559946737156
  - 0.19197144874692773
  - 0.17759067456240757
  - 0.1801549902852904
  train_level5__average_precision_micro_oob:
  - 0.3199072726749511
  - 0.32355385488329175
  - 0.3376122525668438
  - 0.31658250648605657
  - 0.3235858843378797
  train_level5__average_precision_samples:
  - 0.3253055116525148
  - 0.32896535057198045
  - 0.3455680641405433
  - 0.32284822017190906
  - 0.3261412258221711
  train_level5__average_precision_samples_masked:
  - 0.1970506550852229
  - 0.1998113446262606
  - 0.212276064595729
  - 0.19555683446660865
  - 0.19650855875682466
  train_level5__average_precision_samples_oob:
  - 0.3266001677428059
  - 0.32918835207050395
  - 0.34572679311534305
  - 0.32369531513141026
  - 0.3266260247500394
  train_level5__average_precision_weighted:
  - 0.5287247022477377
  - 0.5333652080087804
  - 0.5358635275828374
  - 0.5303967803343735
  - 0.523191879040356
  train_level5__average_precision_weighted_masked:
  - 0.3754284513917929
  - 0.37818698087389396
  - 0.38008451396848125
  - 0.37773997602058995
  - 0.3642624863963744
  train_level5__average_precision_weighted_oob:
  - 0.521960538275427
  - 0.5287159123666327
  - 0.528302968478753
  - 0.5255972992991699
  - 0.5188272814253717
  train_level5__f1_macro:
  - 0.48782748694930955
  - 0.47922525739160216
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.4898758515916159
  train_level5__f1_macro_masked:
  - 0.4359457933230332
  - 0.4275940273856284
  - 0.4292563113167315
  - 0.4110487610021938
  - 0.43908824198531676
  train_level5__f1_macro_oob:
  - 0.48641264575303694
  - 0.4769753735540829
  - 0.479332884744785
  - 0.4626213592233009
  - 0.4886177510860019
  train_level5__f1_micro:
  - 0.48782748694930966
  - 0.47922525739160204
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.48987585159161584
  train_level5__f1_micro_masked:
  - 0.4272362781695009
  - 0.41776644116668515
  - 0.4202957757986764
  - 0.4009786672531339
  - 0.43060450351080143
  train_level5__f1_micro_oob:
  - 0.48641264575303705
  - 0.4769753735540828
  - 0.47933288474478514
  - 0.462621359223301
  - 0.48861775108600186
  train_level5__f1_samples:
  - 0.48782748694930966
  - 0.4792252573916021
  - 0.4816158800346054
  - 0.4647815533980582
  - 0.48987585159161584
  train_level5__f1_samples_masked:
  - 0.42821912285155933
  - 0.41903050469166603
  - 0.42144255052273993
  - 0.40212576147435053
  - 0.43219383329655153
  train_level5__f1_samples_oob:
  - 0.486412645753037
  - 0.47697537355408276
  - 0.47933288474478514
  - 0.46262135922330094
  - 0.48861775108600186
  train_level5__f1_weighted:
  - 0.5696823695959243
  - 0.5685143000044872
  - 0.5658503780350309
  - 0.5583948493379208
  - 0.57012543268251
  train_level5__f1_weighted_masked:
  - 0.501652644363762
  - 0.5013705355730125
  - 0.49752843471036234
  - 0.4881613006072536
  - 0.5033712902959728
  train_level5__f1_weighted_oob:
  - 0.5669710818636843
  - 0.5658004362860006
  - 0.5633174365798833
  - 0.5557376707329789
  - 0.5679035729745301
  train_level5__fn_macro:
  - -0.02012489632629165
  - -0.019979946687535152
  - -0.019729885609920218
  - -0.01740291262135922
  - -0.022004889975550123
  train_level5__fn_macro_masked:
  - -0.016294533600507182
  - -0.015536050528196637
  - -0.01578819027902916
  - -0.013560367879600257
  - -0.017528450937870317
  train_level5__fn_macro_oob:
  - -0.02112504268917402
  - -0.020689149201535792
  - -0.020330673844083443
  - -0.018058252427184465
  - -0.022503382628717927
  train_level5__fn_micro:
  - -0.020124896326291653
  - -0.019979946687535156
  - -0.019729885609920214
  - -0.017402912621359224
  - -0.022004889975550123
  train_level5__fn_micro_masked:
  - -0.015014516798009124
  - -0.014472662748142398
  - -0.01457090720919465
  - -0.012535737849131295
  - -0.016195421161658282
  train_level5__fn_micro_oob:
  - -0.021125042689174027
  - -0.020689149201535792
  - -0.02033067384408344
  - -0.018058252427184465
  - -0.022503382628717924
  train_level5__fn_samples:
  - -0.02012489632629165
  - -0.019979946687535152
  - -0.019729885609920214
  - -0.01740291262135922
  - -0.022004889975550123
  train_level5__fn_samples_masked:
  - -0.014895265480872097
  - -0.014408723344893999
  - -0.014492975251844491
  - -0.012478107519942489
  - -0.01611860596888184
  train_level5__fn_samples_oob:
  - -0.021125042689174024
  - -0.020689149201535792
  - -0.020330673844083436
  - -0.018058252427184462
  - -0.022503382628717924
  train_level5__fn_weighted:
  - -0.0302990130170051
  - -0.0289973005689352
  - -0.029384509967579575
  - -0.025374309248253568
  - -0.032363982369907666
  train_level5__fn_weighted_masked:
  - -0.025970029975670446
  - -0.02356269457057524
  - -0.02506908455608587
  - -0.02138634593718917
  - -0.027622919373845284
  train_level5__fn_weighted_oob:
  - -0.03188201387832073
  - -0.02992781311445383
  - -0.030227552994543726
  - -0.026102074861849647
  - -0.03313947636305218
  train_level5__fp_macro:
  - -0.49204761672439873
  - -0.5007947959208627
  - -0.49865423435547446
  - -0.5178155339805826
  - -0.4881192584328341
  train_level5__fp_macro_masked:
  - -0.5477596730764596
  - -0.5568699220861749
  - -0.5549554984042394
  - -0.575390871118206
  - -0.5433833070768128
  train_level5__fp_macro_oob:
  - -0.49246231155778897
  - -0.5023354772443814
  - -0.5003364414111313
  - -0.5193203883495146
  - -0.48887886628528027
  train_level5__fp_micro:
  - -0.4920476167243987
  - -0.5007947959208627
  - -0.4986542343554744
  - -0.5178155339805826
  - -0.48811925843283405
  train_level5__fp_micro_masked:
  - -0.5577492050324899
  - -0.5677608960851724
  - -0.565133316992129
  - -0.5864855948977348
  - -0.5532000753275403
  train_level5__fp_micro_oob:
  - -0.49246231155778897
  - -0.5023354772443814
  - -0.5003364414111314
  - -0.5193203883495146
  - -0.4888788662852802
  train_level5__fp_samples:
  - -0.4920476167243986
  - -0.5007947959208628
  - -0.4986542343554744
  - -0.5178155339805826
  - -0.48811925843283405
  train_level5__fp_samples_masked:
  - -0.5568856116675686
  - -0.56656077196344
  - -0.5640644742254156
  - -0.585396131005707
  - -0.5516875607345666
  train_level5__fp_samples_oob:
  - -0.49246231155778886
  - -0.5023354772443814
  - -0.5003364414111313
  - -0.5193203883495146
  - -0.48887886628528016
  train_level5__fp_weighted:
  - -0.4000186173870707
  - -0.40248839942657755
  - -0.4047651119973893
  - -0.41623084141382555
  - -0.39751058494758224
  train_level5__fp_weighted_masked:
  - -0.47237732566056734
  - -0.47506676985641216
  - -0.4774024807335517
  - -0.4904523534555573
  - -0.46900579033018175
  train_level5__fp_weighted_oob:
  - -0.40114690425799515
  - -0.40427175059954557
  - -0.4064550104255728
  - -0.41816025440517157
  - -0.39895695066241765
  train_level5__jaccard_macro:
  - 0.3437955660516739
  - 0.33836789909931236
  - 0.33877827765284246
  - 0.32575198789221965
  - 0.3452317763244132
  train_level5__jaccard_macro_masked:
  - 0.29806524375388843
  - 0.2934663100021643
  - 0.29266664671592046
  - 0.2791876639336886
  - 0.3003265724550829
  train_level5__jaccard_macro_oob:
  - 0.34247822986003823
  - 0.3366832274325561
  - 0.33688580779953675
  - 0.32393627301560685
  - 0.34403604774626695
  train_level5__jaccard_micro:
  - 0.3226004194224875
  - 0.31511915865307305
  - 0.3171897504075463
  - 0.3027462016410808
  - 0.3243944228743889
  train_level5__jaccard_micro_masked:
  - 0.2716468292339879
  - 0.2640358870119857
  - 0.2660597910416882
  - 0.2507650517484441
  - 0.2743760285244103
  train_level5__jaccard_micro_oob:
  - 0.32136410520887054
  - 0.31317640258197116
  - 0.3152122380606214
  - 0.30091569308493843
  - 0.32329197424218625
  train_level5__jaccard_samples:
  - 0.32885538087875343
  - 0.3210918898421241
  - 0.3229616394935131
  - 0.30860471083027
  - 0.33026554622577015
  train_level5__jaccard_samples_masked:
  - 0.27840513548229195
  - 0.2704266062323403
  - 0.2725198535430751
  - 0.25714696919323093
  - 0.2807999745920101
  train_level5__jaccard_samples_oob:
  - 0.3275191533449934
  - 0.3189712036482268
  - 0.32090217815254285
  - 0.3067567648092711
  - 0.3291354012202017
  train_level5__jaccard_weighted:
  - 0.4177365382431663
  - 0.4180323473664394
  - 0.41368001552168315
  - 0.4078941714937448
  - 0.41640763986309626
  train_level5__jaccard_weighted_masked:
  - 0.3523954776057923
  - 0.3540003085774443
  - 0.3479384065874454
  - 0.3408698195687889
  - 0.3522000908504685
  train_level5__jaccard_weighted_oob:
  - 0.4150172190736897
  - 0.4156236036162821
  - 0.4112880790411958
  - 0.4055019270524443
  - 0.4142157318769606
  train_level5__label_ranking_average_precision_score:
  - 0.32530551165251476
  - 0.32896535057198056
  - 0.34556806414054314
  - 0.32284822017190895
  - 0.3261412258221709
  train_level5__label_ranking_average_precision_score_oob:
  - 0.326600167742806
  - 0.3291883520705038
  - 0.34572679311534305
  - 0.32369531513141064
  - 0.3266260247500393
  train_level5__matthews_corrcoef_macro:
  - 0.24281383630369055
  - 0.23693638808278505
  - 0.23697501878774224
  - 0.23376570663379528
  - 0.24044962530485264
  train_level5__matthews_corrcoef_macro_masked:
  - 0.1781289481801792
  - 0.17437226717927065
  - 0.17406960655876758
  - 0.17456868410234153
  - 0.17515160464518953
  train_level5__matthews_corrcoef_macro_oob:
  - 0.23659978686507221
  - 0.23126622448381004
  - 0.23211817194145107
  - 0.2278522182693821
  - 0.23687885978680187
  train_level5__matthews_corrcoef_micro:
  - 0.2524811238805723
  - 0.24470481603161165
  - 0.2477241373206944
  - 0.23917336451327736
  - 0.24832131416957676
  train_level5__matthews_corrcoef_micro_masked:
  - 0.1762085960803579
  - 0.17251593196475265
  - 0.1734074838826804
  - 0.16975206375452828
  - 0.17260946621234308
  train_level5__matthews_corrcoef_micro_oob:
  - 0.24786451417304328
  - 0.2401871106535926
  - 0.2435409690179566
  - 0.23484763723923746
  - 0.24549790540406263
  train_level5__matthews_corrcoef_samples:
  - 0.2500805257534663
  - 0.24169486764704493
  - 0.24739674548392007
  - 0.23664954864050286
  - 0.24690782770048922
  train_level5__matthews_corrcoef_samples_masked:
  - 0.1745776306806124
  - 0.16987917075621425
  - 0.1732477711897332
  - 0.1670935059408759
  - 0.17107778691153055
  train_level5__matthews_corrcoef_samples_oob:
  - 0.2455029853102266
  - 0.23715063534852512
  - 0.2428398302265904
  - 0.2325256663653129
  - 0.24380234231813402
  train_level5__matthews_corrcoef_weighted:
  - 0.2752115204272791
  - 0.27214778943690837
  - 0.2684447441150846
  - 0.27397186766090054
  - 0.2743299481593664
  train_level5__matthews_corrcoef_weighted_masked:
  - 0.20468532131677483
  - 0.2070248916991638
  - 0.20100669678005462
  - 0.21043948684394487
  - 0.20536526379210734
  train_level5__matthews_corrcoef_weighted_oob:
  - 0.2661126471843234
  - 0.26457660245353787
  - 0.26223448513350356
  - 0.2650354141316949
  - 0.2686225130927497
  train_level5__ndcg:
  - 0.6673571026706444
  - 0.6704339802870782
  - 0.6827577941484394
  - 0.6649227998986484
  - 0.667817650553056
  train_level5__ndcg_oob:
  - 0.6709615805105201
  - 0.6713346176610834
  - 0.6849594305109346
  - 0.6675418800281929
  - 0.6697484740893942
  train_level5__neg_coverage_error:
  - -81.81909547738694
  - -81.56675062972292
  - -81.4059405940594
  - -82.985
  - -81.92665036674816
  train_level5__neg_coverage_error_oob:
  - -82.79145728643216
  - -82.59193954659949
  - -82.39851485148515
  - -83.9125
  - -82.8679706601467
  train_level5__neg_hamming_loss_macro:
  - -0.5121725130506904
  - -0.5207747426083978
  - -0.5183841199653946
  - -0.5352184466019417
  - -0.5101241484083842
  train_level5__neg_hamming_loss_macro_masked:
  - -0.5640542066769668
  - -0.5724059726143716
  - -0.5707436886832685
  - -0.5889512389978062
  - -0.5609117580146832
  train_level5__neg_hamming_loss_macro_oob:
  - -0.513587354246963
  - -0.5230246264459171
  - -0.5206671152552149
  - -0.5373786407766991
  - -0.5113822489139981
  train_level5__neg_hamming_loss_micro:
  - -0.5121725130506903
  - -0.520774742608398
  - -0.5183841199653946
  - -0.5352184466019417
  - -0.5101241484083842
  train_level5__neg_hamming_loss_micro_masked:
  - -0.5727637218304991
  - -0.5822335588333148
  - -0.5797042242013236
  - -0.5990213327468661
  - -0.5693954964891985
  train_level5__neg_hamming_loss_micro_oob:
  - -0.513587354246963
  - -0.5230246264459172
  - -0.5206671152552148
  - -0.5373786407766991
  - -0.5113822489139982
  train_level5__neg_hamming_loss_samples:
  - -0.5121725130506903
  - -0.520774742608398
  - -0.5183841199653946
  - -0.5352184466019417
  - -0.5101241484083842
  train_level5__neg_hamming_loss_samples_masked:
  - -0.5717808771484406
  - -0.580969495308334
  - -0.5785574494772601
  - -0.5978742385256495
  - -0.5678061667034484
  train_level5__neg_hamming_loss_samples_oob:
  - -0.5135873542469629
  - -0.5230246264459172
  - -0.5206671152552148
  - -0.537378640776699
  - -0.5113822489139981
  train_level5__neg_hamming_loss_weighted:
  - -0.4303176304040758
  - -0.4314856999955128
  - -0.434149621964969
  - -0.44160515066207906
  - -0.42987456731749
  train_level5__neg_hamming_loss_weighted_masked:
  - -0.49834735563623794
  - -0.49862946442698747
  - -0.5024715652896378
  - -0.5118386993927464
  - -0.496628709704027
  train_level5__neg_hamming_loss_weighted_oob:
  - -0.4330289181363159
  - -0.4341995637139994
  - -0.4366825634201166
  - -0.4442623292670212
  - -0.43209642702546985
  train_level5__neg_label_ranking_loss:
  - -0.38230057070853535
  - -0.377960156342863
  - -0.3584753824281104
  - -0.37996214986745513
  - -0.3827200176626546
  train_level5__neg_label_ranking_loss_oob:
  - -0.3871874628526178
  - -0.38212227323656156
  - -0.36360737240138086
  - -0.38364035430253857
  - -0.38707467245643284
  train_level5__precision_macro:
  - 0.48782748694930955
  - 0.47922525739160216
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.4898758515916159
  train_level5__precision_macro_masked:
  - 0.4359457933230332
  - 0.4275940273856284
  - 0.4292563113167315
  - 0.4110487610021938
  - 0.43908824198531676
  train_level5__precision_macro_oob:
  - 0.48641264575303694
  - 0.4769753735540829
  - 0.479332884744785
  - 0.4626213592233009
  - 0.4886177510860019
  train_level5__precision_micro:
  - 0.48782748694930966
  - 0.47922525739160204
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.48987585159161584
  train_level5__precision_micro_masked:
  - 0.4272362781695009
  - 0.41776644116668515
  - 0.4202957757986764
  - 0.4009786672531339
  - 0.43060450351080143
  train_level5__precision_micro_oob:
  - 0.48641264575303705
  - 0.4769753735540828
  - 0.47933288474478514
  - 0.462621359223301
  - 0.48861775108600186
  train_level5__precision_samples:
  - 0.48782748694930966
  - 0.4792252573916021
  - 0.4816158800346054
  - 0.4647815533980582
  - 0.48987585159161584
  train_level5__precision_samples_masked:
  - 0.42821912285155933
  - 0.41903050469166603
  - 0.42144255052273993
  - 0.40212576147435053
  - 0.43219383329655153
  train_level5__precision_samples_oob:
  - 0.486412645753037
  - 0.47697537355408276
  - 0.47933288474478514
  - 0.46262135922330094
  - 0.48861775108600186
  train_level5__precision_weighted:
  - 0.5696823695959243
  - 0.5685143000044872
  - 0.5658503780350309
  - 0.5583948493379208
  - 0.57012543268251
  train_level5__precision_weighted_masked:
  - 0.501652644363762
  - 0.5013705355730125
  - 0.49752843471036234
  - 0.4881613006072536
  - 0.5033712902959728
  train_level5__precision_weighted_oob:
  - 0.5669710818636843
  - 0.5658004362860006
  - 0.5633174365798833
  - 0.5557376707329789
  - 0.5679035729745301
  train_level5__recall_macro:
  - 0.48782748694930955
  - 0.47922525739160216
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.4898758515916159
  train_level5__recall_macro_masked:
  - 0.4359457933230332
  - 0.4275940273856284
  - 0.4292563113167315
  - 0.4110487610021938
  - 0.43908824198531676
  train_level5__recall_macro_oob:
  - 0.48641264575303694
  - 0.4769753735540829
  - 0.479332884744785
  - 0.4626213592233009
  - 0.4886177510860019
  train_level5__recall_micro:
  - 0.48782748694930966
  - 0.47922525739160204
  - 0.4816158800346054
  - 0.46478155339805827
  - 0.48987585159161584
  train_level5__recall_micro_masked:
  - 0.4272362781695009
  - 0.41776644116668515
  - 0.4202957757986764
  - 0.4009786672531339
  - 0.43060450351080143
  train_level5__recall_micro_oob:
  - 0.48641264575303705
  - 0.4769753735540828
  - 0.47933288474478514
  - 0.462621359223301
  - 0.48861775108600186
  train_level5__recall_samples:
  - 0.48782748694930966
  - 0.4792252573916021
  - 0.4816158800346054
  - 0.4647815533980582
  - 0.48987585159161584
  train_level5__recall_samples_masked:
  - 0.42821912285155933
  - 0.41903050469166603
  - 0.42144255052273993
  - 0.40212576147435053
  - 0.43219383329655153
  train_level5__recall_samples_oob:
  - 0.486412645753037
  - 0.47697537355408276
  - 0.47933288474478514
  - 0.46262135922330094
  - 0.48861775108600186
  train_level5__recall_weighted:
  - 0.5696823695959243
  - 0.5685143000044872
  - 0.5658503780350309
  - 0.5583948493379208
  - 0.57012543268251
  train_level5__recall_weighted_masked:
  - 0.501652644363762
  - 0.5013705355730125
  - 0.49752843471036234
  - 0.4881613006072536
  - 0.5033712902959728
  train_level5__recall_weighted_oob:
  - 0.5669710818636843
  - 0.5658004362860006
  - 0.5633174365798833
  - 0.5557376707329789
  - 0.5679035729745301
  train_level5__roc_auc_macro:
  - 0.720922271891909
  - 0.7219495034302436
  - 0.7270796882322524
  - 0.7227715887009367
  - 0.717398221572258
  train_level5__roc_auc_macro_masked:
  - 0.7029738974837069
  - 0.700172064183235
  - 0.7071812881846148
  - 0.7005266341623216
  - 0.6914183941075114
  train_level5__roc_auc_macro_oob:
  - 0.7137979438522933
  - 0.7160964045082796
  - 0.7207705517359155
  - 0.7166029009153992
  - 0.7119490932973985
  train_level5__roc_auc_micro:
  - 0.6682555168519742
  - 0.6699757738330177
  - 0.6808554687631756
  - 0.6631086373351529
  - 0.6700617679407403
  train_level5__roc_auc_micro_masked:
  - 0.6483561024741319
  - 0.6491119252307813
  - 0.6600792561508628
  - 0.6441488528847104
  - 0.6462721921228028
  train_level5__roc_auc_micro_oob:
  - 0.6673441122528427
  - 0.6682623829123195
  - 0.6791029044456318
  - 0.6622348452016494
  - 0.6686274933144494
  train_level5__roc_auc_samples:
  - 0.6517227203676617
  - 0.6524879730651418
  - 0.6673386354126027
  - 0.6462649863021358
  - 0.6511057246547916
  train_level5__roc_auc_samples_masked:
  - 0.6325498065860907
  - 0.6352269181983481
  - 0.6486343890151017
  - 0.6278226499235986
  - 0.6310072598672324
  train_level5__roc_auc_samples_oob:
  - 0.6518589212861852
  - 0.6512176511516786
  - 0.6660791640321331
  - 0.6455118353737822
  - 0.6504377763181131
  train_level5__roc_auc_weighted:
  - 0.7236941555169859
  - 0.724197762103267
  - 0.7287407374724404
  - 0.7290366696496287
  - 0.7223065237240598
  train_level5__roc_auc_weighted_masked:
  - 0.6995529294571147
  - 0.698613349892133
  - 0.7032745698392769
  - 0.7072439173952538
  - 0.6936431531645592
  train_level5__roc_auc_weighted_oob:
  - 0.7153909995548012
  - 0.7170445413401115
  - 0.7209677671517032
  - 0.7204818253093007
  - 0.7156882563943193
  train_level5__tn_macro:
  - 0.2735522271551935
  - 0.26445917194492674
  - 0.26730270114390076
  - 0.24939320388349515
  - 0.2777790965414105
  train_level5__tn_macro_masked:
  - 0.30857309894196444
  - 0.29923056267100345
  - 0.30159543176935066
  - 0.28226263913240884
  - 0.313542583324458
  train_level5__tn_macro_oob:
  - 0.2731375323218032
  - 0.2629184906214081
  - 0.2656204940882438
  - 0.2478883495145631
  - 0.2770194886889643
  train_level5__tn_micro:
  - 0.27355222715519345
  - 0.26445917194492674
  - 0.2673027011439008
  - 0.24939320388349515
  - 0.2777790965414105
  train_level5__tn_micro_masked:
  - 0.3100788054749067
  - 0.29982255739159364
  - 0.3029386932483591
  - 0.2824664614031229
  - 0.3148153130128326
  train_level5__tn_micro_oob:
  - 0.2731375323218032
  - 0.26291849062140815
  - 0.2656204940882438
  - 0.2478883495145631
  - 0.2770194886889643
  train_level5__tn_samples:
  - 0.2735522271551934
  - 0.2644591719449267
  - 0.26730270114390076
  - 0.24939320388349506
  - 0.2777790965414104
  train_level5__tn_samples_masked:
  - 0.31075232546396075
  - 0.3007126969053285
  - 0.30361739132426185
  - 0.2832846188807431
  - 0.3160654133433669
  train_level5__tn_samples_oob:
  - 0.27313753232180316
  - 0.26291849062140804
  - 0.26562049408824373
  - 0.247888349514563
  - 0.27701948868896425
  train_level5__tn_weighted:
  - 0.251814018578688
  - 0.24940570268261042
  - 0.2475089946616594
  - 0.2381438327598791
  - 0.2578899324120293
  train_level5__tn_weighted_masked:
  - 0.2970050921349185
  - 0.2944341911398975
  - 0.29170323441933943
  - 0.2808934958410501
  - 0.3039754583039846
  train_level5__tn_weighted_oob:
  - 0.25068573170776354
  - 0.24762235150964246
  - 0.2458190962334759
  - 0.23621441976853302
  - 0.2564435666971938
  train_level5__tp_macro:
  - 0.2142752597941162
  - 0.21476608544667528
  - 0.21431317889070461
  - 0.2153883495145631
  - 0.21209675505020537
  train_level5__tp_macro_masked:
  - 0.12737269438106888
  - 0.128363464714625
  - 0.12766087954738073
  - 0.1287861218697849
  - 0.12554565866085882
  train_level5__tp_macro_oob:
  - 0.21327511343123381
  - 0.21405688293267464
  - 0.2137123906565414
  - 0.21473300970873785
  - 0.21159826239703758
  train_level5__tp_micro:
  - 0.2142752597941162
  - 0.2147660854466753
  - 0.21431317889070461
  - 0.2153883495145631
  - 0.21209675505020534
  train_level5__tp_micro_masked:
  - 0.11715747269459421
  - 0.11794388377509149
  - 0.1173570825503173
  - 0.118512205850011
  - 0.11578919049796885
  train_level5__tp_micro_oob:
  - 0.21327511343123384
  - 0.21405688293267466
  - 0.21371239065654138
  - 0.21473300970873788
  - 0.21159826239703752
  train_level5__tp_samples:
  - 0.21427525979411616
  - 0.21476608544667525
  - 0.2143131788907046
  - 0.21538834951456307
  - 0.21209675505020528
  train_level5__tp_samples_masked:
  - 0.11746679738759859
  - 0.11831780778633749
  - 0.11782515919847805
  - 0.11884114259360745
  - 0.11612841995318465
  train_level5__tp_samples_oob:
  - 0.2132751134312338
  - 0.2140568829326746
  - 0.21371239065654135
  - 0.2147330097087378
  - 0.21159826239703747
  train_level5__tp_weighted:
  - 0.31786835101723626
  - 0.3191085973218767
  - 0.3183413833733717
  - 0.3202510165780419
  - 0.31223550027048086
  train_level5__tp_weighted_masked:
  - 0.20464755222884357
  - 0.2069363444331151
  - 0.2058252002910229
  - 0.20726780476620343
  - 0.19939583199198838
  train_level5__tp_weighted_oob:
  - 0.31628535015592063
  - 0.31817808477635806
  - 0.31749834034640756
  - 0.3195232509644458
  - 0.31146000627733633
  train_level6__average_precision_macro:
  - 0.39009217970401033
  - 0.39856175700132856
  - 0.39741282867768724
  - 0.39130527505272766
  - 0.391917973103559
  train_level6__average_precision_macro_masked:
  - 0.25809518517724583
  - 0.2655872583590227
  - 0.2633007305193363
  - 0.26066161859279785
  - 0.2559253543103491
  train_level6__average_precision_macro_oob:
  - 0.38505352406340904
  - 0.3942806676517606
  - 0.39319314241622544
  - 0.3874334134700316
  - 0.38776815867333236
  train_level6__average_precision_micro:
  - 0.31892666269833925
  - 0.327507093264978
  - 0.3350732991627065
  - 0.3155264940988408
  - 0.3234289121438469
  train_level6__average_precision_micro_masked:
  - 0.17956266851930394
  - 0.18482786180554947
  - 0.19031478192617235
  - 0.1780224473324806
  - 0.18040547770780868
  train_level6__average_precision_micro_oob:
  - 0.32012444011970376
  - 0.3273176122304099
  - 0.3360153988092187
  - 0.31616182416616634
  - 0.32351027695838847
  train_level6__average_precision_samples:
  - 0.325428821417008
  - 0.3324764181490927
  - 0.3444109275625619
  - 0.32430480469469986
  - 0.326111587294079
  train_level6__average_precision_samples_masked:
  - 0.19611767847513129
  - 0.20259189718370568
  - 0.21080421857925036
  - 0.19636234205641231
  - 0.19680696266587683
  train_level6__average_precision_samples_oob:
  - 0.32600957657596774
  - 0.3323820804720739
  - 0.34455553749900275
  - 0.32470813011155486
  - 0.3264451250994842
  train_level6__average_precision_weighted:
  - 0.5257626480057679
  - 0.5338211667424335
  - 0.532106309186806
  - 0.5287497337184156
  - 0.5239552101799928
  train_level6__average_precision_weighted_masked:
  - 0.3716856143464266
  - 0.37850622541675794
  - 0.3759433629432579
  - 0.3757996171433467
  - 0.36573954702011985
  train_level6__average_precision_weighted_oob:
  - 0.5195349549103876
  - 0.5288801961363893
  - 0.5266781635233826
  - 0.5233459645596188
  - 0.5193201159255265
  train_level6__f1_macro:
  - 0.4882421817826999
  - 0.478956249541464
  - 0.4814957223877728
  - 0.4643203883495146
  - 0.4907541481710067
  train_level6__f1_macro_masked:
  - 0.4366402198557902
  - 0.42727657200193053
  - 0.42891643336297697
  - 0.41055781342583064
  - 0.4400968235795449
  train_level6__f1_macro_oob:
  - 0.487022491096258
  - 0.4771710156269106
  - 0.4793328847447852
  - 0.4621844660194176
  - 0.4886652265767797
  train_level6__f1_micro:
  - 0.4882421817826999
  - 0.4789562495414639
  - 0.4814957223877728
  - 0.46432038834951456
  - 0.4907541481710067
  train_level6__f1_micro_masked:
  - 0.4278722521775197
  - 0.41746146168348675
  - 0.41991448103058526
  - 0.40048383549593136
  - 0.43151919507142666
  train_level6__f1_micro_oob:
  - 0.487022491096258
  - 0.47717101562691056
  - 0.47933288474478514
  - 0.4621844660194175
  - 0.48866522657677974
  train_level6__f1_samples:
  - 0.48824218178269985
  - 0.47895624954146393
  - 0.4814957223877727
  - 0.46432038834951456
  - 0.49075414817100677
  train_level6__f1_samples_masked:
  - 0.4288420503727495
  - 0.41873379809996875
  - 0.4210316897705832
  - 0.40161139515703026
  - 0.4331146558322832
  train_level6__f1_samples_oob:
  - 0.4870224910962579
  - 0.4771710156269105
  - 0.4793328847447851
  - 0.46218446601941743
  - 0.48866522657677974
  train_level6__f1_weighted:
  - 0.5704103303487988
  - 0.5681366893014411
  - 0.566098436519902
  - 0.5578831717234907
  - 0.5715365937467616
  train_level6__f1_weighted_masked:
  - 0.5027940189493202
  - 0.5009606561402544
  - 0.49749742493758237
  - 0.4877076239627009
  - 0.5050820686612435
  train_level6__f1_weighted_oob:
  - 0.5679435265619388
  - 0.5661316000853364
  - 0.5630533661231407
  - 0.5554121050985297
  - 0.5682918158112515
  train_level6__fn_macro:
  - -0.020320046836122357
  - -0.020004401946638623
  - -0.019393444198788815
  - -0.017451456310679608
  - -0.021625086049327037
  train_level6__fn_macro_masked:
  - -0.016367945855762574
  - -0.015603158115078895
  - -0.015657634138704603
  - -0.013597941923437228
  - -0.01714358014089662
  train_level6__fn_macro_oob:
  - -0.02112504268917402
  - -0.020346775574087206
  - -0.020330673844083443
  - -0.018131067961165048
  - -0.022360956156384268
  train_level6__fn_micro:
  - -0.02032004683612236
  - -0.020004401946638623
  - -0.01939344419878881
  - -0.01745145631067961
  - -0.021625086049327034
  train_level6__fn_micro_masked:
  - -0.015069818885662934
  - -0.014500388155705889
  - -0.014434730506304982
  - -0.012563228502309214
  - -0.015845686153183932
  train_level6__fn_micro_oob:
  - -0.021125042689174027
  - -0.020346775574087206
  - -0.02033067384408344
  - -0.018131067961165048
  - -0.022360956156384268
  train_level6__fn_samples:
  - -0.020320046836122357
  - -0.020004401946638623
  - -0.01939344419878881
  - -0.01745145631067961
  - -0.021625086049327034
  train_level6__fn_samples_masked:
  - -0.014953508189817553
  - -0.014435771881917837
  - -0.014359347543223072
  - -0.0125032622770689
  - -0.015767796435325523
  train_level6__fn_samples_oob:
  - -0.021125042689174024
  - -0.020346775574087202
  - -0.02033067384408344
  - -0.018131067961165048
  - -0.022360956156384264
  train_level6__fn_weighted:
  - -0.030643382381780892
  - -0.029278081286280084
  - -0.02898268572108264
  - -0.02553174851423209
  - -0.031718646415893864
  train_level6__fn_weighted_masked:
  - -0.026179714169697974
  - -0.023929656925379662
  - -0.024983573563439023
  - -0.02149875958990545
  - -0.026971797347829958
  train_level6__fn_weighted_oob:
  - -0.03177611441534867
  - -0.029371762329356833
  - -0.030269743269634494
  - -0.02642816181837139
  - -0.03298031167520091
  train_level6__fp_macro:
  - -0.4914377713811779
  - -0.5010393485118975
  - -0.4991108334134385
  - -0.5182281553398057
  - -0.4876207657796663
  train_level6__fp_macro_masked:
  - -0.5469918342884472
  - -0.5571202698829906
  - -0.5554259324983185
  - -0.575844244650732
  - -0.5427595962795585
  train_level6__fp_macro_oob:
  - -0.4918524662145681
  - -0.5024822087990022
  - -0.5003364414111315
  - -0.5196844660194175
  - -0.48897381726683614
  train_level6__fp_micro:
  - -0.4914377713811777
  - -0.5010393485118975
  - -0.4991108334134384
  - -0.5182281553398058
  - -0.48762076577966623
  train_level6__fp_micro_masked:
  - -0.5570579289368174
  - -0.5680381501608074
  - -0.5656507884631097
  - -0.5869529360017594
  - -0.5526351187753894
  train_level6__fp_micro_oob:
  - -0.49185246621456796
  - -0.5024822087990022
  - -0.5003364414111314
  - -0.5196844660194174
  - -0.488973817266836
  train_level6__fp_samples:
  - -0.49143777138117767
  - -0.5010393485118975
  - -0.4991108334134384
  - -0.5182281553398058
  - -0.48762076577966623
  train_level6__fp_samples_masked:
  - -0.5562044414374331
  - -0.5668304300181134
  - -0.5646089626861938
  - -0.5858853425659009
  - -0.5511175477323913
  train_level6__fp_samples_oob:
  - -0.4918524662145679
  - -0.5024822087990022
  - -0.5003364414111314
  - -0.5196844660194175
  - -0.48897381726683603
  train_level6__fp_weighted:
  - -0.3989462872694203
  - -0.40258522941227876
  - -0.40491887775901525
  - -0.41658507976227716
  - -0.39674475983734464
  train_level6__fp_weighted_masked:
  - -0.471026266880982
  - -0.4751096869343659
  - -0.47751900149897847
  - -0.49079361644739367
  - -0.46794613399092655
  train_level6__fp_weighted_oob:
  - -0.4002803590227127
  - -0.4044966375853069
  - -0.40667689060722473
  - -0.41815973308309873
  - -0.3987278725135475
  train_level6__jaccard_macro:
  - 0.3441734070597135
  - 0.33814188051003835
  - 0.33879201540478454
  - 0.3253233256603087
  - 0.3460980824071359
  train_level6__jaccard_macro_masked:
  - 0.2986603717016687
  - 0.29322090534004314
  - 0.2924669215651196
  - 0.2787908144872326
  - 0.30120971531611745
  train_level6__jaccard_macro_oob:
  - 0.3431663234120068
  - 0.3367595231582757
  - 0.33694965394331405
  - 0.32350916086911835
  - 0.34417275362813793
  train_level6__jaccard_micro:
  - 0.3229632259209656
  - 0.3148865700918051
  - 0.3170855225675761
  - 0.3023549865655129
  - 0.3251651462724127
  train_level6__jaccard_micro_masked:
  - 0.2721612494723512
  - 0.26379228788170783
  - 0.2657542746828461
  - 0.2503781108208442
  - 0.2751192068882714
  train_level6__jaccard_micro_oob:
  - 0.3218967157344856
  - 0.31334511000481774
  - 0.3152122380606214
  - 0.30054610309668867
  - 0.32333354275303133
  train_level6__jaccard_samples:
  - 0.3291785618961972
  - 0.32082212890358597
  - 0.32283302868641434
  - 0.3081264628448431
  - 0.331073947886488
  train_level6__jaccard_samples_masked:
  - 0.2788678184284268
  - 0.2701435486543659
  - 0.27217537389101704
  - 0.25665225935697733
  - 0.28158723142463876
  train_level6__jaccard_samples_oob:
  - 0.3279129112815445
  - 0.3191470076885631
  - 0.32084789110455975
  - 0.3062656217663174
  - 0.3292360899949921
  train_level6__jaccard_weighted:
  - 0.41840502343237335
  - 0.4176842131971665
  - 0.4140438811139417
  - 0.40739907484549864
  - 0.41800046892986276
  train_level6__jaccard_weighted_masked:
  - 0.3534055049122269
  - 0.35367456769872563
  - 0.34798509548544015
  - 0.34053542921620283
  - 0.35385760139011035
  train_level6__jaccard_weighted_oob:
  - 0.4161010111687246
  - 0.41585355403664964
  - 0.41111099788972244
  - 0.40500135811877497
  - 0.4147639300628795
  train_level6__label_ranking_average_precision_score:
  - 0.325428821417008
  - 0.3324764181490926
  - 0.3444109275625617
  - 0.32430480469469963
  - 0.32611158729407885
  train_level6__label_ranking_average_precision_score_oob:
  - 0.32600957657596785
  - 0.3323820804720743
  - 0.3445555374990027
  - 0.32470813011155464
  - 0.3264451250994844
  train_level6__matthews_corrcoef_macro:
  - 0.24297830271041557
  - 0.23732808454234183
  - 0.2387581967737091
  - 0.2326046811611265
  - 0.24255113439002018
  train_level6__matthews_corrcoef_macro_masked:
  - 0.17877808062336242
  - 0.1747089411600547
  - 0.17561748264642021
  - 0.17326978848526722
  - 0.17762413654445683
  train_level6__matthews_corrcoef_macro_oob:
  - 0.23728315996433008
  - 0.23255754249201846
  - 0.2313468867846213
  - 0.2269616678198932
  - 0.2378882885154539
  train_level6__matthews_corrcoef_micro:
  - 0.2522461468857778
  - 0.24436371428680792
  - 0.24871737507970507
  - 0.23856386340596128
  - 0.25039392269463956
  train_level6__matthews_corrcoef_micro_masked:
  - 0.17637729508895203
  - 0.1721667861522658
  - 0.17382038982757103
  - 0.16927235711536984
  - 0.17495484495671107
  train_level6__matthews_corrcoef_micro_oob:
  - 0.24845514619877304
  - 0.24150421260009583
  - 0.2435409690179566
  - 0.23417639530513046
  - 0.2460015592795377
  train_level6__matthews_corrcoef_samples:
  - 0.24965469307729296
  - 0.24156641160039863
  - 0.24831466099526822
  - 0.2360031800314485
  - 0.24902070043793484
  train_level6__matthews_corrcoef_samples_masked:
  - 0.17460020929259193
  - 0.1696535259451128
  - 0.1736743612668319
  - 0.16643554453151954
  - 0.17340205262097574
  train_level6__matthews_corrcoef_samples_oob:
  - 0.24616064456351794
  - 0.23859791196398877
  - 0.24292452740167886
  - 0.23154555215876954
  - 0.24446370915205856
  train_level6__matthews_corrcoef_weighted:
  - 0.27555561757484776
  - 0.27266665398237977
  - 0.27084439509949915
  - 0.2732586938889941
  - 0.27807398966083313
  train_level6__matthews_corrcoef_weighted_masked:
  - 0.20539101347365488
  - 0.20725325384045978
  - 0.20285860983391982
  - 0.20981740813163197
  - 0.2095653794042305
  train_level6__matthews_corrcoef_weighted_oob:
  - 0.2674196339453179
  - 0.2665069199087654
  - 0.261320005076105
  - 0.2657120583193394
  - 0.2703399876769756
  train_level6__ndcg:
  - 0.6686274058760775
  - 0.6748242202324282
  - 0.6829623762622727
  - 0.666602376752224
  - 0.6678629009697191
  train_level6__ndcg_oob:
  - 0.6712134023180585
  - 0.6754976477856496
  - 0.6855468401404398
  - 0.6688614337238953
  - 0.669847571593032
  train_level6__neg_coverage_error:
  - -81.8140703517588
  - -81.46851385390428
  - -81.29455445544555
  - -83.0025
  - -81.84596577017115
  train_level6__neg_coverage_error_oob:
  - -82.79145728643216
  - -82.49370277078086
  - -82.29455445544555
  - -83.88
  - -82.84596577017115
  train_level6__neg_hamming_loss_macro:
  - -0.5117578182173002
  - -0.521043750458536
  - -0.5185042776122272
  - -0.5356796116504854
  - -0.5092458518289933
  train_level6__neg_hamming_loss_macro_masked:
  - -0.5633597801442097
  - -0.5727234279980695
  - -0.5710835666370231
  - -0.5894421865741694
  - -0.5599031764204552
  train_level6__neg_hamming_loss_macro_oob:
  - -0.512977508903742
  - -0.5228289843730893
  - -0.5206671152552148
  - -0.5378155339805825
  - -0.5113347734232203
  train_level6__neg_hamming_loss_micro:
  - -0.5117578182173
  - -0.5210437504585361
  - -0.5185042776122273
  - -0.5356796116504854
  - -0.5092458518289933
  train_level6__neg_hamming_loss_micro_masked:
  - -0.5721277478224803
  - -0.5825385383165133
  - -0.5800855189694147
  - -0.5995161645040686
  - -0.5684808049285733
  train_level6__neg_hamming_loss_micro_oob:
  - -0.512977508903742
  - -0.5228289843730894
  - -0.5206671152552148
  - -0.5378155339805826
  - -0.5113347734232203
  train_level6__neg_hamming_loss_samples:
  - -0.5117578182173
  - -0.5210437504585361
  - -0.5185042776122273
  - -0.5356796116504854
  - -0.5092458518289933
  train_level6__neg_hamming_loss_samples_masked:
  - -0.5711579496272506
  - -0.5812662019000313
  - -0.5789683102294167
  - -0.5983886048429697
  - -0.5668853441677169
  train_level6__neg_hamming_loss_samples_oob:
  - -0.512977508903742
  - -0.5228289843730894
  - -0.5206671152552149
  - -0.5378155339805825
  - -0.5113347734232202
  train_level6__neg_hamming_loss_weighted:
  - -0.42958966965120116
  - -0.4318633106985589
  - -0.4339015634800979
  - -0.4421168282765092
  - -0.4284634062532384
  train_level6__neg_hamming_loss_weighted_masked:
  - -0.49720598105067987
  - -0.4990393438597455
  - -0.5025025750624177
  - -0.512292376037299
  - -0.4949179313387565
  train_level6__neg_hamming_loss_weighted_oob:
  - -0.4320564734380613
  - -0.4338683999146637
  - -0.4369466338768594
  - -0.44458789490147027
  - -0.43170818418874857
  train_level6__neg_label_ranking_loss:
  - -0.3855934317291701
  - -0.37665239178084364
  - -0.3602142717901805
  - -0.3796559883935909
  - -0.38264161384536155
  train_level6__neg_label_ranking_loss_oob:
  - -0.3912819075571829
  - -0.38102378825851513
  - -0.36628642778245185
  - -0.38399750876811084
  - -0.38710330908843293
  train_level6__precision_macro:
  - 0.4882421817826999
  - 0.478956249541464
  - 0.4814957223877728
  - 0.4643203883495146
  - 0.4907541481710067
  train_level6__precision_macro_masked:
  - 0.4366402198557902
  - 0.42727657200193053
  - 0.42891643336297697
  - 0.41055781342583064
  - 0.4400968235795449
  train_level6__precision_macro_oob:
  - 0.487022491096258
  - 0.4771710156269106
  - 0.4793328847447852
  - 0.4621844660194176
  - 0.4886652265767797
  train_level6__precision_micro:
  - 0.4882421817826999
  - 0.4789562495414639
  - 0.4814957223877728
  - 0.46432038834951456
  - 0.4907541481710067
  train_level6__precision_micro_masked:
  - 0.4278722521775197
  - 0.41746146168348675
  - 0.41991448103058526
  - 0.40048383549593136
  - 0.43151919507142666
  train_level6__precision_micro_oob:
  - 0.487022491096258
  - 0.47717101562691056
  - 0.47933288474478514
  - 0.4621844660194175
  - 0.48866522657677974
  train_level6__precision_samples:
  - 0.48824218178269985
  - 0.47895624954146393
  - 0.4814957223877727
  - 0.46432038834951456
  - 0.49075414817100677
  train_level6__precision_samples_masked:
  - 0.4288420503727495
  - 0.41873379809996875
  - 0.4210316897705832
  - 0.40161139515703026
  - 0.4331146558322832
  train_level6__precision_samples_oob:
  - 0.4870224910962579
  - 0.4771710156269105
  - 0.4793328847447851
  - 0.46218446601941743
  - 0.48866522657677974
  train_level6__precision_weighted:
  - 0.5704103303487988
  - 0.5681366893014411
  - 0.566098436519902
  - 0.5578831717234907
  - 0.5715365937467616
  train_level6__precision_weighted_masked:
  - 0.5027940189493202
  - 0.5009606561402544
  - 0.49749742493758237
  - 0.4877076239627009
  - 0.5050820686612435
  train_level6__precision_weighted_oob:
  - 0.5679435265619388
  - 0.5661316000853364
  - 0.5630533661231407
  - 0.5554121050985297
  - 0.5682918158112515
  train_level6__recall_macro:
  - 0.4882421817826999
  - 0.478956249541464
  - 0.4814957223877728
  - 0.4643203883495146
  - 0.4907541481710067
  train_level6__recall_macro_masked:
  - 0.4366402198557902
  - 0.42727657200193053
  - 0.42891643336297697
  - 0.41055781342583064
  - 0.4400968235795449
  train_level6__recall_macro_oob:
  - 0.487022491096258
  - 0.4771710156269106
  - 0.4793328847447852
  - 0.4621844660194176
  - 0.4886652265767797
  train_level6__recall_micro:
  - 0.4882421817826999
  - 0.4789562495414639
  - 0.4814957223877728
  - 0.46432038834951456
  - 0.4907541481710067
  train_level6__recall_micro_masked:
  - 0.4278722521775197
  - 0.41746146168348675
  - 0.41991448103058526
  - 0.40048383549593136
  - 0.43151919507142666
  train_level6__recall_micro_oob:
  - 0.487022491096258
  - 0.47717101562691056
  - 0.47933288474478514
  - 0.4621844660194175
  - 0.48866522657677974
  train_level6__recall_samples:
  - 0.48824218178269985
  - 0.47895624954146393
  - 0.4814957223877727
  - 0.46432038834951456
  - 0.49075414817100677
  train_level6__recall_samples_masked:
  - 0.4288420503727495
  - 0.41873379809996875
  - 0.4210316897705832
  - 0.40161139515703026
  - 0.4331146558322832
  train_level6__recall_samples_oob:
  - 0.4870224910962579
  - 0.4771710156269105
  - 0.4793328847447851
  - 0.46218446601941743
  - 0.48866522657677974
  train_level6__recall_weighted:
  - 0.5704103303487988
  - 0.5681366893014411
  - 0.566098436519902
  - 0.5578831717234907
  - 0.5715365937467616
  train_level6__recall_weighted_masked:
  - 0.5027940189493202
  - 0.5009606561402544
  - 0.49749742493758237
  - 0.4877076239627009
  - 0.5050820686612435
  train_level6__recall_weighted_oob:
  - 0.5679435265619388
  - 0.5661316000853364
  - 0.5630533661231407
  - 0.5554121050985297
  - 0.5682918158112515
  train_level6__roc_auc_macro:
  - 0.7207822494174885
  - 0.7230040857920651
  - 0.7272583696682217
  - 0.7231686742247647
  - 0.7192756204684332
  train_level6__roc_auc_macro_masked:
  - 0.7021026673310473
  - 0.7023015619049755
  - 0.7081307673828974
  - 0.7006956641392539
  - 0.6931781572569147
  train_level6__roc_auc_macro_oob:
  - 0.7144525665326518
  - 0.7169702047268168
  - 0.7211197831498753
  - 0.7163542038060223
  - 0.7134257210843304
  train_level6__roc_auc_micro:
  - 0.6682702609418746
  - 0.67230772459587
  - 0.679377622350656
  - 0.6633180089482149
  - 0.6705484076348448
  train_level6__roc_auc_micro_masked:
  - 0.6475961753176069
  - 0.6513421572796447
  - 0.6589733432667837
  - 0.6442964536598439
  - 0.6468622405579457
  train_level6__roc_auc_micro_oob:
  - 0.6674402679912839
  - 0.6706948041226279
  - 0.678146055753597
  - 0.6621666819571755
  - 0.6689970107552409
  train_level6__roc_auc_samples:
  - 0.6517241730005583
  - 0.6550382132224652
  - 0.6664238504878285
  - 0.6470123210857522
  - 0.6509559332742205
  train_level6__roc_auc_samples_masked:
  - 0.6319747038693322
  - 0.637591625445141
  - 0.6480158331862428
  - 0.6284484713239662
  - 0.6315973717981437
  train_level6__roc_auc_samples_oob:
  - 0.6511409602293213
  - 0.6537604471939963
  - 0.665360193361383
  - 0.6461214824416094
  - 0.6502670849848854
  train_level6__roc_auc_weighted:
  - 0.7235994745888732
  - 0.7248000596723738
  - 0.7290243793257603
  - 0.7287835524936588
  - 0.7238794489375755
  train_level6__roc_auc_weighted_masked:
  - 0.6990515692554429
  - 0.6993894827382341
  - 0.7039437260175981
  - 0.706522167991374
  - 0.6954014726679097
  train_level6__roc_auc_weighted_oob:
  - 0.716016330984562
  - 0.7176542213769146
  - 0.721367821379881
  - 0.7199050099114822
  - 0.7170088580028406
  train_level6__tn_macro:
  - 0.2741620724984144
  - 0.26421461935389207
  - 0.26684610208593673
  - 0.2489805825242718
  - 0.2782775891945783
  train_level6__tn_macro_masked:
  - 0.3093409377299768
  - 0.29898021487418774
  - 0.3011249976752716
  - 0.2818092655998829
  - 0.31416629412171254
  train_level6__tn_macro_oob:
  - 0.27374737766502416
  - 0.2627717590667873
  - 0.2656204940882438
  - 0.24752427184466017
  - 0.2769245377074086
  train_level6__tn_micro:
  - 0.2741620724984144
  - 0.26421461935389207
  - 0.26684610208593673
  - 0.24898058252427185
  - 0.2782775891945783
  train_level6__tn_micro_masked:
  - 0.3107700815705793
  - 0.29954530331595874
  - 0.30242122177737835
  - 0.2819991202990983
  - 0.31538026956498344
  train_level6__tn_micro_oob:
  - 0.27374737766502416
  - 0.2627717590667873
  - 0.2656204940882438
  - 0.2475242718446602
  - 0.27692453770740855
  train_level6__tn_samples:
  - 0.27416207249841434
  - 0.264214619353892
  - 0.2668461020859367
  - 0.24898058252427177
  - 0.27827758919457823
  train_level6__tn_samples_masked:
  - 0.31143349569409634
  - 0.30044303885065504
  - 0.3030729028634837
  - 0.2827954073205492
  - 0.3166354263455422
  train_level6__tn_samples_oob:
  - 0.2737473776650241
  - 0.2627717590667873
  - 0.26562049408824373
  - 0.24752427184466014
  - 0.27692453770740844
  train_level6__tn_weighted:
  - 0.25288634869633836
  - 0.24930887269690932
  - 0.24735522890003342
  - 0.23778959441142736
  - 0.25865575752226694
  train_level6__tn_weighted_masked:
  - 0.298356150914504
  - 0.29439127406194376
  - 0.2915867136539127
  - 0.2805522328492138
  - 0.30503511464323985
  train_level6__tn_weighted_oob:
  - 0.25155227694304594
  - 0.24739746452388117
  - 0.2455972160518239
  - 0.23621494109060576
  - 0.25667264484606395
  train_level6__tp_macro:
  - 0.2140801092842855
  - 0.21474163018757178
  - 0.21464962030183604
  - 0.21533980582524267
  - 0.21247655897642845
  train_level6__tp_macro_masked:
  - 0.12729928212581346
  - 0.12829635712774273
  - 0.12779143568770526
  - 0.1287485478259479
  - 0.1259305294578325
  train_level6__tp_macro_oob:
  - 0.21327511343123387
  - 0.2143992565601232
  - 0.2137123906565414
  - 0.21466019417475726
  - 0.21174068886937122
  train_level6__tp_micro:
  - 0.2140801092842855
  - 0.21474163018757184
  - 0.214649620301836
  - 0.21533980582524273
  - 0.21247655897642842
  train_level6__tp_micro_masked:
  - 0.1171021706069404
  - 0.117916158367528
  - 0.11749325925320696
  - 0.11848471519683308
  - 0.1161389255064432
  train_level6__tp_micro_oob:
  - 0.21327511343123384
  - 0.21439925656012326
  - 0.21371239065654138
  - 0.2146601941747573
  - 0.2117406888693712
  train_level6__tp_samples:
  - 0.21408010928428547
  - 0.21474163018757175
  - 0.21464962030183593
  - 0.21533980582524265
  - 0.21247655897642836
  train_level6__tp_samples_masked:
  - 0.11740855467865312
  - 0.11829075924931366
  - 0.11795878690709947
  - 0.11881598783648104
  - 0.11647922948674097
  train_level6__tp_samples_oob:
  - 0.2132751134312338
  - 0.2143992565601232
  - 0.21371239065654135
  - 0.2146601941747572
  - 0.21174068886937114
  train_level6__tp_weighted:
  - 0.31752398165246043
  - 0.3188278166045318
  - 0.3187432076198687
  - 0.3200935773120634
  - 0.3128808362244947
  train_level6__tp_weighted_masked:
  - 0.20443786803481606
  - 0.20656938207831066
  - 0.20591071128366975
  - 0.20715539111348716
  - 0.20004695401800374
  train_level6__tp_weighted_oob:
  - 0.31639124961889264
  - 0.3187341355614551
  - 0.31745615007131683
  - 0.3191971640079241
  - 0.31161917096518765
  train_level7__average_precision_macro:
  - 0.39572035480135137
  - 0.3973170782433964
  - 0.40022264150817477
  - 0.39001616329751393
  - 0.3860891624089299
  train_level7__average_precision_macro_masked:
  - 0.26340823842067795
  - 0.2649595123966184
  - 0.266680918151769
  - 0.25995042856441825
  - 0.2513068924599297
  train_level7__average_precision_macro_oob:
  - 0.3891279794834333
  - 0.39387585305735195
  - 0.3966083649720885
  - 0.38546936348822247
  - 0.382399937455489
  train_level7__average_precision_micro:
  - 0.3225509555678056
  - 0.3236819376198402
  - 0.33757352959463266
  - 0.3147288988625858
  - 0.3193617890077176
  train_level7__average_precision_micro_masked:
  - 0.18224900343966027
  - 0.1825492367819221
  - 0.19243986684914194
  - 0.17717894079112995
  - 0.17831142255487914
  train_level7__average_precision_micro_oob:
  - 0.322363605723761
  - 0.32488836958228384
  - 0.33873370386620744
  - 0.3148709209497674
  - 0.32014501274687057
  train_level7__average_precision_samples:
  - 0.32843866928324883
  - 0.3288661021718155
  - 0.3440168656738859
  - 0.3226366764829358
  - 0.3250417696475462
  train_level7__average_precision_samples_masked:
  - 0.1982596830976458
  - 0.19986832793589754
  - 0.2108005612125495
  - 0.19500067669484494
  - 0.19548591360123999
  train_level7__average_precision_samples_oob:
  - 0.3287710930901008
  - 0.3297354117385474
  - 0.34481675297907455
  - 0.3230333439356153
  - 0.3257850880557384
  train_level7__average_precision_weighted:
  - 0.5308456882293829
  - 0.5336580431039916
  - 0.534776423288073
  - 0.5279753205429776
  - 0.5193561838676425
  train_level7__average_precision_weighted_masked:
  - 0.37687444052405983
  - 0.37849385896879023
  - 0.3803553574688198
  - 0.37598396581806826
  - 0.3616926891746533
  train_level7__average_precision_weighted_oob:
  - 0.5225490139572
  - 0.5299649031712952
  - 0.5297848688021204
  - 0.5222111412569296
  - 0.5153586843624116
  train_level7__f1_macro:
  - 0.4883153632238864
  - 0.4789807048005675
  - 0.4816639430933385
  - 0.4647572815533981
  - 0.4912526408241745
  train_level7__f1_macro_masked:
  - 0.4366538871620016
  - 0.42727617196908957
  - 0.429126808748218
  - 0.41100901874701745
  - 0.4405232773733355
  train_level7__f1_macro_oob:
  - 0.48646143338049475
  - 0.47675527622215164
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.48966221188311526
  train_level7__f1_micro:
  - 0.4883153632238864
  - 0.47898070480056737
  - 0.4816639430933385
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__f1_micro_masked:
  - 0.42781695008986587
  - 0.41743373627592323
  - 0.4201051284146308
  - 0.400951176599956
  - 0.4319227354658201
  train_level7__f1_micro_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.4896622118831153
  train_level7__f1_samples:
  - 0.48831536322388636
  - 0.47898070480056737
  - 0.48166394309333843
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__f1_samples_masked:
  - 0.42875821105106104
  - 0.4187032407886575
  - 0.42122655475230814
  - 0.40207475315129104
  - 0.43348373536833473
  train_level7__f1_samples_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.47904450639238677
  - 0.46259708737864075
  - 0.4896622118831154
  train_level7__f1_weighted:
  - 0.5709173403702874
  - 0.568292299549465
  - 0.5663098962119234
  - 0.5583158690438953
  - 0.5723696051971979
  train_level7__f1_weighted_masked:
  - 0.5033360898882304
  - 0.5011614931058447
  - 0.4978673976163754
  - 0.4880335064138486
  - 0.5056786884874291
  train_level7__f1_weighted_oob:
  - 0.5678078183612411
  - 0.5658618406671768
  - 0.5631911199128948
  - 0.5557155145448855
  - 0.5697260334424347
  train_level7__fn_macro:
  - -0.02010050251256281
  - -0.020224499278569858
  - -0.019441507257521872
  - -0.017402912621359224
  - -0.021458921831604433
  train_level7__fn_macro_masked:
  - -0.01622736946430997
  - -0.01594603562983531
  - -0.015714218499845674
  - -0.013554809328687857
  - -0.017127208921779963
  train_level7__fn_macro_oob:
  - -0.021125042689174027
  - -0.020591328165121908
  - -0.020258579255983854
  - -0.018009708737864078
  - -0.022242267429439553
  train_level7__fn_micro:
  - -0.020100502512562814
  - -0.020224499278569858
  - -0.01944150725752187
  - -0.017402912621359224
  - -0.021458921831604433
  train_level7__fn_micro_masked:
  - -0.014959214710355316
  - -0.014805367638904292
  - -0.014489201187460849
  - -0.012535737849131295
  - -0.01581878346022437
  train_level7__fn_micro_oob:
  - -0.021125042689174027
  - -0.020591328165121908
  - -0.02025857925598385
  - -0.018009708737864078
  - -0.022242267429439553
  train_level7__fn_samples:
  - -0.020100502512562814
  - -0.020224499278569855
  - -0.01944150725752187
  - -0.01740291262135922
  - -0.021458921831604433
  train_level7__fn_samples_masked:
  - -0.014839317853585944
  - -0.01474753159768003
  - -0.014410032974222078
  - -0.012480177666903737
  - -0.01573973533175408
  train_level7__fn_samples_oob:
  - -0.021125042689174024
  - -0.020591328165121908
  - -0.020258579255983847
  - -0.018009708737864075
  - -0.02224226742943955
  train_level7__fn_weighted:
  - -0.03027443388238936
  - -0.029704763011890144
  - -0.029106714963518122
  - -0.025331300177249504
  - -0.03144320721308582
  train_level7__fn_weighted_masked:
  - -0.025811027759652005
  - -0.024556730461308893
  - -0.02505679561131406
  - -0.02133830607609843
  - -0.02703475023424403
  train_level7__fn_weighted_oob:
  - -0.03179624838732113
  - -0.030086309893216732
  - -0.030255510405748455
  - -0.026092691064539666
  - -0.03269123686829346
  train_level7__fp_macro:
  - -0.4915841342635508
  - -0.5007947959208626
  - -0.49889454964913965
  - -0.5178398058252427
  - -0.48728843734422106
  train_level7__fp_macro_masked:
  - -0.5471187433736885
  - -0.5567777924010751
  - -0.5551589727519362
  - -0.5754361719242946
  - -0.5423495137048845
  train_level7__fp_macro_oob:
  - -0.4924135239303314
  - -0.5026533956127265
  - -0.5006969143516294
  - -0.5193932038834952
  - -0.48809552068744516
  train_level7__fp_micro:
  - -0.49158413426355074
  - -0.5007947959208627
  - -0.49889454964913965
  - -0.5178398058252427
  - -0.48728843734422106
  train_level7__fp_micro_masked:
  - -0.5572238351997788
  - -0.5677608960851724
  - -0.5654056703979083
  - -0.5865130855509126
  - -0.5522584810739555
  train_level7__fp_micro_oob:
  - -0.4924135239303313
  - -0.5026533956127265
  - -0.5006969143516293
  - -0.5193932038834952
  - -0.4880955206874451
  train_level7__fp_samples:
  - -0.4915841342635507
  - -0.5007947959208628
  - -0.4988945496491397
  - -0.5178398058252427
  - -0.48728843734422106
  train_level7__fp_samples_masked:
  - -0.556402471095353
  - -0.5665492276136626
  - -0.5643634122734698
  - -0.5854450691818052
  - -0.5507765292999112
  train_level7__fp_samples_oob:
  - -0.4924135239303313
  - -0.5026533956127265
  - -0.5006969143516293
  - -0.5193932038834952
  - -0.4880955206874451
  train_level7__fp_weighted:
  - -0.39880822574732333
  - -0.40200293743864485
  - -0.40458338882455863
  - -0.4163528307788552
  - -0.3961871875897161
  train_level7__fp_weighted_masked:
  - -0.4708528823521177
  - -0.4742817764328465
  - -0.47707580677231043
  - -0.49062818751005294
  - -0.4672865612783268
  train_level7__fp_weighted_oob:
  - -0.4003959332514378
  - -0.4040518494396064
  - -0.40655336968135675
  - -0.4181917943905745
  - -0.3975827296892719
  train_level7__jaccard_macro:
  - 0.3443466840173599
  - 0.338086199004506
  - 0.3388816078125265
  - 0.3255964296184086
  - 0.3466676427059985
  train_level7__jaccard_macro_masked:
  - 0.29871863251403047
  - 0.29311322216343083
  - 0.2925915657811457
  - 0.2790046961305222
  - 0.30168354211927745
  train_level7__jaccard_macro_oob:
  - 0.3427395185955751
  - 0.33647142231971877
  - 0.33675518052233977
  - 0.3238039874942229
  - 0.34514439061110747
  train_level7__jaccard_micro:
  - 0.32302727126028724
  - 0.3149077111068236
  - 0.3172314461626122
  - 0.30272560551445016
  - 0.32560298305511415
  train_level7__jaccard_micro_masked:
  - 0.27211650075627003
  - 0.2637701471618781
  - 0.26590701442879555
  - 0.25074354874757165
  - 0.2754473553279462
  train_level7__jaccard_micro_oob:
  - 0.32140669825613255
  - 0.31298665853227803
  - 0.31496286933164797
  - 0.30089515479705087
  - 0.3242070851538679
  train_level7__jaccard_samples:
  - 0.32922578009032033
  - 0.3208875541842979
  - 0.32301833571913907
  - 0.308500906903481
  - 0.3314402014878754
  train_level7__jaccard_samples_masked:
  - 0.27881641396218193
  - 0.2701761766625729
  - 0.2723667314808635
  - 0.2570282134500422
  - 0.28181556236677935
  train_level7__jaccard_samples_oob:
  - 0.32751100419988644
  - 0.3188057389994273
  - 0.32054732059499363
  - 0.3065887481531244
  - 0.3300014732881137
  train_level7__jaccard_weighted:
  - 0.41896572098640034
  - 0.4177846785123054
  - 0.41422913874166656
  - 0.4076479955301943
  - 0.4188942987543778
  train_level7__jaccard_weighted_masked:
  - 0.35387792480394104
  - 0.35373856535353976
  - 0.3483186299879363
  - 0.3405885576253243
  - 0.3544629689554253
  train_level7__jaccard_weighted_oob:
  - 0.41602414888116124
  - 0.41565500631631014
  - 0.41138833874660063
  - 0.4052026313048113
  - 0.4162700645047446
  train_level7__label_ranking_average_precision_score:
  - 0.32843866928324866
  - 0.32886610217181533
  - 0.34401686567388573
  - 0.32263667648293565
  - 0.3250417696475461
  train_level7__label_ranking_average_precision_score_oob:
  - 0.32877109309010055
  - 0.3297354117385475
  - 0.34481675297907455
  - 0.32303334393561506
  - 0.3257850880557382
  train_level7__matthews_corrcoef_macro:
  - 0.24404001728336014
  - 0.23776603245567568
  - 0.23849900828530868
  - 0.23373363406686892
  - 0.24373916759879616
  train_level7__matthews_corrcoef_macro_masked:
  - 0.1792819650820326
  - 0.17414804703342526
  - 0.17499166587800363
  - 0.17435236618384334
  - 0.17840951642008393
  train_level7__matthews_corrcoef_macro_oob:
  - 0.23724289442982
  - 0.23315445638236593
  - 0.23189811002024396
  - 0.2269340762080026
  - 0.23993895746980326
  train_level7__matthews_corrcoef_micro:
  - 0.25303063968724604
  - 0.24366303141368473
  - 0.24872077354209682
  - 0.2391500557132377
  - 0.251411023002224
  train_level7__matthews_corrcoef_micro_masked:
  - 0.17688265654865906
  - 0.17063261330895585
  - 0.17368147575671122
  - 0.16973325369293407
  - 0.1753668044192894
  train_level7__matthews_corrcoef_micro_oob:
  - 0.2479117712957349
  - 0.240294828453866
  - 0.24349918914722193
  - 0.23499051515889033
  - 0.2473512668686473
  train_level7__matthews_corrcoef_samples:
  - 0.25065544350865004
  - 0.24081722599570793
  - 0.24826535973426345
  - 0.23657395517336105
  - 0.25001710060024357
  train_level7__matthews_corrcoef_samples_masked:
  - 0.17521677057994992
  - 0.16804147552349183
  - 0.17363134339858813
  - 0.16692290298421442
  - 0.17394876514934846
  train_level7__matthews_corrcoef_samples_oob:
  - 0.2455105243343414
  - 0.23707774950012842
  - 0.24298095063399758
  - 0.23261530462497199
  - 0.2457451156521835
  train_level7__matthews_corrcoef_weighted:
  - 0.2771958385949603
  - 0.27430098077313625
  - 0.270441828676182
  - 0.2738388327759957
  - 0.27971851035896556
  train_level7__matthews_corrcoef_weighted_masked:
  - 0.20698654798475702
  - 0.2076910445638809
  - 0.20231841816127552
  - 0.21007770883434718
  - 0.21014393046975574
  train_level7__matthews_corrcoef_weighted_oob:
  - 0.2676795118699612
  - 0.2677617639805442
  - 0.2626980669914072
  - 0.2650928966719899
  - 0.27387162086022365
  train_level7__ndcg:
  - 0.6729189421617151
  - 0.6707060388054956
  - 0.684804151902938
  - 0.6659333659269495
  - 0.6681182284342103
  train_level7__ndcg_oob:
  - 0.6747793747079159
  - 0.6727775317619389
  - 0.6872167493999168
  - 0.6677449822095275
  - 0.6701063578474827
  train_level7__neg_coverage_error:
  - -81.89447236180905
  - -81.48614609571788
  - -81.37623762376238
  - -83.0175
  - -81.77750611246944
  train_level7__neg_coverage_error_oob:
  - -82.86180904522612
  - -82.51133501259446
  - -82.4059405940594
  - -84.06
  - -82.78973105134475
  train_level7__neg_hamming_loss_macro:
  - -0.5116846367761136
  - -0.5210192951994326
  - -0.5183360569066615
  - -0.535242718446602
  - -0.5087473591758255
  train_level7__neg_hamming_loss_macro_masked:
  - -0.5633461128379984
  - -0.5727238280309105
  - -0.570873191251782
  - -0.5889909812529827
  - -0.5594767226266645
  train_level7__neg_hamming_loss_macro_oob:
  - -0.5135385666195054
  - -0.5232447237778484
  - -0.5209554936076132
  - -0.5374029126213592
  - -0.5103377881168847
  train_level7__neg_hamming_loss_micro:
  - -0.5116846367761135
  - -0.5210192951994327
  - -0.5183360569066615
  - -0.535242718446602
  - -0.5087473591758255
  train_level7__neg_hamming_loss_micro_masked:
  - -0.5721830499101341
  - -0.5825662637240767
  - -0.5798948715853691
  - -0.599048823400044
  - -0.5680772645341798
  train_level7__neg_hamming_loss_micro_oob:
  - -0.5135385666195053
  - -0.5232447237778485
  - -0.5209554936076132
  - -0.5374029126213592
  - -0.5103377881168847
  train_level7__neg_hamming_loss_samples:
  - -0.5116846367761135
  - -0.5210192951994326
  - -0.5183360569066615
  - -0.5352427184466019
  - -0.5087473591758255
  train_level7__neg_hamming_loss_samples_masked:
  - -0.571241788948939
  - -0.5812967592113425
  - -0.5787734452476918
  - -0.597925246848709
  - -0.5665162646316653
  train_level7__neg_hamming_loss_samples_oob:
  - -0.5135385666195054
  - -0.5232447237778485
  - -0.5209554936076132
  - -0.5374029126213592
  - -0.5103377881168847
  train_level7__neg_hamming_loss_weighted:
  - -0.4290826596297127
  - -0.43170770045053497
  - -0.4336901037880766
  - -0.4416841309561047
  - -0.42763039480280185
  train_level7__neg_hamming_loss_weighted_masked:
  - -0.4966639101117697
  - -0.4988385068941553
  - -0.5021326023836246
  - -0.5119664935861514
  - -0.4943213115125708
  train_level7__neg_hamming_loss_weighted_oob:
  - -0.43219218163875894
  - -0.4341381593328231
  - -0.4368088800871051
  - -0.44428448545511434
  - -0.43027396655756533
  train_level7__neg_label_ranking_loss:
  - -0.38418165638972723
  - -0.3775745179391127
  - -0.3652324267980461
  - -0.38171997123837587
  - -0.38410882115748235
  train_level7__neg_label_ranking_loss_oob:
  - -0.3890427668274064
  - -0.3817624219811611
  - -0.3702521014857296
  - -0.38647132591581723
  - -0.3894241663686417
  train_level7__precision_macro:
  - 0.4883153632238864
  - 0.4789807048005675
  - 0.4816639430933385
  - 0.4647572815533981
  - 0.4912526408241745
  train_level7__precision_macro_masked:
  - 0.4366538871620016
  - 0.42727617196908957
  - 0.429126808748218
  - 0.41100901874701745
  - 0.4405232773733355
  train_level7__precision_macro_oob:
  - 0.48646143338049475
  - 0.47675527622215164
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.48966221188311526
  train_level7__precision_micro:
  - 0.4883153632238864
  - 0.47898070480056737
  - 0.4816639430933385
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__precision_micro_masked:
  - 0.42781695008986587
  - 0.41743373627592323
  - 0.4201051284146308
  - 0.400951176599956
  - 0.4319227354658201
  train_level7__precision_micro_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.4896622118831153
  train_level7__precision_samples:
  - 0.48831536322388636
  - 0.47898070480056737
  - 0.48166394309333843
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__precision_samples_masked:
  - 0.42875821105106104
  - 0.4187032407886575
  - 0.42122655475230814
  - 0.40207475315129104
  - 0.43348373536833473
  train_level7__precision_samples_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.47904450639238677
  - 0.46259708737864075
  - 0.4896622118831154
  train_level7__precision_weighted:
  - 0.5709173403702874
  - 0.568292299549465
  - 0.5663098962119234
  - 0.5583158690438953
  - 0.5723696051971979
  train_level7__precision_weighted_masked:
  - 0.5033360898882304
  - 0.5011614931058447
  - 0.4978673976163754
  - 0.4880335064138486
  - 0.5056786884874291
  train_level7__precision_weighted_oob:
  - 0.5678078183612411
  - 0.5658618406671768
  - 0.5631911199128948
  - 0.5557155145448855
  - 0.5697260334424347
  train_level7__recall_macro:
  - 0.4883153632238864
  - 0.4789807048005675
  - 0.4816639430933385
  - 0.4647572815533981
  - 0.4912526408241745
  train_level7__recall_macro_masked:
  - 0.4366538871620016
  - 0.42727617196908957
  - 0.429126808748218
  - 0.41100901874701745
  - 0.4405232773733355
  train_level7__recall_macro_oob:
  - 0.48646143338049475
  - 0.47675527622215164
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.48966221188311526
  train_level7__recall_micro:
  - 0.4883153632238864
  - 0.47898070480056737
  - 0.4816639430933385
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__recall_micro_masked:
  - 0.42781695008986587
  - 0.41743373627592323
  - 0.4201051284146308
  - 0.400951176599956
  - 0.4319227354658201
  train_level7__recall_micro_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.4790445063923868
  - 0.4625970873786408
  - 0.4896622118831153
  train_level7__recall_samples:
  - 0.48831536322388636
  - 0.47898070480056737
  - 0.48166394309333843
  - 0.46475728155339807
  - 0.4912526408241745
  train_level7__recall_samples_masked:
  - 0.42875821105106104
  - 0.4187032407886575
  - 0.42122655475230814
  - 0.40207475315129104
  - 0.43348373536833473
  train_level7__recall_samples_oob:
  - 0.4864614333804947
  - 0.4767552762221516
  - 0.47904450639238677
  - 0.46259708737864075
  - 0.4896622118831154
  train_level7__recall_weighted:
  - 0.5709173403702874
  - 0.568292299549465
  - 0.5663098962119234
  - 0.5583158690438953
  - 0.5723696051971979
  train_level7__recall_weighted_masked:
  - 0.5033360898882304
  - 0.5011614931058447
  - 0.4978673976163754
  - 0.4880335064138486
  - 0.5056786884874291
  train_level7__recall_weighted_oob:
  - 0.5678078183612411
  - 0.5658618406671768
  - 0.5631911199128948
  - 0.5557155145448855
  - 0.5697260334424347
  train_level7__roc_auc_macro:
  - 0.7226877067202907
  - 0.7221338776578602
  - 0.7269273945252513
  - 0.7212600792967875
  - 0.7151588060335505
  train_level7__roc_auc_macro_masked:
  - 0.7049677460703834
  - 0.7013246107478837
  - 0.7076774283054199
  - 0.6991599082945719
  - 0.6892767422379406
  train_level7__roc_auc_macro_oob:
  - 0.716105762910575
  - 0.7165766143940783
  - 0.7213357146743108
  - 0.7142274309376472
  - 0.7092769053259677
  train_level7__roc_auc_micro:
  - 0.6703617415122793
  - 0.6701072341958157
  - 0.6803301316366709
  - 0.6622876898994692
  - 0.6674096833528794
  train_level7__roc_auc_micro_masked:
  - 0.6500329288769586
  - 0.6493969692672747
  - 0.6599666246120319
  - 0.6431888887147894
  - 0.643980994249302
  train_level7__roc_auc_micro_oob:
  - 0.6688261079914973
  - 0.6690676279887
  - 0.6792302500657297
  - 0.6607720279010372
  - 0.6662401217382554
  train_level7__roc_auc_samples:
  - 0.6543524014537395
  - 0.6525700905096631
  - 0.6663610571997467
  - 0.645623240796716
  - 0.6498583468794441
  train_level7__roc_auc_samples_masked:
  - 0.6347226552368661
  - 0.6351541050501709
  - 0.648404058703811
  - 0.6268675612880912
  - 0.6303669795572551
  train_level7__roc_auc_samples_oob:
  - 0.6535445221221693
  - 0.6520540071762317
  - 0.665357717702704
  - 0.6445259777372472
  - 0.6494144878429049
  train_level7__roc_auc_weighted:
  - 0.7254634757442732
  - 0.7247930493698564
  - 0.7291846514036322
  - 0.727952282553517
  - 0.7205035609410577
  train_level7__roc_auc_weighted_masked:
  - 0.7011776289096704
  - 0.6992267518937622
  - 0.7041655080295715
  - 0.7058949724832271
  - 0.6917706186809714
  train_level7__roc_auc_weighted_oob:
  - 0.7170307367524722
  - 0.7180699062691817
  - 0.7220446384101158
  - 0.7187407467964596
  - 0.7139049510262272
  train_level7__tn_macro:
  - 0.2740157096160414
  - 0.2644591719449268
  - 0.2670623858502355
  - 0.24936893203883495
  - 0.2786099176300235
  train_level7__tn_macro_masked:
  - 0.3092140286447355
  - 0.29932269235610326
  - 0.3013919574216539
  - 0.2822173383263201
  - 0.3145763766963865
  train_level7__tn_macro_oob:
  - 0.27318631994926085
  - 0.26260057225306305
  - 0.26526002114774594
  - 0.2478155339805825
  - 0.27780283428679947
  train_level7__tn_micro:
  - 0.2740157096160414
  - 0.26445917194492674
  - 0.2670623858502355
  - 0.24936893203883495
  - 0.2786099176300235
  train_level7__tn_micro_masked:
  - 0.31060417530761786
  - 0.29982255739159364
  - 0.30266633984257973
  - 0.282438970749945
  - 0.31575690726641736
  train_level7__tn_micro_oob:
  - 0.27318631994926085
  - 0.26260057225306305
  - 0.26526002114774583
  - 0.24781553398058254
  - 0.2778028342867994
  train_level7__tn_samples:
  - 0.2740157096160413
  - 0.2644591719449267
  - 0.26706238585023545
  - 0.24936893203883492
  - 0.27860991763002346
  train_level7__tn_samples_masked:
  - 0.31123546603617624
  - 0.300724241255106
  - 0.3033184532762077
  - 0.2832356807046449
  - 0.31697644477802234
  train_level7__tn_samples_oob:
  - 0.27318631994926085
  - 0.262600572253063
  - 0.2652600211477458
  - 0.24781553398058245
  - 0.27780283428679936
  train_level7__tn_weighted:
  - 0.25302441021843525
  - 0.24989116467054315
  - 0.2476907178344901
  - 0.23802184339484933
  - 0.2592133297698955
  train_level7__tn_weighted_masked:
  - 0.29852953544336824
  - 0.2952191845634633
  - 0.29202990838058085
  - 0.28071766178655444
  - 0.30569468735583943
  train_level7__tn_weighted_oob:
  - 0.25143670271432084
  - 0.24784225266958174
  - 0.245720736977692
  - 0.23618287978313002
  - 0.2578177876703397
  train_level7__tp_macro:
  - 0.21429965360784503
  - 0.21452153285564055
  - 0.21460155724310293
  - 0.2153883495145631
  - 0.2126427231941511
  train_level7__tp_macro_masked:
  - 0.12743985851726605
  - 0.12795347961298634
  - 0.1277348513265642
  - 0.12879168042069727
  - 0.1259469006769492
  train_level7__tp_macro_oob:
  - 0.21327511343123387
  - 0.21415470396908848
  - 0.21378448524464103
  - 0.21478155339805824
  - 0.21185937759631596
  train_level7__tp_micro:
  - 0.21429965360784506
  - 0.2145215328556406
  - 0.21460155724310295
  - 0.2153883495145631
  - 0.212642723194151
  train_level7__tp_micro_masked:
  - 0.11721277478224804
  - 0.1176111788843296
  - 0.11743878857205109
  - 0.118512205850011
  - 0.11616582819940276
  train_level7__tp_micro_oob:
  - 0.21327511343123384
  - 0.21415470396908856
  - 0.21378448524464097
  - 0.21478155339805824
  - 0.2118593775963159
  train_level7__tp_samples:
  - 0.21429965360784498
  - 0.21452153285564055
  - 0.2146015572431029
  - 0.21538834951456307
  - 0.21264272319415095
  train_level7__tp_samples_masked:
  - 0.11752274501488474
  - 0.11797899953355148
  - 0.11790810147610045
  - 0.1188390724466462
  - 0.11650729059031242
  train_level7__tp_samples_oob:
  - 0.2132751134312338
  - 0.2141547039690885
  - 0.21378448524464094
  - 0.21478155339805816
  - 0.21185937759631585
  train_level7__tp_weighted:
  - 0.317892930151852
  - 0.31840113487892174
  - 0.31861917837743314
  - 0.32029402564904597
  - 0.3131562754273027
  train_level7__tp_weighted_masked:
  - 0.20480655444486204
  - 0.20594230854238138
  - 0.2058374892357947
  - 0.2073158446272942
  - 0.19998400113158965
  train_level7__tp_weighted_oob:
  - 0.3163711156469202
  - 0.3180195879975952
  - 0.3174703829352028
  - 0.3195326347617558
  - 0.3119082457720951
  train_level8__average_precision_macro:
  - 0.39164837169295436
  - 0.3980192743081847
  - 0.3967948069075934
  - 0.3908074471326615
  - 0.39425789034846664
  train_level8__average_precision_macro_masked:
  - 0.26025570462141506
  - 0.2648097522623838
  - 0.26108251048747333
  - 0.2589762004894504
  - 0.2588753163766382
  train_level8__average_precision_macro_oob:
  - 0.38828337709515953
  - 0.392735210592952
  - 0.39182471456674894
  - 0.38716933915071916
  - 0.3904490400283208
  train_level8__average_precision_micro:
  - 0.3195161167218988
  - 0.32629218566147844
  - 0.3364603294682027
  - 0.31519051954350175
  - 0.3230279781429608
  train_level8__average_precision_micro_masked:
  - 0.18076272596340998
  - 0.18374801478713743
  - 0.19087663042657144
  - 0.1766770351938812
  - 0.18021455039431594
  train_level8__average_precision_micro_oob:
  - 0.32087519927020924
  - 0.3259789201826194
  - 0.3369860900967008
  - 0.31617981676749496
  - 0.3237676768501674
  train_level8__average_precision_samples:
  - 0.3263344369825714
  - 0.33141871699929687
  - 0.34465258485165445
  - 0.32261297961330443
  - 0.32597090063567286
  train_level8__average_precision_samples_masked:
  - 0.19698784355558652
  - 0.2019060565502789
  - 0.21010534504322112
  - 0.19517935671326037
  - 0.19625553449358585
  train_level8__average_precision_samples_oob:
  - 0.3276851244758175
  - 0.33167011889771686
  - 0.3447813682642386
  - 0.3232458694902164
  - 0.32681430830140434
  train_level8__average_precision_weighted:
  - 0.5272201351708004
  - 0.5341824256787691
  - 0.5313214573478425
  - 0.5282247635184626
  - 0.5268035233925509
  train_level8__average_precision_weighted_masked:
  - 0.3739349703701282
  - 0.3778598795423196
  - 0.3737221655098647
  - 0.3736595214493853
  - 0.36875466962360587
  train_level8__average_precision_weighted_oob:
  - 0.5223038546736286
  - 0.528627299860609
  - 0.5263843318142273
  - 0.5228886928606308
  - 0.5228262406083061
  train_level8__f1_macro:
  - 0.48880323949846316
  - 0.4787361522095327
  - 0.482192636739402
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__f1_macro_masked:
  - 0.43709232189514846
  - 0.4270771630351314
  - 0.4298411212138431
  - 0.41116718326559865
  - 0.4408590933734589
  train_level8__f1_macro_oob:
  - 0.48775430550812304
  - 0.4767063657039448
  - 0.4793328847447852
  - 0.46281553398058256
  - 0.49023191777244995
  train_level8__f1_micro:
  - 0.4888032394984632
  - 0.47873615220953264
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__f1_micro_masked:
  - 0.4283146688787502
  - 0.4172673838305423
  - 0.42078601192907916
  - 0.4010886298658456
  - 0.43227247047429446
  train_level8__f1_micro_oob:
  - 0.48775430550812315
  - 0.47670636570394465
  - 0.47933288474478514
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__f1_samples:
  - 0.4888032394984632
  - 0.4787361522095327
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.49158496925961975
  train_level8__f1_samples_masked:
  - 0.42925795425723884
  - 0.41852691529948505
  - 0.4219062500219718
  - 0.4021891781521013
  - 0.43382959431553203
  train_level8__f1_samples_oob:
  - 0.4877543055081231
  - 0.4767063657039446
  - 0.4793328847447851
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__f1_weighted:
  - 0.5709769578457381
  - 0.5678367525164644
  - 0.5669386838057459
  - 0.55857679074132
  - 0.5725902540635339
  train_level8__f1_weighted_masked:
  - 0.5033184415292079
  - 0.5007234528944077
  - 0.49883128989341396
  - 0.48835260012062787
  - 0.5059093566694075
  train_level8__f1_weighted_oob:
  - 0.5691450278763994
  - 0.5658579044888964
  - 0.5630762403686717
  - 0.5559712230215826
  - 0.5704192179708336
  train_level8__fn_macro:
  - -0.020198077767478166
  - -0.02034677557408721
  - -0.019609727963087572
  - -0.01720873786407767
  - -0.021411446340826548
  train_level8__fn_macro_masked:
  - -0.01642117744957061
  - -0.016001086423616123
  - -0.01584808176375791
  - -0.013390557578176641
  - -0.01710877745518138
  train_level8__fn_macro_oob:
  - -0.021003073620529833
  - -0.020444596610501086
  - -0.02033067384408344
  - -0.017694174757281557
  - -0.022123578702494835
  train_level8__fn_micro:
  - -0.020198077767478166
  - -0.020346775574087206
  - -0.019609727963087572
  - -0.01720873786407767
  - -0.021411446340826548
  train_level8__fn_micro_masked:
  - -0.015125120973316742
  - -0.014833093046467783
  - -0.014598142549772585
  - -0.012370793930063777
  - -0.0157918807672648
  train_level8__fn_micro_oob:
  - -0.021003073620529833
  - -0.02044459661050109
  - -0.02033067384408344
  - -0.017694174757281553
  - -0.022123578702494838
  train_level8__fn_samples:
  - -0.020198077767478163
  - -0.020346775574087206
  - -0.01960972796308757
  - -0.01720873786407767
  - -0.021411446340826545
  train_level8__fn_samples_masked:
  - -0.01500716604778783
  - -0.014774594813709572
  - -0.014523604754761214
  - -0.012313978712345758
  - -0.015715235068713092
  train_level8__fn_samples_oob:
  - -0.021003073620529833
  - -0.020444596610501083
  - -0.020330673844083436
  - -0.01769417475728155
  - -0.022123578702494835
  train_level8__fn_weighted:
  - -0.03054114364098565
  - -0.03001126009400118
  - -0.029496085454114772
  - -0.02514649150245021
  - -0.031436017530924315
  train_level8__fn_weighted_masked:
  - -0.02621599438669449
  - -0.024818031407422888
  - -0.02537744149875674
  - -0.021179449237992896
  - -0.027078781823204254
  train_level8__fn_weighted_oob:
  - -0.03176330188772983
  - -0.02987428108983855
  - -0.03038538528870857
  - -0.025656083828589298
  - -0.03251744489604464
  train_level8__fp_macro:
  - -0.49099868273405867
  - -0.50091707221638
  - -0.4981976352975104
  - -0.517864077669903
  - -0.4870035843995538
  train_level8__fp_macro_masked:
  - -0.5464865006552809
  - -0.5569217505412526
  - -0.5543107970223989
  - -0.5754422591562247
  - -0.5420321291713598
  train_level8__fp_macro_oob:
  - -0.49124262087134696
  - -0.5028490376855542
  - -0.5003364414111314
  - -0.5194902912621358
  - -0.4876445035250553
  train_level8__fp_micro:
  - -0.49099868273405867
  - -0.5009170722163802
  - -0.4981976352975103
  - -0.517864077669903
  - -0.4870035843995537
  train_level8__fp_micro_masked:
  - -0.5565602101479331
  - -0.5678995231229899
  - -0.5646158455211483
  - -0.5865405762040906
  - -0.5519356487584407
  train_level8__fp_micro_oob:
  - -0.491242620871347
  - -0.5028490376855542
  - -0.5003364414111314
  - -0.519490291262136
  - -0.4876445035250552
  train_level8__fp_samples:
  - -0.4909986827340586
  - -0.50091707221638
  - -0.4981976352975103
  - -0.517864077669903
  - -0.4870035843995537
  train_level8__fp_samples_masked:
  - -0.5557348796949734
  - -0.5666984898868054
  - -0.563570145223267
  - -0.585496843135553
  - -0.5504551706157548
  train_level8__fp_samples_oob:
  - -0.491242620871347
  - -0.5028490376855543
  - -0.5003364414111313
  - -0.5194902912621359
  - -0.48764450352505523
  train_level8__fp_weighted:
  - -0.39848189851327614
  - -0.4021519873895345
  - -0.4035652307401394
  - -0.4162767177562298
  - -0.3959737284055417
  train_level8__fp_weighted_masked:
  - -0.47046556408409773
  - -0.4744585156981694
  - -0.47579126860782933
  - -0.49046795064137927
  - -0.4670118615073883
  train_level8__fp_weighted_oob:
  - -0.3990916702358708
  - -0.4042678144212651
  - -0.4065383743426196
  - -0.41837269314982795
  - -0.3970633371331217
  train_level8__jaccard_macro:
  - 0.34471815735900607
  - 0.3378439457075552
  - 0.33930687094307266
  - 0.3258969327793692
  - 0.3469890985044625
  train_level8__jaccard_macro_masked:
  - 0.2990714466153752
  - 0.2929497071204064
  - 0.2931069747635202
  - 0.27932701622566825
  - 0.301998560908468
  train_level8__jaccard_macro_oob:
  - 0.34389111776147646
  - 0.3363591829542599
  - 0.33687715853222794
  - 0.324009938088642
  - 0.34571059967564044
  train_level8__jaccard_micro:
  - 0.323454398708636
  - 0.314696331543581
  - 0.31769027375354264
  - 0.3028697920784252
  - 0.32589503501455663
  train_level8__jaccard_micro_masked:
  - 0.27251935256861365
  - 0.26363731913253685
  - 0.2664528145695364
  - 0.25085107114610916
  - 0.27573188729107323
  train_level8__jaccard_micro_oob:
  - 0.3225364154017389
  - 0.31294450063414087
  - 0.3152122380606214
  - 0.30108002273732076
  - 0.32470677022735134
  train_level8__jaccard_samples:
  - 0.3296123535677911
  - 0.32070649538450263
  - 0.3234762015186669
  - 0.3085599384138565
  - 0.3317483136987758
  train_level8__jaccard_samples_masked:
  - 0.27917466964341087
  - 0.27005518629272224
  - 0.2729271436218792
  - 0.2570336266926785
  - 0.28212668139281766
  train_level8__jaccard_samples_oob:
  - 0.32859658884160714
  - 0.31875534306403386
  - 0.32090037364496266
  - 0.3067388645716318
  - 0.33046876303183215
  train_level8__jaccard_weighted:
  - 0.4189912070718905
  - 0.417276909445174
  - 0.4147650385719484
  - 0.4081217641153452
  - 0.41915029660724
  train_level8__jaccard_weighted_masked:
  - 0.3538800918258291
  - 0.35331676349245067
  - 0.3490520281441419
  - 0.3411119127446567
  - 0.35472339136404735
  train_level8__jaccard_weighted_oob:
  - 0.4172990663921216
  - 0.41556083683377165
  - 0.41105919469614277
  - 0.4055631280513991
  - 0.41694761744637765
  train_level8__label_ranking_average_precision_score:
  - 0.3263344369825714
  - 0.331418716999297
  - 0.3446525848516547
  - 0.3226129796133042
  - 0.32597090063567297
  train_level8__label_ranking_average_precision_score_oob:
  - 0.3276851244758175
  - 0.33167011889771697
  - 0.3447813682642386
  - 0.3232458694902165
  - 0.3268143083014045
  train_level8__matthews_corrcoef_macro:
  - 0.24430081143179438
  - 0.23730357433336122
  - 0.23925243126862467
  - 0.23481651735497006
  - 0.2439985387957445
  train_level8__matthews_corrcoef_macro_masked:
  - 0.1789019959845221
  - 0.1740616474802199
  - 0.17582427470165907
  - 0.17545237817774095
  - 0.17833320114024812
  train_level8__matthews_corrcoef_macro_oob:
  - 0.23924427314716892
  - 0.23360613678761372
  - 0.23254956973951935
  - 0.22928025159045806
  - 0.24096970356001737
  train_level8__matthews_corrcoef_micro:
  - 0.25318342468544003
  - 0.24302372361928895
  - 0.24867559790308363
  - 0.23997940255619044
  - 0.25188515844184284
  train_level8__matthews_corrcoef_micro_masked:
  - 0.17641217182365548
  - 0.1703794074416931
  - 0.1736112656658162
  - 0.17067361549678242
  - 0.17574126793929248
  train_level8__matthews_corrcoef_micro_oob:
  - 0.24955864227488572
  - 0.24073045245589964
  - 0.2435409690179566
  - 0.2362832214123527
  - 0.24828534065812366
  train_level8__matthews_corrcoef_samples:
  - 0.25056081112174955
  - 0.2400544536932735
  - 0.2482490664725386
  - 0.23753382039491433
  - 0.25032152686152764
  train_level8__matthews_corrcoef_samples_masked:
  - 0.17442277718044305
  - 0.16780378941276233
  - 0.17355681429192876
  - 0.16792552536028757
  - 0.17392598377637614
  train_level8__matthews_corrcoef_samples_oob:
  - 0.2470554661322246
  - 0.23773405845222537
  - 0.24298945140101202
  - 0.23388147937228246
  - 0.24664911197829553
  train_level8__matthews_corrcoef_weighted:
  - 0.276882055890239
  - 0.27320408733794005
  - 0.27142086650056996
  - 0.2750122712605853
  - 0.27990376999556604
  train_level8__matthews_corrcoef_weighted_masked:
  - 0.20596503961005413
  - 0.20660809851459686
  - 0.2033611046226047
  - 0.21163891333067972
  - 0.20939811278247308
  train_level8__matthews_corrcoef_weighted_oob:
  - 0.2690925955672653
  - 0.2682455958505809
  - 0.2621756726317222
  - 0.2670054020150752
  - 0.2758992322329631
  train_level8__ndcg:
  - 0.6715021781991548
  - 0.6730739842049605
  - 0.6849751163332076
  - 0.6645462212820686
  - 0.6670167054635131
  train_level8__ndcg_oob:
  - 0.6739315550378424
  - 0.674404746351556
  - 0.6874211832808603
  - 0.6667049276919687
  - 0.6697179988877967
  train_level8__neg_coverage_error:
  - -81.85678391959799
  - -81.36523929471032
  - -81.38118811881188
  - -82.975
  - -81.87286063569682
  train_level8__neg_coverage_error_oob:
  - -82.87939698492463
  - -82.4735516372796
  - -82.35891089108911
  - -83.8475
  - -82.8875305623472
  train_level8__neg_hamming_loss_macro:
  - -0.5111967605015368
  - -0.5212638477904673
  - -0.517807363260598
  - -0.5350728155339806
  - -0.5084150307403803
  train_level8__neg_hamming_loss_macro_masked:
  - -0.5629076781048515
  - -0.5729228369648686
  - -0.5701588787861569
  - -0.5888328167344014
  - -0.5591409066265411
  train_level8__neg_hamming_loss_macro_oob:
  - -0.5122456944918771
  - -0.5232936342960554
  - -0.5206671152552148
  - -0.5371844660194175
  - -0.50976808222755
  train_level8__neg_hamming_loss_micro:
  - -0.5111967605015368
  - -0.5212638477904673
  - -0.517807363260598
  - -0.5350728155339806
  - -0.5084150307403803
  train_level8__neg_hamming_loss_micro_masked:
  - -0.5716853311212499
  - -0.5827326161694577
  - -0.5792139880709208
  - -0.5989113701341544
  - -0.5677275295257055
  train_level8__neg_hamming_loss_micro_oob:
  - -0.5122456944918768
  - -0.5232936342960554
  - -0.5206671152552148
  - -0.5371844660194175
  - -0.50976808222755
  train_level8__neg_hamming_loss_samples:
  - -0.5111967605015368
  - -0.5212638477904673
  - -0.5178073632605978
  - -0.5350728155339806
  - -0.5084150307403803
  train_level8__neg_hamming_loss_samples_masked:
  - -0.5707420457427611
  - -0.581473084700515
  - -0.5780937499780283
  - -0.5978108218478987
  - -0.566170405684468
  train_level8__neg_hamming_loss_samples_oob:
  - -0.5122456944918768
  - -0.5232936342960555
  - -0.5206671152552149
  - -0.5371844660194174
  - -0.50976808222755
  train_level8__neg_hamming_loss_weighted:
  - -0.4290230421542617
  - -0.4321632474835357
  - -0.4330613161942541
  - -0.44142320925867995
  - -0.427409745936466
  train_level8__neg_hamming_loss_weighted_masked:
  - -0.4966815584707921
  - -0.4992765471055923
  - -0.501168710106586
  - -0.5116473998793721
  - -0.49409064333059255
  train_level8__neg_hamming_loss_weighted_oob:
  - -0.43085497212360063
  - -0.43414209551110367
  - -0.43692375963132823
  - -0.4440287769784174
  - -0.42958078202916633
  train_level8__neg_label_ranking_loss:
  - -0.3845745083583097
  - -0.37667428350884036
  - -0.362771971431696
  - -0.38035092673174875
  - -0.3824058810759793
  train_level8__neg_label_ranking_loss_oob:
  - -0.38906697395664014
  - -0.38152525220756306
  - -0.3679490826564112
  - -0.38531733192560147
  - -0.3878807966839052
  train_level8__precision_macro:
  - 0.48880323949846316
  - 0.4787361522095327
  - 0.482192636739402
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__precision_macro_masked:
  - 0.43709232189514846
  - 0.4270771630351314
  - 0.4298411212138431
  - 0.41116718326559865
  - 0.4408590933734589
  train_level8__precision_macro_oob:
  - 0.48775430550812304
  - 0.4767063657039448
  - 0.4793328847447852
  - 0.46281553398058256
  - 0.49023191777244995
  train_level8__precision_micro:
  - 0.4888032394984632
  - 0.47873615220953264
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__precision_micro_masked:
  - 0.4283146688787502
  - 0.4172673838305423
  - 0.42078601192907916
  - 0.4010886298658456
  - 0.43227247047429446
  train_level8__precision_micro_oob:
  - 0.48775430550812315
  - 0.47670636570394465
  - 0.47933288474478514
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__precision_samples:
  - 0.4888032394984632
  - 0.4787361522095327
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.49158496925961975
  train_level8__precision_samples_masked:
  - 0.42925795425723884
  - 0.41852691529948505
  - 0.4219062500219718
  - 0.4021891781521013
  - 0.43382959431553203
  train_level8__precision_samples_oob:
  - 0.4877543055081231
  - 0.4767063657039446
  - 0.4793328847447851
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__precision_weighted:
  - 0.5709769578457381
  - 0.5678367525164644
  - 0.5669386838057459
  - 0.55857679074132
  - 0.5725902540635339
  train_level8__precision_weighted_masked:
  - 0.5033184415292079
  - 0.5007234528944077
  - 0.49883128989341396
  - 0.48835260012062787
  - 0.5059093566694075
  train_level8__precision_weighted_oob:
  - 0.5691450278763994
  - 0.5658579044888964
  - 0.5630762403686717
  - 0.5559712230215826
  - 0.5704192179708336
  train_level8__recall_macro:
  - 0.48880323949846316
  - 0.4787361522095327
  - 0.482192636739402
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__recall_macro_masked:
  - 0.43709232189514846
  - 0.4270771630351314
  - 0.4298411212138431
  - 0.41116718326559865
  - 0.4408590933734589
  train_level8__recall_macro_oob:
  - 0.48775430550812304
  - 0.4767063657039448
  - 0.4793328847447852
  - 0.46281553398058256
  - 0.49023191777244995
  train_level8__recall_micro:
  - 0.4888032394984632
  - 0.47873615220953264
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.4915849692596197
  train_level8__recall_micro_masked:
  - 0.4283146688787502
  - 0.4172673838305423
  - 0.42078601192907916
  - 0.4010886298658456
  - 0.43227247047429446
  train_level8__recall_micro_oob:
  - 0.48775430550812315
  - 0.47670636570394465
  - 0.47933288474478514
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__recall_samples:
  - 0.4888032394984632
  - 0.4787361522095327
  - 0.4821926367394021
  - 0.46492718446601944
  - 0.49158496925961975
  train_level8__recall_samples_masked:
  - 0.42925795425723884
  - 0.41852691529948505
  - 0.4219062500219718
  - 0.4021891781521013
  - 0.43382959431553203
  train_level8__recall_samples_oob:
  - 0.4877543055081231
  - 0.4767063657039446
  - 0.4793328847447851
  - 0.4628155339805825
  - 0.49023191777244995
  train_level8__recall_weighted:
  - 0.5709769578457381
  - 0.5678367525164644
  - 0.5669386838057459
  - 0.55857679074132
  - 0.5725902540635339
  train_level8__recall_weighted_masked:
  - 0.5033184415292079
  - 0.5007234528944077
  - 0.49883128989341396
  - 0.48835260012062787
  - 0.5059093566694075
  train_level8__recall_weighted_oob:
  - 0.5691450278763994
  - 0.5658579044888964
  - 0.5630762403686717
  - 0.5559712230215826
  - 0.5704192179708336
  train_level8__roc_auc_macro:
  - 0.7222005710983508
  - 0.7225287876407049
  - 0.7270815018366701
  - 0.7225876183834405
  - 0.7186014494945259
  train_level8__roc_auc_macro_masked:
  - 0.7038106111022898
  - 0.7017112571974603
  - 0.7074681559356314
  - 0.6998518939449464
  - 0.6925391395702432
  train_level8__roc_auc_macro_oob:
  - 0.7158135831118081
  - 0.716223727220924
  - 0.7210263261453754
  - 0.7159199584693834
  - 0.713184308775181
  train_level8__roc_auc_micro:
  - 0.6684896317116011
  - 0.6714993034568333
  - 0.6798926537905547
  - 0.6625057334460269
  - 0.6701679630159175
  train_level8__roc_auc_micro_masked:
  - 0.6485298322960292
  - 0.650260411815565
  - 0.6590327437005292
  - 0.6428440820749903
  - 0.646360857323951
  train_level8__roc_auc_micro_oob:
  - 0.6678516319127761
  - 0.6696327390909005
  - 0.6784330702531117
  - 0.661547826196469
  - 0.6689946584420874
  train_level8__roc_auc_samples:
  - 0.652544428451698
  - 0.6541080361394377
  - 0.66700946229446
  - 0.6454901050537373
  - 0.6504178070921341
  train_level8__roc_auc_samples_masked:
  - 0.6331498801050633
  - 0.6365387118347988
  - 0.6485580672818564
  - 0.6263821514556924
  - 0.6306292519045611
  train_level8__roc_auc_samples_oob:
  - 0.6526736477463988
  - 0.6531406688541167
  - 0.6657699788092364
  - 0.6446132663272922
  - 0.6501553585386296
  train_level8__roc_auc_weighted:
  - 0.7248012566537
  - 0.7248487196154632
  - 0.7286574037175078
  - 0.7283734729788378
  - 0.7237778512455783
  train_level8__roc_auc_weighted_masked:
  - 0.7003982077565104
  - 0.6991602379605539
  - 0.7030575074031381
  - 0.7057268329259709
  - 0.6951700954144677
  train_level8__roc_auc_weighted_oob:
  - 0.7171140875653361
  - 0.717452006633093
  - 0.7218712130631509
  - 0.7193837105412795
  - 0.7174152167719169
  train_level8__tn_macro:
  - 0.2746011611455335
  - 0.26433689564940943
  - 0.26775930020186484
  - 0.24934466019417473
  - 0.27889477057469086
  train_level8__tn_macro_masked:
  - 0.309846271363143
  - 0.2991787342159259
  - 0.3022401331511912
  - 0.2822112510943903
  - 0.31489376122991125
  train_level8__tn_macro_oob:
  - 0.2743572230082451
  - 0.26240493018023525
  - 0.26562049408824373
  - 0.24771844660194176
  - 0.27825385144918935
  train_level8__tn_micro:
  - 0.2746011611455335
  - 0.26433689564940943
  - 0.26775930020186484
  - 0.24934466019417476
  - 0.2788947705746908
  train_level8__tn_micro_masked:
  - 0.31126780035946355
  - 0.2996839303537762
  - 0.30345616471933984
  - 0.2824114800967671
  - 0.31607973958193214
  train_level8__tn_micro_oob:
  - 0.2743572230082451
  - 0.26240493018023525
  - 0.2656204940882438
  - 0.24771844660194176
  - 0.27825385144918935
  train_level8__tn_samples:
  - 0.2746011611455334
  - 0.2643368956494093
  - 0.26775930020186484
  - 0.2493446601941747
  - 0.2788947705746908
  train_level8__tn_samples_masked:
  - 0.31190305743655594
  - 0.30057497898196306
  - 0.30411172032641043
  - 0.28318390675089716
  - 0.3172978034621786
  train_level8__tn_samples_oob:
  - 0.27435722300824505
  - 0.2624049301802352
  - 0.26562049408824373
  - 0.2477184466019417
  - 0.2782538514491893
  train_level8__tn_weighted:
  - 0.25335073745248243
  - 0.24974211471965352
  - 0.24870887591890928
  - 0.23809795641747467
  - 0.25942678895406984
  train_level8__tn_weighted_masked:
  - 0.2989168537113882
  - 0.2950424452981403
  - 0.293314446545062
  - 0.2808778986552282
  - 0.30596938712677796
  train_level8__tn_weighted_oob:
  - 0.2527409657298879
  - 0.247626287687923
  - 0.24573573231642915
  - 0.2360019810238766
  - 0.2583371802264898
  train_level8__tp_macro:
  - 0.21420207835292968
  - 0.2143992565601232
  - 0.21443333653753727
  - 0.21558252427184466
  - 0.21269019868492892
  train_level8__tp_macro_masked:
  - 0.12724605053200544
  - 0.12789842881920552
  - 0.12760098806265197
  - 0.12895593217120846
  - 0.12596533214354777
  train_level8__tp_macro_oob:
  - 0.21339708249987804
  - 0.21430143552370934
  - 0.21371239065654138
  - 0.21509708737864075
  - 0.21197806632326066
  train_level8__tp_micro:
  - 0.2142020783529297
  - 0.21439925656012326
  - 0.21443333653753724
  - 0.21558252427184466
  - 0.21269019868492892
  train_level8__tp_micro_masked:
  - 0.1170468685192866
  - 0.1175834534767661
  - 0.11732984720973935
  - 0.11867714976907852
  - 0.11619273089236233
  train_level8__tp_micro_oob:
  - 0.21339708249987804
  - 0.21430143552370937
  - 0.21371239065654138
  - 0.21509708737864078
  - 0.2119780663232606
  train_level8__tp_samples:
  - 0.21420207835292965
  - 0.2143992565601232
  - 0.2144333365375372
  - 0.21558252427184463
  - 0.21269019868492883
  train_level8__tp_samples_masked:
  - 0.11735489682068284
  - 0.11795193631752193
  - 0.11779452969556133
  - 0.11900527140120416
  - 0.1165317908533534
  train_level8__tp_samples_oob:
  - 0.21339708249987796
  - 0.21430143552370934
  - 0.21371239065654135
  - 0.2150970873786407
  - 0.21197806632326055
  train_level8__tp_weighted:
  - 0.31762622039325566
  - 0.3180946377968107
  - 0.31822980788683647
  - 0.3204788343238453
  - 0.31316346510946425
  train_level8__tp_weighted_masked:
  - 0.20440158781781956
  - 0.20568100759626742
  - 0.20551684334835205
  - 0.20747470146539973
  - 0.19993996954262944
  train_level8__tp_weighted_oob:
  - 0.3164040621465115
  - 0.31823161680097345
  - 0.3173405080522427
  - 0.31996924199770616
  - 0.31208203774434384
  train_level9__average_precision_macro:
  - 0.3902559782841191
  - 0.40005118376502247
  - 0.39821741477579625
  - 0.38888543595715364
  - 0.3894593451306351
  train_level9__average_precision_macro_masked:
  - 0.25844164092313754
  - 0.2663814600284938
  - 0.26246066064888074
  - 0.25732813312730013
  - 0.2548150833400812
  train_level9__average_precision_macro_oob:
  - 0.38665011797391124
  - 0.39420617714300565
  - 0.3920447010705999
  - 0.38534880917503067
  - 0.38477046837874923
  train_level9__average_precision_micro:
  - 0.31932247150803045
  - 0.32414707548606636
  - 0.33575897848241576
  - 0.31443445869469955
  - 0.32195866033494885
  train_level9__average_precision_micro_masked:
  - 0.17994814189080838
  - 0.18248498486701936
  - 0.19052700638674486
  - 0.17609069572939864
  - 0.18000829972350757
  train_level9__average_precision_micro_oob:
  - 0.32065869863008467
  - 0.32427864894785363
  - 0.33543843335513224
  - 0.31517236684488004
  - 0.32218850219117595
  train_level9__average_precision_samples:
  - 0.32560706888789176
  - 0.32989550288506864
  - 0.3436361824147364
  - 0.3223553717850106
  - 0.32645209005487413
  train_level9__average_precision_samples_masked:
  - 0.1961095985815543
  - 0.20003905421306936
  - 0.21012270661298565
  - 0.19394463434206827
  - 0.19671564464587799
  train_level9__average_precision_samples_oob:
  - 0.3266018988126433
  - 0.33067008362850764
  - 0.3439098908848636
  - 0.3229482364220628
  - 0.3269058351986891
  train_level9__average_precision_weighted:
  - 0.5265461935320935
  - 0.5365240750225334
  - 0.5323377659303853
  - 0.526065219695759
  - 0.5230641816949106
  train_level9__average_precision_weighted_masked:
  - 0.37218712366837153
  - 0.3803044030869519
  - 0.37533563242411744
  - 0.3714176243071535
  - 0.36609039264363263
  train_level9__average_precision_weighted_oob:
  - 0.5217197114581088
  - 0.5301493705585384
  - 0.5251590986676579
  - 0.5212468339069175
  - 0.5173088695010851
  train_level9__f1_macro:
  - 0.4888276333121919
  - 0.47924971265070554
  - 0.48269729885609913
  - 0.4650000000000001
  - 0.4921784128943434
  train_level9__f1_macro_masked:
  - 0.43703116296717487
  - 0.42750866383646274
  - 0.43028073200790834
  - 0.411231046265872
  - 0.44151943369472824
  train_level9__f1_macro_oob:
  - 0.48719324779235984
  - 0.47736665769973846
  - 0.48010189368451417
  - 0.46296116504854357
  - 0.4903743442447836
  train_level9__f1_micro:
  - 0.48882763331219203
  - 0.47924971265070554
  - 0.4826972988560992
  - 0.465
  - 0.4921784128943433
  train_level9__f1_micro_masked:
  - 0.4282040647034426
  - 0.41768326494399466
  - 0.421276248059482
  - 0.40114361117220143
  - 0.43297194049124316
  train_level9__f1_micro_oob:
  - 0.48719324779235984
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.49037434424478366
  train_level9__f1_samples:
  - 0.488827633312192
  - 0.47924971265070554
  - 0.48269729885609924
  - 0.465
  - 0.4921784128943432
  train_level9__f1_samples_masked:
  - 0.4291416848602582
  - 0.4189636509836732
  - 0.4223997166306727
  - 0.4022441386023536
  - 0.4345216544439791
  train_level9__f1_samples_oob:
  - 0.4871932477923599
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.4903743442447836
  train_level9__f1_weighted:
  - 0.5713898350112514
  - 0.5684164203712446
  - 0.5672398613719056
  - 0.5588048691481599
  - 0.5729430443295968
  train_level9__f1_weighted_masked:
  - 0.5036325094395564
  - 0.5012645062929815
  - 0.4988849519327364
  - 0.48848208233205065
  - 0.5062783134154514
  train_level9__f1_weighted_oob:
  - 0.568861060427541
  - 0.5666251968417154
  - 0.5638496440259078
  - 0.5561940882076948
  - 0.5701333661248952
  train_level9__fn_macro:
  - -0.01997853344391862
  - -0.02015113350125945
  - -0.019609727963087572
  - -0.017305825242718443
  - -0.021506397322382322
  train_level9__fn_macro_masked:
  - -0.01629161470570483
  - -0.015910358877104142
  - -0.015947984328651896
  - -0.013517030714596921
  - -0.017199745418895396
  train_level9__fn_macro_oob:
  - -0.020881104551885642
  - -0.02032232031498374
  - -0.020066327021051617
  - -0.017839805825242718
  - -0.022099840957105897
  train_level9__fn_micro:
  - -0.019978533443918624
  - -0.020151133501259445
  - -0.019609727963087572
  - -0.017305825242718446
  - -0.02150639732238232
  train_level9__fn_micro_masked:
  - -0.015014516798009124
  - -0.014777642231340801
  - -0.014679848571506386
  - -0.012508247195953375
  - -0.0158725888461435
  train_level9__fn_micro_oob:
  - -0.020881104551885642
  - -0.02032232031498374
  - -0.02006632702105162
  - -0.017839805825242718
  - -0.022099840957105894
  train_level9__fn_samples:
  - -0.01997853344391862
  - -0.020151133501259445
  - -0.01960972796308757
  - -0.017305825242718443
  - -0.02150639732238232
  train_level9__fn_samples_masked:
  - -0.014895713033350064
  - -0.014711440753249172
  - -0.014608441717724158
  - -0.012446276278464605
  - -0.015788647497597886
  train_level9__fn_samples_oob:
  - -0.020881104551885642
  - -0.02032232031498374
  - -0.020066327021051617
  - -0.017839805825242715
  - -0.02209984095710589
  train_level9__fn_weighted:
  - -0.030148661927600323
  - -0.029637847981121037
  - -0.029498627036951563
  - -0.02505135022416849
  - -0.03157981117415443
  train_level9__fn_weighted_masked:
  - -0.02594312337320623
  - -0.024460175301916808
  - -0.02561560245147269
  - -0.02122065201406098
  - -0.027248459460360808
  train_level9__fn_weighted_oob:
  - -0.03142834580855154
  - -0.02966198987457499
  - -0.029926121270100112
  - -0.025988426649984357
  - -0.03262330676787095
  train_level9__fp_macro:
  - -0.4911938332438894
  - -0.5005991538480351
  - -0.4976929731808133
  - -0.5176941747572814
  - -0.4863151897832745
  train_level9__fp_macro_masked:
  - -0.5466772223271202
  - -0.5565809772864331
  - -0.5537712836634398
  - -0.5752519230195311
  - -0.5412808208863764
  train_level9__fp_macro_oob:
  - -0.49192564765575447
  - -0.5023110219852779
  - -0.4998317792944343
  - -0.5191990291262136
  - -0.4875258147981105
  train_level9__fp_micro:
  - -0.4911938332438894
  - -0.500599153848035
  - -0.49769297318081324
  - -0.5176941747572815
  - -0.48631518978327437
  train_level9__fp_micro_masked:
  - -0.5567814184985483
  - -0.5675390928246645
  - -0.5640439033690117
  - -0.5863481416318451
  - -0.5511554706626133
  train_level9__fp_micro_oob:
  - -0.4919256476557545
  - -0.5023110219852779
  - -0.4998317792944343
  - -0.5191990291262136
  - -0.48752581479811047
  train_level9__fp_samples:
  - -0.4911938332438893
  - -0.500599153848035
  - -0.4976929731808132
  - -0.5176941747572815
  - -0.4863151897832744
  train_level9__fp_samples_masked:
  - -0.5559626021063917
  - -0.5663249082630777
  - -0.5629918416516032
  - -0.5853095851191819
  - -0.549689698058423
  train_level9__fp_samples_oob:
  - -0.4919256476557545
  - -0.5023110219852779
  - -0.49983177929443434
  - -0.5191990291262135
  - -0.48752581479811047
  train_level9__fp_weighted:
  - -0.3984615030611482
  - -0.4019457316476345
  - -0.4032615115911427
  - -0.41614378062767177
  - -0.3954771444962487
  train_level9__fp_weighted_masked:
  - -0.4704243671872372
  - -0.47427531840510173
  - -0.47549944561579083
  - -0.4902972656538883
  - -0.4664732271241878
  train_level9__fp_weighted_oob:
  - -0.39971059376390744
  - -0.40371281328370956
  - -0.406224234703992
  - -0.41781748514232103
  - -0.3972433271072338
  train_level9__jaccard_macro:
  - 0.34474496667424914
  - 0.33829491103032827
  - 0.3397100862241958
  - 0.32583632481958463
  - 0.34746087513225493
  train_level9__jaccard_macro_masked:
  - 0.2989871933294147
  - 0.2933088669933687
  - 0.29342644173359145
  - 0.2792084672365699
  - 0.30250401827541107
  train_level9__jaccard_macro_oob:
  - 0.34336922628472344
  - 0.3369899076728995
  - 0.3374862201410554
  - 0.32402127805345593
  - 0.3457420684067228
  train_level9__jaccard_micro:
  - 0.3234757623206186
  - 0.31514030714802604
  - 0.3181285438246381
  - 0.30293159609120524
  - 0.3264168765743073
  train_level9__jaccard_micro_masked:
  - 0.27242980789529236
  - 0.26396944157277774
  - 0.2668460821861091
  - 0.25089408528198076
  - 0.27630133223458314
  train_level9__jaccard_micro_oob:
  - 0.3220459236326109
  - 0.31351386078185733
  - 0.3158776839642033
  - 0.30120329722388905
  - 0.324831750424555
  train_level9__jaccard_samples:
  - 0.32968354220991014
  - 0.32110642181177546
  - 0.32390123482334304
  - 0.3086384248391105
  - 0.33217011751427666
  train_level9__jaccard_samples_masked:
  - 0.2791448744445471
  - 0.2703519212040327
  - 0.273317324380462
  - 0.25708967083700335
  - 0.2825699896891456
  train_level9__jaccard_samples_oob:
  - 0.3281669095236669
  - 0.3193645061740115
  - 0.32157973682506935
  - 0.30684728247799237
  - 0.3305586490483426
  train_level9__jaccard_weighted:
  - 0.41944177026659607
  - 0.41783734916423687
  - 0.41500110637844045
  - 0.4082995515131852
  - 0.41937518632571125
  train_level9__jaccard_weighted_masked:
  - 0.3541646662256185
  - 0.35384322430980614
  - 0.34905069493307433
  - 0.34112713781145737
  - 0.3549685483625812
  train_level9__jaccard_weighted_oob:
  - 0.4170694949290536
  - 0.41640489193918395
  - 0.41178199400353754
  - 0.4056934037736197
  - 0.41656944363277215
  train_level9__label_ranking_average_precision_score:
  - 0.32560706888789176
  - 0.32989550288506897
  - 0.34363618241473615
  - 0.32235537178501067
  - 0.3264520900548744
  train_level9__label_ranking_average_precision_score_oob:
  - 0.326601898812643
  - 0.33067008362850775
  - 0.3439098908848638
  - 0.32294823642206266
  - 0.3269058351986893
  train_level9__matthews_corrcoef_macro:
  - 0.2451650337075527
  - 0.2379371319821638
  - 0.23982673215292988
  - 0.23389554255584263
  - 0.2445750429879306
  train_level9__matthews_corrcoef_macro_masked:
  - 0.17950731305091508
  - 0.17406298428942402
  - 0.1759945475102454
  - 0.17410681077582094
  - 0.1791199004104276
  train_level9__matthews_corrcoef_macro_oob:
  - 0.2386504596981376
  - 0.23505805121016352
  - 0.23388060597522095
  - 0.22916448381074955
  - 0.24072379290764498
  train_level9__matthews_corrcoef_micro:
  - 0.25392087300468724
  - 0.2441651344155671
  - 0.2491616734991247
  - 0.23971608009256445
  - 0.2521534754998453
  train_level9__matthews_corrcoef_micro_masked:
  - 0.17687888280776595
  - 0.17094354208498796
  - 0.17354503711123462
  - 0.17000591645233995
  - 0.17583334118681884
  train_level9__matthews_corrcoef_micro_oob:
  - 0.2494112770053919
  - 0.2417747837580972
  - 0.2451549311726567
  - 0.23592395401871194
  - 0.24849973432130754
  train_level9__matthews_corrcoef_samples:
  - 0.25132654134101984
  - 0.24106673410505455
  - 0.24882046295538232
  - 0.23709904852467298
  - 0.25049119337046344
  train_level9__matthews_corrcoef_samples_masked:
  - 0.17490334448869424
  - 0.1682085789196438
  - 0.1735966030789575
  - 0.1670933191772215
  - 0.17400639415854963
  train_level9__matthews_corrcoef_samples_oob:
  - 0.24671609564860258
  - 0.23853165671035284
  - 0.2447339881010581
  - 0.23346325266378593
  - 0.2468425243440448
  train_level9__matthews_corrcoef_weighted:
  - 0.2780132228996077
  - 0.2732209943373744
  - 0.2716928723226413
  - 0.2752676860367955
  - 0.28052282994645533
  train_level9__matthews_corrcoef_weighted_masked:
  - 0.2069665217948028
  - 0.2065166126406941
  - 0.20290398620815156
  - 0.21124210555208725
  - 0.21055414192201602
  train_level9__matthews_corrcoef_weighted_oob:
  - 0.26864473051721044
  - 0.2705325783585905
  - 0.26379593407349716
  - 0.26886475216137184
  - 0.27406765464543925
  train_level9__ndcg:
  - 0.6707399711976108
  - 0.6712620555851556
  - 0.6839905901190036
  - 0.6667058351181478
  - 0.6700875529761727
  train_level9__ndcg_oob:
  - 0.6727313881151402
  - 0.6732964251443254
  - 0.6859696290749795
  - 0.6682230460820061
  - 0.6718663592765551
  train_level9__neg_coverage_error:
  - -81.80653266331659
  - -81.49874055415617
  - -81.45544554455445
  - -82.975
  - -81.79217603911981
  train_level9__neg_coverage_error_oob:
  - -82.77638190954774
  - -82.51637279596977
  - -82.44059405940594
  - -83.8125
  - -82.7677261613692
  train_level9__neg_hamming_loss_macro:
  - -0.5111723666878081
  - -0.5207502873492944
  - -0.5173027011439009
  - -0.5349999999999999
  - -0.5078215871056566
  train_level9__neg_hamming_loss_macro_masked:
  - -0.5629688370328252
  - -0.5724913361635372
  - -0.5697192679920916
  - -0.5887689537341281
  - -0.5584805663052718
  train_level9__neg_hamming_loss_macro_oob:
  - -0.5128067522076403
  - -0.5226333423002616
  - -0.5198981063154858
  - -0.5370388349514564
  - -0.5096256557552165
  train_level9__neg_hamming_loss_micro:
  - -0.511172366687808
  - -0.5207502873492945
  - -0.5173027011439008
  - -0.535
  - -0.5078215871056567
  train_level9__neg_hamming_loss_micro_masked:
  - -0.5717959352965575
  - -0.5823167350560053
  - -0.5787237519405181
  - -0.5988563888277986
  - -0.5670280595087568
  train_level9__neg_hamming_loss_micro_oob:
  - -0.5128067522076402
  - -0.5226333423002617
  - -0.5198981063154859
  - -0.5370388349514563
  - -0.5096256557552163
  train_level9__neg_hamming_loss_samples:
  - -0.511172366687808
  - -0.5207502873492944
  - -0.5173027011439008
  - -0.535
  - -0.5078215871056567
  train_level9__neg_hamming_loss_samples_masked:
  - -0.5708583151397417
  - -0.5810363490163268
  - -0.5776002833693272
  - -0.5977558613976465
  - -0.565478345556021
  train_level9__neg_hamming_loss_samples_oob:
  - -0.5128067522076402
  - -0.5226333423002617
  - -0.5198981063154858
  - -0.5370388349514563
  - -0.5096256557552163
  train_level9__neg_hamming_loss_weighted:
  - -0.42861016498874843
  - -0.4315835796287554
  - -0.4327601386280942
  - -0.4411951308518402
  - -0.42705695567040325
  train_level9__neg_hamming_loss_weighted_masked:
  - -0.4963674905604436
  - -0.4987354937070186
  - -0.5011150480672636
  - -0.5115179176679494
  - -0.49372168658454857
  train_level9__neg_hamming_loss_weighted_oob:
  - -0.4311389395724591
  - -0.4333748031582845
  - -0.4361503559740922
  - -0.4438059117923052
  - -0.4298666338751049
  train_level9__neg_label_ranking_loss:
  - -0.3874309520030811
  - -0.3764097743915054
  - -0.363941625921102
  - -0.3824496841897567
  - -0.38506404525542753
  train_level9__neg_label_ranking_loss_oob:
  - -0.3922442369099953
  - -0.38061212342816914
  - -0.36867562147076477
  - -0.3864258777160029
  - -0.39019176426795965
  train_level9__precision_macro:
  - 0.4888276333121919
  - 0.47924971265070554
  - 0.48269729885609913
  - 0.4650000000000001
  - 0.4921784128943434
  train_level9__precision_macro_masked:
  - 0.43703116296717487
  - 0.42750866383646274
  - 0.43028073200790834
  - 0.411231046265872
  - 0.44151943369472824
  train_level9__precision_macro_oob:
  - 0.48719324779235984
  - 0.47736665769973846
  - 0.48010189368451417
  - 0.46296116504854357
  - 0.4903743442447836
  train_level9__precision_micro:
  - 0.48882763331219203
  - 0.47924971265070554
  - 0.4826972988560992
  - 0.465
  - 0.4921784128943433
  train_level9__precision_micro_masked:
  - 0.4282040647034426
  - 0.41768326494399466
  - 0.421276248059482
  - 0.40114361117220143
  - 0.43297194049124316
  train_level9__precision_micro_oob:
  - 0.48719324779235984
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.49037434424478366
  train_level9__precision_samples:
  - 0.488827633312192
  - 0.47924971265070554
  - 0.48269729885609924
  - 0.465
  - 0.4921784128943432
  train_level9__precision_samples_masked:
  - 0.4291416848602582
  - 0.4189636509836732
  - 0.4223997166306727
  - 0.4022441386023536
  - 0.4345216544439791
  train_level9__precision_samples_oob:
  - 0.4871932477923599
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.4903743442447836
  train_level9__precision_weighted:
  - 0.5713898350112514
  - 0.5684164203712446
  - 0.5672398613719056
  - 0.5588048691481599
  - 0.5729430443295968
  train_level9__precision_weighted_masked:
  - 0.5036325094395564
  - 0.5012645062929815
  - 0.4988849519327364
  - 0.48848208233205065
  - 0.5062783134154514
  train_level9__precision_weighted_oob:
  - 0.568861060427541
  - 0.5666251968417154
  - 0.5638496440259078
  - 0.5561940882076948
  - 0.5701333661248952
  train_level9__recall_macro:
  - 0.4888276333121919
  - 0.47924971265070554
  - 0.48269729885609913
  - 0.4650000000000001
  - 0.4921784128943434
  train_level9__recall_macro_masked:
  - 0.43703116296717487
  - 0.42750866383646274
  - 0.43028073200790834
  - 0.411231046265872
  - 0.44151943369472824
  train_level9__recall_macro_oob:
  - 0.48719324779235984
  - 0.47736665769973846
  - 0.48010189368451417
  - 0.46296116504854357
  - 0.4903743442447836
  train_level9__recall_micro:
  - 0.48882763331219203
  - 0.47924971265070554
  - 0.4826972988560992
  - 0.465
  - 0.4921784128943433
  train_level9__recall_micro_masked:
  - 0.4282040647034426
  - 0.41768326494399466
  - 0.421276248059482
  - 0.40114361117220143
  - 0.43297194049124316
  train_level9__recall_micro_oob:
  - 0.48719324779235984
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.49037434424478366
  train_level9__recall_samples:
  - 0.488827633312192
  - 0.47924971265070554
  - 0.48269729885609924
  - 0.465
  - 0.4921784128943432
  train_level9__recall_samples_masked:
  - 0.4291416848602582
  - 0.4189636509836732
  - 0.4223997166306727
  - 0.4022441386023536
  - 0.4345216544439791
  train_level9__recall_samples_oob:
  - 0.4871932477923599
  - 0.47736665769973835
  - 0.48010189368451406
  - 0.4629611650485437
  - 0.4903743442447836
  train_level9__recall_weighted:
  - 0.5713898350112514
  - 0.5684164203712446
  - 0.5672398613719056
  - 0.5588048691481599
  - 0.5729430443295968
  train_level9__recall_weighted_masked:
  - 0.5036325094395564
  - 0.5012645062929815
  - 0.4988849519327364
  - 0.48848208233205065
  - 0.5062783134154514
  train_level9__recall_weighted_oob:
  - 0.568861060427541
  - 0.5666251968417154
  - 0.5638496440259078
  - 0.5561940882076948
  - 0.5701333661248952
  train_level9__roc_auc_macro:
  - 0.7214964807385352
  - 0.7229212188192917
  - 0.7276339459981568
  - 0.7217393504962153
  - 0.717889256176624
  train_level9__roc_auc_macro_masked:
  - 0.7033071557033129
  - 0.701492251572514
  - 0.7079752943778608
  - 0.6988897131125226
  - 0.6921027398483705
  train_level9__roc_auc_macro_oob:
  - 0.7154021729637396
  - 0.7165326208990068
  - 0.7210726616000488
  - 0.7149926258261574
  - 0.711674508131526
  train_level9__roc_auc_micro:
  - 0.668332709034778
  - 0.6704628832999922
  - 0.6795115898334669
  - 0.6618215050288028
  - 0.6693216959671862
  train_level9__roc_auc_micro_masked:
  - 0.6478852661939751
  - 0.6492807402194833
  - 0.658700182881571
  - 0.641981065011616
  - 0.646228696582375
  train_level9__roc_auc_micro_oob:
  - 0.6677003976394666
  - 0.6688393509821831
  - 0.677723379244496
  - 0.6607660739870169
  - 0.6677316799824562
  train_level9__roc_auc_samples:
  - 0.6522259274078509
  - 0.6527534379332683
  - 0.6659053124656794
  - 0.6456562610193953
  - 0.6508252156603607
  train_level9__roc_auc_samples_masked:
  - 0.6327672335920266
  - 0.6346693898391291
  - 0.6473632720720435
  - 0.6265279550892348
  - 0.631526141956835
  train_level9__roc_auc_samples_oob:
  - 0.6517974946467375
  - 0.6522307944296676
  - 0.6649374700388828
  - 0.6447129788158742
  - 0.6499323407099665
  train_level9__roc_auc_weighted:
  - 0.724599942800211
  - 0.7251843086438716
  - 0.7289512461830903
  - 0.727804867498868
  - 0.7232558730203155
  train_level9__roc_auc_weighted_masked:
  - 0.7000153291323554
  - 0.6993428064658898
  - 0.7034432992801357
  - 0.7050090902725892
  - 0.694692682354035
  train_level9__roc_auc_weighted_oob:
  - 0.717199354477874
  - 0.7176553264730807
  - 0.7209345557296764
  - 0.718845061484337
  - 0.715778822117817
  train_level9__tn_macro:
  - 0.2744060106357028
  - 0.26465481401775454
  - 0.2682639623185619
  - 0.24951456310679607
  - 0.27958316519097015
  train_level9__tn_macro_masked:
  - 0.3096555496913037
  - 0.29951950747074535
  - 0.30277964651015044
  - 0.2824015872310837
  - 0.31564506951489457
  train_level9__tn_macro_oob:
  - 0.2736741962238376
  - 0.2629429458805116
  - 0.26612515620494087
  - 0.24800970873786402
  - 0.27837254017613405
  train_level9__tn_micro:
  - 0.2744060106357028
  - 0.26465481401775454
  - 0.268263962318562
  - 0.24951456310679612
  - 0.27958316519097015
  train_level9__tn_micro_masked:
  - 0.3110465920088483
  - 0.3000443606521016
  - 0.3040281068714764
  - 0.2826039146690125
  - 0.31685991767775956
  train_level9__tn_micro_oob:
  - 0.27367419622383765
  - 0.2629429458805116
  - 0.26612515620494087
  - 0.24800970873786407
  - 0.27837254017613405
  train_level9__tn_samples:
  - 0.2744060106357027
  - 0.2646548140177544
  - 0.26826396231856187
  - 0.24951456310679604
  - 0.2795831651909701
  train_level9__tn_samples_masked:
  - 0.31167533502513767
  - 0.30094856060569086
  - 0.30469002389807437
  - 0.2833711647672682
  - 0.31806327601951057
  train_level9__tn_samples_oob:
  - 0.2736741962238376
  - 0.26294294588051154
  - 0.2661251562049408
  - 0.24800970873786402
  - 0.278372540176134
  train_level9__tn_weighted:
  - 0.25337113290461044
  - 0.24994837046155363
  - 0.24901259506790602
  - 0.23823089354603277
  - 0.2599233728633628
  train_level9__tn_weighted_masked:
  - 0.2989580506082486
  - 0.2952256425912079
  - 0.2936062695371005
  - 0.2810485836427191
  - 0.30650802150997847
  train_level9__tn_weighted_oob:
  - 0.2521220422018512
  - 0.2481812888254785
  - 0.24604987195505662
  - 0.23655718903138356
  - 0.2581571902523777
  train_level9__tp_macro:
  - 0.21442162267648923
  - 0.21459489863295095
  - 0.21443333653753724
  - 0.21548543689320387
  - 0.21259524770337318
  train_level9__tp_macro_masked:
  - 0.12737561327587119
  - 0.12798915636571748
  - 0.127501085497758
  - 0.1288294590347882
  - 0.12587436417983375
  train_level9__tp_macro_oob:
  - 0.21351905156852222
  - 0.21442371181922668
  - 0.2139767374795732
  - 0.2149514563106796
  - 0.21200180406864963
  train_level9__tp_micro:
  - 0.21442162267648923
  - 0.214594898632951
  - 0.21443333653753724
  - 0.21548543689320387
  - 0.21259524770337312
  train_level9__tp_micro_masked:
  - 0.11715747269459421
  - 0.1176389042918931
  - 0.11724814118800556
  - 0.11853969650318892
  - 0.11611202281348362
  train_level9__tp_micro_oob:
  - 0.21351905156852222
  - 0.21442371181922673
  - 0.2139767374795732
  - 0.2149514563106796
  - 0.21200180406864955
  train_level9__tp_samples:
  - 0.21442162267648918
  - 0.21459489863295095
  - 0.2144333365375372
  - 0.21548543689320382
  - 0.21259524770337307
  train_level9__tp_samples_masked:
  - 0.1174663498351206
  - 0.11801509037798233
  - 0.11770969273259839
  - 0.11887297383508531
  - 0.11645837842446863
  train_level9__tp_samples_oob:
  - 0.21351905156852216
  - 0.21442371181922668
  - 0.21397673747957316
  - 0.21495145631067955
  - 0.21200180406864952
  train_level9__tp_weighted:
  - 0.3180187021066409
  - 0.3184680499096909
  - 0.31822726630399967
  - 0.32057397560212697
  - 0.31301967146623405
  train_level9__tp_weighted_masked:
  - 0.2046744588313078
  - 0.2060388637017735
  - 0.20527868239563607
  - 0.20743349868933164
  - 0.19977029190547288
  train_level9__tp_weighted_oob:
  - 0.31673901822568984
  - 0.3184439080162369
  - 0.31779977207085114
  - 0.3196368991763111
  - 0.3119761758725176
start: 2023-12-31 06:26:12.446181
wrapper:
  call: positive_dropper.wrap_estimator
  name: drop50
  params:
    drop: 0.5
    random_state: 0
